{
  "hash": "b56ccaf0f304d846f9d5a5bffa974626",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Web scaping\"\nsubtitle: \"Lecture 10\"\ndate: \"2024-10-01\"\nformat: \n  live-revealjs: \n    output-file: 10-web-scraping-slides.html\n    webr:\n      cell-options:\n        autorun: false\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n<!-- begin: webr fodder -->\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell edit='false'}\n```{webr}\n#| edit: false\n#| echo: false\n#| output: false\noptions(width = 60)\n```\n:::\n\n\n\n\n<!-- end: webr fodder -->\n\n<!--# mello -->\n\n<!-- begin: ae definition -->\n\n\n\n\n\n\n\n\n\n<!-- end: ae definition -->\n\n# Warm-up\n\n## While you wait... {.smaller}\n\n::: appex\n-   If you haven't yet done so: Install a Chrome browser and the SelectorGadget extension:\n\n    -   [Chrome](https://www.google.com/chrome/)\n\n    -   [SelectorGadget](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en)\n\n-   Go to your `ae` project in RStudio.\n\n-   Make sure all of your changes up to this point are committed and pushed, i.e., there's nothing left in your Git pane.\n\n-   Click Pull to get today's application exercise file: *ae\\-10\\-chronicle\\-scrape\\.qmd*.\n\n-   Wait till the you're prompted to work on the application exercise during class before editing the file.\n:::\n\n## Announcements\n\nMidterm things:\n\n-   Practice midterm: Posted on the course website\n-   Lecture recordings: Available until the in-class midterm, link emailed earlier today\n-   Application exercise catch-up: Complete all application exercises up to the midterm by the in-class midterm (and get any missed points!)\n-   Midterm review: In class on Thursday, come with questions!\n\n# From last time\n\n## Age gaps\n\nData prep:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nage_gaps <- read_csv(\"data/age-gaps.csv\")\n\nage_gaps_heterosexual <- age_gaps |>\n  filter(character_1_gender != character_2_gender)\n```\n:::\n\n\n\n\n## Age gaps {.smaller}\n\nLabel the data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2,10|3|4,5|6,7|8\"}\nage_gaps_heterosexual <- age_gaps_heterosexual |>\n  mutate(\n    older = case_when(\n      character_1_gender == \"woman\" & actor_1_age > actor_2_age ~ \"woman older\",\n      character_2_gender == \"woman\" & actor_2_age > actor_1_age ~ \"woman older\",\n      character_1_gender == \"man\"   & actor_1_age > actor_2_age ~ \"man older\",\n      character_2_gender == \"man\"   & actor_2_age > actor_1_age ~ \"man older\",\n      actor_1_age == actor_2_age ~ \"same age\"\n    )\n  )\n```\n:::\n\n\n\n\n## Age gaps\n\nAge gaps split:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwoman_older <- age_gaps_heterosexual |> \n  filter(older == \"woman older\")\nman_older   <- age_gaps_heterosexual |> \n  filter(older == \"man older\")\nsame_age    <- age_gaps_heterosexual |>\n  filter(older == \"same age\")\n```\n:::\n\n\n\n\n. . .\n\nCheck:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(\n  nrow(woman_older) + nrow(man_older) + nrow(same_age)\n) == nrow(age_gaps_heterosexual)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\n## Age gaps\n\nWrite data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(woman_older, file = \"data/woman-older.csv\")\nwrite_csv(man_older, file = \"data/man-older.csv\")\nwrite_csv(same_age, file = \"data/same-age.csv\")\n```\n:::\n\n\n\n\n# Data on the web\n\n## Reading The Chronicle\n\n::: question\nHow often do you read The Chronicle?\n\n-   Every day\n\n-   3-5 times a week\n\n-   Once a week\n\n-   Rarely\n:::\n\n## Reading The Chronicle\n\n::: question\nWhat do you think is the most common word in the titles of The Chronicle opinion pieces?\n:::\n\n## Analyzing The Chronicle\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10-web-scraping_files/figure-revealjs/chronicle-common-words-1.png){width=960}\n:::\n:::\n\n\n\n\n## Reading The Chronicle\n\n::: question\nHow do you think the sentiments in opinion pieces in The Chronicle compare across authors?\nRoughly the same?\nWildly different?\nSomewhere in between?\n:::\n\n## Analyzing The Chronicle\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-web-scraping_files/figure-revealjs/chronicle-sentiments-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n## All of this analysis is done in R! {.centered}\n\n::: hand\n(mostly) with tools you already know!\n:::\n\n## Common words in The Chronicle titles {.smaller}\n\nCode for the earlier plot:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2-3|5|6|8|9|10-23\"}\nstop_words <- read_csv(\"data/stop-words.csv\")\nchronicle |>\n  tidytext::unnest_tokens(word, title) |>\n  mutate(word = str_replace_all(word, \"’\", \"'\")) |>\n  anti_join(stop_words) |>\n  count(word, sort = TRUE) |>\n  filter(word != \"duke's\") |>\n  slice_head(n = 20) |>\n  mutate(word = fct_reorder(word, n)) |>\n  ggplot(aes(y = word, x = n, fill = log(n))) +\n  geom_col(show.legend = FALSE) +\n  theme_minimal(base_size = 16) +\n  labs(\n    x = \"Number of mentions\",\n    y = \"Word\",\n    title = \"The Chronicle - Opinion pieces\",\n    subtitle = \"Common words in the 500 most recent opinion pieces\",\n    caption = \"Source: Data scraped from The Chronicle on Sep 30, 2024\"\n  ) +\n  theme(\n    plot.title.position = \"plot\",\n    plot.caption = element_text(color = \"gray30\")\n  )\n```\n:::\n\n\n\n\n## Avg sentiment scores of abstracts {.smaller}\n\nCode for the earlier plot:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2-3|5|6|7-8|9-13|22-52\"}\nafinn_sentiments <- read_csv(\"data/afinn-sentiments.csv\")\nchronicle |>\n  tidytext::unnest_tokens(word, abstract) |>\n  mutate(word = str_replace_all(word, \"’\", \"'\")) |>\n  anti_join(stop_words) |>\n  left_join(afinn_sentiments) |> \n  group_by(author, title) |>\n  summarize(total_sentiment = sum(value, na.rm = TRUE), .groups = \"drop\") |>\n  group_by(author) |>\n  summarize(\n    n_articles = n(),\n    avg_sentiment = mean(total_sentiment, na.rm = TRUE),\n  ) |>\n  filter(n_articles > 1 & !is.na(author)) |>\n  arrange(desc(avg_sentiment)) |>\n  slice(c(1:10, 40:49)) |>\n  mutate(\n    author = fct_reorder(author, avg_sentiment),\n    neg_pos = if_else(avg_sentiment < 0, \"neg\", \"pos\"),\n    label_position = if_else(neg_pos == \"neg\", 0.25, -0.25)\n  ) |>\n  ggplot(aes(y = author, x = avg_sentiment)) +\n  geom_col(aes(fill = neg_pos), show.legend = FALSE) +\n  geom_text(\n    aes(x = label_position, label = author, color = neg_pos),\n    hjust = c(rep(1,10), rep(0, 10)),\n    show.legend = FALSE,\n    fontface = \"bold\"\n  ) +\n  geom_text(\n    aes(label = round(avg_sentiment, 1)),\n    hjust = c(rep(1.25, 10), rep(-0.25, 10)),\n    color = \"white\",\n    fontface = \"bold\"\n  ) +\n  scale_fill_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  scale_color_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  coord_cartesian(xlim = c(-8, 8)) +\n  labs(\n    x = \"negative  ←     Average sentiment score (AFINN)     →  positive\",\n    y = NULL,\n    title = \"The Chronicle - Opinion pieces\\nAverage sentiment scores of abstracts by author\",\n    subtitle = \"Top 10 average positive and negative scores\",\n    caption = \"Source: Data scraped from The Chronicle on Sep 30, 2024\"\n  ) +\n  theme_void(base_size = 16) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5, margin = unit(c(0.5, 0, 1, 0), \"lines\")),\n    axis.title.x = element_text(color = \"gray30\", size = 12),\n    plot.caption = element_text(color = \"gray30\", size = 10)\n  )\n```\n:::\n\n\n\n\n## Where is the data coming from? {.smaller}\n\n::: center\n<https://www.dukechronicle.com/section/opinion>\n:::\n\n[![](images/10/chronicle-opinion-page.png){fig-align=\"center\" width=\"800\"}](https://www.dukechronicle.com/section/opinion?page=1&per_page=500)\n\n## Where is the data coming from? {.smaller}\n\n::::: columns\n::: {.column width=\"20%\"}\n[![](images/10/chronicle-opinion-page.png){fig-align=\"center\" width=\"800\"}](https://www.dukechronicle.com/section/opinion?page=1&per_page=500)\n:::\n\n::: {.column width=\"80%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchronicle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 × 6\n   title                       author date       abstract column url  \n   <chr>                       <chr>  <date>     <chr>    <chr>  <chr>\n 1 The Chronicle is accepting… Remem… 2024-09-30 If you … Opini… http…\n 2 Polls and prejudice         Cara … 2024-09-30 Sitting… Campu… http…\n 3 I hate Duke’s sodding grass Shamb… 2024-09-30 Duke’s … Campu… http…\n 4 We should reimagine our ve… Zubin… 2024-09-28 In addi… Campu… http…\n 5 Imagining the restorative … Nik N… 2024-09-28 With cr… Campu… http…\n 6 Community members share re… Remem… 2024-09-27 We welc… Opini… http…\n 7 Costs of college campus ec… Lisa … 2024-09-26 What ar… Campu… http…\n 8 Embracing polyhedronism     Aaron… 2024-09-26 But ins… Campu… http…\n 9 Comparison is the thief of… Angar… 2024-09-25 Why do … Campu… http…\n10 We only live once: Protect… Advik… 2024-09-25 I am no… Campu… http…\n# ℹ 490 more rows\n```\n\n\n:::\n:::\n\n\n\n:::\n:::::\n\n# Web scraping\n\n## Scraping the web: what? why? {.smaller}\n\n-   Increasing amount of data is available on the web\n\n-   These data are provided in an unstructured format: you can always copy&paste, but it's time-consuming and prone to errors\n\n-   Web scraping is the process of extracting this information automatically and transform it into a structured dataset\n\n-   Two different scenarios:\n\n    -   Screen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy).\n\n    -   Web APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files.\n\n## Hypertext Markup Language {.smaller}\n\nMost of the data on the web is still largely available as HTML - while it is structured (hierarchical) it often is not available in a form useful for analysis (flat / tidy).\n\n::: small\n``` html\n<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <p align=\"center\">Hello world!</p>\n    <br/>\n    <div class=\"name\" id=\"first\">John</div>\n    <div class=\"name\" id=\"last\">Doe</div>\n    <div class=\"contact\">\n      <div class=\"home\">555-555-1234</div>\n      <div class=\"home\">555-555-2345</div>\n      <div class=\"work\">555-555-9999</div>\n      <div class=\"fax\">555-555-8888</div>\n    </div>\n  </body>\n</html>\n```\n:::\n\n## rvest {.smaller}\n\n::::: columns\n::: {.column width=\"50%\"}\n-   The **rvest** package makes basic processing and manipulation of HTML data straight forward\n-   It's designed to work with pipelines built with `|>`\n-   [rvest.tidyverse.org](https://rvest.tidyverse.org)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\n```\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n[![](images/10/rvest.png){fig-alt=\"rvest hex logo\" fig-align=\"right\" width=\"400\"}](https://rvest.tidyverse.org/)\n:::\n:::::\n\n## rvest {.smaller}\n\nCore functions:\n\n-   `read_html()` - read HTML data from a url or character string.\n\n-   `html_elements()` - select specified elements from the HTML document using CSS selectors (or xpath).\n\n-   `html_element()` - select a single element from the HTML document using CSS selectors (or xpath).\n\n-   `html_table()` - parse an HTML table into a data frame.\n\n-   `html_text()` / `html_text2()` - extract tag's text content.\n\n-   `html_name` - extract a tag/element's name(s).\n\n-   `html_attrs` - extract all attributes.\n\n-   `html_attr` - extract attribute value(s) by name.\n\n## html, rvest, & xml2 {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhtml <- \n'<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <p align=\"center\">Hello world!</p>\n    <br/>\n    <div class=\"name\" id=\"first\">John</div>\n    <div class=\"name\" id=\"last\">Doe</div>\n    <div class=\"contact\">\n      <div class=\"home\">555-555-1234</div>\n      <div class=\"home\">555-555-2345</div>\n      <div class=\"work\">555-555-9999</div>\n      <div class=\"fax\">555-555-8888</div>\n    </div>\n  </body>\n</html>'\n```\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{html_document}\n<html>\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; cha ...\n[2] <body>\\n    <p align=\"center\">Hello world!</p>\\n    <br><div cl ...\n```\n\n\n:::\n:::\n\n\n\n\n## Selecting elements {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (1)}\n[1] <p align=\"center\">Hello world!</p>\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\") |> html_text()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello world!\"\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\") |> html_name()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"p\"\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\") |> html_attrs()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n   align \n\"center\" \n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\") |> html_attr(\"align\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"center\"\n```\n\n\n:::\n:::\n\n\n\n\n## More selecting tags {.smaller}\n\n::: medium\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"div\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (7)}\n[1] <div class=\"name\" id=\"first\">John</div>\n[2] <div class=\"name\" id=\"last\">Doe</div>\n[3] <div class=\"contact\">\\n      <div class=\"home\">555-555-1234</di ...\n[4] <div class=\"home\">555-555-1234</div>\n[5] <div class=\"home\">555-555-2345</div>\n[6] <div class=\"work\">555-555-9999</div>\n[7] <div class=\"fax\">555-555-8888</div>\n```\n\n\n:::\n:::\n\n\n\n:::\n\n. . .\n\n::: medium\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"div\") |> html_text()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"John\"                                                                                  \n[2] \"Doe\"                                                                                   \n[3] \"\\n      555-555-1234\\n      555-555-2345\\n      555-555-9999\\n      555-555-8888\\n    \"\n[4] \"555-555-1234\"                                                                          \n[5] \"555-555-2345\"                                                                          \n[6] \"555-555-9999\"                                                                          \n[7] \"555-555-8888\"                                                                          \n```\n\n\n:::\n:::\n\n\n\n:::\n\n## CSS selectors {.smaller}\n\n-   We will use a tool called SelectorGadget to help us identify the HTML elements of interest by constructing a CSS selector which can be used to subset the HTML document.\n\n. . .\n\n-   Some examples of basic selector syntax is below,\n\n::: small\n| Selector | Example | Description |\n|:-----------------|:-----------------|:-----------------------------------|\n| .class | `.title` | Select all elements with class=\"title\" |\n| #id | `#name` | Select all elements with id=\"name\" |\n| element | `p` | Select all \\<p\\> elements |\n| element element | `div p` | Select all \\<p\\> elements inside a \\<div\\> element |\n| element\\>element | `div > p` | Select all \\<p\\> elements with \\<div\\> as a parent |\n| \\[attribute\\] | `[class]` | Select all elements with a class attribute |\n| \\[attribute=value\\] | `[class=title]` | Select all elements with class=\"title\" |\n:::\n\n## CSS classes and ids\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\".name\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (2)}\n[1] <div class=\"name\" id=\"first\">John</div>\n[2] <div class=\"name\" id=\"last\">Doe</div>\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"div.name\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (2)}\n[1] <div class=\"name\" id=\"first\">John</div>\n[2] <div class=\"name\" id=\"last\">Doe</div>\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"#first\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (1)}\n[1] <div class=\"name\" id=\"first\">John</div>\n```\n\n\n:::\n:::\n\n\n\n\n## Text with `html_text()` vs. `html_text2()` {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhtml = read_html(\n  \"<p>  \n    This is the first sentence in the paragraph.\n    This is the second sentence that should be on the same line as the first sentence.<br>This third sentence should start on a new line.\n  </p>\"\n)\n```\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhtml |> html_text()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"  \\n    This is the first sentence in the paragraph.\\n    This is the second sentence that should be on the same line as the first sentence.This third sentence should start on a new line.\\n  \"\n```\n\n\n:::\n\n```{.r .cell-code}\nhtml |> html_text2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"This is the first sentence in the paragraph. This is the second sentence that should be on the same line as the first sentence.\\nThis third sentence should start on a new line.\"\n```\n\n\n:::\n:::\n\n\n\n\n## HTML tables with `html_table()` {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhtml_table = \n'<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <table>\n      <tr> <th>a</th> <th>b</th> <th>c</th> </tr>\n      <tr> <td>1</td> <td>2</td> <td>3</td> </tr>\n      <tr> <td>2</td> <td>3</td> <td>4</td> </tr>\n      <tr> <td>3</td> <td>4</td> <td>5</td> </tr>\n    </table>\n  </body>\n</html>'\n```\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html_table) |>\n  html_elements(\"table\") |> \n  html_table()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n# A tibble: 3 × 3\n      a     b     c\n  <int> <int> <int>\n1     1     2     3\n2     2     3     4\n3     3     4     5\n```\n\n\n:::\n:::\n\n\n\n\n## SelectorGadget\n\n**SelectorGadget** ([selectorgadget.com](http://selectorgadget.com)) is a javascript based tool that helps you interactively build an appropriate CSS selector for the content you are interested in.\n\n![](images/10/selectorgadget.png){fig-align=\"center\" width=\"1000\"}\n\n# Application exercise\n\n## Opinion articles in The Chronicle\n\nGo to <https://www.dukechronicle.com/section/opinion?page=1&per_page=500>.\n\n::: question\nHow many articles are on the page?\n:::\n\n## Goal\n\n::::: columns\n::: {.column width=\"50%\"}\n-   Scrape data and organize it in a tidy format in R\n-   Perform light text parsing to clean data\n-   Summarize and visualze the data\n:::\n\n::: {.column width=\"50%\"}\n![](images/10/chronicle-data.png){fig-align=\"center\"}\n:::\n:::::\n\n## ae\\-10\\-chronicle\\-scrape {.smaller}\n\n::: appex\n-   Go to your ae project in RStudio.\n\n-   If you haven't yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there's nothing left in your Git pane.\n\n-   If you haven't yet done so, click Pull to get today's application exercise file: *ae\\-10\\-chronicle\\-scrape\\.qmd* and *`chronicle-scrape.R`*.\n:::\n\n## Recap\n\n-   Use the SelectorGadget identify tags for elements you want to grab\n-   Use rvest to first read the whole page (into R) and then parse the object you've read in to the elements you're interested in\n-   Put the components together in a data frame (a tibble) and analyze it like you analyze any other data\n\n## A new R workflow {.smaller}\n\n-   When working in a Quarto document, your analysis is re-run each time you knit\n\n-   If web scraping in a Quarto document, you'd be re-scraping the data each time you knit, which is undesirable (and not *nice*)!\n\n-   An alternative workflow:\n\n    -   Use an R script to save your code\n    -   Saving interim data scraped using the code in the script as CSV or RDS files\n    -   Use the saved data in your analysis in your Quarto document\n\n# Web scraping considerations\n\n## Ethics: \"Can you?\" vs \"Should you?\"\n\n![](images/10/ok-cupid-1.png){fig-align=\"center\" width=\"800\"}\n\n::: aside\nSource: Brian Resnick, [Researchers just released profile data on 70,000 OkCupid users without permission](https://www.vox.com/2016/5/12/11666116/70000-okcupid-users-data-release), Vox.\n:::\n\n## \"Can you?\" vs \"Should you?\"\n\n![](images/10/ok-cupid-2.png){fig-align=\"center\" width=\"699\"}\n\n## Challenges: Unreliable formatting\n\n![](images/10/unreliable-formatting.png){fig-align=\"center\" width=\"699\"}\n\n::: aside\n[alumni.duke.edu/news/notable-alumni](https://alumni.duke.edu/news/notable-alumni)\n:::\n\n## Challenges: Data broken into many pages\n\n![](images/10/many-pages.png){fig-align=\"center\"}\n\n## Workflow: Screen scraping vs. APIs\n\nTwo different scenarios for web scraping:\n\n-   Screen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\n\n-   Web APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files\n",
    "supporting": [
      "10-web-scraping_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}