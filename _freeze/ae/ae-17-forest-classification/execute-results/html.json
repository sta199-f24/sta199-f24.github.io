{
  "hash": "32fa3f1799cdc65e60434e91b3cfdb49",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"AE 17: Forest classification\"\n---\n\n\n\nIn this application exercise, we will\n\n-   Split our data into testing and training\n-   Fit logistic regression regression models to testing data to classify outcomes\n-   Evaluate performance of models on testing data\n\nWe will use **tidyverse** and **tidymodels** for data exploration and modeling, respectively, and the **forested** package for the data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)\n```\n:::\n\n\n\nRemember from the lecture that the `forested` dataset contains information on whether a plot is forested (`Yes`) or not (`No`) as well as numerical and categorical features of that plot.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(forested)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 7,107\nColumns: 19\n$ forested         <fct> Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             <dbl> 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005,…\n$ elevation        <dbl> 881, 113, 164, 299, 806, 736, 636, 224, 52, 2240, 104…\n$ eastness         <dbl> 90, -25, -84, 93, 47, -27, -48, -65, -62, -67, 96, -4…\n$ northness        <dbl> 43, 96, 53, 34, -88, -96, 87, -75, 78, -74, -26, 86, …\n$ roughness        <dbl> 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 190, 95, 212…\n$ tree_no_tree     <fct> Tree, Tree, Tree, No tree, Tree, Tree, No tree, Tree,…\n$ dew_temp         <dbl> 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6.39, 6.50,…\n$ precip_annual    <dbl> 466, 1710, 1297, 2545, 609, 539, 702, 1195, 1312, 103…\n$ temp_annual_mean <dbl> 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61, 10.45, 10…\n$ temp_annual_min  <dbl> -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.76, 1.11, …\n$ temp_annual_max  <dbl> 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 14.23, 15.3…\n$ temp_january_min <dbl> -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, 5.54, 6.20…\n$ vapor_min        <dbl> 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 172, 162, 70…\n$ vapor_max        <dbl> 1194, 938, 754, 1164, 1254, 1331, 1275, 944, 892, 549…\n$ canopy_cover     <dbl> 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74, 66, 83, 6…\n$ lon              <dbl> -118.6865, -123.0825, -122.3468, -121.9144, -117.8841…\n$ lat              <dbl> 48.69537, 47.07991, 48.77132, 45.80776, 48.07396, 48.…\n$ land_type        <fct> Tree, Tree, Tree, Tree, Tree, Tree, Non-tree vegetati…\n```\n\n\n:::\n:::\n\n\n\n# Spending your data\n\nSplit your data into testing and training in a reproducible manner and display the split object.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\nWhat percent of the original `forested` data is allocated to training and what percent to testing?\nCompare your response to your neighbor's.\nAre the percentages roughly consistent?\nWhat determines this in the `initial_split()`?\nHow would the code need to be updated to allocate 80% of the data to training and the remaining 20% to testing?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\nAdd response here.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\nLet's stick with the default split and save our testing and training data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n# Exploratory data analysis\n\nCreate a visualization that explores the relationship between the outcome, one numerical predictor, and one categorical predictor.\nThen, describe, in a few sentences, what the visualization shows about the relationship between these variables.\n\n**Note:** Pay attention to which dataset you use for your exploration.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\nAdd response here.\n\n# Model 1: Custom choice of predictors\n\n## Fit\n\nFit a model for classifying plots as forested or not based on a subset of predictors of your choice.\nName the model `forested_custom_fit` and display a tidy output of the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n## Predict\n\nPredict for the testing data using this model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n## Evaluate\n\nCalculate the false positive and false negative rates for the testing data using this model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\nAnother commonly used display of this information is a confusion matrix.\nCreate this using the `conf_mat()` function.\nYou will need to review the documentation for the function to determine how to use it.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n## Sensitivity, specificity, ROC curve\n\nCalculate sensitivity and specificity and draw the ROC curve.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n# Model 2: All predictors\n\n## Fit\n\nFit a model for classifying plots as forested or not based on all predictors available.\nName the model `forested_full_fit` and display a tidy output of the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n## Predict\n\nPredict for the testing data using this model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n## Evaluate\n\nCalculate the false positive and false negative rates for the testing data using this model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n## Sensitivity, specificity, ROC curve\n\nCalculate sensitivity and specificity and draw the ROC curve.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n# Model 1 vs. Model 2\n\nPlot both ROC curves and articulate how you would use them to compare these models.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\nAdd response here.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}