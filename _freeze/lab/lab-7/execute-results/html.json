{
  "hash": "f5696a06673a7ab08bafa1c8513ea28f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Lab 7\nsubtitle: Explore and classify\ncategories: Lab\ndescription: \"Mon, Nov 18 at 8:30 am\"\n---\n\n\n\n\n\n\n\n\n\n# Introduction\n\nIn this lab you'll start your practice of statistical modeling.\nYou'll fit models for classification, interpret model output, and make decisions about your data and research question based on the model results.\nAnd you'll wrap up the lab sharing a statistics and/or data science experience.\n\n::: callout-note\nThis lab assumes you've completed the labs so far and doesn't repeat setup and overview content from those labs.\nIf you haven't done those yet, you should review the previous labs before starting on this one.\n:::\n\n## Learning objectives\n\nBy the end of the lab, you will...\n\n-   Fit and interpret logistic regression models\n\n-   Understand the difference between odds, log odds, and probability of an event\n\n-   Make classification based on predicted probability of an event\n\n-   See statistics and/or data science in action in the real world\n\nAnd, as usual, you will also...\n\n-   Get more experience with data science workflow using R, RStudio, Git, and GitHub\n-   Further your reproducible authoring skills with Quarto\n-   Improve your familiarity with version control using Git and GitHub\n\n## Getting started\n\nLog in to RStudio, clone your `lab-7` repo from GitHub, open your `lab-7.qmd` document, and get started!\n\n::: {.callout-tip collapse=\"true\"}\n## Click here if you prefer to see step-by-step instructions\n\n### Step 1: Log in to RStudio\n\n-   Go to <https://cmgr.oit.duke.edu/containers> and log in with your Duke NetID and Password.\n-   Click `STA198-199` under My reservations to log into your container. You should now see the RStudio environment.\n\n### Step 2: Clone the repo & start a new RStudio project\n\n-   Go to the course organization at [github.com/sta199-f24](https://github.com/sta199-f24) organization on GitHub.\n    Click on the repo with the prefix **lab-7**.\n    It contains the starter documents you need to complete the lab.\n\n-   Click on the green **CODE** button and select **Use SSH**. This might already be selected by default; if it is, you'll see the text **Clone with SSH**.\n    Click on the clipboard icon to copy the repo URL.\n\n-   In RStudio, go to *File* ➛ *New Project* ➛*Version Control* ➛ *Git*.\n\n-   Copy and paste the URL of your assignment repo into the dialog box *Repository URL*. Again, please make sure to have *SSH* highlighted under *Clone* when you copy the address.\n\n-   Click *Create Project*, and the files from your GitHub repo will be displayed in the *Files* pane in RStudio.\n\n-   Click *lab-7.qmd* to open the template Quarto file.\n    This is where you will write up your code and narrative for the lab.\n\n### Step 3: Update the YAML\n\nIn `lab-7.qmd`, update the `author` field to your name, render your document and examine the changes.\nThen, in the Git pane, click on **Diff** to view your changes, add a commit message (e.g., \"Added author name\"), and click **Commit**.\nThen, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n:::\n\n::: callout-important\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n:::\n\n## Packages\n\nIn this lab, we will work with the\n\n-   **tidyverse** package for doing data analysis in a \"tidy\" way,\n-   **tidymodels** package for modeling in a \"tidy\" way, and\n-   **openintro** package for the dataset for Part 1. **TO DO:** Check.\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n```\n:::\n\n\n\n\n\n\n\n\n\n-   **Run** the code cell by clicking on the green triangle (play) button for the code cell labeled `load-packages`. This loads the package so that its features (the functions and datasets in it) are accessible from your *Console*.\n-   Then, **render** the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\n## Guidelines\n\n\nAs we've discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\n\nAdditionally, code should follow the [tidyverse style](https://style.tidyverse.org/).\nParticularly,\n\n-   there should be spaces before and line breaks after each `+` when building a `ggplot`,\n\n-   there should also be spaces before and line breaks after each `|>` in a data transformation pipeline,\n\n-   code should be properly indented,\n\n-   there should be spaces around `=` signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF.\nLong lines that run off the page should be split across multiple lines with line breaks.\n\n::: callout-important\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course.\nThere will be periodic reminders in this assignment to remind you to **render, commit, and push** your changes to GitHub.\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.\n:::\n\n\n\n::: callout-important\nYou are also expected to pay attention to [code smell](https://en.wikipedia.org/wiki/Code_smell) in addition to code style and readability.\nYou should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., `!` to say \"not\" in one place and `-` in another place), etc.\n:::\n\n# Part 1 - Building a spam filter\n\nThe data come from incoming emails in David Diez's (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012.\nAll personally identifiable information has been removed.\nThe dataset is called `email` and it's in the **openintro** package.\n\nThe outcome variable is `spam`, which takes the value `1` if the email is spam, `0` otherwise.\n\n## Question 1\n\na.  What type of variable is `spam`?\n    What percent of the emails are spam?\n\nb.  What type of variable is `dollar` - number of times a dollar sign or the word “dollar” appeared in the email?\n    Visualize and describe its distribution, supporting your description with the appropriate summary statistics.\n\nc.  Fit a logistic regression model predicting `spam` from `dollar`.\n    Then, display the tidy output of the model.\n\nd.  Using this model and the `predict()` function, predict the probability the email is spam if it contains 5 dollar signs.\n    Based on this probability, how does the model classify this email?\n\n    ::: callout-note\n    To obtain the predicted probability, you can set the `type` argument in `predict()` to `\"prob\"`.\n    :::\n\n## Question 2\n\na.  Fit another logistic regression model predicting `spam` from `dollar`, `winner` (indicating whether “winner” appeared in the email), and `urgent_subj` (whether the word \"urgent\" is in the subject of the email).\n    Then, display the tidy output of the model.\n\nb.  Using this model and the `augment()` function, classify each email in the `email` dataset as spam or not spam.\n    Store the resulting data frame with an appropriate name and display the data frame as well.\n\nc.  Using your data frame from the previous part, determine, in a single pipeline, and using `count()`, the numbers of emails:\n\n    -   that are labelled as spam that are actually spam\n    -   that are not labelled as spam that are actually spam\n    -   that are labelled as spam that are actually not spam\n    -   that are not labelled as spam that are actually not spam\n\n    Store the resulting data frame with an appropriate name and display the data frame as well.\n\nd.  In a single pipeline, and using `mutate()`, calculate the false positive and false negative rates.\n    In addition to these numbers showing in your R output, you must write a sentence that explicitly states and identified the two rates.\n\n## Question 3\n\na.  Fit another logistic regression model predicting `spam` from `dollar` and another variable you think would be a good predictor.\n    Provide a 1-sentence justification for why you chose this variable.\n    Display the tidy output of the model.\n\nb.  Using this model and the `augment()` function, classify each email in the `email` dataset as spam or not spam.\n    Store the resulting data frame with an appropriate name and display the data frame as well.\n\nc.  Using your data frame from the previous part, determine, in a single pipeline, and using `count()`, the numbers of emails:\n\n    -   that are labelled as spam that are actually spam\n    -   that are not labelled as spam that are actually spam\n    -   that are labelled as spam that are actually not spam\n    -   that are not labelled as spam that are actually not spam\n\n    Store the resulting data frame with an appropriate name and display the data frame as well.\n\nd.  In a single pipeline, and using `mutate()`, calculate the false positive and false negative rates.\n    In addition to these numbers showing in your R output, you must write a sentence that explicitly states and identified the two rates.\n\ne.  Based on the false positive and false negatives rates of this model, comment, in 1-2 sentences, on which model (one from Question 2 or Question 3) is preferable and why.\n\n# Part 2 - Hotel cancellations\n\nFor this exercise, we will work with hotel cancellations.\nThe data describe the demand of two different types of hotels.\nEach observation represents a hotel booking between July 1, 2015 and August 31, 2017.\nSome bookings were cancelled (`is_canceled = 1`) and others were kept, i.e., the guests checked into the hotel (`is_canceled = 0`).\nYou can view the code book for all variables [here](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md).\n\n## Question 4\n\nThe dataset, called `hotels.csv`, can be found in the `data` folder.\n\na.  Read it in with `read_csv()`.\n\nb.  Transform the `is_canceled` variable to be a factor with \"not canceled\" (0) as the first level and \"canceled\" (1) as the second level.\n\nc.  Explore attributes of bookings and summarize your findings in 5 bullet points.\n    You must provide a visualization or summary supporting each finding.\n\n::: callout-note\nThis is not meant to be an exhaustive exploration.\nWe anticipate a wide variety of answers to this question.\n:::\n\n## Question 5\n\nUsing these data, one of our goals is to explore the following question:\n\n> *Are reservations earlier in the month or later in the month more likely to be cancelled?*\n\na.  **I**n a single pipeline, calculate the mean arrival dates (`arrival_date_day_of_month`) for reservations that were cancelled and reservations that were not cancelled.\n\nb.  In your own words, explain why we can not use a linear model to model the relationship between if a hotel reservation was cancelled and the day of month for the booking.\n\nc.  Fit the appropriate model to predict whether a reservation was cancelled from `arrival_date_day_of_month` and display a tidy summary of the model output.\n    Then, interpret the slope coefficient in context of the data and the research question.\n\nd.  Calculate the probability that the hotel reservation is cancelled if it the arrival date date is on the 26th of the month.\n    Based on this probability, would you predict this booking would be cancelled or not cancelled.\n    Explain your reasoning for your classification.\n\n## Question 6\n\na.  Fit another model to predict whether a reservation was cancelled from `arrival_date_day_of_month` and `hotel` type (Resort or City Hotel), allowing the relationship between `arrival_date_day_of_month` and `is_canceled` to vary based on `hotel` type.\n    Display a tidy output of the model.\n\nb.  Interpret the intercept in context of the data.\n\n# Part 3 - General Social Survey\n\nThe General Social Survey (GSS) gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviours, and attributes.\nHundreds of trends have been tracked since 1972.\nIn addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.\n\nThe GSS contains a standard core of demographic, behavioural, and attitudinal questions, plus topics of special interest.\nAmong the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.[^1]\n\n[^1]: Smith, Tom W, Peter Marsden, Michael Hout, and Jibum Kim.\n    General Social Surveys, 1972-2016 \\[machine-readable data file\\] /Principal Investigator, Tom W. Smith; Co-Principal Investigator, Peter V. Marsden; Co-Principal Investigator, Michael Hout; Sponsored by National Science Foundation.\n    -NORC ed.- Chicago: NORC at the University of Chicago \\[producer and distributor\\].\n    Data come from the **gssr** R Package, <http://kjhealy.github.io/gssr>.\n\nIn this part you will work with three variables from the 2022 General Social Survey:\n\n-   `advfront`: Do you strongly agree, agree, disagree, or strongly disagree?\n    with the following statement: *\"Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\"*\n\n-   `educ`: Number of years of education.\n\n-   `polviews`: We hear a lot of talk these days about liberals and conservatives.\n    I'm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal--point 1--to extremely conservative--point 7.\n    Where would you place yourself on this scale?\n\n## Question 7\n\na.  Read in the `gss22.csv` file that is in your `data` folder and save it as `gss22`.\n    Report its number of rows and columns.\n\nb.  Create a new data frame called `gss22_advfront` that only contains the variables `advfront`, `educ`, and `polviews`.\n    Then, use the `drop_na()` function to remove rows that contain `NA`s from this new data frame.\n    Report the number of rows and columns of `gss22_advfront`.\n    Additionally, report what percent of the observations were discarded at this step.\n\nc.  Re-level the `advfront` variable such that it has two levels: `\"Strongly agree\"` and `\"Agree\"` combined into a new level called `Agree` and the remaining levels combined into\"`Not agree\"`.\n    Then, re-order the levels in the following order: `\"Agree\"` and `\"Not agree\"`.\n    Finally, `count()` how many times each new level appears in the `advfront` variable.\n\n::: callout-tip\nYou can do this in various ways.\nOne option is to use the `str_detect()` function to detect the existence of words.\nNote that these sometimes show up with lowercase first letters and sometimes with upper case first letters.\nTo detect either in the `str_detect()` function, you can use \"\\[Aa\\]gree\".\nHowever, solve the problem however you like, this is just one option!\n:::\n\nd.  Combine the levels of the `polviews` variable such that levels that have the word \"liberal\" in them are lumped into a level called `\"Liberal\"` and those that have the word conservative in them are lumped into a level called `\"Conservative\"`. Then, re-order the levels in the following order: `\"Conservative\"` , `\"Moderate\"`, and `\"Liberal\"`. Finally, `count()` how many times each new level appears in the `polviews` variable.\n\n## Question 8\n\na.  Fit a logistic regression model that predicts `advfront` from `educ`.\n    Report the tidy output of the model.\n\nb.  Write out the estimated model in proper notation.\n\nc.  Using your estimated model, predict the probability of agreeing with the statement *\"Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\"* (`Agree` in `advfront`) for someone with 7 years of education.\n\n## Question 9\n\na.  Fit a new model that adds the additional explanatory variable of `polviews` to your model from Question 8.\n    Report the tidy output of the model.\n\nb.  Now, predict the probability of agreeing with the following statement *\"Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\"* (`Agree` in `advfront`) for a Conservative person with 7 years of education.\n\n# Part 4 - Statistics and/or data science experience\n\n## Question 10\n\n::: callout-warning\nStart this question early, it's not one you want to try to cram into the last night before the deadline!\n:::\n\nYou have two options for this exercise.\nClearly indicate which option you choose.\nThen, summarize your experience in no more than 10 bullet points.\n\nInclude the following on your summary:\n\n-   Name and brief description of what you did.\n-   Something you found new, interesting, or unexpected\n-   How the talk/podcast/interview/etc. connects to something we’ve done in class.\n-   Citation or link to web page for what you watched or who you interviewed.\n\n**Option 1:** Listen to a podcast or watch a video about statistics and data science.\nThe podcast or video must be *at least 30 minutes* to count towards the statistics experience.\nA few suggestions are below:\n\n-   [posit::conf 2024 talks](https://www.youtube.com/playlist?list=PL9HYL-VRX0oSFkdF4fJeY63eGDvgofcbn)\n-   [useR 2024 talks](https://www.youtube.com/playlist?list=PL77T87Q0eoJjrpUmYVYLgi9fVFSKkbooc) or [user 2024 keynotes](https://www.youtube.com/playlist?list=PL77T87Q0eoJj734NXspCSNCEjrnX1y2z0)\n-   [posit::conf 2023 talks](https://youtube.com/playlist?list=PL9HYL-VRX0oRFZslRGHwHuwea7SvAATHp&si=95wk_4q3-mex9hhT)\n-   [rstudio::conf 2022 talks](https://www.youtube.com/watch?v=u1Gzxg8Pd08&list=PL9HYL-VRX0oTOwqzVtL_q5T8MNrzn0mdH)\n-   [Harvard Data Science Review Podcast](https://hdsr.mitpress.mit.edu/podcast)\n-   [Stats + Stories Podcast](https://statsandstories.net/)\n-   [Casual Inference Podcast](https://casualinfer.libsyn.com/)\n-   [Not So Standard Deviations](https://nssdeviations.com/)\n\nThis list is not exhaustive.\nYou may listen to other podcasts or watch other statistics/data science videos not included on this list.\nAsk your professor if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n**Option 2:** Talk with someone who uses statistics and/or data science in their daily work.\nThis could include a professor, professional in industry, graduate student, etc.\n",
    "supporting": [
      "lab-7_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}