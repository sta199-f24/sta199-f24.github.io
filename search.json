[
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#while-you-wait",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#while-you-wait",
    "title": "Linear regression with a multiple predictors I",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-14-modeling-penguins-multi.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#announcements",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#announcements",
    "title": "Linear regression with a multiple predictors I",
    "section": "Announcements",
    "text": "Announcements\n\nProject repos closed (you won’t see them on GitHub) until proposal grading is done. You’ll get access back to them on Monday. In the meantime, if you want to work on your project, you can make local commits on RStudio and you’ll be able to push them when you regain access.\nPeer evaluations (via TEAMMATES) are due by Friday, 5 pm."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#goals",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#goals",
    "title": "Linear regression with a multiple predictors I",
    "section": "Goals",
    "text": "Goals\n\nRecap modeling with a single predictor\nFit and interpret models with a categorical predictor\nFit and interpret models with multiple predictors\nDistinguish between additive and interaction models"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#honorable-mention-1-austin-liu",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#honorable-mention-1-austin-liu",
    "title": "Linear regression with a multiple predictors I",
    "section": "Honorable mention 1: Austin Liu",
    "text": "Honorable mention 1: Austin Liu\n\nCodemtcars |&gt;\n  mutate(\n    am = case_when(\n      am == 0 ~ \"Automatic\",\n      am == 1 ~ \"Manual\"\n    ),\n    vs = case_when(\n      vs == 0 ~ \"V-shaped\",\n      vs == 1 ~ \"Straight\"\n    ),\n    am = fct_relevel(am, c(\"Manual\", \"Automatic\")),\n    vs = fct_relevel(vs)\n  ) |&gt;\n  ggplot(aes(x = wt, y = mpg, color = am, shape = vs)) +\n  geom_point() +\n  labs(\n    title = \"ggplot2 \n    plot \n    of \n    car \n    weight \n    in \n    thousands \n    of pounds versus \n    fuel \n    efficiency in miles per \n    gallon from thirty-two \n    automobiles in\n    the nineteen-seventy-four \n    Motor Trend United \n    States magazine \n    issue\",\n    subtitle = \"of cars\",\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\",\n    color = \"Transmission\",\n    shape = \"Engine configuration\"\n  ) +\n  theme(\n    legend.position = \"right\",\n    plot.background = element_rect(fill = \"green\"),\n    legend.background = element_rect(fill = \"yellow\"),\n    panel.background = element_rect(fill = \"red\"),\n    text = element_text(size = 1, family = \"AvantGarde\"),\n    aspect.ratio = 0.1,\n    panel.grid.major = element_blank(), \n    panel.grid.minor = element_blank()\n  ) +\n  scale_color_manual(\n    values = c(\"Manual\" = \"red1\", \"Automatic\" = \"red2\")\n  ) +\n  scale_shape_manual(\n    values = c(\"V-shaped\" = 19, \"Straight\" = 20)\n  )"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#honorable-mention-2-clarke-campbell",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#honorable-mention-2-clarke-campbell",
    "title": "Linear regression with a multiple predictors I",
    "section": "Honorable mention 2: Clarke Campbell",
    "text": "Honorable mention 2: Clarke Campbell\n\nCodemtcars |&gt;\n  mutate(trans_type = case_when(\n    am == 0 ~ \"Automatic\",\n    am == 1 ~ \"Manual\"\n    )\n  ) |&gt;\n  mutate(engine_type = case_when(\n    am == 0 ~ \"V-shaped\",\n    am == 1 ~ \"Straight\"\n    )\n  ) |&gt;\nggplot(aes(x = wt, y = mpg, color = trans_type, shape = engine_type)) +\n  geom_point(size = 0.1) +\n  labs(\n    x = \"Weight (in 1000s of lbs)\",\n    y = \"Miles / gallon\",\n    title = \"Weight vs. miles per gallon of 32 cars\",\n    subtitle = \"from the 1974 Motor Trend US magazine\",\n    color = \"Transmission Type:\",\n    shape = \"Engine Type\"\n  ) +\n  guides(\n    color = guide_legend(position = \"top\"),\n    shape = guide_legend(position = \"right\")\n  ) +\n  scale_color_manual(\n    values = c(\n      \"Manual\" = \"grey\",\n      \"Automatic\" = \"darkgrey\"\n    ),\n    breaks = c(\n      \"Manual\", \"Automatic\"\n      )\n  ) +\n  theme(\n    text = element_text(\n      size = 20, \n      family = \"URWBookman\", \n      face = \"italic\"),\n    panel.background = element_rect(colour = 'yellow'),\n    plot.background = element_rect(fill = \"#473417\"))"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#honorable-mention-3-charlie-pausic",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#honorable-mention-3-charlie-pausic",
    "title": "Linear regression with a multiple predictors I",
    "section": "Honorable mention 3: Charlie Pausic",
    "text": "Honorable mention 3: Charlie Pausic\n\nCodeggplot(mtcars, \n       aes(x = wt, y = mpg, \n           color = factor(am), shape = factor(vs)\n           )\n       ) +\n  geom_point(size = 15, alpha = 0.1) + \n\n  labs(\n    title = \"carssssss\",\n    x = \"variable\",\n    y = \"other variable\",\n    color = \"Transmission\",\n    shape = \"Engine Type\"\n  )+\n  theme_void() +\n  theme(legend.title = element_text(size = 1),\n        plot.background = element_rect(fill = \"black\")\n        ) +\n  scale_color_manual(\n    values = c(\"blue\", \"blue\"),\n    labels = c(\"Automatic\", \"Manual\")\n  ) +\n  scale_shape_manual(\n    values = c(\"circle\", \"triangle\"),\n    labels = c(\"Straight\", \"V-shaped\")\n  )"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#honorable-mention-4-natalie-veale",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#honorable-mention-4-natalie-veale",
    "title": "Linear regression with a multiple predictors I",
    "section": "Honorable mention 4: Natalie Veale",
    "text": "Honorable mention 4: Natalie Veale\n\nCodemtcars |&gt;\n  mutate(am = case_when(\n           am == \"0\" ~ \"automatic\",\n           am == \"1\" ~ \"manual\"),\n         am = factor(am, levels = c(\"manual\", \"automatic\")),\n         vs = case_when(\n           vs == \"0\" ~ \"v-shaped\",\n           vs == \"1\" ~ \"straight\")\n  ) |&gt;\nggplot(aes(x = wt, y = mpg, color = am, shape = vs)) +\n  geom_point(size = 20) +\n  labs(\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\",\n    title = \"MPG for Vehicles of Different Weights\",\n    color = \"Transmission\",\n    shape = \"Engine Type\"\n  ) +\n  scale_y_continuous(breaks = seq(0, 50, by = 1)) +\n  scale_color_manual(values = c(\n    \"automatic\" = \"darkgoldenrod\",\n    \"manual\" = \"burlywood2\"\n    )\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    plot.background = element_rect(fill = \"darkgoldenrod4\"),\n    legend.text = element_text(size = 1)\n  )"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#winner-neha-shukla",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#winner-neha-shukla",
    "title": "Linear regression with a multiple predictors I",
    "section": "Winner: Neha Shukla",
    "text": "Winner: Neha Shukla\n\nCodelibrary(ggimage)\nmtcars_new &lt;- mtcars |&gt;\n  mutate(\n    am = if_else(am == 0, \"automatic\", \"manual\"),\n    am = fct_relevel(am, \"manual\", \"automatic\")\n  )\n\nggplot(\n  mtcars_new,\n  aes(x = wt, y = mpg)\n) +\n  labs(\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\",\n    title = \"Car's Mileage per Gallon vs. Car Weight\",\n    subtitle = \"Colored by type of transmission\",\n    color = \"Transmission\",\n    shape = \"Engine\"\n  ) +\n  geom_image(\n    data = tibble(wt = 3.5, mpg = 25),\n    aes(image = \"images/16/rickroll.png\"),\n    size = 0.8\n  ) +\n  geom_image(\n    data = tibble(wt = 2, mpg = 15),\n    aes(image = \"images/16/dino.png\"),\n    size = 0.4\n  ) +\n  geom_image(\n    data = tibble(wt = 4, mpg = 25),\n    aes(image = \"images/16/sparkle.png\"),\n    size = 0.4\n  ) +\n  geom_point(\n    aes(shape = vs, alpha = wt, color = am),\n    size = 15\n  ) +\n  theme_dark() +\n  theme(\n    legend.position = \"right\",\n    legend.background = element_rect(fill = \"green\")\n  ) +\n  scale_color_manual(\n    values = c(\n      \"manual\" = \"#b9bbda\",\n      \"automatic\" = \"#6d3617\"\n    )\n  ) +\n  guides(\n    shape = guide_legend(override.aes = list(size = 0.2)),\n    color = guide_legend(override.aes = list(size = 0.2)),\n    alpha = guide_legend(override.aes = list(size = 0.2))\n  )"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#from-last-time-with-penguins",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#from-last-time-with-penguins",
    "title": "Linear regression with a multiple predictors I",
    "section": "From last time (with penguins)",
    "text": "From last time (with penguins)\n\nA different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\n\n\noutcome: body weight (numerical)\npredictor: island (categorical)"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#visualize-body-weight-vs.-island",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#visualize-body-weight-vs.-island",
    "title": "Linear regression with a multiple predictors I",
    "section": "Visualize body weight vs. island",
    "text": "Visualize body weight vs. island\n\nDetermine whether each of the following plot types would be an appropriate choice for visualizing the relationship between body weight and island of penguins.\n\n\nScatterplot ❌\nBox plot ✅\nViolin plot ✅\nDensity plot ✅\nBar plot ❌\nStacked bar plot ❌"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#visualize",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#visualize",
    "title": "Linear regression with a multiple predictors I",
    "section": "Visualize",
    "text": "Visualize\n\nVisualize the relationship between body weight and island of penguins. Also calculate the average body weight per island."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#model---fit",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#model---fit",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - fit",
    "text": "Model - fit\n\nFit a linear regression model predicting body weight from island and display the results. Why is Biscoe not on the output?"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#model---interpret",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#model---interpret",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - interpret",
    "text": "Model - interpret\n\\[\n\\widehat{body~mass} = 4716 - 1003 \\times islandDream - 1010 \\times islandTorgersen\n\\]\n\nIntercept: Penguins from Biscoe island are expected to weigh, on average, 4,716 grams.\nSlope - islandDream: Penguins from Dream island are expected to weigh, on average, 1,003 grams less than those from Biscoe island.\nSlope - islandTorgersen: Penguins from Torgersen island are expected to weigh, on average, 1,010 grams less than those from Biscoe island."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#model---predict",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#model---predict",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - predict",
    "text": "Model - predict\n\nWhat is the predicted body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands? Where have we seen these values before?"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#model---predict-1",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#model---predict-1",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - predict",
    "text": "Model - predict\n\nCalculate the predicted body weights of penguins on Biscoe, Dream, and Torgersen islands by hand.\n\n\\[\n\\widehat{body~mass} = 4716 - 1003 \\times islandDream - 1010 \\times islandTorgersen\n\\]\n\n\nBiscoe: \\(\\widehat{body~mass} = 4716 - 1003 \\times 0 - 1010 \\times 0 = 4716\\)\n\n\n\n\n\nDream: \\(\\widehat{body~mass} = 4716 - 1003 \\times 1 - 1010 \\times 0 = 3713\\)\n\n\n\n\n\nTorgersen: \\(\\widehat{body~mass} = 4716 - 1003 \\times 0 - 1010 \\times 1 = 3706\\)"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I-slides.html#models-with-categorical-predictors",
    "href": "slides/16-linear-model-multiple-predictors-I-slides.html#models-with-categorical-predictors",
    "title": "Linear regression with a multiple predictors I",
    "section": "Models with categorical predictors",
    "text": "Models with categorical predictors\n\n\nWhen the categorical predictor has many levels, they’re encoded to dummy variables.\nThe first level of the categorical variable is the baseline level. In a model with one categorical predictor, the intercept is the predicted value of the outcome for the baseline level (x = 0).\nEach slope coefficient describes the difference between the predicted value of the outcome for that level of the categorical variable compared to the baseline level."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#while-you-wait",
    "href": "slides/16-linear-model-multiple-predictors-I.html#while-you-wait",
    "title": "Linear regression with a multiple predictors I",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-14-modeling-penguins-multi.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#announcements",
    "href": "slides/16-linear-model-multiple-predictors-I.html#announcements",
    "title": "Linear regression with a multiple predictors I",
    "section": "Announcements",
    "text": "Announcements\n\nProject repos closed (you won’t see them on GitHub) until proposal grading is done. You’ll get access back to them on Monday. In the meantime, if you want to work on your project, you can make local commits on RStudio and you’ll be able to push them when you regain access.\nPeer evaluations (via TEAMMATES) are due by Friday, 5 pm."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#goals",
    "href": "slides/16-linear-model-multiple-predictors-I.html#goals",
    "title": "Linear regression with a multiple predictors I",
    "section": "Goals",
    "text": "Goals\n\nRecap modeling with a single predictor\nFit and interpret models with a categorical predictor\nFit and interpret models with multiple predictors\nDistinguish between additive and interaction models"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#honorable-mention-1-austin-liu",
    "href": "slides/16-linear-model-multiple-predictors-I.html#honorable-mention-1-austin-liu",
    "title": "Linear regression with a multiple predictors I",
    "section": "Honorable mention 1: Austin Liu",
    "text": "Honorable mention 1: Austin Liu\n\nCodemtcars |&gt;\n  mutate(\n    am = case_when(\n      am == 0 ~ \"Automatic\",\n      am == 1 ~ \"Manual\"\n    ),\n    vs = case_when(\n      vs == 0 ~ \"V-shaped\",\n      vs == 1 ~ \"Straight\"\n    ),\n    am = fct_relevel(am, c(\"Manual\", \"Automatic\")),\n    vs = fct_relevel(vs)\n  ) |&gt;\n  ggplot(aes(x = wt, y = mpg, color = am, shape = vs)) +\n  geom_point() +\n  labs(\n    title = \"ggplot2 \n    plot \n    of \n    car \n    weight \n    in \n    thousands \n    of pounds versus \n    fuel \n    efficiency in miles per \n    gallon from thirty-two \n    automobiles in\n    the nineteen-seventy-four \n    Motor Trend United \n    States magazine \n    issue\",\n    subtitle = \"of cars\",\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\",\n    color = \"Transmission\",\n    shape = \"Engine configuration\"\n  ) +\n  theme(\n    legend.position = \"right\",\n    plot.background = element_rect(fill = \"green\"),\n    legend.background = element_rect(fill = \"yellow\"),\n    panel.background = element_rect(fill = \"red\"),\n    text = element_text(size = 1, family = \"AvantGarde\"),\n    aspect.ratio = 0.1,\n    panel.grid.major = element_blank(), \n    panel.grid.minor = element_blank()\n  ) +\n  scale_color_manual(\n    values = c(\"Manual\" = \"red1\", \"Automatic\" = \"red2\")\n  ) +\n  scale_shape_manual(\n    values = c(\"V-shaped\" = 19, \"Straight\" = 20)\n  )"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#honorable-mention-2-clarke-campbell",
    "href": "slides/16-linear-model-multiple-predictors-I.html#honorable-mention-2-clarke-campbell",
    "title": "Linear regression with a multiple predictors I",
    "section": "Honorable mention 2: Clarke Campbell",
    "text": "Honorable mention 2: Clarke Campbell\n\nCodemtcars |&gt;\n  mutate(trans_type = case_when(\n    am == 0 ~ \"Automatic\",\n    am == 1 ~ \"Manual\"\n    )\n  ) |&gt;\n  mutate(engine_type = case_when(\n    am == 0 ~ \"V-shaped\",\n    am == 1 ~ \"Straight\"\n    )\n  ) |&gt;\nggplot(aes(x = wt, y = mpg, color = trans_type, shape = engine_type)) +\n  geom_point(size = 0.1) +\n  labs(\n    x = \"Weight (in 1000s of lbs)\",\n    y = \"Miles / gallon\",\n    title = \"Weight vs. miles per gallon of 32 cars\",\n    subtitle = \"from the 1974 Motor Trend US magazine\",\n    color = \"Transmission Type:\",\n    shape = \"Engine Type\"\n  ) +\n  guides(\n    color = guide_legend(position = \"top\"),\n    shape = guide_legend(position = \"right\")\n  ) +\n  scale_color_manual(\n    values = c(\n      \"Manual\" = \"grey\",\n      \"Automatic\" = \"darkgrey\"\n    ),\n    breaks = c(\n      \"Manual\", \"Automatic\"\n      )\n  ) +\n  theme(\n    text = element_text(\n      size = 20, \n      family = \"URWBookman\", \n      face = \"italic\"),\n    panel.background = element_rect(colour = 'yellow'),\n    plot.background = element_rect(fill = \"#473417\"))"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#honorable-mention-3-charlie-pausic",
    "href": "slides/16-linear-model-multiple-predictors-I.html#honorable-mention-3-charlie-pausic",
    "title": "Linear regression with a multiple predictors I",
    "section": "Honorable mention 3: Charlie Pausic",
    "text": "Honorable mention 3: Charlie Pausic\n\nCodeggplot(mtcars, \n       aes(x = wt, y = mpg, \n           color = factor(am), shape = factor(vs)\n           )\n       ) +\n  geom_point(size = 15, alpha = 0.1) + \n\n  labs(\n    title = \"carssssss\",\n    x = \"variable\",\n    y = \"other variable\",\n    color = \"Transmission\",\n    shape = \"Engine Type\"\n  )+\n  theme_void() +\n  theme(legend.title = element_text(size = 1),\n        plot.background = element_rect(fill = \"black\")\n        ) +\n  scale_color_manual(\n    values = c(\"blue\", \"blue\"),\n    labels = c(\"Automatic\", \"Manual\")\n  ) +\n  scale_shape_manual(\n    values = c(\"circle\", \"triangle\"),\n    labels = c(\"Straight\", \"V-shaped\")\n  )"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#honorable-mention-4-natalie-veale",
    "href": "slides/16-linear-model-multiple-predictors-I.html#honorable-mention-4-natalie-veale",
    "title": "Linear regression with a multiple predictors I",
    "section": "Honorable mention 4: Natalie Veale",
    "text": "Honorable mention 4: Natalie Veale\n\nCodemtcars |&gt;\n  mutate(am = case_when(\n           am == \"0\" ~ \"automatic\",\n           am == \"1\" ~ \"manual\"),\n         am = factor(am, levels = c(\"manual\", \"automatic\")),\n         vs = case_when(\n           vs == \"0\" ~ \"v-shaped\",\n           vs == \"1\" ~ \"straight\")\n  ) |&gt;\nggplot(aes(x = wt, y = mpg, color = am, shape = vs)) +\n  geom_point(size = 20) +\n  labs(\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\",\n    title = \"MPG for Vehicles of Different Weights\",\n    color = \"Transmission\",\n    shape = \"Engine Type\"\n  ) +\n  scale_y_continuous(breaks = seq(0, 50, by = 1)) +\n  scale_color_manual(values = c(\n    \"automatic\" = \"darkgoldenrod\",\n    \"manual\" = \"burlywood2\"\n    )\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    plot.background = element_rect(fill = \"darkgoldenrod4\"),\n    legend.text = element_text(size = 1)\n  )"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#winner-neha-shukla",
    "href": "slides/16-linear-model-multiple-predictors-I.html#winner-neha-shukla",
    "title": "Linear regression with a multiple predictors I",
    "section": "Winner: Neha Shukla",
    "text": "Winner: Neha Shukla\n\nCodelibrary(ggimage)\nmtcars_new &lt;- mtcars |&gt;\n  mutate(\n    am = if_else(am == 0, \"automatic\", \"manual\"),\n    am = fct_relevel(am, \"manual\", \"automatic\")\n  )\n\nggplot(\n  mtcars_new,\n  aes(x = wt, y = mpg)\n) +\n  labs(\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\",\n    title = \"Car's Mileage per Gallon vs. Car Weight\",\n    subtitle = \"Colored by type of transmission\",\n    color = \"Transmission\",\n    shape = \"Engine\"\n  ) +\n  geom_image(\n    data = tibble(wt = 3.5, mpg = 25),\n    aes(image = \"images/16/rickroll.png\"),\n    size = 0.8\n  ) +\n  geom_image(\n    data = tibble(wt = 2, mpg = 15),\n    aes(image = \"images/16/dino.png\"),\n    size = 0.4\n  ) +\n  geom_image(\n    data = tibble(wt = 4, mpg = 25),\n    aes(image = \"images/16/sparkle.png\"),\n    size = 0.4\n  ) +\n  geom_point(\n    aes(shape = vs, alpha = wt, color = am),\n    size = 15\n  ) +\n  theme_dark() +\n  theme(\n    legend.position = \"right\",\n    legend.background = element_rect(fill = \"green\")\n  ) +\n  scale_color_manual(\n    values = c(\n      \"manual\" = \"#b9bbda\",\n      \"automatic\" = \"#6d3617\"\n    )\n  ) +\n  guides(\n    shape = guide_legend(override.aes = list(size = 0.2)),\n    color = guide_legend(override.aes = list(size = 0.2)),\n    alpha = guide_legend(override.aes = list(size = 0.2))\n  )"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#from-last-time-with-penguins",
    "href": "slides/16-linear-model-multiple-predictors-I.html#from-last-time-with-penguins",
    "title": "Linear regression with a multiple predictors I",
    "section": "From last time (with penguins)",
    "text": "From last time (with penguins)\n\nA different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\n. . .\n\noutcome: body weight (numerical)\npredictor: island (categorical)"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#visualize-body-weight-vs.-island",
    "href": "slides/16-linear-model-multiple-predictors-I.html#visualize-body-weight-vs.-island",
    "title": "Linear regression with a multiple predictors I",
    "section": "Visualize body weight vs. island",
    "text": "Visualize body weight vs. island\n\nDetermine whether each of the following plot types would be an appropriate choice for visualizing the relationship between body weight and island of penguins.\n\n\nScatterplot ❌\nBox plot ✅\nViolin plot ✅\nDensity plot ✅\nBar plot ❌\nStacked bar plot ❌"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#visualize",
    "href": "slides/16-linear-model-multiple-predictors-I.html#visualize",
    "title": "Linear regression with a multiple predictors I",
    "section": "Visualize",
    "text": "Visualize\n\nVisualize the relationship between body weight and island of penguins. Also calculate the average body weight per island."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#model---fit",
    "href": "slides/16-linear-model-multiple-predictors-I.html#model---fit",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - fit",
    "text": "Model - fit\n\nFit a linear regression model predicting body weight from island and display the results. Why is Biscoe not on the output?"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#model---interpret",
    "href": "slides/16-linear-model-multiple-predictors-I.html#model---interpret",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - interpret",
    "text": "Model - interpret\n\\[\n\\widehat{body~mass} = 4716 - 1003 \\times islandDream - 1010 \\times islandTorgersen\n\\]\n\nIntercept: Penguins from Biscoe island are expected to weigh, on average, 4,716 grams.\nSlope - islandDream: Penguins from Dream island are expected to weigh, on average, 1,003 grams less than those from Biscoe island.\nSlope - islandTorgersen: Penguins from Torgersen island are expected to weigh, on average, 1,010 grams less than those from Biscoe island."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#model---predict",
    "href": "slides/16-linear-model-multiple-predictors-I.html#model---predict",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - predict",
    "text": "Model - predict\n\nWhat is the predicted body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands? Where have we seen these values before?"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#model---predict-1",
    "href": "slides/16-linear-model-multiple-predictors-I.html#model---predict-1",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - predict",
    "text": "Model - predict\n\nCalculate the predicted body weights of penguins on Biscoe, Dream, and Torgersen islands by hand.\n\n\\[\n\\widehat{body~mass} = 4716 - 1003 \\times islandDream - 1010 \\times islandTorgersen\n\\]\n. . .\n\nBiscoe: \\(\\widehat{body~mass} = 4716 - 1003 \\times 0 - 1010 \\times 0 = 4716\\)\n\n\n. . .\n\nDream: \\(\\widehat{body~mass} = 4716 - 1003 \\times 1 - 1010 \\times 0 = 3713\\)\n\n\n. . .\n\nTorgersen: \\(\\widehat{body~mass} = 4716 - 1003 \\times 0 - 1010 \\times 1 = 3706\\)"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#models-with-categorical-predictors",
    "href": "slides/16-linear-model-multiple-predictors-I.html#models-with-categorical-predictors",
    "title": "Linear regression with a multiple predictors I",
    "section": "Models with categorical predictors",
    "text": "Models with categorical predictors\n\n\nWhen the categorical predictor has many levels, they’re encoded to dummy variables.\nThe first level of the categorical variable is the baseline level. In a model with one categorical predictor, the intercept is the predicted value of the outcome for the baseline level (x = 0).\nEach slope coefficient describes the difference between the predicted value of the outcome for that level of the categorical variable compared to the baseline level."
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II-slides.html#while-you-wait",
    "href": "slides/17-linear-model-multiple-predictors-II-slides.html#while-you-wait",
    "title": "Linear regression with a multiple predictors II",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-15-modeling-loans.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II-slides.html#announcements",
    "href": "slides/17-linear-model-multiple-predictors-II-slides.html#announcements",
    "title": "Linear regression with a multiple predictors II",
    "section": "Announcements",
    "text": "Announcements\n\nPeer evaluations (via TEAMMATES) are due by Friday (tomorrow), 5 pm.\nLab 5 due on Monday, 8:30 am.\nYou’ll receive project proposal feedback on Monday. Milestone 3 does not have a lab session dedicated, but you’re to review and address the feedback issues and close them with commits you make to your repo – opportunity to practice data science workflows and make progress on your project. Make sure you have weekly team meetings scheduled for the remainder of the semester!"
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II-slides.html#finish-up-tuesdays-ae",
    "href": "slides/17-linear-model-multiple-predictors-II-slides.html#finish-up-tuesdays-ae",
    "title": "Linear regression with a multiple predictors II",
    "section": "Finish up Tuesday’s AE",
    "text": "Finish up Tuesday’s AE\n\nGo to your ae project in RStudio.\nGet back to working on ae-14-modeling-penguins-multi"
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II-slides.html#ae-15-modeling-loans",
    "href": "slides/17-linear-model-multiple-predictors-II-slides.html#ae-15-modeling-loans",
    "title": "Linear regression with a multiple predictors II",
    "section": "ae-15-modeling-loans",
    "text": "ae-15-modeling-loans\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-15-modeling-loans.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II.html#while-you-wait",
    "href": "slides/17-linear-model-multiple-predictors-II.html#while-you-wait",
    "title": "Linear regression with a multiple predictors II",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-15-modeling-loans.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II.html#announcements",
    "href": "slides/17-linear-model-multiple-predictors-II.html#announcements",
    "title": "Linear regression with a multiple predictors II",
    "section": "Announcements",
    "text": "Announcements\n\nPeer evaluations (via TEAMMATES) are due by Friday (tomorrow), 5 pm.\nLab 5 due on Monday, 8:30 am.\nYou’ll receive project proposal feedback on Monday. Milestone 3 does not have a lab session dedicated, but you’re to review and address the feedback issues and close them with commits you make to your repo – opportunity to practice data science workflows and make progress on your project. Make sure you have weekly team meetings scheduled for the remainder of the semester!"
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II.html#finish-up-tuesdays-ae",
    "href": "slides/17-linear-model-multiple-predictors-II.html#finish-up-tuesdays-ae",
    "title": "Linear regression with a multiple predictors II",
    "section": "Finish up Tuesday’s AE",
    "text": "Finish up Tuesday’s AE\n\nGo to your ae project in RStudio.\nGet back to working on ae-14-modeling-penguins-multi"
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II.html#ae-15-modeling-loans",
    "href": "slides/17-linear-model-multiple-predictors-II.html#ae-15-modeling-loans",
    "title": "Linear regression with a multiple predictors II",
    "section": "ae-15-modeling-loans",
    "text": "ae-15-modeling-loans\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-15-modeling-loans.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#while-you-wait",
    "href": "slides/06-tidying-data-slides.html#while-you-wait",
    "title": "Tidying data",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-06-majors-tidy\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-06-majors-tidy.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-layering-geoms",
    "href": "slides/06-tidying-data-slides.html#recap-layering-geoms",
    "title": "Tidying data",
    "section": "Recap: layering geoms",
    "text": "Recap: layering geoms\n\n\n\nUpdate the following code to create the visualization on the right.\n\n\nlibrary(tidyverse)\nlibrary(usdata)\nlibrary(ggbeeswarm)"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-logical-operators",
    "href": "slides/06-tidying-data-slides.html#recap-logical-operators",
    "title": "Tidying data",
    "section": "Recap: logical operators",
    "text": "Recap: logical operators\nGenerally useful in a filter() but will come up in various other places as well…\n\n\n\n\n\n\noperator\ndefinition\n\n\n\n&lt;\nis less than?\n\n\n&lt;=\nis less than or equal to?\n\n\n&gt;\nis greater than?\n\n\n&gt;=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-logical-operators-cont.",
    "href": "slides/06-tidying-data-slides.html#recap-logical-operators-cont.",
    "title": "Tidying data",
    "section": "Recap: logical operators (cont.)",
    "text": "Recap: logical operators (cont.)\nGenerally useful in a filter() but will come up in various other places as well…\n\n\n\n\n\n\noperator\ndefinition\n\n\n\nx & y\nis x AND y?\n\n\nx \\| y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x? (only makes sense if x is TRUE or FALSE)"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-assignment",
    "href": "slides/06-tidying-data-slides.html#recap-assignment",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\nLet’s make a tiny data frame to use as an example:\n\ndf &lt;- tibble(x = c(1, 2, 3, 4, 5), y = c(\"a\", \"a\", \"b\", \"c\", \"c\"))\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 a    \n2     2 a    \n3     3 b    \n4     4 c    \n5     5 c"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-assignment-1",
    "href": "slides/06-tidying-data-slides.html#recap-assignment-1",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\nSuppose you run the following and then you inspect df, will the x variable has values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo something and show me"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-assignment-2",
    "href": "slides/06-tidying-data-slides.html#recap-assignment-2",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\nSuppose you run the following and then you inspect df, will the x variable has values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo something and save result"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-assignment-3",
    "href": "slides/06-tidying-data-slides.html#recap-assignment-3",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something, save result, overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\nDo something, save result, not overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_new &lt;- df |&gt;\n  mutate(x = x * 2)\ndf_new\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-assignment-4",
    "href": "slides/06-tidying-data-slides.html#recap-assignment-4",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something, save result, overwriting original when you shouldn’t\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf\n\n# A tibble: 3 × 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5\n\n\n\n\nDo something, save result, not overwriting original when you shouldn’t\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_summary &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf_summary\n\n# A tibble: 3 × 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-assignment-5",
    "href": "slides/06-tidying-data-slides.html#recap-assignment-5",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something, save result, overwriting originaldata frame\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(z = x + 2)\ndf\n\n# A tibble: 5 × 3\n      x y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a         3\n2     2 a         4\n3     3 b         5\n4     4 c         6\n5     5 c         7\n\n\n\n\nDo something, save result, overwriting originalcolumn\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x + 2)\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     3 a    \n2     4 a    \n3     5 b    \n4     6 c    \n5     7 c"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#tidy-data",
    "href": "slides/06-tidying-data-slides.html#tidy-data",
    "title": "Tidying data",
    "section": "Tidy data",
    "text": "Tidy data\n\n“Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.”\nTidy Data, https://vita.had.co.nz/papers/tidy-data.pdf\n\n\nNote: “easy to manipulate” = “straightforward to manipulate”"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#goal",
    "href": "slides/06-tidying-data-slides.html#goal",
    "title": "Tidying data",
    "section": "Goal",
    "text": "Goal\nVisualize StatSci majors over the years!"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#data",
    "href": "slides/06-tidying-data-slides.html#data",
    "title": "Tidying data",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#data-1",
    "href": "slides/06-tidying-data-slides.html#data-1",
    "title": "Tidying data",
    "section": "Data",
    "text": "Data\n\nstatsci\n\n# A tibble: 4 × 15\n  degree       `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018`\n  &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statistical…     NA      1     NA     NA      4      4      1     NA\n2 Statistical…      2      2      4      1      3      6      3      4\n3 Statistical…      2      6      1     NA      5      6      6      8\n4 Statistical…      5      9      4     13     10     17     24     21\n# ℹ 6 more variables: `2019` &lt;dbl&gt;, `2020` &lt;dbl&gt;, `2021` &lt;dbl&gt;,\n#   `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;, `2024` &lt;dbl&gt;\n\n\n\nThe first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major).\nThe remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2024."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#lets-plan",
    "href": "slides/06-tidying-data-slides.html#lets-plan",
    "title": "Tidying data",
    "section": "Let’s plan!",
    "text": "Let’s plan!\n\nReview the goal plot and sketch the data frame needed to make the plot. Determine rows and columns of the data frame. Hint: Data need to be in columns to map to aesthetic elements of the plot."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#pivot_longer",
    "href": "slides/06-tidying-data-slides.html#pivot_longer",
    "title": "Tidying data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nPivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#year",
    "href": "slides/06-tidying-data-slides.html#year",
    "title": "Tidying data",
    "section": "year",
    "text": "year\n\nWhat is the type of the year variable? Why? What should it be?\n\n\nIt’s a character (chr) variable since the information came from the columns of the original data frame and R cannot know that these character strings represent years. The variable type should be numeric."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#pivot_longer-again",
    "href": "slides/06-tidying-data-slides.html#pivot_longer-again",
    "title": "Tidying data",
    "section": "\npivot_longer() again",
    "text": "pivot_longer() again\n\nStart over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#na-counts",
    "href": "slides/06-tidying-data-slides.html#na-counts",
    "title": "Tidying data",
    "section": "\nNA counts",
    "text": "NA counts\n\nWhat does an NA mean in this context? Hint: The data come from the university registrar, and they have records on every single graduates, there shouldn’t be anything “unknown” to them about who graduated when.\n\n\nNAs should actually be 0s."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#clean-up",
    "href": "slides/06-tidying-data-slides.html#clean-up",
    "title": "Tidying data",
    "section": "Clean-up",
    "text": "Clean-up\n\nAdd on to your pipeline that you started with pivoting and convert NAs in n to 0s."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#more-clean-up",
    "href": "slides/06-tidying-data-slides.html#more-clean-up",
    "title": "Tidying data",
    "section": "More clean-up",
    "text": "More clean-up\n\nIn our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don’t need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree. Do this by adding on to your pipeline from earlier."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#finish",
    "href": "slides/06-tidying-data-slides.html#finish",
    "title": "Tidying data",
    "section": "Finish",
    "text": "Finish\n\nNow that you have your data pivoting and cleaning pipeline figured out, save the resulting data frame as statsci_longer."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#ae-06-majors-tidy",
    "href": "slides/06-tidying-data-slides.html#ae-06-majors-tidy",
    "title": "Tidying data",
    "section": "ae-06-majors-tidy",
    "text": "ae-06-majors-tidy\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-06-majors-tidy.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/06-tidying-data-slides.html#recap-pivoting",
    "href": "slides/06-tidying-data-slides.html#recap-pivoting",
    "title": "Tidying data",
    "section": "Recap: pivoting",
    "text": "Recap: pivoting\n\n\nData sets can’t be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate."
  },
  {
    "objectID": "slides/06-tidying-data.html#while-you-wait",
    "href": "slides/06-tidying-data.html#while-you-wait",
    "title": "Tidying data",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-06-majors-tidy\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-06-majors-tidy.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-layering-geoms",
    "href": "slides/06-tidying-data.html#recap-layering-geoms",
    "title": "Tidying data",
    "section": "Recap: layering geoms",
    "text": "Recap: layering geoms\n\n\n\nUpdate the following code to create the visualization on the right.\n\n\nlibrary(tidyverse)\nlibrary(usdata)\nlibrary(ggbeeswarm)"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-logical-operators",
    "href": "slides/06-tidying-data.html#recap-logical-operators",
    "title": "Tidying data",
    "section": "Recap: logical operators",
    "text": "Recap: logical operators\nGenerally useful in a filter() but will come up in various other places as well…\n\n\n\n\n\n\noperator\ndefinition\n\n\n\n&lt;\nis less than?\n\n\n&lt;=\nis less than or equal to?\n\n\n&gt;\nis greater than?\n\n\n&gt;=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-logical-operators-cont.",
    "href": "slides/06-tidying-data.html#recap-logical-operators-cont.",
    "title": "Tidying data",
    "section": "Recap: logical operators (cont.)",
    "text": "Recap: logical operators (cont.)\nGenerally useful in a filter() but will come up in various other places as well…\n\n\n\n\n\n\noperator\ndefinition\n\n\n\nx & y\nis x AND y?\n\n\nx \\| y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x? (only makes sense if x is TRUE or FALSE)"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment",
    "href": "slides/06-tidying-data.html#recap-assignment",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\nLet’s make a tiny data frame to use as an example:\n\ndf &lt;- tibble(x = c(1, 2, 3, 4, 5), y = c(\"a\", \"a\", \"b\", \"c\", \"c\"))\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 a    \n2     2 a    \n3     3 b    \n4     4 c    \n5     5 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment-1",
    "href": "slides/06-tidying-data.html#recap-assignment-1",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\nSuppose you run the following and then you inspect df, will the x variable has values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n. . .\n\nDo something and show me"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment-2",
    "href": "slides/06-tidying-data.html#recap-assignment-2",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\nSuppose you run the following and then you inspect df, will the x variable has values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n. . .\n\nDo something and save result"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment-3",
    "href": "slides/06-tidying-data.html#recap-assignment-3",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something, save result, overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\n\nDo something, save result, not overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_new &lt;- df |&gt;\n  mutate(x = x * 2)\ndf_new\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment-4",
    "href": "slides/06-tidying-data.html#recap-assignment-4",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something, save result, overwriting original when you shouldn’t\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf\n\n# A tibble: 3 × 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5\n\n\n\n\n\nDo something, save result, not overwriting original when you shouldn’t\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_summary &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf_summary\n\n# A tibble: 3 × 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment-5",
    "href": "slides/06-tidying-data.html#recap-assignment-5",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something, save result, overwriting originaldata frame\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(z = x + 2)\ndf\n\n# A tibble: 5 × 3\n      x y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a         3\n2     2 a         4\n3     3 b         5\n4     4 c         6\n5     5 c         7\n\n\n\n\n\nDo something, save result, overwriting originalcolumn\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x + 2)\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     3 a    \n2     4 a    \n3     5 b    \n4     6 c    \n5     7 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#tidy-data",
    "href": "slides/06-tidying-data.html#tidy-data",
    "title": "Tidying data",
    "section": "Tidy data",
    "text": "Tidy data\n\n“Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.”\nTidy Data, https://vita.had.co.nz/papers/tidy-data.pdf\n\n. . .\nNote: “easy to manipulate” = “straightforward to manipulate”"
  },
  {
    "objectID": "slides/06-tidying-data.html#goal",
    "href": "slides/06-tidying-data.html#goal",
    "title": "Tidying data",
    "section": "Goal",
    "text": "Goal\nVisualize StatSci majors over the years!"
  },
  {
    "objectID": "slides/06-tidying-data.html#data",
    "href": "slides/06-tidying-data.html#data",
    "title": "Tidying data",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "slides/06-tidying-data.html#data-1",
    "href": "slides/06-tidying-data.html#data-1",
    "title": "Tidying data",
    "section": "Data",
    "text": "Data\n\nstatsci\n\n# A tibble: 4 × 15\n  degree       `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018`\n  &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statistical…     NA      1     NA     NA      4      4      1     NA\n2 Statistical…      2      2      4      1      3      6      3      4\n3 Statistical…      2      6      1     NA      5      6      6      8\n4 Statistical…      5      9      4     13     10     17     24     21\n# ℹ 6 more variables: `2019` &lt;dbl&gt;, `2020` &lt;dbl&gt;, `2021` &lt;dbl&gt;,\n#   `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;, `2024` &lt;dbl&gt;\n\n\n\nThe first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major).\nThe remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2024."
  },
  {
    "objectID": "slides/06-tidying-data.html#lets-plan",
    "href": "slides/06-tidying-data.html#lets-plan",
    "title": "Tidying data",
    "section": "Let’s plan!",
    "text": "Let’s plan!\n\nReview the goal plot and sketch the data frame needed to make the plot. Determine rows and columns of the data frame. Hint: Data need to be in columns to map to aesthetic elements of the plot."
  },
  {
    "objectID": "slides/06-tidying-data.html#pivot_longer",
    "href": "slides/06-tidying-data.html#pivot_longer",
    "title": "Tidying data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nPivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame."
  },
  {
    "objectID": "slides/06-tidying-data.html#year",
    "href": "slides/06-tidying-data.html#year",
    "title": "Tidying data",
    "section": "year",
    "text": "year\n\nWhat is the type of the year variable? Why? What should it be?\n\n. . .\nIt’s a character (chr) variable since the information came from the columns of the original data frame and R cannot know that these character strings represent years. The variable type should be numeric."
  },
  {
    "objectID": "slides/06-tidying-data.html#pivot_longer-again",
    "href": "slides/06-tidying-data.html#pivot_longer-again",
    "title": "Tidying data",
    "section": "\npivot_longer() again",
    "text": "pivot_longer() again\n\nStart over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame."
  },
  {
    "objectID": "slides/06-tidying-data.html#na-counts",
    "href": "slides/06-tidying-data.html#na-counts",
    "title": "Tidying data",
    "section": "\nNA counts",
    "text": "NA counts\n\nWhat does an NA mean in this context? Hint: The data come from the university registrar, and they have records on every single graduates, there shouldn’t be anything “unknown” to them about who graduated when.\n\n. . .\nNAs should actually be 0s."
  },
  {
    "objectID": "slides/06-tidying-data.html#clean-up",
    "href": "slides/06-tidying-data.html#clean-up",
    "title": "Tidying data",
    "section": "Clean-up",
    "text": "Clean-up\n\nAdd on to your pipeline that you started with pivoting and convert NAs in n to 0s."
  },
  {
    "objectID": "slides/06-tidying-data.html#more-clean-up",
    "href": "slides/06-tidying-data.html#more-clean-up",
    "title": "Tidying data",
    "section": "More clean-up",
    "text": "More clean-up\n\nIn our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don’t need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree. Do this by adding on to your pipeline from earlier."
  },
  {
    "objectID": "slides/06-tidying-data.html#finish",
    "href": "slides/06-tidying-data.html#finish",
    "title": "Tidying data",
    "section": "Finish",
    "text": "Finish\n\nNow that you have your data pivoting and cleaning pipeline figured out, save the resulting data frame as statsci_longer."
  },
  {
    "objectID": "slides/06-tidying-data.html#ae-06-majors-tidy",
    "href": "slides/06-tidying-data.html#ae-06-majors-tidy",
    "title": "Tidying data",
    "section": "ae-06-majors-tidy",
    "text": "ae-06-majors-tidy\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-06-majors-tidy.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-pivoting",
    "href": "slides/06-tidying-data.html#recap-pivoting",
    "title": "Tidying data",
    "section": "Recap: pivoting",
    "text": "Recap: pivoting\n\n\nData sets can’t be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#while-you-wait",
    "href": "slides/12-gen-ai-slides.html#while-you-wait",
    "title": "Working with Generative AI tools",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-11-un-votes-revisit-chatgpt\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-11-un-votes-revisit-chatgpt.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#announcements",
    "href": "slides/12-gen-ai-slides.html#announcements",
    "title": "Working with Generative AI tools",
    "section": "Announcements",
    "text": "Announcements\n\nMidterm take-home due at 5:00 pm tomorrow (Friday, Oct 11)\n\nUpload to Gradescope and\n\nCommit and push to your GitHub repo\n\n\n\n\n\nMidsemester course evaluation due at midnight tonight (optional) – there will be some time at the end of class today to fill them out\nPeer evaluation 1 due by 5:00 pm next Friday (Oct 18) – look for an email from TEAMMATES\nReadings and videos for next Thursday’s class posted on the course website"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#code-smell",
    "href": "slides/12-gen-ai-slides.html#code-smell",
    "title": "Working with Generative AI tools",
    "section": "Code smell",
    "text": "Code smell\n\nOne way to look at smells is with respect to principles and quality: “Smells are certain structures in the code that indicate violation of fundamental design principles and negatively impact design quality”. Code smells are usually not bugs; they are not technically incorrect and do not prevent the program from functioning. Instead, they indicate weaknesses in design that may slow down development or increase the risk of bugs or failures in the future.\n\n\n\nSource: Code smell on Wikipedia"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#code-style",
    "href": "slides/12-gen-ai-slides.html#code-style",
    "title": "Working with Generative AI tools",
    "section": "Code style",
    "text": "Code style\nFollow the Tidyverse style guide:\n\nSpaces before and line breaks after each + when building a ggplot\nSpaces before and line breaks after each |&gt; in a data transformation pipeline,\nProper indentation\nSpaces around = signs and spaces after commas\nLines should not span more than 80 characters, long lines should be broken up with each argument on its own line"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#ae-11-un-votes-revisit-chatgpt",
    "href": "slides/12-gen-ai-slides.html#ae-11-un-votes-revisit-chatgpt",
    "title": "Working with Generative AI tools",
    "section": "ae-11-un-votes-revisit-chatgpt",
    "text": "ae-11-un-votes-revisit-chatgpt\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-11-un-votes-revisit-chatgpt.qmd.\nWork through Part 1 of the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#take-a-pulse",
    "href": "slides/12-gen-ai-slides.html#take-a-pulse",
    "title": "Working with Generative AI tools",
    "section": "Take a pulse",
    "text": "Take a pulse\n\nHow are you using Chat GPT or similar AI tools for this class?"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#example-1---from-lab-4",
    "href": "slides/12-gen-ai-slides.html#example-1---from-lab-4",
    "title": "Working with Generative AI tools",
    "section": "Example 1 - From Lab 4",
    "text": "Example 1 - From Lab 4\n\nSurveyUSA polled 900 NC adults between September 4-7, 2024. Of the 900 NC adults, 771 were identified by SurveyUSA as being registered to vote. The following question was asked to these 771 adults: “Should the use of marijuana for medical use remain against the law in North Carolina? Or be legalized?”\nOf the 771 responses, 391 were between the ages of 18-49. Of the individuals that are between 18-49, 59 individuals responded that they think medical marijuana should remain against the law, 292 said it should be made legal, and the remainder were not sure. Of the individuals that are 50+, 67 individuals responded that they think medical marijuana should remain against the law, 245 said it should be made legal, and the remainder were not sure.\nCalculate the proportions of 18-49 year olds and 50+ year-olds in this sample. make sure the result is an ungrouped data frame with a column for relevant counts, a column for relevant proportions, and a column for the groups you’re interested in."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-1-prompt",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-1-prompt",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 prompt",
    "text": "Chat GPT - Take 1 prompt\n\nWhat is wrong with this prompt? How would you correct it?\n\n\nSurveyUSA polled 900 NC adults between September 4-7, 2024. Of the 900 NC adults, 771 were identified by SurveyUSA as being registered to vote. The following question was asked to these 771 adults: “Should the use of marijuana for medical use remain against the law in North Carolina? Or be legalized?”\n\n\nOf the 771 responses, 391 were between the ages of 18-49. Of the individuals that are between 18-49, 59 individuals responded that they think medical marijuana should remain against the law, 292 said it should be made legal, and the remainder were not sure. Of the individuals that are 50+, 67 individuals responded that they think medical marijuana should remain against the law, 245 said it should be made legal, and the remainder were not sure.\n\n\nCalculate the proportions of 18-49 year olds and 50+ year-olds in this sample. Make sure the result is an ungrouped data frame with a column for relevant counts, a column for relevant proportions, and a column for the groups you’re interested in."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-1-response",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-1-response",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 response",
    "text": "Chat GPT - Take 1 response\n\nIdentify at least one mistake or code smell/style issue with the code below."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#ae-11-un-votes-revisit-chatgpt-1",
    "href": "slides/12-gen-ai-slides.html#ae-11-un-votes-revisit-chatgpt-1",
    "title": "Working with Generative AI tools",
    "section": "ae-11-un-votes-revisit-chatgpt",
    "text": "ae-11-un-votes-revisit-chatgpt\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-11-un-votes-revisit-chatgpt.qmd.\nWork through Part 2 of the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#lets-follow-along-with-chat-gpt",
    "href": "slides/12-gen-ai-slides.html#lets-follow-along-with-chat-gpt",
    "title": "Working with Generative AI tools",
    "section": "Let’s follow along with Chat GPT…",
    "text": "Let’s follow along with Chat GPT…\nhttps://chatgpt.com/share/6707d8c3-98c4-8000-9732-e65bc5be916b"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#example-2",
    "href": "slides/12-gen-ai-slides.html#example-2",
    "title": "Working with Generative AI tools",
    "section": "Example 2",
    "text": "Example 2\n\nEach CSI franchise includes a number of series, each with the character string \"CSI\" (in capital letters) in their title. Using this information, create a new data frame called csi that only has titles from the CSI-verse and all of the columns from tv for these titles. Then, display the first 10 rows of csi. Note: The titles and seasons included in the dataset may not be all CSI titles and titles that have ever aired."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-1-prompt-1",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-1-prompt-1",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 prompt",
    "text": "Chat GPT - Take 1 prompt\n\nEach CSI franchise includes a number of series, each with the character string \"CSI\" (in capital letters) in their title. Using this information, create a new data frame called csi that only has titles from the CSI-verse and all of the columns from tv for these titles. Then, display the first 10 rows of csi. Note: The titles and seasons included in the dataset may not be all CSI titles and titles that have ever aired."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-1-response-1",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-1-response-1",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 response",
    "text": "Chat GPT - Take 1 response\n\nCertainly! To filter the tv data frame to include only titles from the CSI-verse, you can use the filter function from the dplyr package. Here’s the code:\nlibrary(dplyr)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(str_detect(title, \"CSI\", case_insensitive = TRUE))\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\nThis code uses the filter function to select rows where the title column contains the string “CSI” (case-insensitive). The resulting data frame, csi, will include only titles from the CSI-verse along with all the columns from the original tv data frame. Make sure to replace ‘tv’ with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-1-code",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-1-code",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 code",
    "text": "Chat GPT - Take 1 code\n\nWhat is wrong with the following code?"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-2-prompt",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-2-prompt",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 2 prompt",
    "text": "Chat GPT - Take 2 prompt\n\nstr_detect doesn’t have a case_insensitive argument, can you try again?"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-2-response",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-2-response",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 2 response",
    "text": "Chat GPT - Take 2 response\n\nYou are correct, and I appreciate your understanding. The str_detect function itself doesn’t have a case_insensitive argument. Instead, you can use the str_which function along with the case_insensitive argument in the filter function. Here’s the corrected code:\nlibrary(dplyr)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(str_detect(title, \"CSI\", ignore_case = TRUE))\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\nThis code uses str_detect within the filter function and includes the ignore_case = TRUE argument to perform a case-insensitive search. The resulting csi data frame will contain only titles from the CSI-verse along with all the columns from the original tv data frame. Make sure to replace ‘tv’ with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-2-code",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-2-code",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 2 code",
    "text": "Chat GPT - Take 2 code"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-3-prompt",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-3-prompt",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 3 prompt",
    "text": "Chat GPT - Take 3 prompt\n\nstr_detect doesn’t have an ignore_case argument either, can you try again?"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#chat-gpt---take-3-response",
    "href": "slides/12-gen-ai-slides.html#chat-gpt---take-3-response",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 3 response",
    "text": "Chat GPT - Take 3 response\n\nI apologize for the oversight. It seems there was a mistake in my responses. To perform a case-insensitive search, you can use the stringi package along with stri_detect_regex. Here’s the corrected code:\nlibrary(dplyr)\nlibrary(stringi)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(stri_detect_regex(title, \"CSI\", case_insensitive = TRUE))\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\nThis code uses stri_detect_regex from the stringi package within the filter function, and it includes the case_insensitive = TRUE argument for a case-insensitive search. The resulting csi data frame will contain only titles from the CSI-verse along with all the columns from the original tv data frame. Make sure to replace ‘tv’ with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#lets-go-back-to-take-1",
    "href": "slides/12-gen-ai-slides.html#lets-go-back-to-take-1",
    "title": "Working with Generative AI tools",
    "section": "Let’s go back to Take 1",
    "text": "Let’s go back to Take 1\nand edit it a bit:"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#lets-go-back-to-take-1-1",
    "href": "slides/12-gen-ai-slides.html#lets-go-back-to-take-1-1",
    "title": "Working with Generative AI tools",
    "section": "Let’s go back to Take 1",
    "text": "Let’s go back to Take 1"
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#guidelines-and-best-practices-for-using-chat-gpt",
    "href": "slides/12-gen-ai-slides.html#guidelines-and-best-practices-for-using-chat-gpt",
    "title": "Working with Generative AI tools",
    "section": "Guidelines and best practices for using Chat GPT",
    "text": "Guidelines and best practices for using Chat GPT\n\n\nDo not just copy-paste the prompt – for appropriate academic conduct, for your own learning, and for getting to better results faster\nEngineer the prompt until the response starts to look like code you’re learning in the course\nIf the response is not correct, ask for a correction\nIf the response doesn’t follow the guidelines, ask for a correction\nWhen you ask for a correction, be ready for it to “correct” (i.e., change) more than you asked for\nDo not just copy-paste code from Chat GPT responses, run it line-by-line and edit as needed – Chat GPT does not execute R code so there’s no guarantee any of the code it gives you works\nWatch out for clear mistakes in the response: do not keep loading packages that are already loaded, use the base pipe |&gt;, use the tidyverse style, do not use unnecessary print() statements, be critical of code smell, etc."
  },
  {
    "objectID": "slides/12-gen-ai-slides.html#midsemester-course-evaluation",
    "href": "slides/12-gen-ai-slides.html#midsemester-course-evaluation",
    "title": "Working with Generative AI tools",
    "section": "Midsemester course evaluation",
    "text": "Midsemester course evaluation\nTake a few minutes to fill it out on Canvas &gt; Quizzes\n\nAnonymous\nOptional\nMuch appreciated!\n\nAnd good luck with the rest of the take-home midterm! ♥️"
  },
  {
    "objectID": "slides/12-gen-ai.html#while-you-wait",
    "href": "slides/12-gen-ai.html#while-you-wait",
    "title": "Working with Generative AI tools",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-11-un-votes-revisit-chatgpt\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-11-un-votes-revisit-chatgpt.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/12-gen-ai.html#announcements",
    "href": "slides/12-gen-ai.html#announcements",
    "title": "Working with Generative AI tools",
    "section": "Announcements",
    "text": "Announcements\n\nMidterm take-home due at 5:00 pm tomorrow (Friday, Oct 11)\n\nUpload to Gradescope and\n\nCommit and push to your GitHub repo\n\n\n\n. . .\n\nMidsemester course evaluation due at midnight tonight (optional) – there will be some time at the end of class today to fill them out\nPeer evaluation 1 due by 5:00 pm next Friday (Oct 18) – look for an email from TEAMMATES\nReadings and videos for next Thursday’s class posted on the course website"
  },
  {
    "objectID": "slides/12-gen-ai.html#code-smell",
    "href": "slides/12-gen-ai.html#code-smell",
    "title": "Working with Generative AI tools",
    "section": "Code smell",
    "text": "Code smell\n\nOne way to look at smells is with respect to principles and quality: “Smells are certain structures in the code that indicate violation of fundamental design principles and negatively impact design quality”. Code smells are usually not bugs; they are not technically incorrect and do not prevent the program from functioning. Instead, they indicate weaknesses in design that may slow down development or increase the risk of bugs or failures in the future.\n\n\n\nSource: Code smell on Wikipedia"
  },
  {
    "objectID": "slides/12-gen-ai.html#code-style",
    "href": "slides/12-gen-ai.html#code-style",
    "title": "Working with Generative AI tools",
    "section": "Code style",
    "text": "Code style\nFollow the Tidyverse style guide:\n\nSpaces before and line breaks after each + when building a ggplot\nSpaces before and line breaks after each |&gt; in a data transformation pipeline,\nProper indentation\nSpaces around = signs and spaces after commas\nLines should not span more than 80 characters, long lines should be broken up with each argument on its own line"
  },
  {
    "objectID": "slides/12-gen-ai.html#ae-11-un-votes-revisit-chatgpt",
    "href": "slides/12-gen-ai.html#ae-11-un-votes-revisit-chatgpt",
    "title": "Working with Generative AI tools",
    "section": "ae-11-un-votes-revisit-chatgpt",
    "text": "ae-11-un-votes-revisit-chatgpt\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-11-un-votes-revisit-chatgpt.qmd.\nWork through Part 1 of the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/12-gen-ai.html#take-a-pulse",
    "href": "slides/12-gen-ai.html#take-a-pulse",
    "title": "Working with Generative AI tools",
    "section": "Take a pulse",
    "text": "Take a pulse\n\nHow are you using Chat GPT or similar AI tools for this class?"
  },
  {
    "objectID": "slides/12-gen-ai.html#example-1---from-lab-4",
    "href": "slides/12-gen-ai.html#example-1---from-lab-4",
    "title": "Working with Generative AI tools",
    "section": "Example 1 - From Lab 4",
    "text": "Example 1 - From Lab 4\n\nSurveyUSA polled 900 NC adults between September 4-7, 2024. Of the 900 NC adults, 771 were identified by SurveyUSA as being registered to vote. The following question was asked to these 771 adults: “Should the use of marijuana for medical use remain against the law in North Carolina? Or be legalized?”\nOf the 771 responses, 391 were between the ages of 18-49. Of the individuals that are between 18-49, 59 individuals responded that they think medical marijuana should remain against the law, 292 said it should be made legal, and the remainder were not sure. Of the individuals that are 50+, 67 individuals responded that they think medical marijuana should remain against the law, 245 said it should be made legal, and the remainder were not sure.\nCalculate the proportions of 18-49 year olds and 50+ year-olds in this sample. make sure the result is an ungrouped data frame with a column for relevant counts, a column for relevant proportions, and a column for the groups you’re interested in."
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-1-prompt",
    "href": "slides/12-gen-ai.html#chat-gpt---take-1-prompt",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 prompt",
    "text": "Chat GPT - Take 1 prompt\n\nWhat is wrong with this prompt? How would you correct it?\n\n\nSurveyUSA polled 900 NC adults between September 4-7, 2024. Of the 900 NC adults, 771 were identified by SurveyUSA as being registered to vote. The following question was asked to these 771 adults: “Should the use of marijuana for medical use remain against the law in North Carolina? Or be legalized?”\n\n\nOf the 771 responses, 391 were between the ages of 18-49. Of the individuals that are between 18-49, 59 individuals responded that they think medical marijuana should remain against the law, 292 said it should be made legal, and the remainder were not sure. Of the individuals that are 50+, 67 individuals responded that they think medical marijuana should remain against the law, 245 said it should be made legal, and the remainder were not sure.\n\n\nCalculate the proportions of 18-49 year olds and 50+ year-olds in this sample. Make sure the result is an ungrouped data frame with a column for relevant counts, a column for relevant proportions, and a column for the groups you’re interested in."
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-1-response",
    "href": "slides/12-gen-ai.html#chat-gpt---take-1-response",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 response",
    "text": "Chat GPT - Take 1 response\n\nIdentify at least one mistake or code smell/style issue with the code below."
  },
  {
    "objectID": "slides/12-gen-ai.html#ae-11-un-votes-revisit-chatgpt-1",
    "href": "slides/12-gen-ai.html#ae-11-un-votes-revisit-chatgpt-1",
    "title": "Working with Generative AI tools",
    "section": "ae-11-un-votes-revisit-chatgpt",
    "text": "ae-11-un-votes-revisit-chatgpt\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-11-un-votes-revisit-chatgpt.qmd.\nWork through Part 2 of the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/12-gen-ai.html#lets-follow-along-with-chat-gpt",
    "href": "slides/12-gen-ai.html#lets-follow-along-with-chat-gpt",
    "title": "Working with Generative AI tools",
    "section": "Let’s follow along with Chat GPT…",
    "text": "Let’s follow along with Chat GPT…\nhttps://chatgpt.com/share/6707d8c3-98c4-8000-9732-e65bc5be916b"
  },
  {
    "objectID": "slides/12-gen-ai.html#example-2",
    "href": "slides/12-gen-ai.html#example-2",
    "title": "Working with Generative AI tools",
    "section": "Example 2",
    "text": "Example 2\n\nEach CSI franchise includes a number of series, each with the character string \"CSI\" (in capital letters) in their title. Using this information, create a new data frame called csi that only has titles from the CSI-verse and all of the columns from tv for these titles. Then, display the first 10 rows of csi. Note: The titles and seasons included in the dataset may not be all CSI titles and titles that have ever aired."
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-1-prompt-1",
    "href": "slides/12-gen-ai.html#chat-gpt---take-1-prompt-1",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 prompt",
    "text": "Chat GPT - Take 1 prompt\n\nEach CSI franchise includes a number of series, each with the character string \"CSI\" (in capital letters) in their title. Using this information, create a new data frame called csi that only has titles from the CSI-verse and all of the columns from tv for these titles. Then, display the first 10 rows of csi. Note: The titles and seasons included in the dataset may not be all CSI titles and titles that have ever aired."
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-1-response-1",
    "href": "slides/12-gen-ai.html#chat-gpt---take-1-response-1",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 response",
    "text": "Chat GPT - Take 1 response\n\nCertainly! To filter the tv data frame to include only titles from the CSI-verse, you can use the filter function from the dplyr package. Here’s the code:\nlibrary(dplyr)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(str_detect(title, \"CSI\", case_insensitive = TRUE))\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\nThis code uses the filter function to select rows where the title column contains the string “CSI” (case-insensitive). The resulting data frame, csi, will include only titles from the CSI-verse along with all the columns from the original tv data frame. Make sure to replace ‘tv’ with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-1-code",
    "href": "slides/12-gen-ai.html#chat-gpt---take-1-code",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 1 code",
    "text": "Chat GPT - Take 1 code\n\nWhat is wrong with the following code?"
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-2-prompt",
    "href": "slides/12-gen-ai.html#chat-gpt---take-2-prompt",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 2 prompt",
    "text": "Chat GPT - Take 2 prompt\n\nstr_detect doesn’t have a case_insensitive argument, can you try again?"
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-2-response",
    "href": "slides/12-gen-ai.html#chat-gpt---take-2-response",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 2 response",
    "text": "Chat GPT - Take 2 response\n\nYou are correct, and I appreciate your understanding. The str_detect function itself doesn’t have a case_insensitive argument. Instead, you can use the str_which function along with the case_insensitive argument in the filter function. Here’s the corrected code:\nlibrary(dplyr)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(str_detect(title, \"CSI\", ignore_case = TRUE))\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\nThis code uses str_detect within the filter function and includes the ignore_case = TRUE argument to perform a case-insensitive search. The resulting csi data frame will contain only titles from the CSI-verse along with all the columns from the original tv data frame. Make sure to replace ‘tv’ with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-2-code",
    "href": "slides/12-gen-ai.html#chat-gpt---take-2-code",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 2 code",
    "text": "Chat GPT - Take 2 code"
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-3-prompt",
    "href": "slides/12-gen-ai.html#chat-gpt---take-3-prompt",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 3 prompt",
    "text": "Chat GPT - Take 3 prompt\n\nstr_detect doesn’t have an ignore_case argument either, can you try again?"
  },
  {
    "objectID": "slides/12-gen-ai.html#chat-gpt---take-3-response",
    "href": "slides/12-gen-ai.html#chat-gpt---take-3-response",
    "title": "Working with Generative AI tools",
    "section": "Chat GPT - Take 3 response",
    "text": "Chat GPT - Take 3 response\n\nI apologize for the oversight. It seems there was a mistake in my responses. To perform a case-insensitive search, you can use the stringi package along with stri_detect_regex. Here’s the corrected code:\nlibrary(dplyr)\nlibrary(stringi)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(stri_detect_regex(title, \"CSI\", case_insensitive = TRUE))\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\nThis code uses stri_detect_regex from the stringi package within the filter function, and it includes the case_insensitive = TRUE argument for a case-insensitive search. The resulting csi data frame will contain only titles from the CSI-verse along with all the columns from the original tv data frame. Make sure to replace ‘tv’ with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-gen-ai.html#lets-go-back-to-take-1",
    "href": "slides/12-gen-ai.html#lets-go-back-to-take-1",
    "title": "Working with Generative AI tools",
    "section": "Let’s go back to Take 1",
    "text": "Let’s go back to Take 1\nand edit it a bit:"
  },
  {
    "objectID": "slides/12-gen-ai.html#lets-go-back-to-take-1-1",
    "href": "slides/12-gen-ai.html#lets-go-back-to-take-1-1",
    "title": "Working with Generative AI tools",
    "section": "Let’s go back to Take 1",
    "text": "Let’s go back to Take 1"
  },
  {
    "objectID": "slides/12-gen-ai.html#guidelines-and-best-practices-for-using-chat-gpt",
    "href": "slides/12-gen-ai.html#guidelines-and-best-practices-for-using-chat-gpt",
    "title": "Working with Generative AI tools",
    "section": "Guidelines and best practices for using Chat GPT",
    "text": "Guidelines and best practices for using Chat GPT\n\n\nDo not just copy-paste the prompt – for appropriate academic conduct, for your own learning, and for getting to better results faster\nEngineer the prompt until the response starts to look like code you’re learning in the course\nIf the response is not correct, ask for a correction\nIf the response doesn’t follow the guidelines, ask for a correction\nWhen you ask for a correction, be ready for it to “correct” (i.e., change) more than you asked for\nDo not just copy-paste code from Chat GPT responses, run it line-by-line and edit as needed – Chat GPT does not execute R code so there’s no guarantee any of the code it gives you works\nWatch out for clear mistakes in the response: do not keep loading packages that are already loaded, use the base pipe |&gt;, use the tidyverse style, do not use unnecessary print() statements, be critical of code smell, etc."
  },
  {
    "objectID": "slides/12-gen-ai.html#midsemester-course-evaluation",
    "href": "slides/12-gen-ai.html#midsemester-course-evaluation",
    "title": "Working with Generative AI tools",
    "section": "Midsemester course evaluation",
    "text": "Midsemester course evaluation\nTake a few minutes to fill it out on Canvas &gt; Quizzes\n\nAnonymous\nOptional\nMuch appreciated!\n\nAnd good luck with the rest of the take-home midterm! ♥️"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#while-you-wait",
    "href": "slides/10-web-scraping-slides.html#while-you-wait",
    "title": "Web scaping",
    "section": "While you wait…",
    "text": "While you wait…\n\n\n\nIf you haven’t yet done so: Install a Chrome browser and the SelectorGadget extension:\n\nChrome\nSelectorGadget\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-10-chronicle-scrape.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#announcements",
    "href": "slides/10-web-scraping-slides.html#announcements",
    "title": "Web scaping",
    "section": "Announcements",
    "text": "Announcements\nMidterm things:\n\nPractice midterm: Posted on the course website\nLecture recordings: Available until the in-class midterm, link emailed earlier today\nApplication exercise catch-up: Complete all application exercises up to the midterm by the in-class midterm (and get any missed points!)\nMidterm review: In class on Thursday, come with questions!"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#age-gaps",
    "href": "slides/10-web-scraping-slides.html#age-gaps",
    "title": "Web scaping",
    "section": "Age gaps",
    "text": "Age gaps\nData prep:\n\nlibrary(tidyverse)\n\nage_gaps &lt;- read_csv(\"data/age-gaps.csv\")\n\nage_gaps_heterosexual &lt;- age_gaps |&gt;\n  filter(character_1_gender != character_2_gender)"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#age-gaps-1",
    "href": "slides/10-web-scraping-slides.html#age-gaps-1",
    "title": "Web scaping",
    "section": "Age gaps",
    "text": "Age gaps\nLabel the data:\n\nage_gaps_heterosexual &lt;- age_gaps_heterosexual |&gt;\n  mutate(\n    older = case_when(\n      character_1_gender == \"woman\" & actor_1_age &gt; actor_2_age ~ \"woman older\",\n      character_2_gender == \"woman\" & actor_2_age &gt; actor_1_age ~ \"woman older\",\n      character_1_gender == \"man\"   & actor_1_age &gt; actor_2_age ~ \"man older\",\n      character_2_gender == \"man\"   & actor_2_age &gt; actor_1_age ~ \"man older\",\n      actor_1_age == actor_2_age ~ \"same age\"\n    )\n  )"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#age-gaps-2",
    "href": "slides/10-web-scraping-slides.html#age-gaps-2",
    "title": "Web scaping",
    "section": "Age gaps",
    "text": "Age gaps\nAge gaps split:\n\nwoman_older &lt;- age_gaps_heterosexual |&gt; \n  filter(older == \"woman older\")\nman_older   &lt;- age_gaps_heterosexual |&gt; \n  filter(older == \"man older\")\nsame_age    &lt;- age_gaps_heterosexual |&gt;\n  filter(older == \"same age\")\n\n\nCheck:\n\n(\n  nrow(woman_older) + nrow(man_older) + nrow(same_age)\n) == nrow(age_gaps_heterosexual)\n\n[1] TRUE"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#age-gaps-3",
    "href": "slides/10-web-scraping-slides.html#age-gaps-3",
    "title": "Web scaping",
    "section": "Age gaps",
    "text": "Age gaps\nWrite data\n\nwrite_csv(woman_older, file = \"data/woman-older.csv\")\nwrite_csv(man_older, file = \"data/man-older.csv\")\nwrite_csv(same_age, file = \"data/same-age.csv\")"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#reading-the-chronicle",
    "href": "slides/10-web-scraping-slides.html#reading-the-chronicle",
    "title": "Web scaping",
    "section": "Reading The Chronicle",
    "text": "Reading The Chronicle\n\nHow often do you read The Chronicle?\n\nEvery day\n3-5 times a week\nOnce a week\nRarely"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#reading-the-chronicle-1",
    "href": "slides/10-web-scraping-slides.html#reading-the-chronicle-1",
    "title": "Web scaping",
    "section": "Reading The Chronicle",
    "text": "Reading The Chronicle\n\nWhat do you think is the most common word in the titles of The Chronicle opinion pieces?"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#analyzing-the-chronicle",
    "href": "slides/10-web-scraping-slides.html#analyzing-the-chronicle",
    "title": "Web scaping",
    "section": "Analyzing The Chronicle",
    "text": "Analyzing The Chronicle"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#reading-the-chronicle-2",
    "href": "slides/10-web-scraping-slides.html#reading-the-chronicle-2",
    "title": "Web scaping",
    "section": "Reading The Chronicle",
    "text": "Reading The Chronicle\n\nHow do you think the sentiments in opinion pieces in The Chronicle compare across authors? Roughly the same? Wildly different? Somewhere in between?"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#analyzing-the-chronicle-1",
    "href": "slides/10-web-scraping-slides.html#analyzing-the-chronicle-1",
    "title": "Web scaping",
    "section": "Analyzing The Chronicle",
    "text": "Analyzing The Chronicle"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#all-of-this-analysis-is-done-in-r",
    "href": "slides/10-web-scraping-slides.html#all-of-this-analysis-is-done-in-r",
    "title": "Web scaping",
    "section": "All of this analysis is done in R!",
    "text": "All of this analysis is done in R!\n\n(mostly) with tools you already know!"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#common-words-in-the-chronicle-titles",
    "href": "slides/10-web-scraping-slides.html#common-words-in-the-chronicle-titles",
    "title": "Web scaping",
    "section": "Common words in The Chronicle titles",
    "text": "Common words in The Chronicle titles\nCode for the earlier plot:\n\nstop_words &lt;- read_csv(\"data/stop-words.csv\")\nchronicle |&gt;\n  tidytext::unnest_tokens(word, title) |&gt;\n  mutate(word = str_replace_all(word, \"’\", \"'\")) |&gt;\n  anti_join(stop_words) |&gt;\n  count(word, sort = TRUE) |&gt;\n  filter(word != \"duke's\") |&gt;\n  slice_head(n = 20) |&gt;\n  mutate(word = fct_reorder(word, n)) |&gt;\n  ggplot(aes(y = word, x = n, fill = log(n))) +\n  geom_col(show.legend = FALSE) +\n  theme_minimal(base_size = 16) +\n  labs(\n    x = \"Number of mentions\",\n    y = \"Word\",\n    title = \"The Chronicle - Opinion pieces\",\n    subtitle = \"Common words in the 500 most recent opinion pieces\",\n    caption = \"Source: Data scraped from The Chronicle on Sep 30, 2024\"\n  ) +\n  theme(\n    plot.title.position = \"plot\",\n    plot.caption = element_text(color = \"gray30\")\n  )"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#avg-sentiment-scores-of-abstracts",
    "href": "slides/10-web-scraping-slides.html#avg-sentiment-scores-of-abstracts",
    "title": "Web scaping",
    "section": "Avg sentiment scores of abstracts",
    "text": "Avg sentiment scores of abstracts\nCode for the earlier plot:\n\nafinn_sentiments &lt;- read_csv(\"data/afinn-sentiments.csv\")\nchronicle |&gt;\n  tidytext::unnest_tokens(word, abstract) |&gt;\n  mutate(word = str_replace_all(word, \"’\", \"'\")) |&gt;\n  anti_join(stop_words) |&gt;\n  left_join(afinn_sentiments) |&gt; \n  group_by(author, title) |&gt;\n  summarize(total_sentiment = sum(value, na.rm = TRUE), .groups = \"drop\") |&gt;\n  group_by(author) |&gt;\n  summarize(\n    n_articles = n(),\n    avg_sentiment = mean(total_sentiment, na.rm = TRUE),\n  ) |&gt;\n  filter(n_articles &gt; 1 & !is.na(author)) |&gt;\n  arrange(desc(avg_sentiment)) |&gt;\n  slice(c(1:10, 40:49)) |&gt;\n  mutate(\n    author = fct_reorder(author, avg_sentiment),\n    neg_pos = if_else(avg_sentiment &lt; 0, \"neg\", \"pos\"),\n    label_position = if_else(neg_pos == \"neg\", 0.25, -0.25)\n  ) |&gt;\n  ggplot(aes(y = author, x = avg_sentiment)) +\n  geom_col(aes(fill = neg_pos), show.legend = FALSE) +\n  geom_text(\n    aes(x = label_position, label = author, color = neg_pos),\n    hjust = c(rep(1,10), rep(0, 10)),\n    show.legend = FALSE,\n    fontface = \"bold\"\n  ) +\n  geom_text(\n    aes(label = round(avg_sentiment, 1)),\n    hjust = c(rep(1.25, 10), rep(-0.25, 10)),\n    color = \"white\",\n    fontface = \"bold\"\n  ) +\n  scale_fill_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  scale_color_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  coord_cartesian(xlim = c(-8, 8)) +\n  labs(\n    x = \"negative  ←     Average sentiment score (AFINN)     →  positive\",\n    y = NULL,\n    title = \"The Chronicle - Opinion pieces\\nAverage sentiment scores of abstracts by author\",\n    subtitle = \"Top 10 average positive and negative scores\",\n    caption = \"Source: Data scraped from The Chronicle on Sep 30, 2024\"\n  ) +\n  theme_void(base_size = 16) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5, margin = unit(c(0.5, 0, 1, 0), \"lines\")),\n    axis.title.x = element_text(color = \"gray30\", size = 12),\n    plot.caption = element_text(color = \"gray30\", size = 10)\n  )"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#where-is-the-data-coming-from",
    "href": "slides/10-web-scraping-slides.html#where-is-the-data-coming-from",
    "title": "Web scaping",
    "section": "Where is the data coming from?",
    "text": "Where is the data coming from?\n\nhttps://www.dukechronicle.com/section/opinion"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#where-is-the-data-coming-from-1",
    "href": "slides/10-web-scraping-slides.html#where-is-the-data-coming-from-1",
    "title": "Web scaping",
    "section": "Where is the data coming from?",
    "text": "Where is the data coming from?\n\n\n\n\n\n\n\n\nchronicle\n\n# A tibble: 500 × 6\n   title                       author date       abstract column url  \n   &lt;chr&gt;                       &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;\n 1 The Chronicle is accepting… Remem… 2024-09-30 If you … Opini… http…\n 2 Polls and prejudice         Cara … 2024-09-30 Sitting… Campu… http…\n 3 I hate Duke’s sodding grass Shamb… 2024-09-30 Duke’s … Campu… http…\n 4 We should reimagine our ve… Zubin… 2024-09-28 In addi… Campu… http…\n 5 Imagining the restorative … Nik N… 2024-09-28 With cr… Campu… http…\n 6 Community members share re… Remem… 2024-09-27 We welc… Opini… http…\n 7 Costs of college campus ec… Lisa … 2024-09-26 What ar… Campu… http…\n 8 Embracing polyhedronism     Aaron… 2024-09-26 But ins… Campu… http…\n 9 Comparison is the thief of… Angar… 2024-09-25 Why do … Campu… http…\n10 We only live once: Protect… Advik… 2024-09-25 I am no… Campu… http…\n# ℹ 490 more rows"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#scraping-the-web-what-why",
    "href": "slides/10-web-scraping-slides.html#scraping-the-web-what-why",
    "title": "Web scaping",
    "section": "Scraping the web: what? why?",
    "text": "Scraping the web: what? why?\n\nIncreasing amount of data is available on the web\nThese data are provided in an unstructured format: you can always copy&paste, but it’s time-consuming and prone to errors\nWeb scraping is the process of extracting this information automatically and transform it into a structured dataset\n\nTwo different scenarios:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy).\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files."
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#hypertext-markup-language",
    "href": "slides/10-web-scraping-slides.html#hypertext-markup-language",
    "title": "Web scaping",
    "section": "Hypertext Markup Language",
    "text": "Hypertext Markup Language\nMost of the data on the web is still largely available as HTML - while it is structured (hierarchical) it often is not available in a form useful for analysis (flat / tidy).\n\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n    &lt;br/&gt;\n    &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n    &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n    &lt;div class=\"contact\"&gt;\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n      &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n      &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n      &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#rvest",
    "href": "slides/10-web-scraping-slides.html#rvest",
    "title": "Web scaping",
    "section": "rvest",
    "text": "rvest\n\n\n\nThe rvest package makes basic processing and manipulation of HTML data straight forward\nIt’s designed to work with pipelines built with |&gt;\n\nrvest.tidyverse.org\n\n\nlibrary(rvest)"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#rvest-1",
    "href": "slides/10-web-scraping-slides.html#rvest-1",
    "title": "Web scaping",
    "section": "rvest",
    "text": "rvest\nCore functions:\n\nread_html() - read HTML data from a url or character string.\nhtml_elements() - select specified elements from the HTML document using CSS selectors (or xpath).\nhtml_element() - select a single element from the HTML document using CSS selectors (or xpath).\nhtml_table() - parse an HTML table into a data frame.\nhtml_text() / html_text2() - extract tag’s text content.\nhtml_name - extract a tag/element’s name(s).\nhtml_attrs - extract all attributes.\nhtml_attr - extract attribute value(s) by name."
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#html-rvest-xml2",
    "href": "slides/10-web-scraping-slides.html#html-rvest-xml2",
    "title": "Web scaping",
    "section": "html, rvest, & xml2",
    "text": "html, rvest, & xml2\n\nhtml &lt;- \n'&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n    &lt;br/&gt;\n    &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n    &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n    &lt;div class=\"contact\"&gt;\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n      &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n      &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n      &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;'\n\n\n\nread_html(html)\n\n{html_document}\n&lt;html&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; cha ...\n[2] &lt;body&gt;\\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\\n    &lt;br&gt;&lt;div cl ..."
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#selecting-elements",
    "href": "slides/10-web-scraping-slides.html#selecting-elements",
    "title": "Web scaping",
    "section": "Selecting elements",
    "text": "Selecting elements\n\nread_html(html) |&gt; html_elements(\"p\")\n\n{xml_nodeset (1)}\n[1] &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n\n\n\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_text()\n\n[1] \"Hello world!\"\n\n\n\n\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_name()\n\n[1] \"p\"\n\n\n\n\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_attrs()\n\n[[1]]\n   align \n\"center\" \n\n\n\n\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_attr(\"align\")\n\n[1] \"center\""
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#more-selecting-tags",
    "href": "slides/10-web-scraping-slides.html#more-selecting-tags",
    "title": "Web scaping",
    "section": "More selecting tags",
    "text": "More selecting tags\n\n\nread_html(html) |&gt; html_elements(\"div\")\n\n{xml_nodeset (7)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n[2] &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n[3] &lt;div class=\"contact\"&gt;\\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/di ...\n[4] &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n[5] &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n[6] &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n[7] &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n\n\n\n\n\n\nread_html(html) |&gt; html_elements(\"div\") |&gt; html_text()\n\n[1] \"John\"                                                                                  \n[2] \"Doe\"                                                                                   \n[3] \"\\n      555-555-1234\\n      555-555-2345\\n      555-555-9999\\n      555-555-8888\\n    \"\n[4] \"555-555-1234\"                                                                          \n[5] \"555-555-2345\"                                                                          \n[6] \"555-555-9999\"                                                                          \n[7] \"555-555-8888\""
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#css-selectors",
    "href": "slides/10-web-scraping-slides.html#css-selectors",
    "title": "Web scaping",
    "section": "CSS selectors",
    "text": "CSS selectors\n\nWe will use a tool called SelectorGadget to help us identify the HTML elements of interest by constructing a CSS selector which can be used to subset the HTML document.\n\n\n\nSome examples of basic selector syntax is below,\n\n\n\n\n\n\n\n\n\nSelector\nExample\nDescription\n\n\n\n.class\n.title\nSelect all elements with class=“title”\n\n\n#id\n#name\nSelect all elements with id=“name”\n\n\nelement\np\nSelect all &lt;p&gt; elements\n\n\nelement element\ndiv p\nSelect all &lt;p&gt; elements inside a &lt;div&gt; element\n\n\nelement&gt;element\ndiv &gt; p\nSelect all &lt;p&gt; elements with &lt;div&gt; as a parent\n\n\n[attribute]\n[class]\nSelect all elements with a class attribute\n\n\n[attribute=value]\n[class=title]\nSelect all elements with class=“title”"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#css-classes-and-ids",
    "href": "slides/10-web-scraping-slides.html#css-classes-and-ids",
    "title": "Web scaping",
    "section": "CSS classes and ids",
    "text": "CSS classes and ids\n\nread_html(html) |&gt; html_elements(\".name\")\n\n{xml_nodeset (2)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n[2] &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n\n\n\n\nread_html(html) |&gt; html_elements(\"div.name\")\n\n{xml_nodeset (2)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n[2] &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n\n\n\n\n\nread_html(html) |&gt; html_elements(\"#first\")\n\n{xml_nodeset (1)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#text-with-html_text-vs.-html_text2",
    "href": "slides/10-web-scraping-slides.html#text-with-html_text-vs.-html_text2",
    "title": "Web scaping",
    "section": "Text with html_text() vs. html_text2()\n",
    "text": "Text with html_text() vs. html_text2()\n\n\nhtml = read_html(\n  \"&lt;p&gt;  \n    This is the first sentence in the paragraph.\n    This is the second sentence that should be on the same line as the first sentence.&lt;br&gt;This third sentence should start on a new line.\n  &lt;/p&gt;\"\n)\n\n\n\nhtml |&gt; html_text()\n\n[1] \"  \\n    This is the first sentence in the paragraph.\\n    This is the second sentence that should be on the same line as the first sentence.This third sentence should start on a new line.\\n  \"\n\nhtml |&gt; html_text2()\n\n[1] \"This is the first sentence in the paragraph. This is the second sentence that should be on the same line as the first sentence.\\nThis third sentence should start on a new line.\""
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#html-tables-with-html_table",
    "href": "slides/10-web-scraping-slides.html#html-tables-with-html_table",
    "title": "Web scaping",
    "section": "HTML tables with html_table()\n",
    "text": "HTML tables with html_table()\n\n\nhtml_table = \n'&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;table&gt;\n      &lt;tr&gt; &lt;th&gt;a&lt;/th&gt; &lt;th&gt;b&lt;/th&gt; &lt;th&gt;c&lt;/th&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;5&lt;/td&gt; &lt;/tr&gt;\n    &lt;/table&gt;\n  &lt;/body&gt;\n&lt;/html&gt;'\n\n\n\nread_html(html_table) |&gt;\n  html_elements(\"table\") |&gt; \n  html_table()\n\n[[1]]\n# A tibble: 3 × 3\n      a     b     c\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     2     3\n2     2     3     4\n3     3     4     5"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#selectorgadget",
    "href": "slides/10-web-scraping-slides.html#selectorgadget",
    "title": "Web scaping",
    "section": "SelectorGadget",
    "text": "SelectorGadget\nSelectorGadget (selectorgadget.com) is a javascript based tool that helps you interactively build an appropriate CSS selector for the content you are interested in."
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#opinion-articles-in-the-chronicle",
    "href": "slides/10-web-scraping-slides.html#opinion-articles-in-the-chronicle",
    "title": "Web scaping",
    "section": "Opinion articles in The Chronicle",
    "text": "Opinion articles in The Chronicle\nGo to https://www.dukechronicle.com/section/opinion?page=1&per_page=500.\n\nHow many articles are on the page?"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#goal",
    "href": "slides/10-web-scraping-slides.html#goal",
    "title": "Web scaping",
    "section": "Goal",
    "text": "Goal\n\n\n\nScrape data and organize it in a tidy format in R\nPerform light text parsing to clean data\nSummarize and visualze the data"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#ae-10-chronicle-scrape",
    "href": "slides/10-web-scraping-slides.html#ae-10-chronicle-scrape",
    "title": "Web scaping",
    "section": "ae-10-chronicle-scrape",
    "text": "ae-10-chronicle-scrape\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-10-chronicle-scrape.qmd and chronicle-scrape.R."
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#recap",
    "href": "slides/10-web-scraping-slides.html#recap",
    "title": "Web scaping",
    "section": "Recap",
    "text": "Recap\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse rvest to first read the whole page (into R) and then parse the object you’ve read in to the elements you’re interested in\nPut the components together in a data frame (a tibble) and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#a-new-r-workflow",
    "href": "slides/10-web-scraping-slides.html#a-new-r-workflow",
    "title": "Web scaping",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in a Quarto document, your analysis is re-run each time you knit\nIf web scraping in a Quarto document, you’d be re-scraping the data each time you knit, which is undesirable (and not nice)!\n\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your Quarto document"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#ethics-can-you-vs-should-you",
    "href": "slides/10-web-scraping-slides.html#ethics-can-you-vs-should-you",
    "title": "Web scaping",
    "section": "Ethics: “Can you?” vs “Should you?”",
    "text": "Ethics: “Can you?” vs “Should you?”\n\n\n\n\n\n\nSource: Brian Resnick, Researchers just released profile data on 70,000 OkCupid users without permission, Vox."
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#can-you-vs-should-you",
    "href": "slides/10-web-scraping-slides.html#can-you-vs-should-you",
    "title": "Web scaping",
    "section": "“Can you?” vs “Should you?”",
    "text": "“Can you?” vs “Should you?”"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#challenges-unreliable-formatting",
    "href": "slides/10-web-scraping-slides.html#challenges-unreliable-formatting",
    "title": "Web scaping",
    "section": "Challenges: Unreliable formatting",
    "text": "Challenges: Unreliable formatting\n\n\n\n\n\n\nalumni.duke.edu/news/notable-alumni"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#challenges-data-broken-into-many-pages",
    "href": "slides/10-web-scraping-slides.html#challenges-data-broken-into-many-pages",
    "title": "Web scaping",
    "section": "Challenges: Data broken into many pages",
    "text": "Challenges: Data broken into many pages"
  },
  {
    "objectID": "slides/10-web-scraping-slides.html#workflow-screen-scraping-vs.-apis",
    "href": "slides/10-web-scraping-slides.html#workflow-screen-scraping-vs.-apis",
    "title": "Web scaping",
    "section": "Workflow: Screen scraping vs. APIs",
    "text": "Workflow: Screen scraping vs. APIs\nTwo different scenarios for web scraping:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files"
  },
  {
    "objectID": "slides/10-web-scraping.html#while-you-wait",
    "href": "slides/10-web-scraping.html#while-you-wait",
    "title": "Web scaping",
    "section": "While you wait…",
    "text": "While you wait…\n\n\n\nIf you haven’t yet done so: Install a Chrome browser and the SelectorGadget extension:\n\nChrome\nSelectorGadget\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-10-chronicle-scrape.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/10-web-scraping.html#announcements",
    "href": "slides/10-web-scraping.html#announcements",
    "title": "Web scaping",
    "section": "Announcements",
    "text": "Announcements\nMidterm things:\n\nPractice midterm: Posted on the course website\nLecture recordings: Available until the in-class midterm, link emailed earlier today\nApplication exercise catch-up: Complete all application exercises up to the midterm by the in-class midterm (and get any missed points!)\nMidterm review: In class on Thursday, come with questions!"
  },
  {
    "objectID": "slides/10-web-scraping.html#age-gaps",
    "href": "slides/10-web-scraping.html#age-gaps",
    "title": "Web scaping",
    "section": "Age gaps",
    "text": "Age gaps\nData prep:\n\nlibrary(tidyverse)\n\nage_gaps &lt;- read_csv(\"data/age-gaps.csv\")\n\nage_gaps_heterosexual &lt;- age_gaps |&gt;\n  filter(character_1_gender != character_2_gender)"
  },
  {
    "objectID": "slides/10-web-scraping.html#age-gaps-1",
    "href": "slides/10-web-scraping.html#age-gaps-1",
    "title": "Web scaping",
    "section": "Age gaps",
    "text": "Age gaps\nLabel the data:\n\nage_gaps_heterosexual &lt;- age_gaps_heterosexual |&gt;\n  mutate(\n    older = case_when(\n      character_1_gender == \"woman\" & actor_1_age &gt; actor_2_age ~ \"woman older\",\n      character_2_gender == \"woman\" & actor_2_age &gt; actor_1_age ~ \"woman older\",\n      character_1_gender == \"man\"   & actor_1_age &gt; actor_2_age ~ \"man older\",\n      character_2_gender == \"man\"   & actor_2_age &gt; actor_1_age ~ \"man older\",\n      actor_1_age == actor_2_age ~ \"same age\"\n    )\n  )"
  },
  {
    "objectID": "slides/10-web-scraping.html#age-gaps-2",
    "href": "slides/10-web-scraping.html#age-gaps-2",
    "title": "Web scaping",
    "section": "Age gaps",
    "text": "Age gaps\nAge gaps split:\n\nwoman_older &lt;- age_gaps_heterosexual |&gt; \n  filter(older == \"woman older\")\nman_older   &lt;- age_gaps_heterosexual |&gt; \n  filter(older == \"man older\")\nsame_age    &lt;- age_gaps_heterosexual |&gt;\n  filter(older == \"same age\")\n\n. . .\nCheck:\n\n(\n  nrow(woman_older) + nrow(man_older) + nrow(same_age)\n) == nrow(age_gaps_heterosexual)\n\n[1] TRUE"
  },
  {
    "objectID": "slides/10-web-scraping.html#age-gaps-3",
    "href": "slides/10-web-scraping.html#age-gaps-3",
    "title": "Web scaping",
    "section": "Age gaps",
    "text": "Age gaps\nWrite data\n\nwrite_csv(woman_older, file = \"data/woman-older.csv\")\nwrite_csv(man_older, file = \"data/man-older.csv\")\nwrite_csv(same_age, file = \"data/same-age.csv\")"
  },
  {
    "objectID": "slides/10-web-scraping.html#reading-the-chronicle",
    "href": "slides/10-web-scraping.html#reading-the-chronicle",
    "title": "Web scaping",
    "section": "Reading The Chronicle",
    "text": "Reading The Chronicle\n\nHow often do you read The Chronicle?\n\nEvery day\n3-5 times a week\nOnce a week\nRarely"
  },
  {
    "objectID": "slides/10-web-scraping.html#reading-the-chronicle-1",
    "href": "slides/10-web-scraping.html#reading-the-chronicle-1",
    "title": "Web scaping",
    "section": "Reading The Chronicle",
    "text": "Reading The Chronicle\n\nWhat do you think is the most common word in the titles of The Chronicle opinion pieces?"
  },
  {
    "objectID": "slides/10-web-scraping.html#analyzing-the-chronicle",
    "href": "slides/10-web-scraping.html#analyzing-the-chronicle",
    "title": "Web scaping",
    "section": "Analyzing The Chronicle",
    "text": "Analyzing The Chronicle"
  },
  {
    "objectID": "slides/10-web-scraping.html#reading-the-chronicle-2",
    "href": "slides/10-web-scraping.html#reading-the-chronicle-2",
    "title": "Web scaping",
    "section": "Reading The Chronicle",
    "text": "Reading The Chronicle\n\nHow do you think the sentiments in opinion pieces in The Chronicle compare across authors? Roughly the same? Wildly different? Somewhere in between?"
  },
  {
    "objectID": "slides/10-web-scraping.html#analyzing-the-chronicle-1",
    "href": "slides/10-web-scraping.html#analyzing-the-chronicle-1",
    "title": "Web scaping",
    "section": "Analyzing The Chronicle",
    "text": "Analyzing The Chronicle"
  },
  {
    "objectID": "slides/10-web-scraping.html#all-of-this-analysis-is-done-in-r",
    "href": "slides/10-web-scraping.html#all-of-this-analysis-is-done-in-r",
    "title": "Web scaping",
    "section": "All of this analysis is done in R!",
    "text": "All of this analysis is done in R!\n\n(mostly) with tools you already know!"
  },
  {
    "objectID": "slides/10-web-scraping.html#common-words-in-the-chronicle-titles",
    "href": "slides/10-web-scraping.html#common-words-in-the-chronicle-titles",
    "title": "Web scaping",
    "section": "Common words in The Chronicle titles",
    "text": "Common words in The Chronicle titles\nCode for the earlier plot:\n\nstop_words &lt;- read_csv(\"data/stop-words.csv\")\nchronicle |&gt;\n  tidytext::unnest_tokens(word, title) |&gt;\n  mutate(word = str_replace_all(word, \"’\", \"'\")) |&gt;\n  anti_join(stop_words) |&gt;\n  count(word, sort = TRUE) |&gt;\n  filter(word != \"duke's\") |&gt;\n  slice_head(n = 20) |&gt;\n  mutate(word = fct_reorder(word, n)) |&gt;\n  ggplot(aes(y = word, x = n, fill = log(n))) +\n  geom_col(show.legend = FALSE) +\n  theme_minimal(base_size = 16) +\n  labs(\n    x = \"Number of mentions\",\n    y = \"Word\",\n    title = \"The Chronicle - Opinion pieces\",\n    subtitle = \"Common words in the 500 most recent opinion pieces\",\n    caption = \"Source: Data scraped from The Chronicle on Sep 30, 2024\"\n  ) +\n  theme(\n    plot.title.position = \"plot\",\n    plot.caption = element_text(color = \"gray30\")\n  )"
  },
  {
    "objectID": "slides/10-web-scraping.html#avg-sentiment-scores-of-abstracts",
    "href": "slides/10-web-scraping.html#avg-sentiment-scores-of-abstracts",
    "title": "Web scaping",
    "section": "Avg sentiment scores of abstracts",
    "text": "Avg sentiment scores of abstracts\nCode for the earlier plot:\n\nafinn_sentiments &lt;- read_csv(\"data/afinn-sentiments.csv\")\nchronicle |&gt;\n  tidytext::unnest_tokens(word, abstract) |&gt;\n  mutate(word = str_replace_all(word, \"’\", \"'\")) |&gt;\n  anti_join(stop_words) |&gt;\n  left_join(afinn_sentiments) |&gt; \n  group_by(author, title) |&gt;\n  summarize(total_sentiment = sum(value, na.rm = TRUE), .groups = \"drop\") |&gt;\n  group_by(author) |&gt;\n  summarize(\n    n_articles = n(),\n    avg_sentiment = mean(total_sentiment, na.rm = TRUE),\n  ) |&gt;\n  filter(n_articles &gt; 1 & !is.na(author)) |&gt;\n  arrange(desc(avg_sentiment)) |&gt;\n  slice(c(1:10, 40:49)) |&gt;\n  mutate(\n    author = fct_reorder(author, avg_sentiment),\n    neg_pos = if_else(avg_sentiment &lt; 0, \"neg\", \"pos\"),\n    label_position = if_else(neg_pos == \"neg\", 0.25, -0.25)\n  ) |&gt;\n  ggplot(aes(y = author, x = avg_sentiment)) +\n  geom_col(aes(fill = neg_pos), show.legend = FALSE) +\n  geom_text(\n    aes(x = label_position, label = author, color = neg_pos),\n    hjust = c(rep(1,10), rep(0, 10)),\n    show.legend = FALSE,\n    fontface = \"bold\"\n  ) +\n  geom_text(\n    aes(label = round(avg_sentiment, 1)),\n    hjust = c(rep(1.25, 10), rep(-0.25, 10)),\n    color = \"white\",\n    fontface = \"bold\"\n  ) +\n  scale_fill_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  scale_color_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  coord_cartesian(xlim = c(-8, 8)) +\n  labs(\n    x = \"negative  ←     Average sentiment score (AFINN)     →  positive\",\n    y = NULL,\n    title = \"The Chronicle - Opinion pieces\\nAverage sentiment scores of abstracts by author\",\n    subtitle = \"Top 10 average positive and negative scores\",\n    caption = \"Source: Data scraped from The Chronicle on Sep 30, 2024\"\n  ) +\n  theme_void(base_size = 16) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5, margin = unit(c(0.5, 0, 1, 0), \"lines\")),\n    axis.title.x = element_text(color = \"gray30\", size = 12),\n    plot.caption = element_text(color = \"gray30\", size = 10)\n  )"
  },
  {
    "objectID": "slides/10-web-scraping.html#where-is-the-data-coming-from",
    "href": "slides/10-web-scraping.html#where-is-the-data-coming-from",
    "title": "Web scaping",
    "section": "Where is the data coming from?",
    "text": "Where is the data coming from?\n\nhttps://www.dukechronicle.com/section/opinion"
  },
  {
    "objectID": "slides/10-web-scraping.html#where-is-the-data-coming-from-1",
    "href": "slides/10-web-scraping.html#where-is-the-data-coming-from-1",
    "title": "Web scaping",
    "section": "Where is the data coming from?",
    "text": "Where is the data coming from?\n\n\n\n\n\n\n\n\nchronicle\n\n# A tibble: 500 × 6\n   title                       author date       abstract column url  \n   &lt;chr&gt;                       &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;\n 1 The Chronicle is accepting… Remem… 2024-09-30 If you … Opini… http…\n 2 Polls and prejudice         Cara … 2024-09-30 Sitting… Campu… http…\n 3 I hate Duke’s sodding grass Shamb… 2024-09-30 Duke’s … Campu… http…\n 4 We should reimagine our ve… Zubin… 2024-09-28 In addi… Campu… http…\n 5 Imagining the restorative … Nik N… 2024-09-28 With cr… Campu… http…\n 6 Community members share re… Remem… 2024-09-27 We welc… Opini… http…\n 7 Costs of college campus ec… Lisa … 2024-09-26 What ar… Campu… http…\n 8 Embracing polyhedronism     Aaron… 2024-09-26 But ins… Campu… http…\n 9 Comparison is the thief of… Angar… 2024-09-25 Why do … Campu… http…\n10 We only live once: Protect… Advik… 2024-09-25 I am no… Campu… http…\n# ℹ 490 more rows"
  },
  {
    "objectID": "slides/10-web-scraping.html#scraping-the-web-what-why",
    "href": "slides/10-web-scraping.html#scraping-the-web-what-why",
    "title": "Web scaping",
    "section": "Scraping the web: what? why?",
    "text": "Scraping the web: what? why?\n\nIncreasing amount of data is available on the web\nThese data are provided in an unstructured format: you can always copy&paste, but it’s time-consuming and prone to errors\nWeb scraping is the process of extracting this information automatically and transform it into a structured dataset\n\nTwo different scenarios:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy).\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files."
  },
  {
    "objectID": "slides/10-web-scraping.html#hypertext-markup-language",
    "href": "slides/10-web-scraping.html#hypertext-markup-language",
    "title": "Web scaping",
    "section": "Hypertext Markup Language",
    "text": "Hypertext Markup Language\nMost of the data on the web is still largely available as HTML - while it is structured (hierarchical) it often is not available in a form useful for analysis (flat / tidy).\n\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n    &lt;br/&gt;\n    &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n    &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n    &lt;div class=\"contact\"&gt;\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n      &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n      &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n      &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "slides/10-web-scraping.html#rvest",
    "href": "slides/10-web-scraping.html#rvest",
    "title": "Web scaping",
    "section": "rvest",
    "text": "rvest\n\n\n\nThe rvest package makes basic processing and manipulation of HTML data straight forward\nIt’s designed to work with pipelines built with |&gt;\n\nrvest.tidyverse.org\n\n\nlibrary(rvest)"
  },
  {
    "objectID": "slides/10-web-scraping.html#rvest-1",
    "href": "slides/10-web-scraping.html#rvest-1",
    "title": "Web scaping",
    "section": "rvest",
    "text": "rvest\nCore functions:\n\nread_html() - read HTML data from a url or character string.\nhtml_elements() - select specified elements from the HTML document using CSS selectors (or xpath).\nhtml_element() - select a single element from the HTML document using CSS selectors (or xpath).\nhtml_table() - parse an HTML table into a data frame.\nhtml_text() / html_text2() - extract tag’s text content.\nhtml_name - extract a tag/element’s name(s).\nhtml_attrs - extract all attributes.\nhtml_attr - extract attribute value(s) by name."
  },
  {
    "objectID": "slides/10-web-scraping.html#html-rvest-xml2",
    "href": "slides/10-web-scraping.html#html-rvest-xml2",
    "title": "Web scaping",
    "section": "html, rvest, & xml2",
    "text": "html, rvest, & xml2\n\nhtml &lt;- \n'&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n    &lt;br/&gt;\n    &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n    &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n    &lt;div class=\"contact\"&gt;\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n      &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n      &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n      &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;'\n\n. . .\n\nread_html(html)\n\n{html_document}\n&lt;html&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; cha ...\n[2] &lt;body&gt;\\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\\n    &lt;br&gt;&lt;div cl ..."
  },
  {
    "objectID": "slides/10-web-scraping.html#selecting-elements",
    "href": "slides/10-web-scraping.html#selecting-elements",
    "title": "Web scaping",
    "section": "Selecting elements",
    "text": "Selecting elements\n\nread_html(html) |&gt; html_elements(\"p\")\n\n{xml_nodeset (1)}\n[1] &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n\n\n. . .\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_text()\n\n[1] \"Hello world!\"\n\n\n. . .\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_name()\n\n[1] \"p\"\n\n\n. . .\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_attrs()\n\n[[1]]\n   align \n\"center\" \n\n\n. . .\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_attr(\"align\")\n\n[1] \"center\""
  },
  {
    "objectID": "slides/10-web-scraping.html#more-selecting-tags",
    "href": "slides/10-web-scraping.html#more-selecting-tags",
    "title": "Web scaping",
    "section": "More selecting tags",
    "text": "More selecting tags\n\n\nread_html(html) |&gt; html_elements(\"div\")\n\n{xml_nodeset (7)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n[2] &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n[3] &lt;div class=\"contact\"&gt;\\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/di ...\n[4] &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n[5] &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n[6] &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n[7] &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n\n\n\n. . .\n\n\nread_html(html) |&gt; html_elements(\"div\") |&gt; html_text()\n\n[1] \"John\"                                                                                  \n[2] \"Doe\"                                                                                   \n[3] \"\\n      555-555-1234\\n      555-555-2345\\n      555-555-9999\\n      555-555-8888\\n    \"\n[4] \"555-555-1234\"                                                                          \n[5] \"555-555-2345\"                                                                          \n[6] \"555-555-9999\"                                                                          \n[7] \"555-555-8888\""
  },
  {
    "objectID": "slides/10-web-scraping.html#css-selectors",
    "href": "slides/10-web-scraping.html#css-selectors",
    "title": "Web scaping",
    "section": "CSS selectors",
    "text": "CSS selectors\n\nWe will use a tool called SelectorGadget to help us identify the HTML elements of interest by constructing a CSS selector which can be used to subset the HTML document.\n\n. . .\n\nSome examples of basic selector syntax is below,\n\n\n\n\n\n\n\n\n\nSelector\nExample\nDescription\n\n\n\n.class\n.title\nSelect all elements with class=“title”\n\n\n#id\n#name\nSelect all elements with id=“name”\n\n\nelement\np\nSelect all &lt;p&gt; elements\n\n\nelement element\ndiv p\nSelect all &lt;p&gt; elements inside a &lt;div&gt; element\n\n\nelement&gt;element\ndiv &gt; p\nSelect all &lt;p&gt; elements with &lt;div&gt; as a parent\n\n\n[attribute]\n[class]\nSelect all elements with a class attribute\n\n\n[attribute=value]\n[class=title]\nSelect all elements with class=“title”"
  },
  {
    "objectID": "slides/10-web-scraping.html#css-classes-and-ids",
    "href": "slides/10-web-scraping.html#css-classes-and-ids",
    "title": "Web scaping",
    "section": "CSS classes and ids",
    "text": "CSS classes and ids\n\nread_html(html) |&gt; html_elements(\".name\")\n\n{xml_nodeset (2)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n[2] &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n\n\n. . .\n\nread_html(html) |&gt; html_elements(\"div.name\")\n\n{xml_nodeset (2)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n[2] &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n\n\n. . .\n\nread_html(html) |&gt; html_elements(\"#first\")\n\n{xml_nodeset (1)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;"
  },
  {
    "objectID": "slides/10-web-scraping.html#text-with-html_text-vs.-html_text2",
    "href": "slides/10-web-scraping.html#text-with-html_text-vs.-html_text2",
    "title": "Web scaping",
    "section": "Text with html_text() vs. html_text2()\n",
    "text": "Text with html_text() vs. html_text2()\n\n\nhtml = read_html(\n  \"&lt;p&gt;  \n    This is the first sentence in the paragraph.\n    This is the second sentence that should be on the same line as the first sentence.&lt;br&gt;This third sentence should start on a new line.\n  &lt;/p&gt;\"\n)\n\n. . .\n\nhtml |&gt; html_text()\n\n[1] \"  \\n    This is the first sentence in the paragraph.\\n    This is the second sentence that should be on the same line as the first sentence.This third sentence should start on a new line.\\n  \"\n\nhtml |&gt; html_text2()\n\n[1] \"This is the first sentence in the paragraph. This is the second sentence that should be on the same line as the first sentence.\\nThis third sentence should start on a new line.\""
  },
  {
    "objectID": "slides/10-web-scraping.html#html-tables-with-html_table",
    "href": "slides/10-web-scraping.html#html-tables-with-html_table",
    "title": "Web scaping",
    "section": "HTML tables with html_table()\n",
    "text": "HTML tables with html_table()\n\n\nhtml_table = \n'&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;table&gt;\n      &lt;tr&gt; &lt;th&gt;a&lt;/th&gt; &lt;th&gt;b&lt;/th&gt; &lt;th&gt;c&lt;/th&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;5&lt;/td&gt; &lt;/tr&gt;\n    &lt;/table&gt;\n  &lt;/body&gt;\n&lt;/html&gt;'\n\n. . .\n\nread_html(html_table) |&gt;\n  html_elements(\"table\") |&gt; \n  html_table()\n\n[[1]]\n# A tibble: 3 × 3\n      a     b     c\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     2     3\n2     2     3     4\n3     3     4     5"
  },
  {
    "objectID": "slides/10-web-scraping.html#selectorgadget",
    "href": "slides/10-web-scraping.html#selectorgadget",
    "title": "Web scaping",
    "section": "SelectorGadget",
    "text": "SelectorGadget\nSelectorGadget (selectorgadget.com) is a javascript based tool that helps you interactively build an appropriate CSS selector for the content you are interested in."
  },
  {
    "objectID": "slides/10-web-scraping.html#opinion-articles-in-the-chronicle",
    "href": "slides/10-web-scraping.html#opinion-articles-in-the-chronicle",
    "title": "Web scaping",
    "section": "Opinion articles in The Chronicle",
    "text": "Opinion articles in The Chronicle\nGo to https://www.dukechronicle.com/section/opinion?page=1&per_page=500.\n\nHow many articles are on the page?"
  },
  {
    "objectID": "slides/10-web-scraping.html#goal",
    "href": "slides/10-web-scraping.html#goal",
    "title": "Web scaping",
    "section": "Goal",
    "text": "Goal\n\n\n\nScrape data and organize it in a tidy format in R\nPerform light text parsing to clean data\nSummarize and visualze the data"
  },
  {
    "objectID": "slides/10-web-scraping.html#ae-10-chronicle-scrape",
    "href": "slides/10-web-scraping.html#ae-10-chronicle-scrape",
    "title": "Web scaping",
    "section": "ae-10-chronicle-scrape",
    "text": "ae-10-chronicle-scrape\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-10-chronicle-scrape.qmd and chronicle-scrape.R."
  },
  {
    "objectID": "slides/10-web-scraping.html#recap",
    "href": "slides/10-web-scraping.html#recap",
    "title": "Web scaping",
    "section": "Recap",
    "text": "Recap\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse rvest to first read the whole page (into R) and then parse the object you’ve read in to the elements you’re interested in\nPut the components together in a data frame (a tibble) and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/10-web-scraping.html#a-new-r-workflow",
    "href": "slides/10-web-scraping.html#a-new-r-workflow",
    "title": "Web scaping",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in a Quarto document, your analysis is re-run each time you knit\nIf web scraping in a Quarto document, you’d be re-scraping the data each time you knit, which is undesirable (and not nice)!\n\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your Quarto document"
  },
  {
    "objectID": "slides/10-web-scraping.html#ethics-can-you-vs-should-you",
    "href": "slides/10-web-scraping.html#ethics-can-you-vs-should-you",
    "title": "Web scaping",
    "section": "Ethics: “Can you?” vs “Should you?”",
    "text": "Ethics: “Can you?” vs “Should you?”\n\n\n\n\n\n\nSource: Brian Resnick, Researchers just released profile data on 70,000 OkCupid users without permission, Vox."
  },
  {
    "objectID": "slides/10-web-scraping.html#can-you-vs-should-you",
    "href": "slides/10-web-scraping.html#can-you-vs-should-you",
    "title": "Web scaping",
    "section": "“Can you?” vs “Should you?”",
    "text": "“Can you?” vs “Should you?”"
  },
  {
    "objectID": "slides/10-web-scraping.html#challenges-unreliable-formatting",
    "href": "slides/10-web-scraping.html#challenges-unreliable-formatting",
    "title": "Web scaping",
    "section": "Challenges: Unreliable formatting",
    "text": "Challenges: Unreliable formatting\n\n\n\n\n\n\nalumni.duke.edu/news/notable-alumni"
  },
  {
    "objectID": "slides/10-web-scraping.html#challenges-data-broken-into-many-pages",
    "href": "slides/10-web-scraping.html#challenges-data-broken-into-many-pages",
    "title": "Web scaping",
    "section": "Challenges: Data broken into many pages",
    "text": "Challenges: Data broken into many pages"
  },
  {
    "objectID": "slides/10-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "href": "slides/10-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "title": "Web scaping",
    "section": "Workflow: Screen scraping vs. APIs",
    "text": "Workflow: Screen scraping vs. APIs\nTwo different scenarios for web scraping:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#announcements",
    "href": "slides/03-grammar-of-data-transformation-slides.html#announcements",
    "title": "Grammar of data transformation",
    "section": "Announcements",
    "text": "Announcements\n\nAE 01 and AE 02 suggested answers posted on the course website.\nEd Discussion posts:\n\nKeep them coming!\nKeep them public!\nFeel free to make them anonymous if you prefer.\n\nMonday’s lab:\n\nShow up on time\nShow up to learn and get support\nLeave with all questions answered and a plan to work on the lab throughout the week"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#ae-02-bechdel-dataviz",
    "href": "slides/03-grammar-of-data-transformation-slides.html#ae-02-bechdel-dataviz",
    "title": "Grammar of data transformation",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\nGo to RStudio, confirm that you’re in the ae project, and open the document ae-02-bechdel-dataviz.qmd."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#recap-code-cells-aka-code-chunks",
    "href": "slides/03-grammar-of-data-transformation-slides.html#recap-code-cells-aka-code-chunks",
    "title": "Grammar of data transformation",
    "section": "Recap: Code cells (aka code chunks)",
    "text": "Recap: Code cells (aka code chunks)\n . . .\n\nCell labels are helpful for describing what the code is doing, for jumping between code cells in the editor, and for troubleshooting\nmessage: false hides any messages emitted by the code in your rendered document"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#ae-03-bechdel-data-viz-transform",
    "href": "slides/03-grammar-of-data-transformation-slides.html#ae-03-bechdel-data-viz-transform",
    "title": "Grammar of data transformation",
    "section": "ae-03-bechdel-data-viz-transform",
    "text": "ae-03-bechdel-data-viz-transform\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-03-bechdel-data-viz-transform.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#a-quick-reminder",
    "href": "slides/03-grammar-of-data-transformation-slides.html#a-quick-reminder",
    "title": "Grammar of data transformation",
    "section": "A quick reminder",
    "text": "A quick reminder\n\n1bechdel |&gt;\n2  filter(roi &gt; 400) |&gt;\n3  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n\n1\n\nStart with the bechdel data frame\n\n2\n\nFilter for movies with roi greater than 400 (gross is more than 400 times budget)\n\n3\n\nSelect the columns title, roi, budget_2013, gross_2013, year, and clean_test\n\n\n\n\n# A tibble: 3 × 6\n  title                    roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity     671.      505595  339424558  2007 dubious   \n2 The Blair Witch Proje…  648.      839077  543776715  1999 ok        \n3 El Mariachi             583.       11622    6778946  1992 nowomen"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#the-pipe",
    "href": "slides/03-grammar-of-data-transformation-slides.html#the-pipe",
    "title": "Grammar of data transformation",
    "section": "The pipe |>",
    "text": "The pipe |&gt;\nThe pipe operator passes what comes before it into the function that comes after it as the first argument in that function.\n\n\n\nsum(1, 2)\n\n[1] 3\n\n\n\n\n1 |&gt; \n  sum(2)\n\n[1] 3\n\n\n\n\n\n\n\nselect(filter(bechdel, roi &gt; 400), title)\n\n# A tibble: 3 × 1\n  title                  \n  &lt;chr&gt;                  \n1 Paranormal Activity    \n2 The Blair Witch Project\n3 El Mariachi            \n\n\n\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title)\n\n# A tibble: 3 × 1\n  title                  \n  &lt;chr&gt;                  \n1 Paranormal Activity    \n2 The Blair Witch Project\n3 El Mariachi"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#code-style-tip",
    "href": "slides/03-grammar-of-data-transformation-slides.html#code-style-tip",
    "title": "Grammar of data transformation",
    "section": "Code style tip ",
    "text": "Code style tip \n\nIn data transformation pipelines, always use a\n\nspace before |&gt;\nline break after |&gt;\nindent the next line of code\n\n\n\n\nIn data visualization layers, always use a\n\nspace before +\nline break after +\nindent the next line of code"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#the-pipe-in-action",
    "href": "slides/03-grammar-of-data-transformation-slides.html#the-pipe-in-action",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\n\nStart with the bechdel data frame:"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#the-pipe-in-action-1",
    "href": "slides/03-grammar-of-data-transformation-slides.html#the-pipe-in-action-1",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nFilter for rows where binary is equal to \"PASS\":"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#the-pipe-in-action-2",
    "href": "slides/03-grammar-of-data-transformation-slides.html#the-pipe-in-action-2",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nArrange the rows in descending order of roi:"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#the-pipe-in-action-3",
    "href": "slides/03-grammar-of-data-transformation-slides.html#the-pipe-in-action-3",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nSelect columns title and roi:"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation-slides.html#time-permitting",
    "href": "slides/03-grammar-of-data-transformation-slides.html#time-permitting",
    "title": "Grammar of data transformation",
    "section": "Time permitting",
    "text": "Time permitting\n\nAsk another question of the data that can be answered with a data transformation pipeline."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#announcements",
    "href": "slides/03-grammar-of-data-transformation.html#announcements",
    "title": "Grammar of data transformation",
    "section": "Announcements",
    "text": "Announcements\n\nAE 01 and AE 02 suggested answers posted on the course website.\nEd Discussion posts:\n\nKeep them coming!\nKeep them public!\nFeel free to make them anonymous if you prefer.\n\nMonday’s lab:\n\nShow up on time\nShow up to learn and get support\nLeave with all questions answered and a plan to work on the lab throughout the week"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#ae-02-bechdel-dataviz",
    "href": "slides/03-grammar-of-data-transformation.html#ae-02-bechdel-dataviz",
    "title": "Grammar of data transformation",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\nGo to RStudio, confirm that you’re in the ae project, and open the document ae-02-bechdel-dataviz.qmd."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#recap-code-cells-aka-code-chunks",
    "href": "slides/03-grammar-of-data-transformation.html#recap-code-cells-aka-code-chunks",
    "title": "Grammar of data transformation",
    "section": "Recap: Code cells (aka code chunks)",
    "text": "Recap: Code cells (aka code chunks)\n . . .\n\nCell labels are helpful for describing what the code is doing, for jumping between code cells in the editor, and for troubleshooting\nmessage: false hides any messages emitted by the code in your rendered document"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#ae-03-bechdel-data-viz-transform",
    "href": "slides/03-grammar-of-data-transformation.html#ae-03-bechdel-data-viz-transform",
    "title": "Grammar of data transformation",
    "section": "ae-03-bechdel-data-viz-transform",
    "text": "ae-03-bechdel-data-viz-transform\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-03-bechdel-data-viz-transform.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#a-quick-reminder",
    "href": "slides/03-grammar-of-data-transformation.html#a-quick-reminder",
    "title": "Grammar of data transformation",
    "section": "A quick reminder",
    "text": "A quick reminder\n\n1bechdel |&gt;\n2  filter(roi &gt; 400) |&gt;\n3  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n\n1\n\nStart with the bechdel data frame\n\n2\n\nFilter for movies with roi greater than 400 (gross is more than 400 times budget)\n\n3\n\nSelect the columns title, roi, budget_2013, gross_2013, year, and clean_test\n\n\n\n\n# A tibble: 3 × 6\n  title                    roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity     671.      505595  339424558  2007 dubious   \n2 The Blair Witch Proje…  648.      839077  543776715  1999 ok        \n3 El Mariachi             583.       11622    6778946  1992 nowomen"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe",
    "title": "Grammar of data transformation",
    "section": "The pipe |>",
    "text": "The pipe |&gt;\nThe pipe operator passes what comes before it into the function that comes after it as the first argument in that function.\n\n\n\nsum(1, 2)\n\n[1] 3\n\n\n\n\n1 |&gt; \n  sum(2)\n\n[1] 3\n\n\n\n\n\n\n\n\nselect(filter(bechdel, roi &gt; 400), title)\n\n# A tibble: 3 × 1\n  title                  \n  &lt;chr&gt;                  \n1 Paranormal Activity    \n2 The Blair Witch Project\n3 El Mariachi            \n\n\n\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title)\n\n# A tibble: 3 × 1\n  title                  \n  &lt;chr&gt;                  \n1 Paranormal Activity    \n2 The Blair Witch Project\n3 El Mariachi"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#code-style-tip",
    "href": "slides/03-grammar-of-data-transformation.html#code-style-tip",
    "title": "Grammar of data transformation",
    "section": "Code style tip ",
    "text": "Code style tip \n\nIn data transformation pipelines, always use a\n\nspace before |&gt;\nline break after |&gt;\nindent the next line of code\n\n\n. . .\n\nIn data visualization layers, always use a\n\nspace before +\nline break after +\nindent the next line of code"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\n. . .\nStart with the bechdel data frame:"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-1",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-1",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nFilter for rows where binary is equal to \"PASS\":"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-2",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-2",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nArrange the rows in descending order of roi:"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-3",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-3",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nSelect columns title and roi:"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#time-permitting",
    "href": "slides/03-grammar-of-data-transformation.html#time-permitting",
    "title": "Grammar of data transformation",
    "section": "Time permitting",
    "text": "Time permitting\n\nAsk another question of the data that can be answered with a data transformation pipeline."
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#while-you-wait",
    "href": "slides/05-exploring-data-II-slides.html#while-you-wait",
    "title": "Exploring data II",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-05-gerrymander-explore-II\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-05-gerrymander-explore-II.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#reminder-lab-guidelines",
    "href": "slides/05-exploring-data-II-slides.html#reminder-lab-guidelines",
    "title": "Exploring data II",
    "section": "Reminder: Lab guidelines",
    "text": "Reminder: Lab guidelines\n\n\nPlots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\n\nCode should follow the tidyverse style (style.tidyverse.org) Particularly,\n\nspace before and line breaks after each + when building a ggplot\n\nspace before and line breaks after each |&gt; in a data transformation pipeline\ncode should be properly indented\nspaces around = signs and spaces after commas\n\n\nAll code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks. Tip: Haikus not novellas when writing code!\nAt least three commits with meaningful commit messages."
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#code-style-and-readability",
    "href": "slides/05-exploring-data-II-slides.html#code-style-and-readability",
    "title": "Exploring data II",
    "section": "Code style and readability",
    "text": "Code style and readability\n\nWhydowecareaboutthestyleandreadabilityofyourcode? \\(\\rightarrow\\) Why do we care about the style and readability of your code?\n\n\n\n\nJe voudrais un cafe \\(\\rightarrow\\) Je voudrais un café"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#packages",
    "href": "slides/05-exploring-data-II-slides.html#packages",
    "title": "Exploring data II",
    "section": "Packages",
    "text": "Packages\n\nFor the data: usdata\n\n\n\nlibrary(usdata)\n\n\nFor the analysis: tidyverse and ggthemes\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ──────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#from-last-time",
    "href": "slides/05-exploring-data-II-slides.html#from-last-time",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics."
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#what-does-group_by-do",
    "href": "slides/05-exploring-data-II-slides.html#what-does-group_by-do",
    "title": "Exploring data II",
    "section": "What does group_by() do?",
    "text": "What does group_by() do?\n\nWhat does group_by() do in the following pipeline?"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#lets-simplify",
    "href": "slides/05-exploring-data-II-slides.html#lets-simplify",
    "title": "Exploring data II",
    "section": "Let’s simplify!",
    "text": "Let’s simplify!\n\nWhat does group_by() do in the following pipeline?"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#group_by",
    "href": "slides/05-exploring-data-II-slides.html#group_by",
    "title": "Exploring data II",
    "section": "group_by()",
    "text": "group_by()\n\nGroup by converts a data frame to a grouped data frame, where subsequent operations are performed once per group\nungroup() removes grouping"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#group_by-summarize",
    "href": "slides/05-exploring-data-II-slides.html#group_by-summarize",
    "title": "Exploring data II",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\nA common pipeline is group_by() and then summarize() to calculate summary statistics for each group:\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(\n    mean_trump16 = mean(trump16),\n    median_trump16 = median(trump16)\n  )\n\n# A tibble: 50 × 3\n   state mean_trump16 median_trump16\n   &lt;chr&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n 1 AK            52.8           52.8\n 2 AL            62.6           64.9\n 3 AR            60.9           63.0\n 4 AZ            46.9           47.7\n 5 CA            31.7           28.4\n 6 CO            43.6           41.3\n 7 CT            41.0           40.4\n 8 DE            41.9           41.9\n 9 FL            47.9           49.6\n10 GA            51.3           56.6\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#group_by-summarize-1",
    "href": "slides/05-exploring-data-II-slides.html#group_by-summarize-1",
    "title": "Exploring data II",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\nThis pipeline can also be used to count number of observations for each group:\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n())\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#summarize",
    "href": "slides/05-exploring-data-II-slides.html#summarize",
    "title": "Exploring data II",
    "section": "summarize()",
    "text": "summarize()\n... |&gt;\n  summarize(\n    name_of_summary_statistic = summary_function(variable)\n  )\n\n\n\nname_of_summary_statistic: Anything you want to call it!\n\nRecommendation: Keep it short and evocative\n\n\n\nsummary_function():\n\n\nn(): number of observations\n\nmean(): mean\n\nmedian(): median\n…"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#spot-the-difference",
    "href": "slides/05-exploring-data-II-slides.html#spot-the-difference",
    "title": "Exploring data II",
    "section": "Spot the difference",
    "text": "Spot the difference\n\nWhat’s the difference between the following two pipelines?\n\n\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n())\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows\n\n\n\n\ngerrymander |&gt;\n  count(state)\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#count",
    "href": "slides/05-exploring-data-II-slides.html#count",
    "title": "Exploring data II",
    "section": "count()",
    "text": "count()\n\n\n... |&gt;\n  count(variable)\n\n... |&gt;\n  count(variable1, variable2)\n\n\nCount the number of observations in each level of variable(s)\nPlace the counts in a variable called n"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#count-and-sort",
    "href": "slides/05-exploring-data-II-slides.html#count-and-sort",
    "title": "Exploring data II",
    "section": "\ncount() and sort\n",
    "text": "count() and sort\n\n\nWhat does the following pipeline do? Rewrite it with count() instead."
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#flip-the-question",
    "href": "slides/05-exploring-data-II-slides.html#flip-the-question",
    "title": "Exploring data II",
    "section": "Flip the question",
    "text": "Flip the question\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election?\n\nvs.\n\nIs a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#flipping-vs.-gerrymandering-prevalence",
    "href": "slides/05-exploring-data-II-slides.html#flipping-vs.-gerrymandering-prevalence",
    "title": "Exploring data II",
    "section": "Flipping vs. gerrymandering prevalence",
    "text": "Flipping vs. gerrymandering prevalence\n\nThe following code should produce a visualization that answers the question “Is a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?” However, it produces a warning and an unexpected plot. What’s going on?\n\n\n\n\nggplot(\n  gerrymander, \n  aes(x = gerry, fill = flip18)\n  ) +\n  geom_bar(position = \"fill\")\n\nWarning: The following aesthetics were dropped during statistical\ntransformation: fill.\nℹ This can happen when ggplot fails to infer the correct grouping\n  structure in the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a\n  numerical variable into a factor?"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#another-glimpse-at-gerrymander",
    "href": "slides/05-exploring-data-II-slides.html#another-glimpse-at-gerrymander",
    "title": "Exploring data II",
    "section": "Another glimpse at gerrymander\n",
    "text": "Another glimpse at gerrymander\n\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 3…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 6…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mi…"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#mutate-1",
    "href": "slides/05-exploring-data-II-slides.html#mutate-1",
    "title": "Exploring data II",
    "section": "mutate()",
    "text": "mutate()\n\nWe want to use flip18 as a categorical variable\nBut it’s stored as a numeric\nSo we need to change its type first, before we can use it as a categorical variable\nThe mutate() function transforms (mutates) a data frame by creating a new column or updating an existing one"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#mutate-in-action",
    "href": "slides/05-exploring-data-II-slides.html#mutate-in-action",
    "title": "Exploring data II",
    "section": "\nmutate() in action",
    "text": "mutate() in action"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#revisit-the-plot",
    "href": "slides/05-exploring-data-II-slides.html#revisit-the-plot",
    "title": "Exploring data II",
    "section": "Revisit the plot",
    "text": "Revisit the plot\n\n“Is a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?”"
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#ae-05-gerrymander-explore-ii",
    "href": "slides/05-exploring-data-II-slides.html#ae-05-gerrymander-explore-ii",
    "title": "Exploring data II",
    "section": "ae-05-gerrymander-explore-II",
    "text": "ae-05-gerrymander-explore-II\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-05-gerrymander-explore-II.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/05-exploring-data-II-slides.html#recap-aesthetic-mappings",
    "href": "slides/05-exploring-data-II-slides.html#recap-aesthetic-mappings",
    "title": "Exploring data II",
    "section": "Recap: aesthetic mappings",
    "text": "Recap: aesthetic mappings\n\nLocal aesthetic mappings for a given geom\nGlobal aesthetic mappings for all geoms"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#while-you-wait",
    "href": "slides/05-exploring-data-II.html#while-you-wait",
    "title": "Exploring data II",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-05-gerrymander-explore-II\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-05-gerrymander-explore-II.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/05-exploring-data-II.html#reminder-lab-guidelines",
    "href": "slides/05-exploring-data-II.html#reminder-lab-guidelines",
    "title": "Exploring data II",
    "section": "Reminder: Lab guidelines",
    "text": "Reminder: Lab guidelines\n\n\nPlots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\n\nCode should follow the tidyverse style (style.tidyverse.org) Particularly,\n\nspace before and line breaks after each + when building a ggplot\n\nspace before and line breaks after each |&gt; in a data transformation pipeline\ncode should be properly indented\nspaces around = signs and spaces after commas\n\n\nAll code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks. Tip: Haikus not novellas when writing code!\nAt least three commits with meaningful commit messages."
  },
  {
    "objectID": "slides/05-exploring-data-II.html#code-style-and-readability",
    "href": "slides/05-exploring-data-II.html#code-style-and-readability",
    "title": "Exploring data II",
    "section": "Code style and readability",
    "text": "Code style and readability\n\nWhydowecareaboutthestyleandreadabilityofyourcode? \\(\\rightarrow\\) Why do we care about the style and readability of your code?\n\n\n. . .\n\nJe voudrais un cafe \\(\\rightarrow\\) Je voudrais un café"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#packages",
    "href": "slides/05-exploring-data-II.html#packages",
    "title": "Exploring data II",
    "section": "Packages",
    "text": "Packages\n\nFor the data: usdata\n\n\n\nlibrary(usdata)\n\n\nFor the analysis: tidyverse and ggthemes\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ──────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#from-last-time",
    "href": "slides/05-exploring-data-II.html#from-last-time",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics."
  },
  {
    "objectID": "slides/05-exploring-data-II.html#what-does-group_by-do",
    "href": "slides/05-exploring-data-II.html#what-does-group_by-do",
    "title": "Exploring data II",
    "section": "What does group_by() do?",
    "text": "What does group_by() do?\n\nWhat does group_by() do in the following pipeline?"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#lets-simplify",
    "href": "slides/05-exploring-data-II.html#lets-simplify",
    "title": "Exploring data II",
    "section": "Let’s simplify!",
    "text": "Let’s simplify!\n\nWhat does group_by() do in the following pipeline?"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#group_by",
    "href": "slides/05-exploring-data-II.html#group_by",
    "title": "Exploring data II",
    "section": "group_by()",
    "text": "group_by()\n\nGroup by converts a data frame to a grouped data frame, where subsequent operations are performed once per group\nungroup() removes grouping"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#group_by-summarize",
    "href": "slides/05-exploring-data-II.html#group_by-summarize",
    "title": "Exploring data II",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\nA common pipeline is group_by() and then summarize() to calculate summary statistics for each group:\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(\n    mean_trump16 = mean(trump16),\n    median_trump16 = median(trump16)\n  )\n\n# A tibble: 50 × 3\n   state mean_trump16 median_trump16\n   &lt;chr&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n 1 AK            52.8           52.8\n 2 AL            62.6           64.9\n 3 AR            60.9           63.0\n 4 AZ            46.9           47.7\n 5 CA            31.7           28.4\n 6 CO            43.6           41.3\n 7 CT            41.0           40.4\n 8 DE            41.9           41.9\n 9 FL            47.9           49.6\n10 GA            51.3           56.6\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#group_by-summarize-1",
    "href": "slides/05-exploring-data-II.html#group_by-summarize-1",
    "title": "Exploring data II",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\nThis pipeline can also be used to count number of observations for each group:\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n())\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#summarize",
    "href": "slides/05-exploring-data-II.html#summarize",
    "title": "Exploring data II",
    "section": "summarize()",
    "text": "summarize()\n... |&gt;\n  summarize(\n    name_of_summary_statistic = summary_function(variable)\n  )\n. . .\n\n\nname_of_summary_statistic: Anything you want to call it!\n\nRecommendation: Keep it short and evocative\n\n\n\nsummary_function():\n\n\nn(): number of observations\n\nmean(): mean\n\nmedian(): median\n…"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#spot-the-difference",
    "href": "slides/05-exploring-data-II.html#spot-the-difference",
    "title": "Exploring data II",
    "section": "Spot the difference",
    "text": "Spot the difference\n\nWhat’s the difference between the following two pipelines?\n\n\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n())\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows\n\n\n\n\ngerrymander |&gt;\n  count(state)\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#count",
    "href": "slides/05-exploring-data-II.html#count",
    "title": "Exploring data II",
    "section": "count()",
    "text": "count()\n\n\n... |&gt;\n  count(variable)\n\n... |&gt;\n  count(variable1, variable2)\n\n\n\nCount the number of observations in each level of variable(s)\nPlace the counts in a variable called n"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#count-and-sort",
    "href": "slides/05-exploring-data-II.html#count-and-sort",
    "title": "Exploring data II",
    "section": "\ncount() and sort\n",
    "text": "count() and sort\n\n\nWhat does the following pipeline do? Rewrite it with count() instead."
  },
  {
    "objectID": "slides/05-exploring-data-II.html#flip-the-question",
    "href": "slides/05-exploring-data-II.html#flip-the-question",
    "title": "Exploring data II",
    "section": "Flip the question",
    "text": "Flip the question\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election?\n\nvs.\n\nIs a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#flipping-vs.-gerrymandering-prevalence",
    "href": "slides/05-exploring-data-II.html#flipping-vs.-gerrymandering-prevalence",
    "title": "Exploring data II",
    "section": "Flipping vs. gerrymandering prevalence",
    "text": "Flipping vs. gerrymandering prevalence\n\nThe following code should produce a visualization that answers the question “Is a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?” However, it produces a warning and an unexpected plot. What’s going on?\n\n\n\n\nggplot(\n  gerrymander, \n  aes(x = gerry, fill = flip18)\n  ) +\n  geom_bar(position = \"fill\")\n\nWarning: The following aesthetics were dropped during statistical\ntransformation: fill.\nℹ This can happen when ggplot fails to infer the correct grouping\n  structure in the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a\n  numerical variable into a factor?"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#another-glimpse-at-gerrymander",
    "href": "slides/05-exploring-data-II.html#another-glimpse-at-gerrymander",
    "title": "Exploring data II",
    "section": "Another glimpse at gerrymander\n",
    "text": "Another glimpse at gerrymander\n\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 3…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 6…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mi…"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#mutate-1",
    "href": "slides/05-exploring-data-II.html#mutate-1",
    "title": "Exploring data II",
    "section": "mutate()",
    "text": "mutate()\n\nWe want to use flip18 as a categorical variable\nBut it’s stored as a numeric\nSo we need to change its type first, before we can use it as a categorical variable\nThe mutate() function transforms (mutates) a data frame by creating a new column or updating an existing one"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#mutate-in-action",
    "href": "slides/05-exploring-data-II.html#mutate-in-action",
    "title": "Exploring data II",
    "section": "\nmutate() in action",
    "text": "mutate() in action"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#revisit-the-plot",
    "href": "slides/05-exploring-data-II.html#revisit-the-plot",
    "title": "Exploring data II",
    "section": "Revisit the plot",
    "text": "Revisit the plot\n\n“Is a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?”"
  },
  {
    "objectID": "slides/05-exploring-data-II.html#ae-05-gerrymander-explore-ii",
    "href": "slides/05-exploring-data-II.html#ae-05-gerrymander-explore-ii",
    "title": "Exploring data II",
    "section": "ae-05-gerrymander-explore-II",
    "text": "ae-05-gerrymander-explore-II\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-05-gerrymander-explore-II.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/05-exploring-data-II.html#recap-aesthetic-mappings",
    "href": "slides/05-exploring-data-II.html#recap-aesthetic-mappings",
    "title": "Exploring data II",
    "section": "Recap: aesthetic mappings",
    "text": "Recap: aesthetic mappings\n\nLocal aesthetic mappings for a given geom\nGlobal aesthetic mappings for all geoms"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#announcements",
    "href": "slides/02-grammar-of-data-visualization-slides.html#announcements",
    "title": "Grammar of data visualization",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours are posted on the course website!\n\nIf you can follow along with today’s application exercise steps, great! If something doesn’t work as expected, ask me/TA during the exercise. We’ll either:\n\nhelp you on the spot and get you unstuck or\nidentify that you’re missing an earlier step, ask you to follow along with your neighbor, and visit office hours before Thursday for one-on-one help"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#outline",
    "href": "slides/02-grammar-of-data-visualization-slides.html#outline",
    "title": "Grammar of data visualization",
    "section": "Outline",
    "text": "Outline\n\n\nLast time:\n\nWe introduced you to the course toolkit.\nYou cloned your ae repositories and started making some updates in your Quarto documents.\nYou did not commit and push your changes back.\n\n\n\n\n\n\nToday:\n\nYou will commit your changes from last time and push them to wrap up that application exercise.\nWe will introduce data visualization.\nYou will pull to get today’s application exercise file.\nYou will work on the new application exercise on data visualization, commit your changes, and push them."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#ae-01-meet-the-penguins",
    "href": "slides/02-grammar-of-data-visualization-slides.html#ae-01-meet-the-penguins",
    "title": "Grammar of data visualization",
    "section": "ae-01-meet-the-penguins",
    "text": "ae-01-meet-the-penguins\n\nGo to RStudio, confirm that you’re in the ae project, and open the document ae-01-meet-the-penguins.qmd."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#tour-recap-quarto",
    "href": "slides/02-grammar-of-data-visualization-slides.html#tour-recap-quarto",
    "title": "Grammar of data visualization",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#tour-recap-git-github",
    "href": "slides/02-grammar-of-data-visualization-slides.html#tour-recap-git-github",
    "title": "Grammar of data visualization",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\nOnce we made changes to our Quarto document, we\n\nwent to the Git pane in RStudio\nstaged our changes by clicking the checkboxes next to the relevant files\ncommitted our changes with an informative commit message\n\npushed our changes to our application exercise repos\n\nif this failed, we pulled first to get the new application exercise files, and then pushed\n\n\nconfirmed on GitHub that we could see our changes pushed from RStudio"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#how-will-we-use-quarto",
    "href": "slides/02-grammar-of-data-visualization-slides.html#how-will-we-use-quarto",
    "title": "Grammar of data visualization",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise, lab, project, etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#whats-with-all-the-hexes",
    "href": "slides/02-grammar-of-data-visualization-slides.html#whats-with-all-the-hexes",
    "title": "Grammar of data visualization",
    "section": "What’s with all the hexes?",
    "text": "What’s with all the hexes?"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#we-have-hexes-too",
    "href": "slides/02-grammar-of-data-visualization-slides.html#we-have-hexes-too",
    "title": "Grammar of data visualization",
    "section": "We have hexes too!",
    "text": "We have hexes too!\n\nGrab one before you leave!"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#un-votes",
    "href": "slides/02-grammar-of-data-visualization-slides.html#un-votes",
    "title": "Grammar of data visualization",
    "section": "UN Votes",
    "text": "UN Votes\n\nRemember this visualization from the first day of class?"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#let-see",
    "href": "slides/02-grammar-of-data-visualization-slides.html#let-see",
    "title": "Grammar of data visualization",
    "section": "Let’ see…",
    "text": "Let’ see…\n\nhow the sausage is made!"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#load-packages",
    "href": "slides/02-grammar-of-data-visualization-slides.html#load-packages",
    "title": "Grammar of data visualization",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(unvotes)\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#prepare-the-data",
    "href": "slides/02-grammar-of-data-visualization-slides.html#prepare-the-data",
    "title": "Grammar of data visualization",
    "section": "Prepare the data",
    "text": "Prepare the data\n\nus_uk_tr_votes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\") |&gt;\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n  mutate(year = year(date)) |&gt;\n  group_by(country, year, issue) |&gt;\n  summarize(percent_yes = mean(vote == \"yes\"), .groups = \"drop\")\n\n\n\n\n\n\n\n\nNote\n\n\nLet’s leave these details aside for a bit, we’ll revisit this code at a later point in the semester. For now, let’s agree that we need to do some “data wrangling” to get the data into the right format for the plot we want to create. Just note that we called the data frame we’ll visualize us_uk_tr_votes."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#visualize-the-data",
    "href": "slides/02-grammar-of-data-visualization-slides.html#visualize-the-data",
    "title": "Grammar of data visualization",
    "section": "Visualize the data",
    "text": "Visualize the data\n\nggplot(\n  us_uk_tr_votes, \n  mapping = aes(x = year, y = percent_yes, color = country)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  labs(\n    x = \"Year\", \n    y = \"% yes\", \n    color = \"Country\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#visualize-the-data-output",
    "href": "slides/02-grammar-of-data-visualization-slides.html#visualize-the-data-output",
    "title": "Grammar of data visualization",
    "section": "Visualize the data",
    "text": "Visualize the data"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-1.-prepare-a-canvas-for-plotting",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-1.-prepare-a-canvas-for-plotting",
    "title": "Grammar of data visualization",
    "section": "Step 1. Prepare a canvas for plotting",
    "text": "Step 1. Prepare a canvas for plotting"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-2.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-2.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 2. Map variables to aesthetics",
    "text": "Step 2. Map variables to aesthetics\nMap year to the x aesthetic"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-3.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-3.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 3. Map variables to aesthetics",
    "text": "Step 3. Map variables to aesthetics\nMap percent_yes to the y aesthetic"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#mapping-and-aesthetics",
    "href": "slides/02-grammar-of-data-visualization-slides.html#mapping-and-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Mapping and aesthetics",
    "text": "Mapping and aesthetics\n\nAesthetics are visual properties of a plot\nIn the grammar of graphics, variables from the data frame are mapped to aesthetics"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#argument-names",
    "href": "slides/02-grammar-of-data-visualization-slides.html#argument-names",
    "title": "Grammar of data visualization",
    "section": "Argument names",
    "text": "Argument names\nIt’s common practice in R to omit the names of first two arguments of a function:\n\n\nInstead of\n\nggplot(data = us_uk_tr_votes, mapping = aes(x = year, y = percent_yes))\n\nUse\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes))"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-4.-represent-data-on-your-canvas",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-4.-represent-data-on-your-canvas",
    "title": "Grammar of data visualization",
    "section": "Step 4. Represent data on your canvas",
    "text": "Step 4. Represent data on your canvas\nwith a geom"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-5.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-5.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 5. Map variables to aesthetics",
    "text": "Step 5. Map variables to aesthetics\nMap country to the color aesthetic"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-6.-represent-data-on-your-canvas",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-6.-represent-data-on-your-canvas",
    "title": "Grammar of data visualization",
    "section": "Step 6. Represent data on your canvas",
    "text": "Step 6. Represent data on your canvas\nwith another geom"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#warnings-and-messages",
    "href": "slides/02-grammar-of-data-visualization-slides.html#warnings-and-messages",
    "title": "Grammar of data visualization",
    "section": "Warnings and messages",
    "text": "Warnings and messages\n\nAdding geom_smooth() resulted in the following warning:\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nIt tells us the type of smoothing ggplot2 does under the hood when drawing the smooth curves that represent trends for each country.\n\n\n\n\nGoing forward we’ll suppress this warning to save some space."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-7.-split-plot-into-facets",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-7.-split-plot-into-facets",
    "title": "Grammar of data visualization",
    "section": "Step 7. Split plot into facets",
    "text": "Step 7. Split plot into facets"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-8.-use-a-different-color-scale",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-8.-use-a-different-color-scale",
    "title": "Grammar of data visualization",
    "section": "Step 8. Use a different color scale",
    "text": "Step 8. Use a different color scale"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-10.-apply-a-different-theme",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-10.-apply-a-different-theme",
    "title": "Grammar of data visualization",
    "section": "Step 10. Apply a different theme",
    "text": "Step 10. Apply a different theme"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-11.-add-labels",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-11.-add-labels",
    "title": "Grammar of data visualization",
    "section": "Step 11. Add labels",
    "text": "Step 11. Add labels"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-12.-set-transparency-of-points",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-12.-set-transparency-of-points",
    "title": "Grammar of data visualization",
    "section": "Step 12. Set transparency of points",
    "text": "Step 12. Set transparency of points\nwith alpha"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#step-13.-hide-standard-errors-of-curves",
    "href": "slides/02-grammar-of-data-visualization-slides.html#step-13.-hide-standard-errors-of-curves",
    "title": "Grammar of data visualization",
    "section": "Step 13. Hide standard errors of curves",
    "text": "Step 13. Hide standard errors of curves\nwith se = FALSE"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#grammar-of-graphics",
    "href": "slides/02-grammar-of-data-visualization-slides.html#grammar-of-graphics",
    "title": "Grammar of data visualization",
    "section": "Grammar of graphics",
    "text": "Grammar of graphics\n\n\nWe built a plot layer-by-layer\n\njust like described in the book The Grammar of Graphics and\nimplemented in the ggplot2 package, the data visualization package of the tidyverse."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#ae-02-bechdel-dataviz",
    "href": "slides/02-grammar-of-data-visualization-slides.html#ae-02-bechdel-dataviz",
    "title": "Grammar of data visualization",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization-slides.html#recap",
    "href": "slides/02-grammar-of-data-visualization-slides.html#recap",
    "title": "Grammar of data visualization",
    "section": "Recap",
    "text": "Recap\n\nConstruct plots with ggplot().\nLayers of ggplots are separated by +s.\nThe formula is (almost) always as follows:\n\n\nggplot(DATA, aes(x = X-VAR, y = Y-VAR, ...)) +\n  geom_XXX()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#announcements",
    "href": "slides/02-grammar-of-data-visualization.html#announcements",
    "title": "Grammar of data visualization",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours are posted on the course website!\n\nIf you can follow along with today’s application exercise steps, great! If something doesn’t work as expected, ask me/TA during the exercise. We’ll either:\n\nhelp you on the spot and get you unstuck or\nidentify that you’re missing an earlier step, ask you to follow along with your neighbor, and visit office hours before Thursday for one-on-one help"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#outline",
    "href": "slides/02-grammar-of-data-visualization.html#outline",
    "title": "Grammar of data visualization",
    "section": "Outline",
    "text": "Outline\n\n\nLast time:\n\nWe introduced you to the course toolkit.\nYou cloned your ae repositories and started making some updates in your Quarto documents.\nYou did not commit and push your changes back.\n\n\n\n. . .\n\n\nToday:\n\nYou will commit your changes from last time and push them to wrap up that application exercise.\nWe will introduce data visualization.\nYou will pull to get today’s application exercise file.\nYou will work on the new application exercise on data visualization, commit your changes, and push them."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#ae-01-meet-the-penguins",
    "href": "slides/02-grammar-of-data-visualization.html#ae-01-meet-the-penguins",
    "title": "Grammar of data visualization",
    "section": "ae-01-meet-the-penguins",
    "text": "ae-01-meet-the-penguins\n\nGo to RStudio, confirm that you’re in the ae project, and open the document ae-01-meet-the-penguins.qmd."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#tour-recap-quarto",
    "href": "slides/02-grammar-of-data-visualization.html#tour-recap-quarto",
    "title": "Grammar of data visualization",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#tour-recap-git-github",
    "href": "slides/02-grammar-of-data-visualization.html#tour-recap-git-github",
    "title": "Grammar of data visualization",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\nOnce we made changes to our Quarto document, we\n\nwent to the Git pane in RStudio\nstaged our changes by clicking the checkboxes next to the relevant files\ncommitted our changes with an informative commit message\n\npushed our changes to our application exercise repos\n\nif this failed, we pulled first to get the new application exercise files, and then pushed\n\n\nconfirmed on GitHub that we could see our changes pushed from RStudio"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#how-will-we-use-quarto",
    "href": "slides/02-grammar-of-data-visualization.html#how-will-we-use-quarto",
    "title": "Grammar of data visualization",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise, lab, project, etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#whats-with-all-the-hexes",
    "href": "slides/02-grammar-of-data-visualization.html#whats-with-all-the-hexes",
    "title": "Grammar of data visualization",
    "section": "What’s with all the hexes?",
    "text": "What’s with all the hexes?"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#we-have-hexes-too",
    "href": "slides/02-grammar-of-data-visualization.html#we-have-hexes-too",
    "title": "Grammar of data visualization",
    "section": "We have hexes too!",
    "text": "We have hexes too!\n\nGrab one before you leave!"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#un-votes",
    "href": "slides/02-grammar-of-data-visualization.html#un-votes",
    "title": "Grammar of data visualization",
    "section": "UN Votes",
    "text": "UN Votes\n\nRemember this visualization from the first day of class?"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#let-see",
    "href": "slides/02-grammar-of-data-visualization.html#let-see",
    "title": "Grammar of data visualization",
    "section": "Let’ see…",
    "text": "Let’ see…\n\nhow the sausage is made!"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#load-packages",
    "href": "slides/02-grammar-of-data-visualization.html#load-packages",
    "title": "Grammar of data visualization",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(unvotes)\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#prepare-the-data",
    "href": "slides/02-grammar-of-data-visualization.html#prepare-the-data",
    "title": "Grammar of data visualization",
    "section": "Prepare the data",
    "text": "Prepare the data\n\nus_uk_tr_votes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\") |&gt;\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n  mutate(year = year(date)) |&gt;\n  group_by(country, year, issue) |&gt;\n  summarize(percent_yes = mean(vote == \"yes\"), .groups = \"drop\")\n\n. . .\n\n\n\n\n\n\nNote\n\n\n\nLet’s leave these details aside for a bit, we’ll revisit this code at a later point in the semester. For now, let’s agree that we need to do some “data wrangling” to get the data into the right format for the plot we want to create. Just note that we called the data frame we’ll visualize us_uk_tr_votes."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#visualize-the-data",
    "href": "slides/02-grammar-of-data-visualization.html#visualize-the-data",
    "title": "Grammar of data visualization",
    "section": "Visualize the data",
    "text": "Visualize the data\n\nggplot(\n  us_uk_tr_votes, \n  mapping = aes(x = year, y = percent_yes, color = country)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  labs(\n    x = \"Year\", \n    y = \"% yes\", \n    color = \"Country\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-1.-prepare-a-canvas-for-plotting",
    "href": "slides/02-grammar-of-data-visualization.html#step-1.-prepare-a-canvas-for-plotting",
    "title": "Grammar of data visualization",
    "section": "Step 1. Prepare a canvas for plotting",
    "text": "Step 1. Prepare a canvas for plotting"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-2.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#step-2.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 2. Map variables to aesthetics",
    "text": "Step 2. Map variables to aesthetics\nMap year to the x aesthetic"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-3.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#step-3.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 3. Map variables to aesthetics",
    "text": "Step 3. Map variables to aesthetics\nMap percent_yes to the y aesthetic"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#mapping-and-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#mapping-and-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Mapping and aesthetics",
    "text": "Mapping and aesthetics\n\nAesthetics are visual properties of a plot\nIn the grammar of graphics, variables from the data frame are mapped to aesthetics"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#argument-names",
    "href": "slides/02-grammar-of-data-visualization.html#argument-names",
    "title": "Grammar of data visualization",
    "section": "Argument names",
    "text": "Argument names\nIt’s common practice in R to omit the names of first two arguments of a function:\n. . .\n\nInstead of\n\nggplot(data = us_uk_tr_votes, mapping = aes(x = year, y = percent_yes))\n\nUse\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes))"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-4.-represent-data-on-your-canvas",
    "href": "slides/02-grammar-of-data-visualization.html#step-4.-represent-data-on-your-canvas",
    "title": "Grammar of data visualization",
    "section": "Step 4. Represent data on your canvas",
    "text": "Step 4. Represent data on your canvas\nwith a geom"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-5.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#step-5.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 5. Map variables to aesthetics",
    "text": "Step 5. Map variables to aesthetics\nMap country to the color aesthetic"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-6.-represent-data-on-your-canvas",
    "href": "slides/02-grammar-of-data-visualization.html#step-6.-represent-data-on-your-canvas",
    "title": "Grammar of data visualization",
    "section": "Step 6. Represent data on your canvas",
    "text": "Step 6. Represent data on your canvas\nwith another geom"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#warnings-and-messages",
    "href": "slides/02-grammar-of-data-visualization.html#warnings-and-messages",
    "title": "Grammar of data visualization",
    "section": "Warnings and messages",
    "text": "Warnings and messages\n\nAdding geom_smooth() resulted in the following warning:\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n. . .\n\nIt tells us the type of smoothing ggplot2 does under the hood when drawing the smooth curves that represent trends for each country.\n\n. . .\n\nGoing forward we’ll suppress this warning to save some space."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-7.-split-plot-into-facets",
    "href": "slides/02-grammar-of-data-visualization.html#step-7.-split-plot-into-facets",
    "title": "Grammar of data visualization",
    "section": "Step 7. Split plot into facets",
    "text": "Step 7. Split plot into facets"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-8.-use-a-different-color-scale",
    "href": "slides/02-grammar-of-data-visualization.html#step-8.-use-a-different-color-scale",
    "title": "Grammar of data visualization",
    "section": "Step 8. Use a different color scale",
    "text": "Step 8. Use a different color scale"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-10.-apply-a-different-theme",
    "href": "slides/02-grammar-of-data-visualization.html#step-10.-apply-a-different-theme",
    "title": "Grammar of data visualization",
    "section": "Step 10. Apply a different theme",
    "text": "Step 10. Apply a different theme"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-11.-add-labels",
    "href": "slides/02-grammar-of-data-visualization.html#step-11.-add-labels",
    "title": "Grammar of data visualization",
    "section": "Step 11. Add labels",
    "text": "Step 11. Add labels"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-12.-set-transparency-of-points",
    "href": "slides/02-grammar-of-data-visualization.html#step-12.-set-transparency-of-points",
    "title": "Grammar of data visualization",
    "section": "Step 12. Set transparency of points",
    "text": "Step 12. Set transparency of points\nwith alpha"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-13.-hide-standard-errors-of-curves",
    "href": "slides/02-grammar-of-data-visualization.html#step-13.-hide-standard-errors-of-curves",
    "title": "Grammar of data visualization",
    "section": "Step 13. Hide standard errors of curves",
    "text": "Step 13. Hide standard errors of curves\nwith se = FALSE"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#grammar-of-graphics",
    "href": "slides/02-grammar-of-data-visualization.html#grammar-of-graphics",
    "title": "Grammar of data visualization",
    "section": "Grammar of graphics",
    "text": "Grammar of graphics\n\n\nWe built a plot layer-by-layer\n\njust like described in the book The Grammar of Graphics and\nimplemented in the ggplot2 package, the data visualization package of the tidyverse."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#ae-02-bechdel-dataviz",
    "href": "slides/02-grammar-of-data-visualization.html#ae-02-bechdel-dataviz",
    "title": "Grammar of data visualization",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#recap",
    "href": "slides/02-grammar-of-data-visualization.html#recap",
    "title": "Grammar of data visualization",
    "section": "Recap",
    "text": "Recap\n\nConstruct plots with ggplot().\nLayers of ggplots are separated by +s.\nThe formula is (almost) always as follows:\n\n\nggplot(DATA, aes(x = X-VAR, y = Y-VAR, ...)) +\n  geom_XXX()"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#while-you-wait",
    "href": "slides/08-data-types-classes-slides.html#while-you-wait",
    "title": "Data types and classes",
    "section": "While you wait…",
    "text": "While you wait…\n\n\n\n\nLoading…\n\n\nPrepare for today’s application exercise: ae-08-durham-climate-factors\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-08-durham-climate-factors.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#lab-1-feedback",
    "href": "slides/08-data-types-classes-slides.html#lab-1-feedback",
    "title": "Data types and classes",
    "section": "Lab 1 feedback",
    "text": "Lab 1 feedback\n\n\nDescribing a distribution:\n\nshape (modality and skewness)\ncenter (with calculated value or estimated value or range)\nspread (with calculated value or estimated value or range)\nunusual observations (and, where possible, explanation for why they’re unusual)\n\n\nDescribing a relationship:\n\ndirection (positive or negative)\nform (linear or non-linear)\nstrength\nunusual observations (and, where possible, explanation for why they’re unusual)"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#lab-1-commits",
    "href": "slides/08-data-types-classes-slides.html#lab-1-commits",
    "title": "Data types and classes",
    "section": "Lab 1 commits",
    "text": "Lab 1 commits"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#regrade-request-policy",
    "href": "slides/08-data-types-classes-slides.html#regrade-request-policy",
    "title": "Data types and classes",
    "section": "Regrade request policy",
    "text": "Regrade request policy\nhttps://sta199-f24.github.io/course-syllabus.html#regrade-requests\n\n\nConsidered for errors in grade calculation or if a correct answer was mistakenly marked as incorrect\n\nNot a mechanism for:\n\ndisputing the number of points deducted for an incorrect response\nasking for clarification on feedback (come to office hours instead)\n\n\nDue on Gradescope within a week after an assignment is returned\nThe entire assignment may be regraded, which could result in an adjustment in either direction\nNo regrade requests after the final exam has been administered"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#how-many-classes-do-you-have-on-tuesdays",
    "href": "slides/08-data-types-classes-slides.html#how-many-classes-do-you-have-on-tuesdays",
    "title": "Data types and classes",
    "section": "How many classes do you have on Tuesdays?",
    "text": "How many classes do you have on Tuesdays?\n\nsurvey\n\n# A tibble: 61 × 3\n   Timestamp     How many classes do you have o…¹ `What year are you?`\n   &lt;chr&gt;         &lt;chr&gt;                            &lt;chr&gt;               \n 1 9/23/24 19:57 2                                Sophomore           \n 2 9/23/24 19:58 3                                First-year          \n 3 9/23/24 20:06 2                                Sophomore           \n 4 9/23/24 20:09 2                                Sophomore           \n 5 9/23/24 21:48 0                                Senior              \n 6 9/24/24 9:44  2                                First-year          \n 7 9/24/24 10:15 2                                Senior              \n 8 9/24/24 10:50 2                                Sophomore           \n 9 9/24/24 10:54 3                                First-year          \n10 9/24/24 11:08 2                                Senior              \n# ℹ 51 more rows\n# ℹ abbreviated name: ¹​`How many classes do you have on Tuesdays?`"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#rename-variables",
    "href": "slides/08-data-types-classes-slides.html#rename-variables",
    "title": "Data types and classes",
    "section": "\nrename() variables",
    "text": "rename() variables\nTo make them easier to work with…\n\nsurvey &lt;- survey |&gt;\n  rename(\n    tue_classes = `How many classes do you have on Tuesdays?`,\n    year = `What year are you?`\n  )"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#variable-types",
    "href": "slides/08-data-types-classes-slides.html#variable-types",
    "title": "Data types and classes",
    "section": "Variable types",
    "text": "Variable types\n\nWhat type of variable is tue_classes?\n\n\nsurvey\n\n# A tibble: 61 × 3\n   Timestamp     tue_classes year      \n   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;     \n 1 9/23/24 19:57 2           Sophomore \n 2 9/23/24 19:58 3           First-year\n 3 9/23/24 20:06 2           Sophomore \n 4 9/23/24 20:09 2           Sophomore \n 5 9/23/24 21:48 0           Senior    \n 6 9/24/24 9:44  2           First-year\n 7 9/24/24 10:15 2           Senior    \n 8 9/24/24 10:50 2           Sophomore \n 9 9/24/24 10:54 3           First-year\n10 9/24/24 11:08 2           Senior    \n# ℹ 51 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#lets-attempt-to-clean-it-up",
    "href": "slides/08-data-types-classes-slides.html#lets-attempt-to-clean-it-up",
    "title": "Data types and classes",
    "section": "Let’s (attempt to) clean it up…",
    "text": "Let’s (attempt to) clean it up…"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#data-types-in-r",
    "href": "slides/08-data-types-classes-slides.html#data-types-in-r",
    "title": "Data types and classes",
    "section": "Data types in R",
    "text": "Data types in R\n\nlogical\ndouble\ninteger\ncharacter\nand some more, but we won’t be focusing on those"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#logical-character",
    "href": "slides/08-data-types-classes-slides.html#logical-character",
    "title": "Data types and classes",
    "section": "Logical & character",
    "text": "Logical & character\n\n\nlogical - Boolean values TRUE and FALSE\n\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\n\ncharacter - character strings\n\n\ntypeof(\"First-year\")\n\n[1] \"character\""
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#double-integer",
    "href": "slides/08-data-types-classes-slides.html#double-integer",
    "title": "Data types and classes",
    "section": "Double & integer",
    "text": "Double & integer\n\n\ndouble - floating point numerical values (default numerical type)\n\n\ntypeof(2.5)\n\n[1] \"double\"\n\ntypeof(3)\n\n[1] \"double\"\n\n\n\ninteger - integer numerical values (indicated with an L)\n\n\ntypeof(3L)\n\n[1] \"integer\"\n\ntypeof(1:3)\n\n[1] \"integer\""
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#concatenation",
    "href": "slides/08-data-types-classes-slides.html#concatenation",
    "title": "Data types and classes",
    "section": "Concatenation",
    "text": "Concatenation\nVectors can be constructed using the c() function.\n\nNumeric vector:\n\n\nc(1, 2, 3)\n\n[1] 1 2 3\n\n\n\n\nCharacter vector:\n\n\nc(\"Hello\", \"World!\")\n\n[1] \"Hello\"  \"World!\"\n\n\n\n\n\nVector made of vectors:\n\n\nc(c(\"hi\", \"hello\"), c(\"bye\", \"jello\"))\n\n[1] \"hi\"    \"hello\" \"bye\"   \"jello\""
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#converting-between-types",
    "href": "slides/08-data-types-classes-slides.html#converting-between-types",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwith intention…\n\n\n\n\nx &lt;- 1:3\nx\n\n[1] 1 2 3\n\ntypeof(x)\n\n[1] \"integer\"\n\n\n\n\ny &lt;- as.character(x)\ny\n\n[1] \"1\" \"2\" \"3\"\n\ntypeof(y)\n\n[1] \"character\""
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#converting-between-types-1",
    "href": "slides/08-data-types-classes-slides.html#converting-between-types-1",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwith intention…\n\n\n\n\nx &lt;- c(TRUE, FALSE)\nx\n\n[1]  TRUE FALSE\n\ntypeof(x)\n\n[1] \"logical\"\n\n\n\n\ny &lt;- as.numeric(x)\ny\n\n[1] 1 0\n\ntypeof(y)\n\n[1] \"double\""
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#converting-between-types-2",
    "href": "slides/08-data-types-classes-slides.html#converting-between-types-2",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwithout intention…\n\n\nc(2, \"Just this one!\")\n\n[1] \"2\"              \"Just this one!\"\n\n\n\nR will happily convert between various types without complaint when different types of data are concatenated in a vector, and that’s not always a great thing!"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#converting-between-types-3",
    "href": "slides/08-data-types-classes-slides.html#converting-between-types-3",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwithout intention…\n\n\nc(FALSE, 3L)\n\n[1] 0 3\n\n\n\n\nc(1.2, 3L)\n\n[1] 1.2 3.0\n\n\n\n\n\nc(2L, \"two\")\n\n[1] \"2\"   \"two\""
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#explicit-vs.-implicit-coercion",
    "href": "slides/08-data-types-classes-slides.html#explicit-vs.-implicit-coercion",
    "title": "Data types and classes",
    "section": "Explicit vs. implicit coercion",
    "text": "Explicit vs. implicit coercion\n\n\nExplicit coercion:\nWhen you call a function like as.logical(), as.numeric(), as.integer(), as.double(), or as.character().\n\nImplicit coercion:\nHappens when you use a vector in a specific context that expects a certain type of vector."
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#data-classes-1",
    "href": "slides/08-data-types-classes-slides.html#data-classes-1",
    "title": "Data types and classes",
    "section": "Data classes",
    "text": "Data classes\n\n\nVectors are like Lego building blocks\nWe stick them together to build more complicated constructs, e.g. representations of data\n\nThe class attribute relates to the S3 class of an object which determines its behaviour\n\nYou don’t need to worry about what S3 classes really mean, but you can read more about it here if you’re curious\n\n\nExamples: factors, dates, and data frames"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#factors",
    "href": "slides/08-data-types-classes-slides.html#factors",
    "title": "Data types and classes",
    "section": "Factors",
    "text": "Factors\nR uses factors to handle categorical variables, variables that have a fixed and known set of possible values\n\nclass_years &lt;- factor(\n  c(\n    \"First-year\", \"Sophomore\", \"Sophomore\", \"Senior\", \"Junior\"\n    )\n  )\nclass_years\n\n[1] First-year Sophomore  Sophomore  Senior     Junior    \nLevels: First-year Junior Senior Sophomore\n\n\n\n\n\ntypeof(class_years)\n\n[1] \"integer\"\n\n\n\n\nclass(class_years)\n\n[1] \"factor\""
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#more-on-factors",
    "href": "slides/08-data-types-classes-slides.html#more-on-factors",
    "title": "Data types and classes",
    "section": "More on factors",
    "text": "More on factors\nWe can think of factors like character (level labels) and an integer (level numbers) glued together\n\nglimpse(class_years)\n\n Factor w/ 4 levels \"First-year\",\"Junior\",..: 1 4 4 3 2\n\n\n\nas.integer(class_years)\n\n[1] 1 4 4 3 2"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#dates",
    "href": "slides/08-data-types-classes-slides.html#dates",
    "title": "Data types and classes",
    "section": "Dates",
    "text": "Dates\n\ntoday &lt;- as.Date(\"2024-09-24\")\ntoday\n\n[1] \"2024-09-24\"\n\n\n\ntypeof(today)\n\n[1] \"double\"\n\n\n\nclass(today)\n\n[1] \"Date\""
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#more-on-dates",
    "href": "slides/08-data-types-classes-slides.html#more-on-dates",
    "title": "Data types and classes",
    "section": "More on dates",
    "text": "More on dates\nWe can think of dates like an integer (the number of days since the origin, 1 Jan 1970) and an integer (the origin) glued together\n\nas.integer(today)\n\n[1] 19990\n\n\n\nas.integer(today) / 365 # roughly 55 yrs\n\n[1] 54.76712"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#data-frames",
    "href": "slides/08-data-types-classes-slides.html#data-frames",
    "title": "Data types and classes",
    "section": "Data frames",
    "text": "Data frames\nWe can think of data frames like like vectors of equal length glued together\n\ndf &lt;- data.frame(x = 1:2, y = 3:4)\ndf\n\n  x y\n1 1 3\n2 2 4\n\n\n\n\n\ntypeof(df)\n\n[1] \"list\"\n\n\n\n\nclass(df)\n\n[1] \"data.frame\""
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#lists",
    "href": "slides/08-data-types-classes-slides.html#lists",
    "title": "Data types and classes",
    "section": "Lists",
    "text": "Lists\nLists are a generic vector container; vectors of any type can go in them\n\nl &lt;- list(\n  x = 1:4,\n  y = c(\"hi\", \"hello\", \"jello\"),\n  z = c(TRUE, FALSE)\n)\nl\n\n$x\n[1] 1 2 3 4\n\n$y\n[1] \"hi\"    \"hello\" \"jello\"\n\n$z\n[1]  TRUE FALSE"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#lists-and-data-frames",
    "href": "slides/08-data-types-classes-slides.html#lists-and-data-frames",
    "title": "Data types and classes",
    "section": "Lists and data frames",
    "text": "Lists and data frames\n\nA data frame is a special list containing vectors of equal length\n\n\ndf\n\n  x y\n1 1 3\n2 2 4\n\n\n\nWhen we use the pull() function, we extract a vector from the data frame\n\n\ndf |&gt;\n  pull(y)\n\n[1] 3 4"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#read-data-in-as-character-strings",
    "href": "slides/08-data-types-classes-slides.html#read-data-in-as-character-strings",
    "title": "Data types and classes",
    "section": "Read data in as character strings",
    "text": "Read data in as character strings\n\nsurvey\n\n# A tibble: 61 × 3\n   Timestamp     tue_classes year      \n   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;     \n 1 9/23/24 19:57 2           Sophomore \n 2 9/23/24 19:58 3           First-year\n 3 9/23/24 20:06 2           Sophomore \n 4 9/23/24 20:09 2           Sophomore \n 5 9/23/24 21:48 0           Senior    \n 6 9/24/24 9:44  2           First-year\n 7 9/24/24 10:15 2           Senior    \n 8 9/24/24 10:50 2           Sophomore \n 9 9/24/24 10:54 3           First-year\n10 9/24/24 11:08 2           Senior    \n# ℹ 51 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#but-coerce-when-plotting",
    "href": "slides/08-data-types-classes-slides.html#but-coerce-when-plotting",
    "title": "Data types and classes",
    "section": "But coerce when plotting",
    "text": "But coerce when plotting\n\nggplot(survey, mapping = aes(x = year)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#use-forcats-to-reorder-levels",
    "href": "slides/08-data-types-classes-slides.html#use-forcats-to-reorder-levels",
    "title": "Data types and classes",
    "section": "Use forcats to reorder levels",
    "text": "Use forcats to reorder levels"
  },
  {
    "objectID": "slides/08-data-types-classes-slides.html#a-peek-into-forcats",
    "href": "slides/08-data-types-classes-slides.html#a-peek-into-forcats",
    "title": "Data types and classes",
    "section": "A peek into forcats",
    "text": "A peek into forcats\nReordering levels by:\n\nfct_relevel(): hand\nfct_infreq(): frequency\nfct_reorder(): sorting along another variable\nfct_rev(): reversing\n\n…\n\nChanging level values by:\n\nfct_lump(): lumping uncommon levels together into “other”\nfct_other(): manually replacing some levels with “other”\n\n…"
  },
  {
    "objectID": "slides/08-data-types-classes.html#while-you-wait",
    "href": "slides/08-data-types-classes.html#while-you-wait",
    "title": "Data types and classes",
    "section": "While you wait…",
    "text": "While you wait…\n\n\n\n\nLoading…\n\n\nPrepare for today’s application exercise: ae-08-durham-climate-factors\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-08-durham-climate-factors.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/08-data-types-classes.html#lab-1-feedback",
    "href": "slides/08-data-types-classes.html#lab-1-feedback",
    "title": "Data types and classes",
    "section": "Lab 1 feedback",
    "text": "Lab 1 feedback\n\n\nDescribing a distribution:\n\nshape (modality and skewness)\ncenter (with calculated value or estimated value or range)\nspread (with calculated value or estimated value or range)\nunusual observations (and, where possible, explanation for why they’re unusual)\n\n\nDescribing a relationship:\n\ndirection (positive or negative)\nform (linear or non-linear)\nstrength\nunusual observations (and, where possible, explanation for why they’re unusual)"
  },
  {
    "objectID": "slides/08-data-types-classes.html#lab-1-commits",
    "href": "slides/08-data-types-classes.html#lab-1-commits",
    "title": "Data types and classes",
    "section": "Lab 1 commits",
    "text": "Lab 1 commits"
  },
  {
    "objectID": "slides/08-data-types-classes.html#regrade-request-policy",
    "href": "slides/08-data-types-classes.html#regrade-request-policy",
    "title": "Data types and classes",
    "section": "Regrade request policy",
    "text": "Regrade request policy\nhttps://sta199-f24.github.io/course-syllabus.html#regrade-requests\n\n\nConsidered for errors in grade calculation or if a correct answer was mistakenly marked as incorrect\n\nNot a mechanism for:\n\ndisputing the number of points deducted for an incorrect response\nasking for clarification on feedback (come to office hours instead)\n\n\nDue on Gradescope within a week after an assignment is returned\nThe entire assignment may be regraded, which could result in an adjustment in either direction\nNo regrade requests after the final exam has been administered"
  },
  {
    "objectID": "slides/08-data-types-classes.html#how-many-classes-do-you-have-on-tuesdays",
    "href": "slides/08-data-types-classes.html#how-many-classes-do-you-have-on-tuesdays",
    "title": "Data types and classes",
    "section": "How many classes do you have on Tuesdays?",
    "text": "How many classes do you have on Tuesdays?\n\nsurvey\n\n# A tibble: 61 × 3\n   Timestamp     How many classes do you have o…¹ `What year are you?`\n   &lt;chr&gt;         &lt;chr&gt;                            &lt;chr&gt;               \n 1 9/23/24 19:57 2                                Sophomore           \n 2 9/23/24 19:58 3                                First-year          \n 3 9/23/24 20:06 2                                Sophomore           \n 4 9/23/24 20:09 2                                Sophomore           \n 5 9/23/24 21:48 0                                Senior              \n 6 9/24/24 9:44  2                                First-year          \n 7 9/24/24 10:15 2                                Senior              \n 8 9/24/24 10:50 2                                Sophomore           \n 9 9/24/24 10:54 3                                First-year          \n10 9/24/24 11:08 2                                Senior              \n# ℹ 51 more rows\n# ℹ abbreviated name: ¹​`How many classes do you have on Tuesdays?`"
  },
  {
    "objectID": "slides/08-data-types-classes.html#rename-variables",
    "href": "slides/08-data-types-classes.html#rename-variables",
    "title": "Data types and classes",
    "section": "\nrename() variables",
    "text": "rename() variables\nTo make them easier to work with…\n\nsurvey &lt;- survey |&gt;\n  rename(\n    tue_classes = `How many classes do you have on Tuesdays?`,\n    year = `What year are you?`\n  )"
  },
  {
    "objectID": "slides/08-data-types-classes.html#variable-types",
    "href": "slides/08-data-types-classes.html#variable-types",
    "title": "Data types and classes",
    "section": "Variable types",
    "text": "Variable types\n\nWhat type of variable is tue_classes?\n\n\nsurvey\n\n# A tibble: 61 × 3\n   Timestamp     tue_classes year      \n   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;     \n 1 9/23/24 19:57 2           Sophomore \n 2 9/23/24 19:58 3           First-year\n 3 9/23/24 20:06 2           Sophomore \n 4 9/23/24 20:09 2           Sophomore \n 5 9/23/24 21:48 0           Senior    \n 6 9/24/24 9:44  2           First-year\n 7 9/24/24 10:15 2           Senior    \n 8 9/24/24 10:50 2           Sophomore \n 9 9/24/24 10:54 3           First-year\n10 9/24/24 11:08 2           Senior    \n# ℹ 51 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes.html#lets-attempt-to-clean-it-up",
    "href": "slides/08-data-types-classes.html#lets-attempt-to-clean-it-up",
    "title": "Data types and classes",
    "section": "Let’s (attempt to) clean it up…",
    "text": "Let’s (attempt to) clean it up…"
  },
  {
    "objectID": "slides/08-data-types-classes.html#data-types-in-r",
    "href": "slides/08-data-types-classes.html#data-types-in-r",
    "title": "Data types and classes",
    "section": "Data types in R",
    "text": "Data types in R\n\nlogical\ndouble\ninteger\ncharacter\nand some more, but we won’t be focusing on those"
  },
  {
    "objectID": "slides/08-data-types-classes.html#logical-character",
    "href": "slides/08-data-types-classes.html#logical-character",
    "title": "Data types and classes",
    "section": "Logical & character",
    "text": "Logical & character\n\n\nlogical - Boolean values TRUE and FALSE\n\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\n\n\ncharacter - character strings\n\n\ntypeof(\"First-year\")\n\n[1] \"character\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#double-integer",
    "href": "slides/08-data-types-classes.html#double-integer",
    "title": "Data types and classes",
    "section": "Double & integer",
    "text": "Double & integer\n\n\ndouble - floating point numerical values (default numerical type)\n\n\ntypeof(2.5)\n\n[1] \"double\"\n\ntypeof(3)\n\n[1] \"double\"\n\n\n\n\ninteger - integer numerical values (indicated with an L)\n\n\ntypeof(3L)\n\n[1] \"integer\"\n\ntypeof(1:3)\n\n[1] \"integer\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#concatenation",
    "href": "slides/08-data-types-classes.html#concatenation",
    "title": "Data types and classes",
    "section": "Concatenation",
    "text": "Concatenation\nVectors can be constructed using the c() function.\n\nNumeric vector:\n\n\nc(1, 2, 3)\n\n[1] 1 2 3\n\n\n. . .\n\nCharacter vector:\n\n\nc(\"Hello\", \"World!\")\n\n[1] \"Hello\"  \"World!\"\n\n\n. . .\n\nVector made of vectors:\n\n\nc(c(\"hi\", \"hello\"), c(\"bye\", \"jello\"))\n\n[1] \"hi\"    \"hello\" \"bye\"   \"jello\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types",
    "href": "slides/08-data-types-classes.html#converting-between-types",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwith intention…\n\n\n\n\nx &lt;- 1:3\nx\n\n[1] 1 2 3\n\ntypeof(x)\n\n[1] \"integer\"\n\n\n\n\n\ny &lt;- as.character(x)\ny\n\n[1] \"1\" \"2\" \"3\"\n\ntypeof(y)\n\n[1] \"character\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types-1",
    "href": "slides/08-data-types-classes.html#converting-between-types-1",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwith intention…\n\n\n\n\nx &lt;- c(TRUE, FALSE)\nx\n\n[1]  TRUE FALSE\n\ntypeof(x)\n\n[1] \"logical\"\n\n\n\n\n\ny &lt;- as.numeric(x)\ny\n\n[1] 1 0\n\ntypeof(y)\n\n[1] \"double\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types-2",
    "href": "slides/08-data-types-classes.html#converting-between-types-2",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwithout intention…\n\n\nc(2, \"Just this one!\")\n\n[1] \"2\"              \"Just this one!\"\n\n\n. . .\nR will happily convert between various types without complaint when different types of data are concatenated in a vector, and that’s not always a great thing!"
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types-3",
    "href": "slides/08-data-types-classes.html#converting-between-types-3",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwithout intention…\n\n\nc(FALSE, 3L)\n\n[1] 0 3\n\n\n. . .\n\nc(1.2, 3L)\n\n[1] 1.2 3.0\n\n\n. . .\n\nc(2L, \"two\")\n\n[1] \"2\"   \"two\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#explicit-vs.-implicit-coercion",
    "href": "slides/08-data-types-classes.html#explicit-vs.-implicit-coercion",
    "title": "Data types and classes",
    "section": "Explicit vs. implicit coercion",
    "text": "Explicit vs. implicit coercion\n\n\nExplicit coercion:\nWhen you call a function like as.logical(), as.numeric(), as.integer(), as.double(), or as.character().\n\n\nImplicit coercion:\nHappens when you use a vector in a specific context that expects a certain type of vector."
  },
  {
    "objectID": "slides/08-data-types-classes.html#data-classes-1",
    "href": "slides/08-data-types-classes.html#data-classes-1",
    "title": "Data types and classes",
    "section": "Data classes",
    "text": "Data classes\n\n\nVectors are like Lego building blocks\nWe stick them together to build more complicated constructs, e.g. representations of data\n\nThe class attribute relates to the S3 class of an object which determines its behaviour\n\nYou don’t need to worry about what S3 classes really mean, but you can read more about it here if you’re curious\n\n\nExamples: factors, dates, and data frames"
  },
  {
    "objectID": "slides/08-data-types-classes.html#factors",
    "href": "slides/08-data-types-classes.html#factors",
    "title": "Data types and classes",
    "section": "Factors",
    "text": "Factors\nR uses factors to handle categorical variables, variables that have a fixed and known set of possible values\n\nclass_years &lt;- factor(\n  c(\n    \"First-year\", \"Sophomore\", \"Sophomore\", \"Senior\", \"Junior\"\n    )\n  )\nclass_years\n\n[1] First-year Sophomore  Sophomore  Senior     Junior    \nLevels: First-year Junior Senior Sophomore\n\n\n\n\n\ntypeof(class_years)\n\n[1] \"integer\"\n\n\n\n\n\nclass(class_years)\n\n[1] \"factor\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#more-on-factors",
    "href": "slides/08-data-types-classes.html#more-on-factors",
    "title": "Data types and classes",
    "section": "More on factors",
    "text": "More on factors\nWe can think of factors like character (level labels) and an integer (level numbers) glued together\n\nglimpse(class_years)\n\n Factor w/ 4 levels \"First-year\",\"Junior\",..: 1 4 4 3 2\n\n\n\nas.integer(class_years)\n\n[1] 1 4 4 3 2"
  },
  {
    "objectID": "slides/08-data-types-classes.html#dates",
    "href": "slides/08-data-types-classes.html#dates",
    "title": "Data types and classes",
    "section": "Dates",
    "text": "Dates\n\ntoday &lt;- as.Date(\"2024-09-24\")\ntoday\n\n[1] \"2024-09-24\"\n\n\n\ntypeof(today)\n\n[1] \"double\"\n\n\n\nclass(today)\n\n[1] \"Date\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#more-on-dates",
    "href": "slides/08-data-types-classes.html#more-on-dates",
    "title": "Data types and classes",
    "section": "More on dates",
    "text": "More on dates\nWe can think of dates like an integer (the number of days since the origin, 1 Jan 1970) and an integer (the origin) glued together\n\nas.integer(today)\n\n[1] 19990\n\n\n\nas.integer(today) / 365 # roughly 55 yrs\n\n[1] 54.76712"
  },
  {
    "objectID": "slides/08-data-types-classes.html#data-frames",
    "href": "slides/08-data-types-classes.html#data-frames",
    "title": "Data types and classes",
    "section": "Data frames",
    "text": "Data frames\nWe can think of data frames like like vectors of equal length glued together\n\ndf &lt;- data.frame(x = 1:2, y = 3:4)\ndf\n\n  x y\n1 1 3\n2 2 4\n\n\n\n\n\ntypeof(df)\n\n[1] \"list\"\n\n\n\n\nclass(df)\n\n[1] \"data.frame\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#lists",
    "href": "slides/08-data-types-classes.html#lists",
    "title": "Data types and classes",
    "section": "Lists",
    "text": "Lists\nLists are a generic vector container; vectors of any type can go in them\n\nl &lt;- list(\n  x = 1:4,\n  y = c(\"hi\", \"hello\", \"jello\"),\n  z = c(TRUE, FALSE)\n)\nl\n\n$x\n[1] 1 2 3 4\n\n$y\n[1] \"hi\"    \"hello\" \"jello\"\n\n$z\n[1]  TRUE FALSE"
  },
  {
    "objectID": "slides/08-data-types-classes.html#lists-and-data-frames",
    "href": "slides/08-data-types-classes.html#lists-and-data-frames",
    "title": "Data types and classes",
    "section": "Lists and data frames",
    "text": "Lists and data frames\n\nA data frame is a special list containing vectors of equal length\n\n\ndf\n\n  x y\n1 1 3\n2 2 4\n\n\n\nWhen we use the pull() function, we extract a vector from the data frame\n\n\ndf |&gt;\n  pull(y)\n\n[1] 3 4"
  },
  {
    "objectID": "slides/08-data-types-classes.html#read-data-in-as-character-strings",
    "href": "slides/08-data-types-classes.html#read-data-in-as-character-strings",
    "title": "Data types and classes",
    "section": "Read data in as character strings",
    "text": "Read data in as character strings\n\nsurvey\n\n# A tibble: 61 × 3\n   Timestamp     tue_classes year      \n   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;     \n 1 9/23/24 19:57 2           Sophomore \n 2 9/23/24 19:58 3           First-year\n 3 9/23/24 20:06 2           Sophomore \n 4 9/23/24 20:09 2           Sophomore \n 5 9/23/24 21:48 0           Senior    \n 6 9/24/24 9:44  2           First-year\n 7 9/24/24 10:15 2           Senior    \n 8 9/24/24 10:50 2           Sophomore \n 9 9/24/24 10:54 3           First-year\n10 9/24/24 11:08 2           Senior    \n# ℹ 51 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes.html#but-coerce-when-plotting",
    "href": "slides/08-data-types-classes.html#but-coerce-when-plotting",
    "title": "Data types and classes",
    "section": "But coerce when plotting",
    "text": "But coerce when plotting\n\nggplot(survey, mapping = aes(x = year)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/08-data-types-classes.html#use-forcats-to-reorder-levels",
    "href": "slides/08-data-types-classes.html#use-forcats-to-reorder-levels",
    "title": "Data types and classes",
    "section": "Use forcats to reorder levels",
    "text": "Use forcats to reorder levels"
  },
  {
    "objectID": "slides/08-data-types-classes.html#a-peek-into-forcats",
    "href": "slides/08-data-types-classes.html#a-peek-into-forcats",
    "title": "Data types and classes",
    "section": "A peek into forcats",
    "text": "A peek into forcats\nReordering levels by:\n\nfct_relevel(): hand\nfct_infreq(): frequency\nfct_reorder(): sorting along another variable\nfct_rev(): reversing\n\n…\n. . .\nChanging level values by:\n\nfct_lump(): lumping uncommon levels together into “other”\nfct_other(): manually replacing some levels with “other”\n\n…"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#announcements",
    "href": "slides/01-meet-the-toolkit-slides.html#announcements",
    "title": "Meet the toolkit",
    "section": "Announcements",
    "text": "Announcements\n\nIf you have not yet completed the Getting to know you survey, please do so asap!\nIf you have not yet accepted the invite to join the course GitHub Organization (I’m looking at 25 of you as of this morning!), please do so asap!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#additional-resource",
    "href": "slides/01-meet-the-toolkit-slides.html#additional-resource",
    "title": "Meet the toolkit",
    "section": "Additional resource",
    "text": "Additional resource\n\nPeer tutoring\nMore info at https://sta199-f24.github.io/course-support.html#peer-tutoring"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#five-tips-for-success",
    "href": "slides/01-meet-the-toolkit-slides.html#five-tips-for-success",
    "title": "Meet the toolkit",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class.\nAsk questions.\nDo the readings.\nDo the lab.\nDon’t procrastinate – at least on a weekly basis!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#course-toolkit-1",
    "href": "slides/01-meet-the-toolkit-slides.html#course-toolkit-1",
    "title": "Meet the toolkit",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n\nCourse operation\n\nMaterials: sta199-f24.github.io\n\nSubmission: Gradescope\nDiscussion: Ed Discussion\nGradebook: Canvas\n\n\nDoing data science\n\nComputing:\n\nR\nRStudio\ntidyverse\nQuarto\n\n\nVersion control and collaboration:\n\nGit\nGitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#learning-goals",
    "href": "slides/01-meet-the-toolkit-slides.html#learning-goals",
    "title": "Meet the toolkit",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the course, you will be able to…\n\n\ngain insight from data\ngain insight from data, reproducibly\n\ngain insight from data, reproducibly, using modern programming tools and techniques\n\ngain insight from data, reproducibly and collaboratively, using modern programming tools and techniques\ngain insight from data, reproducibly (with literate programming and version control) and collaboratively, using modern programming tools and techniques"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#reproducibility-checklist",
    "href": "slides/01-meet-the-toolkit-slides.html#reproducibility-checklist",
    "title": "Meet the toolkit",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for a data analysis to be “reproducible”?\n\n\nShort-term goals:\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done?\n\n\n\nLong-term goals:\n\nCan the code be used for other data?\nCan you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#toolkit-for-reproducibility",
    "href": "slides/01-meet-the-toolkit-slides.html#toolkit-for-reproducibility",
    "title": "Meet the toolkit",
    "section": "Toolkit for reproducibility",
    "text": "Toolkit for reproducibility\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#r-and-rstudio-1",
    "href": "slides/01-meet-the-toolkit-slides.html#r-and-rstudio-1",
    "title": "Meet the toolkit",
    "section": "R and RStudio",
    "text": "R and RStudio\n\n\n\n\n\n\n\nR is an open-source statistical programming language\n\nR is also an environment for statistical computing and graphics\nIt’s easily extensible with packages\n\n\n\n\n\nRStudio is a convenient interface for R called an IDE (integrated development environment), e.g. “I write R code in the RStudio IDE”\n\nRStudio is not a requirement for programming with R, but it’s very commonly used by R programmers and data scientists"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#r-vs.-rstudio",
    "href": "slides/01-meet-the-toolkit-slides.html#r-vs.-rstudio",
    "title": "Meet the toolkit",
    "section": "R vs. RStudio",
    "text": "R vs. RStudio\n\n\n\n\n\n\nSource: Modern Dive."
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#r-packages",
    "href": "slides/01-meet-the-toolkit-slides.html#r-packages",
    "title": "Meet the toolkit",
    "section": "R packages",
    "text": "R packages\n\n\nPackages: Fundamental units of reproducible R code, including reusable R functions, the documentation that describes how to use them, and sample data1\nAs of 27 August 2024, there are 21,168 R packages available on CRAN (the Comprehensive R Archive Network)2\nWe’re going to work with a small (but important) subset of these!\n\n\n\n\n1 Wickham and Bryan, R Packages.\n2CRAN contributed packages."
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#tour-r-rstudio",
    "href": "slides/01-meet-the-toolkit-slides.html#tour-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour: R + RStudio",
    "text": "Tour: R + RStudio\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\nOption 2:\nGo to your container and launch RStudio."
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#tour-recap-r-rstudio",
    "href": "slides/01-meet-the-toolkit-slides.html#tour-recap-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour recap: R + RStudio",
    "text": "Tour recap: R + RStudio"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#packages",
    "href": "slides/01-meet-the-toolkit-slides.html#packages",
    "title": "Meet the toolkit",
    "section": "Packages",
    "text": "Packages\n\nInstalled with install.packages(), once per system:\n\n\ninstall.packages(\"palmerpenguins\")\n\n\n\n\n\n\n\nNote\n\n\nWe already pre-installed many of the package you’ll need for this course, so you might go the whole semester without needing to run install.packages()!\n\n\n\n\n\nLoaded with library(), once per session:\n\n\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#packages-an-analogy",
    "href": "slides/01-meet-the-toolkit-slides.html#packages-an-analogy",
    "title": "Meet the toolkit",
    "section": "Packages, an analogy",
    "text": "Packages, an analogy\nIf data analysis was cooking…\n\n\nInstalling a package would be like buying ingredients from the store\nLoading a package would be like getting the ingredients out of your pantry and setting them on your counter top to be used"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#tidyverse",
    "href": "slides/01-meet-the-toolkit-slides.html#tidyverse",
    "title": "Meet the toolkit",
    "section": "tidyverse",
    "text": "tidyverse\n\naka the package you’ll hear about the most…\n\n\n\n\n\ntidyverse.org\n\nThe tidyverse is an opinionated collection of R packages designed for data science\nAll packages share an underlying philosophy and a common grammar"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#data-frames-and-variables",
    "href": "slides/01-meet-the-toolkit-slides.html#data-frames-and-variables",
    "title": "Meet the toolkit",
    "section": "Data frames and variables",
    "text": "Data frames and variables\n\nEach row of a data frame is an observation\n\n\n\n\nEach column of a data frame is a variable\n\n\n\n\n\nColumns (variables) in data frames can be accessed with $:\n\n\ndataframe$variable_name"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#penguins-data-frame",
    "href": "slides/01-meet-the-toolkit-slides.html#penguins-data-frame",
    "title": "Meet the toolkit",
    "section": "\npenguins data frame",
    "text": "penguins data frame"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#bill_length_mm",
    "href": "slides/01-meet-the-toolkit-slides.html#bill_length_mm",
    "title": "Meet the toolkit",
    "section": "bill_length_mm",
    "text": "bill_length_mm"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#flipper_length_mm",
    "href": "slides/01-meet-the-toolkit-slides.html#flipper_length_mm",
    "title": "Meet the toolkit",
    "section": "flipper_length_mm",
    "text": "flipper_length_mm\n\nFirst, run the code below and read the error. Then, fix the code to access the flipper_length_mm variable in the penguins data frame."
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#functionargument",
    "href": "slides/01-meet-the-toolkit-slides.html#functionargument",
    "title": "Meet the toolkit",
    "section": "function(argument)",
    "text": "function(argument)\nFunctions are (most often) verbs, followed by what they will be applied to in parentheses:\n\ndo_this(to_this)\ndo_that(to_this, to_that, with_those)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#trimmed-mean",
    "href": "slides/01-meet-the-toolkit-slides.html#trimmed-mean",
    "title": "Meet the toolkit",
    "section": "\ntrimmed mean()\n",
    "text": "trimmed mean()"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#help",
    "href": "slides/01-meet-the-toolkit-slides.html#help",
    "title": "Meet the toolkit",
    "section": "Help",
    "text": "Help\nObject documentation can be accessed with ?\n\n\n\n?mean\n\n\nVideo"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#a-pause-common-birthdays",
    "href": "slides/01-meet-the-toolkit-slides.html#a-pause-common-birthdays",
    "title": "Meet the toolkit",
    "section": "A pause – Common birthdays \n",
    "text": "A pause – Common birthdays \n\n\nI cleaned up your data!\n\n\n\nNo thanks to the people who responded “yo” or “The fifth day in the month of October!!” or “may twentieth”! 🤣\n\n\n\n\n\nDates with more than one student with a birthday:\n\n\n\n# A tibble: 65 × 2\n   birthday     n\n   &lt;chr&gt;    &lt;int&gt;\n 1 04-05        4\n 2 04-15        4\n 3 05-20        4\n 4 06-18        4\n 5 10-25        4\n 6 01-24        3\n 7 03-15        3\n 8 03-29        3\n 9 04-19        3\n10 04-22        3\n11 05-15        3\n12 06-25        3\n13 07-26        3\n14 08-29        3\n15 09-11        3\n16 11-19        3\n17 12-20        3\n18 01-07        2\n19 01-08        2\n20 01-13        2\n21 01-20        2\n22 01-21        2\n23 01-23        2\n24 01-25        2\n25 01-27        2\n26 02-07        2\n27 02-18        2\n28 03-07        2\n29 03-14        2\n30 03-16        2\n31 03-22        2\n32 03-23        2\n33 03-28        2\n34 03-30        2\n35 04-06        2\n36 04-12        2\n37 05-01        2\n38 05-05        2\n39 05-11        2\n40 05-12        2\n41 05-28        2\n42 05-30        2\n43 06-02        2\n44 06-04        2\n45 06-28        2\n46 07-22        2\n47 08-09        2\n48 08-16        2\n49 09-04        2\n50 09-15        2\n51 09-17        2\n52 09-19        2\n53 09-28        2\n54 09-30        2\n55 10-12        2\n56 10-14        2\n57 10-28        2\n58 11-03        2\n59 11-06        2\n60 11-07        2\n61 11-14        2\n62 11-16        2\n63 11-17        2\n64 11-21        2\n65 12-03        2"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#git-and-github",
    "href": "slides/01-meet-the-toolkit-slides.html#git-and-github",
    "title": "Meet the toolkit",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\n\n\n\n\n\n\nGit is a version control system – like “Track Changes” features from Microsoft Word, on steroids\nIt’s not the only version control system, but it’s a very popular one\n\n\n\n\n\n\n\nGitHub is the home for your Git-based projects on the internet – like DropBox but much, much better\nWe will use GitHub as a platform for web hosting and collaboration (and as our course management system!)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#versioning---done-badly",
    "href": "slides/01-meet-the-toolkit-slides.html#versioning---done-badly",
    "title": "Meet the toolkit",
    "section": "Versioning - done badly",
    "text": "Versioning - done badly"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#versioning---done-better",
    "href": "slides/01-meet-the-toolkit-slides.html#versioning---done-better",
    "title": "Meet the toolkit",
    "section": "Versioning - done better",
    "text": "Versioning - done better"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#versioning---done-even-better",
    "href": "slides/01-meet-the-toolkit-slides.html#versioning---done-even-better",
    "title": "Meet the toolkit",
    "section": "Versioning - done even better",
    "text": "Versioning - done even better\n\nwith human readable messages"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-git-and-github",
    "href": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-git-and-github",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-git-and-github-1",
    "href": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-git-and-github-1",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-git-and-github-2",
    "href": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-git-and-github-2",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-git-and-github-3",
    "href": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-git-and-github-3",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#git-and-github-tips",
    "href": "slides/01-meet-the-toolkit-slides.html#git-and-github-tips",
    "title": "Meet the toolkit",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\n\nThere are millions of git commands – ok, that’s an exaggeration, but there are a lot of them – and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\nWe will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line – skip that and move on to the next resource unless you feel comfortable trying it out.\nThere is a great resource for working with git and R: happygitwithr.com. Some of the content in there is beyond the scope of this course, but it’s a good place to look for help."
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#tour-git-github",
    "href": "slides/01-meet-the-toolkit-slides.html#tour-git-github",
    "title": "Meet the toolkit",
    "section": "Tour: Git + GitHub",
    "text": "Tour: Git + GitHub\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\n\n\n\n\nNote\n\n\nYou’ll need to stick to this option if you haven’t yet accepted your GitHub invite and don’t have a repo created for you.\n\n\n\n\n\nOption 2:\nGo to the course GitHub organization and clone ae-your_github_name repo to your container."
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#tour-recap-git-github",
    "href": "slides/01-meet-the-toolkit-slides.html#tour-recap-git-github",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\n\nFind your application repo, that will always be named using the naming convention assignment_title-your_github_name\nClick on the green “Code” button, make sure SSH is selected, copy the repo URL"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#tour-recap-git-github-1",
    "href": "slides/01-meet-the-toolkit-slides.html#tour-recap-git-github-1",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\n\nIn RStudio, File &gt; New Project &gt; From Version Control &gt; Git\nPaste repo URL copied in previous step, then click tab to auto-fill the project name, then click Create Project\n\nFor one time only, type yes in the pop-up dialogue\n\n\nVideo"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#what-could-have-gone-wrong",
    "href": "slides/01-meet-the-toolkit-slides.html#what-could-have-gone-wrong",
    "title": "Meet the toolkit",
    "section": "What could have gone wrong?",
    "text": "What could have gone wrong?\n\nNever received GitHub invite \\(\\rightarrow\\) Fill out “Getting to know you survey\nNever accepted GitHub invite \\(\\rightarrow\\) Look for it in your email and accept it\nCloning repo fails \\(\\rightarrow\\) Review/redo Lab 0 steps for setting up SSH key\nStill no luck? Come by my office today (Thursday, 8/29) between 4-5pm or post on Ed for help"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#quarto-1",
    "href": "slides/01-meet-the-toolkit-slides.html#quarto-1",
    "title": "Meet the toolkit",
    "section": "Quarto",
    "text": "Quarto\n\n\nFully reproducible reports – each time you render the analysis is ran from the beginning\nCode goes in chunks narrative goes outside of chunks\nA visual editor for a familiar / Google docs-like editing experience"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#tour-quarto",
    "href": "slides/01-meet-the-toolkit-slides.html#tour-quarto",
    "title": "Meet the toolkit",
    "section": "Tour: Quarto",
    "text": "Tour: Quarto\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\n\n\n\n\nNote\n\n\nIf you chose (or had to choose) this option for the previous tour, or if you couldn’t clone your repo for any reason, you’ll need to stick to this option.\n\n\n\n\n\nOption 2:\nGo to RStudio and open the document ae-01-meet-the-penguins.qmd."
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#tour-recap-quarto",
    "href": "slides/01-meet-the-toolkit-slides.html#tour-recap-quarto",
    "title": "Meet the toolkit",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#tour-recap-git-github-2",
    "href": "slides/01-meet-the-toolkit-slides.html#tour-recap-git-github-2",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\nOnce we made changes to our Quarto document, we\n\nwent to the Git pane in RStudio\nstaged our changes by clicking the checkboxes next to the relevant files\ncommitted our changes with an informative commit message\npushed our changes to our application exercise repos\nconfirmed on GitHub that we could see our changes pushed from RStudio"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-quarto",
    "href": "slides/01-meet-the-toolkit-slides.html#how-will-we-use-quarto",
    "title": "Meet the toolkit",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise, lab, project, etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#whats-with-all-the-hexes",
    "href": "slides/01-meet-the-toolkit-slides.html#whats-with-all-the-hexes",
    "title": "Meet the toolkit",
    "section": "What’s with all the hexes?",
    "text": "What’s with all the hexes?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit-slides.html#we-have-hexes-too",
    "href": "slides/01-meet-the-toolkit-slides.html#we-have-hexes-too",
    "title": "Meet the toolkit",
    "section": "We have hexes too!",
    "text": "We have hexes too!\n\nGrab one before you leave!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#announcements",
    "href": "slides/01-meet-the-toolkit.html#announcements",
    "title": "Meet the toolkit",
    "section": "Announcements",
    "text": "Announcements\n\nIf you have not yet completed the Getting to know you survey, please do so asap!\nIf you have not yet accepted the invite to join the course GitHub Organization (I’m looking at 25 of you as of this morning!), please do so asap!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#additional-resource",
    "href": "slides/01-meet-the-toolkit.html#additional-resource",
    "title": "Meet the toolkit",
    "section": "Additional resource",
    "text": "Additional resource\n\nPeer tutoring\nMore info at https://sta199-f24.github.io/course-support.html#peer-tutoring"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#five-tips-for-success",
    "href": "slides/01-meet-the-toolkit.html#five-tips-for-success",
    "title": "Meet the toolkit",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class.\nAsk questions.\nDo the readings.\nDo the lab.\nDon’t procrastinate – at least on a weekly basis!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "href": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "title": "Meet the toolkit",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n\nCourse operation\n\nMaterials: sta199-f24.github.io\n\nSubmission: Gradescope\nDiscussion: Ed Discussion\nGradebook: Canvas\n\n\nDoing data science\n\nComputing:\n\nR\nRStudio\ntidyverse\nQuarto\n\n\nVersion control and collaboration:\n\nGit\nGitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#learning-goals",
    "href": "slides/01-meet-the-toolkit.html#learning-goals",
    "title": "Meet the toolkit",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the course, you will be able to…\n\n\ngain insight from data\ngain insight from data, reproducibly\n\ngain insight from data, reproducibly, using modern programming tools and techniques\n\ngain insight from data, reproducibly and collaboratively, using modern programming tools and techniques\ngain insight from data, reproducibly (with literate programming and version control) and collaboratively, using modern programming tools and techniques"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "href": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "title": "Meet the toolkit",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for a data analysis to be “reproducible”?\n\n. . .\nShort-term goals:\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done?\n\n. . .\nLong-term goals:\n\nCan the code be used for other data?\nCan you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "href": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "title": "Meet the toolkit",
    "section": "Toolkit for reproducibility",
    "text": "Toolkit for reproducibility\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-and-rstudio-1",
    "href": "slides/01-meet-the-toolkit.html#r-and-rstudio-1",
    "title": "Meet the toolkit",
    "section": "R and RStudio",
    "text": "R and RStudio\n\n\n\n\n\n\n\nR is an open-source statistical programming language\n\nR is also an environment for statistical computing and graphics\nIt’s easily extensible with packages\n\n\n\n\n\n\nRStudio is a convenient interface for R called an IDE (integrated development environment), e.g. “I write R code in the RStudio IDE”\n\nRStudio is not a requirement for programming with R, but it’s very commonly used by R programmers and data scientists"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-vs.-rstudio",
    "href": "slides/01-meet-the-toolkit.html#r-vs.-rstudio",
    "title": "Meet the toolkit",
    "section": "R vs. RStudio",
    "text": "R vs. RStudio\n\n\n\n\n\n\nSource: Modern Dive."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-packages",
    "href": "slides/01-meet-the-toolkit.html#r-packages",
    "title": "Meet the toolkit",
    "section": "R packages",
    "text": "R packages\n\n\nPackages: Fundamental units of reproducible R code, including reusable R functions, the documentation that describes how to use them, and sample data1\nAs of 27 August 2024, there are 21,168 R packages available on CRAN (the Comprehensive R Archive Network)2\nWe’re going to work with a small (but important) subset of these!\n\n\n\n\n1 Wickham and Bryan, R Packages.\n2CRAN contributed packages."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-r-rstudio",
    "href": "slides/01-meet-the-toolkit.html#tour-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour: R + RStudio",
    "text": "Tour: R + RStudio\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\nOption 2:\nGo to your container and launch RStudio."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-r-rstudio",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour recap: R + RStudio",
    "text": "Tour recap: R + RStudio"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#packages",
    "href": "slides/01-meet-the-toolkit.html#packages",
    "title": "Meet the toolkit",
    "section": "Packages",
    "text": "Packages\n\nInstalled with install.packages(), once per system:\n\n\ninstall.packages(\"palmerpenguins\")\n\n\n\n\n\n\n\nNote\n\n\n\nWe already pre-installed many of the package you’ll need for this course, so you might go the whole semester without needing to run install.packages()!\n\n\n. . .\n\nLoaded with library(), once per session:\n\n\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#packages-an-analogy",
    "href": "slides/01-meet-the-toolkit.html#packages-an-analogy",
    "title": "Meet the toolkit",
    "section": "Packages, an analogy",
    "text": "Packages, an analogy\nIf data analysis was cooking…\n\n\nInstalling a package would be like buying ingredients from the store\nLoading a package would be like getting the ingredients out of your pantry and setting them on your counter top to be used"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tidyverse",
    "href": "slides/01-meet-the-toolkit.html#tidyverse",
    "title": "Meet the toolkit",
    "section": "tidyverse",
    "text": "tidyverse\n\naka the package you’ll hear about the most…\n\n\n\n\n\n\ntidyverse.org\n\nThe tidyverse is an opinionated collection of R packages designed for data science\nAll packages share an underlying philosophy and a common grammar"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#data-frames-and-variables",
    "href": "slides/01-meet-the-toolkit.html#data-frames-and-variables",
    "title": "Meet the toolkit",
    "section": "Data frames and variables",
    "text": "Data frames and variables\n\nEach row of a data frame is an observation\n\n\n. . .\n\nEach column of a data frame is a variable\n\n\n. . .\n\nColumns (variables) in data frames can be accessed with $:\n\n\ndataframe$variable_name"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#penguins-data-frame",
    "href": "slides/01-meet-the-toolkit.html#penguins-data-frame",
    "title": "Meet the toolkit",
    "section": "\npenguins data frame",
    "text": "penguins data frame"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#bill_length_mm",
    "href": "slides/01-meet-the-toolkit.html#bill_length_mm",
    "title": "Meet the toolkit",
    "section": "bill_length_mm",
    "text": "bill_length_mm"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#flipper_length_mm",
    "href": "slides/01-meet-the-toolkit.html#flipper_length_mm",
    "title": "Meet the toolkit",
    "section": "flipper_length_mm",
    "text": "flipper_length_mm\n\nFirst, run the code below and read the error. Then, fix the code to access the flipper_length_mm variable in the penguins data frame."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#functionargument",
    "href": "slides/01-meet-the-toolkit.html#functionargument",
    "title": "Meet the toolkit",
    "section": "function(argument)",
    "text": "function(argument)\nFunctions are (most often) verbs, followed by what they will be applied to in parentheses:\n\ndo_this(to_this)\ndo_that(to_this, to_that, with_those)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#trimmed-mean",
    "href": "slides/01-meet-the-toolkit.html#trimmed-mean",
    "title": "Meet the toolkit",
    "section": "\ntrimmed mean()\n",
    "text": "trimmed mean()"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#help",
    "href": "slides/01-meet-the-toolkit.html#help",
    "title": "Meet the toolkit",
    "section": "Help",
    "text": "Help\nObject documentation can be accessed with ?\n\n\n\n?mean\n\n\nVideo"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#a-pause-common-birthdays",
    "href": "slides/01-meet-the-toolkit.html#a-pause-common-birthdays",
    "title": "Meet the toolkit",
    "section": "A pause – Common birthdays \n",
    "text": "A pause – Common birthdays \n\n\nI cleaned up your data!\n\n. . .\n\nNo thanks to the people who responded “yo” or “The fifth day in the month of October!!” or “may twentieth”! 🤣\n\n. . .\n\n\nDates with more than one student with a birthday:\n\n\n\n# A tibble: 65 × 2\n   birthday     n\n   &lt;chr&gt;    &lt;int&gt;\n 1 04-05        4\n 2 04-15        4\n 3 05-20        4\n 4 06-18        4\n 5 10-25        4\n 6 01-24        3\n 7 03-15        3\n 8 03-29        3\n 9 04-19        3\n10 04-22        3\n11 05-15        3\n12 06-25        3\n13 07-26        3\n14 08-29        3\n15 09-11        3\n16 11-19        3\n17 12-20        3\n18 01-07        2\n19 01-08        2\n20 01-13        2\n21 01-20        2\n22 01-21        2\n23 01-23        2\n24 01-25        2\n25 01-27        2\n26 02-07        2\n27 02-18        2\n28 03-07        2\n29 03-14        2\n30 03-16        2\n31 03-22        2\n32 03-23        2\n33 03-28        2\n34 03-30        2\n35 04-06        2\n36 04-12        2\n37 05-01        2\n38 05-05        2\n39 05-11        2\n40 05-12        2\n41 05-28        2\n42 05-30        2\n43 06-02        2\n44 06-04        2\n45 06-28        2\n46 07-22        2\n47 08-09        2\n48 08-16        2\n49 09-04        2\n50 09-15        2\n51 09-17        2\n52 09-19        2\n53 09-28        2\n54 09-30        2\n55 10-12        2\n56 10-14        2\n57 10-28        2\n58 11-03        2\n59 11-06        2\n60 11-07        2\n61 11-14        2\n62 11-16        2\n63 11-17        2\n64 11-21        2\n65 12-03        2"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#git-and-github",
    "href": "slides/01-meet-the-toolkit.html#git-and-github",
    "title": "Meet the toolkit",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\n\n\n\n\n\n\nGit is a version control system – like “Track Changes” features from Microsoft Word, on steroids\nIt’s not the only version control system, but it’s a very popular one\n\n\n\n\n\n\n\n\nGitHub is the home for your Git-based projects on the internet – like DropBox but much, much better\nWe will use GitHub as a platform for web hosting and collaboration (and as our course management system!)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#versioning---done-badly",
    "href": "slides/01-meet-the-toolkit.html#versioning---done-badly",
    "title": "Meet the toolkit",
    "section": "Versioning - done badly",
    "text": "Versioning - done badly"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#versioning---done-better",
    "href": "slides/01-meet-the-toolkit.html#versioning---done-better",
    "title": "Meet the toolkit",
    "section": "Versioning - done better",
    "text": "Versioning - done better"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#versioning---done-even-better",
    "href": "slides/01-meet-the-toolkit.html#versioning---done-even-better",
    "title": "Meet the toolkit",
    "section": "Versioning - done even better",
    "text": "Versioning - done even better\n\nwith human readable messages"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-1",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-1",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-2",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-2",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-3",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-3",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#git-and-github-tips",
    "href": "slides/01-meet-the-toolkit.html#git-and-github-tips",
    "title": "Meet the toolkit",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\n\nThere are millions of git commands – ok, that’s an exaggeration, but there are a lot of them – and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\nWe will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line – skip that and move on to the next resource unless you feel comfortable trying it out.\nThere is a great resource for working with git and R: happygitwithr.com. Some of the content in there is beyond the scope of this course, but it’s a good place to look for help."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-git-github",
    "href": "slides/01-meet-the-toolkit.html#tour-git-github",
    "title": "Meet the toolkit",
    "section": "Tour: Git + GitHub",
    "text": "Tour: Git + GitHub\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\n\n\n\n\nNote\n\n\n\nYou’ll need to stick to this option if you haven’t yet accepted your GitHub invite and don’t have a repo created for you.\n\n\n\n\nOption 2:\nGo to the course GitHub organization and clone ae-your_github_name repo to your container."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-git-github",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-git-github",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\n\nFind your application repo, that will always be named using the naming convention assignment_title-your_github_name\nClick on the green “Code” button, make sure SSH is selected, copy the repo URL"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-git-github-1",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-git-github-1",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\n\nIn RStudio, File &gt; New Project &gt; From Version Control &gt; Git\nPaste repo URL copied in previous step, then click tab to auto-fill the project name, then click Create Project\n\nFor one time only, type yes in the pop-up dialogue\n\n\nVideo"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#what-could-have-gone-wrong",
    "href": "slides/01-meet-the-toolkit.html#what-could-have-gone-wrong",
    "title": "Meet the toolkit",
    "section": "What could have gone wrong?",
    "text": "What could have gone wrong?\n\nNever received GitHub invite \\(\\rightarrow\\) Fill out “Getting to know you survey\nNever accepted GitHub invite \\(\\rightarrow\\) Look for it in your email and accept it\nCloning repo fails \\(\\rightarrow\\) Review/redo Lab 0 steps for setting up SSH key\nStill no luck? Come by my office today (Thursday, 8/29) between 4-5pm or post on Ed for help"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#quarto-1",
    "href": "slides/01-meet-the-toolkit.html#quarto-1",
    "title": "Meet the toolkit",
    "section": "Quarto",
    "text": "Quarto\n\n\nFully reproducible reports – each time you render the analysis is ran from the beginning\nCode goes in chunks narrative goes outside of chunks\nA visual editor for a familiar / Google docs-like editing experience"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-quarto",
    "href": "slides/01-meet-the-toolkit.html#tour-quarto",
    "title": "Meet the toolkit",
    "section": "Tour: Quarto",
    "text": "Tour: Quarto\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\n\n\n\n\nNote\n\n\n\nIf you chose (or had to choose) this option for the previous tour, or if you couldn’t clone your repo for any reason, you’ll need to stick to this option.\n\n\n\n\nOption 2:\nGo to RStudio and open the document ae-01-meet-the-penguins.qmd."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-quarto",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-quarto",
    "title": "Meet the toolkit",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-git-github-2",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-git-github-2",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\nOnce we made changes to our Quarto document, we\n\nwent to the Git pane in RStudio\nstaged our changes by clicking the checkboxes next to the relevant files\ncommitted our changes with an informative commit message\npushed our changes to our application exercise repos\nconfirmed on GitHub that we could see our changes pushed from RStudio"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-quarto",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-quarto",
    "title": "Meet the toolkit",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise, lab, project, etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#whats-with-all-the-hexes",
    "href": "slides/01-meet-the-toolkit.html#whats-with-all-the-hexes",
    "title": "Meet the toolkit",
    "section": "What’s with all the hexes?",
    "text": "What’s with all the hexes?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#we-have-hexes-too",
    "href": "slides/01-meet-the-toolkit.html#we-have-hexes-too",
    "title": "Meet the toolkit",
    "section": "We have hexes too!",
    "text": "We have hexes too!\n\nGrab one before you leave!"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#while-you-wait",
    "href": "slides/07-joining-data-slides.html#while-you-wait",
    "title": "Joining data",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-07-taxes-join\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-07-taxes-join.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/07-joining-data-slides.html#announcements",
    "href": "slides/07-joining-data-slides.html#announcements",
    "title": "Joining data",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#notes-from-lab-1-submissions",
    "href": "slides/07-joining-data-slides.html#notes-from-lab-1-submissions",
    "title": "Joining data",
    "section": "Notes from Lab 1 submissions",
    "text": "Notes from Lab 1 submissions\nUse of AI tools:\n\nIf using an AI tool for code, CITE!\n\n\n\nThe bare minimum citation must include the AI tool you’re using (e.g., ChatGPT) and your prompt. The prompt you use cannot be copied and pasted directly from the assignment; you must create a prompt yourself.\n\nIf we suspect code was generated with by / with the help of an AI tool but not cited, it’s an automatic 0 on that question + potentially further penalties as outlined in https://sta199-f24.github.io/course-syllabus.html#academic-honesty.\n\n\nIf using an AI tool for narrative, STOP!"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#notes-from-lab-1-submissions-1",
    "href": "slides/07-joining-data-slides.html#notes-from-lab-1-submissions-1",
    "title": "Joining data",
    "section": "Notes from Lab 1 submissions",
    "text": "Notes from Lab 1 submissions\n\nPlot labeling: Keep it concise and non-redundant (same info doesn’t need to be repeated, in detail, in axis labels and title).\n\nCode style and readability:\n\nLooking good overall!\nA tool that can help (but won’t get everything right):\n\nHighlight code you want to style\nClick on Addins (top of editor), scroll down to STYLER, select Style selection\n\n\n\n\nNarrative: Avoid lengthy or conflicting prose"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#recap-statsci-majors",
    "href": "slides/07-joining-data-slides.html#recap-statsci-majors",
    "title": "Joining data",
    "section": "Recap: StatSci majors",
    "text": "Recap: StatSci majors\n\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line()"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#recap-scales",
    "href": "slides/07-joining-data-slides.html#recap-scales",
    "title": "Joining data",
    "section": "Recap: Scales",
    "text": "Recap: Scales\n\nUpdate x-axis scale: 2012 to 2024, increments of 2 years.\n\n\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2))"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#recap-colors",
    "href": "slides/07-joining-data-slides.html#recap-colors",
    "title": "Joining data",
    "section": "Recap: Colors",
    "text": "Recap: Colors\n\nUse custom colors.\n\n\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  )"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#recap-labels-and-themes",
    "href": "slides/07-joining-data-slides.html#recap-labels-and-themes",
    "title": "Joining data",
    "section": "Recap: Labels and themes",
    "text": "Recap: Labels and themes\n\nAdd custom labels and change theme.\n\n\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#recap-legends",
    "href": "slides/07-joining-data-slides.html#recap-legends",
    "title": "Joining data",
    "section": "Recap: Legends",
    "text": "Recap: Legends\n\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(0.1, 0.7),\n    legend.background = element_rect(fill = \"white\", color = \"gray\")\n  )"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#recap-plot-sizing",
    "href": "slides/07-joining-data-slides.html#recap-plot-sizing",
    "title": "Joining data",
    "section": "Recap: Plot sizing",
    "text": "Recap: Plot sizing\n#| label: statsci-plot-5\n#| out-width: 100% \n#| fig-width: 8\n#| fig-asp: 0.5\n# plot code goes here"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#recap-data-tidying",
    "href": "slides/07-joining-data-slides.html#recap-data-tidying",
    "title": "Joining data",
    "section": "Recap: Data tidying",
    "text": "Recap: Data tidying\n\n\nData sets can’t be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate."
  },
  {
    "objectID": "slides/07-joining-data-slides.html#whats-going-on-in-this-plot",
    "href": "slides/07-joining-data-slides.html#whats-going-on-in-this-plot",
    "title": "Joining data",
    "section": "What’s going on in this plot?",
    "text": "What’s going on in this plot?\n\nCan you guess the variable plotted here?"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#sales-taxes-in-us-states",
    "href": "slides/07-joining-data-slides.html#sales-taxes-in-us-states",
    "title": "Joining data",
    "section": "Sales taxes in US states",
    "text": "Sales taxes in US states\n\nsales_taxes\n\n# A tibble: 51 × 5\n   state       state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;                &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Alabama             0.04               0.0529        0.0929\n 2 Alaska              0                  0.0182        0.0182\n 3 Arizona             0.056              0.0278        0.0838\n 4 Arkansas            0.065              0.0295        0.0945\n 5 California          0.0725             0.016         0.0885\n 6 Colorado            0.029              0.0491        0.0781\n 7 Connecticut         0.0635             0             0.0635\n 8 Delaware            0                  0             0     \n 9 Florida             0.06               0.01          0.07  \n10 Georgia             0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#sales-tax-in-swing-states",
    "href": "slides/07-joining-data-slides.html#sales-tax-in-swing-states",
    "title": "Joining data",
    "section": "Sales tax in swing states",
    "text": "Sales tax in swing states\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of swing states (Arizona, Georgia, Michigan, Nevada, North Carolina, Pennsylvania, and Wisconsin) vs. non-swing states.\n\nHow would you approach this task?\n\n\n\nCreate a new variable called swing_state with levels \"Swing\" and \"Non-swing\"\n\nGroup by swing_state\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#mutate-with-if_else",
    "href": "slides/07-joining-data-slides.html#mutate-with-if_else",
    "title": "Joining data",
    "section": "\nmutate() with if_else()\n",
    "text": "mutate() with if_else()\n\n\nCreate a new variable called swing_state with levels \"Swing\" and \"Non-swing\"."
  },
  {
    "objectID": "slides/07-joining-data-slides.html#recap-if_else",
    "href": "slides/07-joining-data-slides.html#recap-if_else",
    "title": "Joining data",
    "section": "Recap: if_else()\n",
    "text": "Recap: if_else()\n\nif_else(\n1  x == y,\n2  \"x is equal to y\",\n3  \"x is not equal to y\"\n)\n\n1\n\nCondition\n\n2\n\nValue if condition is TRUE\n\n3\n\nValue if condition is FALSE"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#sales-tax-in-swing-states-1",
    "href": "slides/07-joining-data-slides.html#sales-tax-in-swing-states-1",
    "title": "Joining data",
    "section": "Sales tax in swing states",
    "text": "Sales tax in swing states\n\nCompare the average state sales tax rates of swing states vs. non-swing states."
  },
  {
    "objectID": "slides/07-joining-data-slides.html#sales-tax-in-coastal-states",
    "href": "slides/07-joining-data-slides.html#sales-tax-in-coastal-states",
    "title": "Joining data",
    "section": "Sales tax in coastal states",
    "text": "Sales tax in coastal states\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of states on the Pacific Coast, states on the Atlantic Coast, and the rest of the states.\n\nHow would you approach this task?\n\n\n\nCreate a new variable called coast with levels \"Pacific\", \"Atlantic\", and \"Neither\"\n\nGroup by coast\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#mutate-with-case_when",
    "href": "slides/07-joining-data-slides.html#mutate-with-case_when",
    "title": "Joining data",
    "section": "\nmutate() with case_when()\n",
    "text": "mutate() with case_when()\n\n\nCreate a new variable called coast with levels \"Pacific\", \"Atlantic\", and \"Neither\"."
  },
  {
    "objectID": "slides/07-joining-data-slides.html#recap-case_when",
    "href": "slides/07-joining-data-slides.html#recap-case_when",
    "title": "Joining data",
    "section": "Recap: case_when()\n",
    "text": "Recap: case_when()\n\ncase_when(\n1  x &gt; y  ~ \"x is greater than y\",\n2  x &lt; y  ~ \"x is less than y\",\n3  .default = \"x is equal to y\"\n)\n\n1\n\nValue if first condition is TRUE\n\n2\n\nValue if second condition is TRUE\n\n3\n\nValue if neither condition is TRUE, i.e., default value"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#sales-tax-in-coastal-states-1",
    "href": "slides/07-joining-data-slides.html#sales-tax-in-coastal-states-1",
    "title": "Joining data",
    "section": "Sales tax in coastal states",
    "text": "Sales tax in coastal states\n\nCompare the average state sales tax rates of states on the Pacific Coast, states on the Atlantic Coast, and the rest of the states."
  },
  {
    "objectID": "slides/07-joining-data-slides.html#sales-tax-in-us-regions",
    "href": "slides/07-joining-data-slides.html#sales-tax-in-us-regions",
    "title": "Joining data",
    "section": "Sales tax in US regions",
    "text": "Sales tax in US regions\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of states in various regions (Midwest - 12 states, Northeast - 9 states, South - 16 states, West - 13 states).\n\nHow would you approach this task?\n\n\n\nCreate a new variable called region with levels \"Midwest\", \"Northeast\", \"South\", and \"West\".\nGroup by region\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#mutate-with-case_when-1",
    "href": "slides/07-joining-data-slides.html#mutate-with-case_when-1",
    "title": "Joining data",
    "section": "\nmutate() with case_when()\n",
    "text": "mutate() with case_when()\n\n\nWho feels like filling in the blanks lists of states in each region? Who feels like it’s simply too tedious to write out names of all states?"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#why-join",
    "href": "slides/07-joining-data-slides.html#why-join",
    "title": "Joining data",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nIs there a relationship between\n- number of QS courses taken\n- having scored a 4 or 5 on the AP stats exam\n- motivation for taking course\n- …\nand performance in this course?”\n\n\nEach of these would require joining class performance data with an outside data source so we can have all relevant information (columns) in a single data frame."
  },
  {
    "objectID": "slides/07-joining-data-slides.html#why-join-1",
    "href": "slides/07-joining-data-slides.html#why-join-1",
    "title": "Joining data",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nCompare the average state sales tax rates of states in various regions (Midwest - 12 states, Northeast - 9 states, South - 16 states, West - 13 states).\n\n\nThis can also be solved with joining region information with the state-level sales tax data."
  },
  {
    "objectID": "slides/07-joining-data-slides.html#setup",
    "href": "slides/07-joining-data-slides.html#setup",
    "title": "Joining data",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n\n\n\nx &lt;- tibble(\n  id = c(1, 2, 3),\n  value_x = c(\"x1\", \"x2\", \"x3\")\n  )\n\nx\n\n# A tibble: 3 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny &lt;- tibble(\n  id = c(1, 2, 4),\n  value_y = c(\"y1\", \"y2\", \"y4\")\n  )\n\ny\n\n# A tibble: 3 × 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#left_join",
    "href": "slides/07-joining-data-slides.html#left_join",
    "title": "Joining data",
    "section": "left_join()",
    "text": "left_join()\n\n\n\n\n\nleft_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#right_join",
    "href": "slides/07-joining-data-slides.html#right_join",
    "title": "Joining data",
    "section": "right_join()",
    "text": "right_join()\n\n\n\n\n\nright_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#full_join",
    "href": "slides/07-joining-data-slides.html#full_join",
    "title": "Joining data",
    "section": "full_join()",
    "text": "full_join()\n\n\n\n\n\nfull_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 4 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#inner_join",
    "href": "slides/07-joining-data-slides.html#inner_join",
    "title": "Joining data",
    "section": "inner_join()",
    "text": "inner_join()\n\n\n\n\n\ninner_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 2 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#semi_join",
    "href": "slides/07-joining-data-slides.html#semi_join",
    "title": "Joining data",
    "section": "semi_join()",
    "text": "semi_join()\n\n\n\n\n\nsemi_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 2 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#anti_join",
    "href": "slides/07-joining-data-slides.html#anti_join",
    "title": "Joining data",
    "section": "anti_join()",
    "text": "anti_join()\n\n\n\n\n\nanti_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 1 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     3 x3"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#goal",
    "href": "slides/07-joining-data-slides.html#goal",
    "title": "Joining data",
    "section": "Goal",
    "text": "Goal\nCompare the average state sales tax rates of states in various regions (Midwest, Northeast, South, West), where the input data are:\n\nStates and sales taxes\nStates and regions"
  },
  {
    "objectID": "slides/07-joining-data-slides.html#ae-07-taxes-join",
    "href": "slides/07-joining-data-slides.html#ae-07-taxes-join",
    "title": "Joining data",
    "section": "ae-07-taxes-join",
    "text": "ae-07-taxes-join\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-07-taxes-join.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/07-joining-data.html#while-you-wait",
    "href": "slides/07-joining-data.html#while-you-wait",
    "title": "Joining data",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-07-taxes-join\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-07-taxes-join.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/07-joining-data.html#announcements",
    "href": "slides/07-joining-data.html#announcements",
    "title": "Joining data",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "slides/07-joining-data.html#notes-from-lab-1-submissions",
    "href": "slides/07-joining-data.html#notes-from-lab-1-submissions",
    "title": "Joining data",
    "section": "Notes from Lab 1 submissions",
    "text": "Notes from Lab 1 submissions\nUse of AI tools:\n\nIf using an AI tool for code, CITE!\n\n\n\nThe bare minimum citation must include the AI tool you’re using (e.g., ChatGPT) and your prompt. The prompt you use cannot be copied and pasted directly from the assignment; you must create a prompt yourself.\n\nIf we suspect code was generated with by / with the help of an AI tool but not cited, it’s an automatic 0 on that question + potentially further penalties as outlined in https://sta199-f24.github.io/course-syllabus.html#academic-honesty.\n. . .\n\nIf using an AI tool for narrative, STOP!"
  },
  {
    "objectID": "slides/07-joining-data.html#notes-from-lab-1-submissions-1",
    "href": "slides/07-joining-data.html#notes-from-lab-1-submissions-1",
    "title": "Joining data",
    "section": "Notes from Lab 1 submissions",
    "text": "Notes from Lab 1 submissions\n\nPlot labeling: Keep it concise and non-redundant (same info doesn’t need to be repeated, in detail, in axis labels and title).\n\nCode style and readability:\n\nLooking good overall!\nA tool that can help (but won’t get everything right):\n\nHighlight code you want to style\nClick on Addins (top of editor), scroll down to STYLER, select Style selection\n\n\n\n\nNarrative: Avoid lengthy or conflicting prose"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-statsci-majors",
    "href": "slides/07-joining-data.html#recap-statsci-majors",
    "title": "Joining data",
    "section": "Recap: StatSci majors",
    "text": "Recap: StatSci majors\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line()"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-scales",
    "href": "slides/07-joining-data.html#recap-scales",
    "title": "Joining data",
    "section": "Recap: Scales",
    "text": "Recap: Scales\n\nUpdate x-axis scale: 2012 to 2024, increments of 2 years.\n\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2))"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-colors",
    "href": "slides/07-joining-data.html#recap-colors",
    "title": "Joining data",
    "section": "Recap: Colors",
    "text": "Recap: Colors\n\nUse custom colors.\n\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  )"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-labels-and-themes",
    "href": "slides/07-joining-data.html#recap-labels-and-themes",
    "title": "Joining data",
    "section": "Recap: Labels and themes",
    "text": "Recap: Labels and themes\n\nAdd custom labels and change theme.\n\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-legends",
    "href": "slides/07-joining-data.html#recap-legends",
    "title": "Joining data",
    "section": "Recap: Legends",
    "text": "Recap: Legends\n\nggplot(\n  statsci_longer, \n  aes(\n    x = year, y = n, color = degree_type\n    )\n  ) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(0.1, 0.7),\n    legend.background = element_rect(fill = \"white\", color = \"gray\")\n  )"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-plot-sizing",
    "href": "slides/07-joining-data.html#recap-plot-sizing",
    "title": "Joining data",
    "section": "Recap: Plot sizing",
    "text": "Recap: Plot sizing\n#| label: statsci-plot-5\n#| out-width: 100% \n#| fig-width: 8\n#| fig-asp: 0.5\n# plot code goes here"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-data-tidying",
    "href": "slides/07-joining-data.html#recap-data-tidying",
    "title": "Joining data",
    "section": "Recap: Data tidying",
    "text": "Recap: Data tidying\n\n\nData sets can’t be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate."
  },
  {
    "objectID": "slides/07-joining-data.html#whats-going-on-in-this-plot",
    "href": "slides/07-joining-data.html#whats-going-on-in-this-plot",
    "title": "Joining data",
    "section": "What’s going on in this plot?",
    "text": "What’s going on in this plot?\n\nCan you guess the variable plotted here?"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-taxes-in-us-states",
    "href": "slides/07-joining-data.html#sales-taxes-in-us-states",
    "title": "Joining data",
    "section": "Sales taxes in US states",
    "text": "Sales taxes in US states\n\nsales_taxes\n\n# A tibble: 51 × 5\n   state       state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;                &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Alabama             0.04               0.0529        0.0929\n 2 Alaska              0                  0.0182        0.0182\n 3 Arizona             0.056              0.0278        0.0838\n 4 Arkansas            0.065              0.0295        0.0945\n 5 California          0.0725             0.016         0.0885\n 6 Colorado            0.029              0.0491        0.0781\n 7 Connecticut         0.0635             0             0.0635\n 8 Delaware            0                  0             0     \n 9 Florida             0.06               0.01          0.07  \n10 Georgia             0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-swing-states",
    "href": "slides/07-joining-data.html#sales-tax-in-swing-states",
    "title": "Joining data",
    "section": "Sales tax in swing states",
    "text": "Sales tax in swing states\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of swing states (Arizona, Georgia, Michigan, Nevada, North Carolina, Pennsylvania, and Wisconsin) vs. non-swing states.\n\nHow would you approach this task?\n\n. . .\n\nCreate a new variable called swing_state with levels \"Swing\" and \"Non-swing\"\n\nGroup by swing_state\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data.html#mutate-with-if_else",
    "href": "slides/07-joining-data.html#mutate-with-if_else",
    "title": "Joining data",
    "section": "\nmutate() with if_else()\n",
    "text": "mutate() with if_else()\n\n\nCreate a new variable called swing_state with levels \"Swing\" and \"Non-swing\"."
  },
  {
    "objectID": "slides/07-joining-data.html#recap-if_else",
    "href": "slides/07-joining-data.html#recap-if_else",
    "title": "Joining data",
    "section": "Recap: if_else()\n",
    "text": "Recap: if_else()\n\nif_else(\n  x == y,\n  \"x is equal to y\",\n  \"x is not equal to y\"\n)\n\n1\n\nCondition\n\n2\n\nValue if condition is TRUE\n\n3\n\nValue if condition is FALSE"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-swing-states-1",
    "href": "slides/07-joining-data.html#sales-tax-in-swing-states-1",
    "title": "Joining data",
    "section": "Sales tax in swing states",
    "text": "Sales tax in swing states\n\nCompare the average state sales tax rates of swing states vs. non-swing states."
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-coastal-states",
    "href": "slides/07-joining-data.html#sales-tax-in-coastal-states",
    "title": "Joining data",
    "section": "Sales tax in coastal states",
    "text": "Sales tax in coastal states\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of states on the Pacific Coast, states on the Atlantic Coast, and the rest of the states.\n\nHow would you approach this task?\n\n. . .\n\nCreate a new variable called coast with levels \"Pacific\", \"Atlantic\", and \"Neither\"\n\nGroup by coast\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data.html#mutate-with-case_when",
    "href": "slides/07-joining-data.html#mutate-with-case_when",
    "title": "Joining data",
    "section": "\nmutate() with case_when()\n",
    "text": "mutate() with case_when()\n\n\nCreate a new variable called coast with levels \"Pacific\", \"Atlantic\", and \"Neither\"."
  },
  {
    "objectID": "slides/07-joining-data.html#recap-case_when",
    "href": "slides/07-joining-data.html#recap-case_when",
    "title": "Joining data",
    "section": "Recap: case_when()\n",
    "text": "Recap: case_when()\n\ncase_when(\n  x &gt; y  ~ \"x is greater than y\",\n  x &lt; y  ~ \"x is less than y\",\n  .default = \"x is equal to y\"\n)\n\n1\n\nValue if first condition is TRUE\n\n2\n\nValue if second condition is TRUE\n\n3\n\nValue if neither condition is TRUE, i.e., default value"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-coastal-states-1",
    "href": "slides/07-joining-data.html#sales-tax-in-coastal-states-1",
    "title": "Joining data",
    "section": "Sales tax in coastal states",
    "text": "Sales tax in coastal states\n\nCompare the average state sales tax rates of states on the Pacific Coast, states on the Atlantic Coast, and the rest of the states."
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-us-regions",
    "href": "slides/07-joining-data.html#sales-tax-in-us-regions",
    "title": "Joining data",
    "section": "Sales tax in US regions",
    "text": "Sales tax in US regions\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of states in various regions (Midwest - 12 states, Northeast - 9 states, South - 16 states, West - 13 states).\n\nHow would you approach this task?\n\n. . .\n\nCreate a new variable called region with levels \"Midwest\", \"Northeast\", \"South\", and \"West\".\nGroup by region\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data.html#mutate-with-case_when-1",
    "href": "slides/07-joining-data.html#mutate-with-case_when-1",
    "title": "Joining data",
    "section": "\nmutate() with case_when()\n",
    "text": "mutate() with case_when()\n\n\nWho feels like filling in the blanks lists of states in each region? Who feels like it’s simply too tedious to write out names of all states?"
  },
  {
    "objectID": "slides/07-joining-data.html#why-join",
    "href": "slides/07-joining-data.html#why-join",
    "title": "Joining data",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nIs there a relationship between\n- number of QS courses taken\n- having scored a 4 or 5 on the AP stats exam\n- motivation for taking course\n- …\nand performance in this course?”\n\n. . .\nEach of these would require joining class performance data with an outside data source so we can have all relevant information (columns) in a single data frame."
  },
  {
    "objectID": "slides/07-joining-data.html#why-join-1",
    "href": "slides/07-joining-data.html#why-join-1",
    "title": "Joining data",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nCompare the average state sales tax rates of states in various regions (Midwest - 12 states, Northeast - 9 states, South - 16 states, West - 13 states).\n\n. . .\nThis can also be solved with joining region information with the state-level sales tax data."
  },
  {
    "objectID": "slides/07-joining-data.html#setup",
    "href": "slides/07-joining-data.html#setup",
    "title": "Joining data",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n\n\n\nx &lt;- tibble(\n  id = c(1, 2, 3),\n  value_x = c(\"x1\", \"x2\", \"x3\")\n  )\n\nx\n\n# A tibble: 3 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny &lt;- tibble(\n  id = c(1, 2, 4),\n  value_y = c(\"y1\", \"y2\", \"y4\")\n  )\n\ny\n\n# A tibble: 3 × 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/07-joining-data.html#left_join",
    "href": "slides/07-joining-data.html#left_join",
    "title": "Joining data",
    "section": "left_join()",
    "text": "left_join()\n\n\n\n\n\nleft_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#right_join",
    "href": "slides/07-joining-data.html#right_join",
    "title": "Joining data",
    "section": "right_join()",
    "text": "right_join()\n\n\n\n\n\nright_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data.html#full_join",
    "href": "slides/07-joining-data.html#full_join",
    "title": "Joining data",
    "section": "full_join()",
    "text": "full_join()\n\n\n\n\n\nfull_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 4 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data.html#inner_join",
    "href": "slides/07-joining-data.html#inner_join",
    "title": "Joining data",
    "section": "inner_join()",
    "text": "inner_join()\n\n\n\n\n\ninner_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 2 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2"
  },
  {
    "objectID": "slides/07-joining-data.html#semi_join",
    "href": "slides/07-joining-data.html#semi_join",
    "title": "Joining data",
    "section": "semi_join()",
    "text": "semi_join()\n\n\n\n\n\nsemi_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 2 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2"
  },
  {
    "objectID": "slides/07-joining-data.html#anti_join",
    "href": "slides/07-joining-data.html#anti_join",
    "title": "Joining data",
    "section": "anti_join()",
    "text": "anti_join()\n\n\n\n\n\nanti_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 1 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     3 x3"
  },
  {
    "objectID": "slides/07-joining-data.html#goal",
    "href": "slides/07-joining-data.html#goal",
    "title": "Joining data",
    "section": "Goal",
    "text": "Goal\nCompare the average state sales tax rates of states in various regions (Midwest, Northeast, South, West), where the input data are:\n\nStates and sales taxes\nStates and regions"
  },
  {
    "objectID": "slides/07-joining-data.html#ae-07-taxes-join",
    "href": "slides/07-joining-data.html#ae-07-taxes-join",
    "title": "Joining data",
    "section": "ae-07-taxes-join",
    "text": "ae-07-taxes-join\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-07-taxes-join.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/18-model-selection-overfitting-slides.html#while-you-wait",
    "href": "slides/18-model-selection-overfitting-slides.html#while-you-wait",
    "title": "Model selection and overfitting",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you missed class last Thursday, pull to get today’s application exercise file: ae-15-modeling-loans.qmd.\nMake sure you’ve completed the “Get to know the data” section of your AE."
  },
  {
    "objectID": "slides/18-model-selection-overfitting-slides.html#announcements",
    "href": "slides/18-model-selection-overfitting-slides.html#announcements",
    "title": "Model selection and overfitting",
    "section": "Announcements",
    "text": "Announcements\n\nMy office hours this week:\n\nI’ll hold them at a modified time: 1-2 pm on Wednesday at Old Chem 213 (in place of Dav’s office hours)\nDav will fill in for me 2-4 pm on Wednesday at Old Chem 203B\n\n\nMake sure you’re caught up with prepare materials before Thursday’s class"
  },
  {
    "objectID": "slides/18-model-selection-overfitting-slides.html#what-is-the-difference-between-r2-and-adjusted-r2",
    "href": "slides/18-model-selection-overfitting-slides.html#what-is-the-difference-between-r2-and-adjusted-r2",
    "title": "Model selection and overfitting",
    "section": "What is the difference between \\(R^2\\) and adjusted \\(R^2\\)?",
    "text": "What is the difference between \\(R^2\\) and adjusted \\(R^2\\)?\n\n\n\\(R^2\\):\n\nProportion of variability in the outcome explained by the model.\nUseful for quantifying the fit of a given model.\n\n\n\nAdjusted \\(R^2\\):\n\nProportion of variability in the outcome explained by the model, with a penalty added for the number of predictors in the model.\nUseful for comparing models."
  },
  {
    "objectID": "slides/18-model-selection-overfitting-slides.html#finish-up-thursdays-ae",
    "href": "slides/18-model-selection-overfitting-slides.html#finish-up-thursdays-ae",
    "title": "Model selection and overfitting",
    "section": "Finish up Thursday’s AE",
    "text": "Finish up Thursday’s AE\n\n\nGo to your ae project in RStudio.\nGet back to working on ae-15-modeling-loans\n\n\nGoals:\n\nReview prediction and interpretation of model results\nReview main and interaction effects models\nDiscuss model selection further"
  },
  {
    "objectID": "slides/18-model-selection-overfitting-slides.html#recap",
    "href": "slides/18-model-selection-overfitting-slides.html#recap",
    "title": "Model selection and overfitting",
    "section": "Recap",
    "text": "Recap\n\nWhat is the practical difference between a model with parallel and non-parallel lines?\nWhat is the definition of R-squared?\nWhy do we choose models based on adjusted R-squared and not R-squared?"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#while-you-wait",
    "href": "slides/18-model-selection-overfitting.html#while-you-wait",
    "title": "Model selection and overfitting",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you missed class last Thursday, pull to get today’s application exercise file: ae-15-modeling-loans.qmd.\nMake sure you’ve completed the “Get to know the data” section of your AE."
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#announcements",
    "href": "slides/18-model-selection-overfitting.html#announcements",
    "title": "Model selection and overfitting",
    "section": "Announcements",
    "text": "Announcements\n\nMy office hours this week:\n\nI’ll hold them at a modified time: 1-2 pm on Wednesday at Old Chem 213 (in place of Dav’s office hours)\nDav will fill in for me 2-4 pm on Wednesday at Old Chem 203B\n\n\nMake sure you’re caught up with prepare materials before Thursday’s class"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#what-is-the-difference-between-r2-and-adjusted-r2",
    "href": "slides/18-model-selection-overfitting.html#what-is-the-difference-between-r2-and-adjusted-r2",
    "title": "Model selection and overfitting",
    "section": "What is the difference between \\(R^2\\) and adjusted \\(R^2\\)?",
    "text": "What is the difference between \\(R^2\\) and adjusted \\(R^2\\)?\n\n\n\\(R^2\\):\n\nProportion of variability in the outcome explained by the model.\nUseful for quantifying the fit of a given model.\n\n\n\nAdjusted \\(R^2\\):\n\nProportion of variability in the outcome explained by the model, with a penalty added for the number of predictors in the model.\nUseful for comparing models."
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#finish-up-thursdays-ae",
    "href": "slides/18-model-selection-overfitting.html#finish-up-thursdays-ae",
    "title": "Model selection and overfitting",
    "section": "Finish up Thursday’s AE",
    "text": "Finish up Thursday’s AE\n\n\nGo to your ae project in RStudio.\nGet back to working on ae-15-modeling-loans\n\n\nGoals:\n\nReview prediction and interpretation of model results\nReview main and interaction effects models\nDiscuss model selection further"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#recap",
    "href": "slides/18-model-selection-overfitting.html#recap",
    "title": "Model selection and overfitting",
    "section": "Recap",
    "text": "Recap\n\nWhat is the practical difference between a model with parallel and non-parallel lines?\nWhat is the definition of R-squared?\nWhy do we choose models based on adjusted R-squared and not R-squared?"
  },
  {
    "objectID": "computing-cheatsheets.html",
    "href": "computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://www.rstudio.com/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "project/3-improvement-progress.html",
    "href": "project/3-improvement-progress.html",
    "title": "Improvement and progress",
    "section": "",
    "text": "By this point you’ve received feedback on your proposal and you should be working on incorporating that feedback to improve your project and making further progress on it. This milestone ensures you’re keeping on task and doing these things.\n\nGoals\nThe goals of this milestone are as follows:\n\nIncorporate feedback from your proposal\nMake progress on your project prior to the peer review\n\n\n\nInstructions\nMake some progress, evidenced by commits to your repo since project milestone 2. These commits should\n\nexplicitly closing issues opened as proposal feedback, and\nmake further progress on the project.\n\n\n\nGrading\nThis milestone will be graded for completion, not accuracy. We will check to see if the team has made commits to their repo since project milestone 2 and closed all issues that were opened as part of proposal feedback.\n\n0 points: No commits since project milestone 2\n1 point: Only a single commit since project milestone 2, regardless of how many issues closed\n2-4 points: More than 1 commit since project milestone 2 and but not all issues closed\n5 points: More than 1 commit since project milestone 2 and all issues closed\n\n\n\n\n\n\n\nNote\n\n\n\nThere won’t be a lab session dedicated to this milestone. You are to work with your team outside of class time to complete this task.",
    "crumbs": [
      "Project",
      "Milestone 3"
    ]
  },
  {
    "objectID": "project/4-peer-review.html",
    "href": "project/4-peer-review.html",
    "title": "Peer review",
    "section": "",
    "text": "During the peer feedback process, you will be provided read-only access to your partner team’s GitHub repo. You will provide your feedback in the form of GitHub issues to your partner team’s GitHub repo.\nGoals\nThe goals of this milestone are as follows:\n\nReview others’ project drafts as a team and provide feedback\nPost issues on GitHub using an issue template\nLearn from others’ projects and improve your own project based on their strengths and weaknesses\nInstructions\nReview two other teams’ projects. As a team you should spend ~30 minutes on each team’s project.\n\nFind the names of the teams whose projects you’re reviewing below. You should already have access to this team’s repo.\nEach team member should go to the repo of the team you’re reviewing.\n\nThen,\n\n1-2 team members clone the team’s project and renders it to check for reproducibility.\n1-2 team members open the team’s project in their browser and starts reading through the project draft.\n1 team member opens an issue on the team’s repo using the peer review template.\nAll team members discuss the project based on the prompts on the issue template and one team member records the feedback and submits the issue.\n\n\n\nTo open an issue in the repo you’re reviewing, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical reasoning aspect of the project, but do feel free to comment on aspects beyond the reasoning as well.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation?\nWere you able to reproduce the project by clicking on Render Website once you cloned it? Were there any issues with reproducibility?\nProvide constructive feedback on any issues with file and/or code organization.\nWhat have you learned from this team’s project that you are considering implementing in your own project?\n(Optional) Any further comments or feedback?\n\n\nReview pairings\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nL1 - 8:30 am\nL2 - 10:05 am\nL3 - 10:05 am\nL4 - 11:45 am\nL5 - 11:45 am\nL6 - 1:25 pm\nL7 - 1:25 pm\nL8 - 3:05 pm\nL9 - 3:05 pm\nL10 - 4:40 pm\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_1''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\nGIVJA\ntheoutliers\ndatadinos\n\n\ntheoutliers\ndatadinos\ntheAteam\n\n\ndatadinos\ntheAteam\nflamingos\n\n\ntheAteam\nflamingos\nthebusybees\n\n\nflamingos\nthebusybees\ntheelephants\n\n\nthebusybees\ntheelephants\nGIVJA\n\n\ntheelephants\nGIVJA\ntheoutliers\n\n\n\n\n\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_2''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\ngithub_lit\ncommitment_issue\narctic_coders\n\n\ncommitment_issue\narctic_coders\nrendeers\n\n\narctic_coders\nrendeers\nsyntax_samurai\n\n\nrendeers\nsyntax_samurai\nkraft_kings\n\n\nsyntax_samurai\nkraft_kings\nmission_impossible\n\n\nkraft_kings\nmission_impossible\ngithub_lit\n\n\nmission_impossible\ngithub_lit\ncommitment_issue\n\n\n\n\n\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_3''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\njmeg\n3D-coders\nBASK\n\n\n3D-coders\nBASK\nthe_outliers\n\n\nBASK\nthe_outliers\ndebug_divas\n\n\nthe_outliers\ndebug_divas\ndream_team\n\n\ndebug_divas\ndream_team\nClustered_Chaos\n\n\ndream_team\nClustered_Chaos\njmeg\n\n\nClustered_Chaos\njmeg\n3D-coders\n\n\n\n\n\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_4''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\nVermillion_Alligators\nStats_Squad_4F\nDevils_R_Us\n\n\nStats_Squad_4F\nDevils_R_Us\nPickleball\n\n\nDevils_R_Us\nPickleball\nThe_DJs\n\n\nPickleball\nThe_DJs\nSpeedy_Statisticians\n\n\nThe_DJs\nSpeedy_Statisticians\nBlue\n\n\nSpeedy_Statisticians\nBlue\nVermillion_Alligators\n\n\nBlue\nVermillion_Alligators\nStats_Squad_4F\n\n\n\n\n\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_5''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\nteam_great\nvariable_chaos\nsaved_by_the_bell_curve\n\n\nvariable_chaos\nsaved_by_the_bell_curve\nedwards_ensemble\n\n\nsaved_by_the_bell_curve\nedwards_ensemble\ndata_jemms\n\n\nedwards_ensemble\ndata_jemms\nmean_girls\n\n\ndata_jemms\nmean_girls\nsuper_cool_team\n\n\nmean_girls\nsuper_cool_team\ndata_dorks\n\n\nsuper_cool_team\ndata_dorks\nfaang_fans\n\n\ndata_dorks\nfaang_fans\nteam_great\n\n\nfaang_fans\nteam_great\nvariable_chaos\n\n\n\n\n\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_6''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\ncoding-goats\naardvark\nggplotters\n\n\naardvark\nggplotters\namee\n\n\nggplotters\namee\nmjca\n\n\namee\nmjca\npivot_better\n\n\nmjca\npivot_better\nr-masters\n\n\npivot_better\nr-masters\ncoding-goats\n\n\nr-masters\ncoding-goats\naardvark\n\n\n\n\n\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_7''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\njamm\nlatte\njada\n\n\nlatte\njada\nmuchahos\n\n\njada\nmuchahos\nstatistical-significance\n\n\nmuchahos\nstatistical-significance\na-team\n\n\nstatistical-significance\na-team\nstandard-deviants\n\n\na-team\nstandard-deviants\nsultans-of-stats\n\n\nstandard-deviants\nsultans-of-stats\nranch\n\n\nsultans-of-stats\nranch\njamm\n\n\nranch\njamm\nlatte\n\n\n\n\n\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_8''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\nblue-cheese\ntop-of-the-bell-curve\nbluebears\n\n\ntop-of-the-bell-curve\nbluebears\ncodebreakers\n\n\nbluebears\ncodebreakers\ntidyverse-titans\n\n\ncodebreakers\ntidyverse-titans\nthe-pipe\n\n\ntidyverse-titans\nthe-pipe\ndigital-warriors\n\n\nthe-pipe\ndigital-warriors\nblue-cheese\n\n\ndigital-warriors\nblue-cheese\ntop-of-the-bell-curve\n\n\n\n\n\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_9''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\nthe-data-devils\nquarto-crew\nblue-dolphins\n\n\nquarto-crew\nblue-dolphins\nr-studio-devils\n\n\nblue-dolphins\nr-studio-devils\nstats-stars\n\n\nr-studio-devils\nstats-stars\nspa-r-kles\n\n\nstats-stars\nspa-r-kles\ndyplr-maniacs\n\n\nspa-r-kles\ndyplr-maniacs\ntibble-twins\n\n\ndyplr-maniacs\ntibble-twins\nthe-data-devils\n\n\ntibble-twins\nthe-data-devils\nquarto-crew\n\n\n\n\n\n\n\n\n\n\n✔ Reading from \"STA199 - Fall 2024 - Project Milestone 4 Review Assignments\".\n\n\n✔ Range ''lab_10''.\n\n\n\n\n\n\n\n\n\n\n\nYour team name\nTeam to review 1\nTeam to review 2\n\n\n\nsigma-squad\nzebras\nstates199\n\n\nzebras\nstates199\nstats-shawties\n\n\nstates199\nstats-shawties\ndata-divas\n\n\nstats-shawties\ndata-divas\nstats-bros\n\n\ndata-divas\nstats-bros\nglobal-variables\n\n\nstats-bros\nglobal-variables\nsigma-squad\n\n\nglobal-variables\nsigma-squad\nzebras\n\n\n\n\n\n\n\n\n\nGrading\nPeer reviews will be graded on the extent to which it comprehensively and constructively addresses the components of the reviewee’s team’s report.\nOnly the team members participating in the review during the lab session are eligible for points for the peer review. If you’re unable to make it to lab in person, you should arrange to virtually connect with your team during your lab session.\n\n0 points: No peer review\n1 point: Feedback provided is not constructive or actionable\n2-4 points: Feedback provided is not sufficiently thorough\n5 points: Peer review is constructive, actionable, and sufficiently thorough\n\n\n\n\n\n\n\nNote\n\n\n\nThe feedback issue will come from one team member on GitHub since you can’t collectively edit an issue. However it must represent the opinions of the entire team. It is not a single team member’s responsibility to provide feedback, they’re just the record keeper for the team.",
    "crumbs": [
      "Project",
      "Milestone 4"
    ]
  },
  {
    "objectID": "project/2-proposal.html",
    "href": "project/2-proposal.html",
    "title": "Proposal",
    "section": "",
    "text": "The goals of this milestone are as follows:\n\nDiscuss topics you’re interested in investigating and find data sets on those topics.\nIdentify 2 data sets you’re interested in potentially using for the project.\nGet these datasets into R.\nWrite up reasons and justifications for why you want to work with these datasets.\nReview your team contract.\n\n\n\n\n\n\n\nImportant\n\n\n\nYou must use one of the data sets in the proposal for the final project, unless instructed otherwise when given feedback.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#criteria-for-datasets",
    "href": "project/2-proposal.html#criteria-for-datasets",
    "title": "Proposal",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 500 observations.\nAt least 8 columns.\nAt least 6 of the columns must be useful and unique explanatory variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\nYou can curate one of your datasets via web scraping.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#resources-for-datasets",
    "href": "project/2-proposal.html#resources-for-datasets",
    "title": "Proposal",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nUNICEF Data\nYouth Risk Behavior Surveillance System (YRBSS)\nGoogle Dataset Search\nData is Plural\nElection Studies\nUS Census Data\nWorld Bank Data\nCDC\nEuropean Statistics\nCORGIS: The Collection of ReallyGreat, Interesting, Situated Datasets\nGeneral Social Survey\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nResponsible Datasets in Context\nStatistics Canada\nTidyTuesday\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Government Data\nFRED Economic Data\nData.gov\nAwesome public datasets\nDurham Open Data Portal\nEdinburgh Open Data\nFiveThirtyEight",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#introduction-and-data",
    "href": "project/2-proposal.html#introduction-and-data",
    "title": "Proposal",
    "section": "Introduction and data",
    "text": "Introduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#research-question",
    "href": "project/2-proposal.html#research-question",
    "title": "Proposal",
    "section": "Research question",
    "text": "Research question\nYour research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#glimpse-of-data",
    "href": "project/2-proposal.html#glimpse-of-data",
    "title": "Proposal",
    "section": "Glimpse of data",
    "text": "Glimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the glimpse() function to provide a glimpse of the data set.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#data-dictionary",
    "href": "project/2-proposal.html#data-dictionary",
    "title": "Proposal",
    "section": "Data dictionary",
    "text": "Data dictionary\nFor each data set, add a data dictionary to the README.md file in the data folder describing each variable.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "ae/ae-12-modeling-fish.html",
    "href": "ae/ae-12-modeling-fish.html",
    "title": "AE 12: Modelling fish",
    "section": "",
    "text": "For this application exercise, we will work with data on fish. The dataset we will use, called fish, is on two common fish species in fish market sales.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nfish &lt;- read_csv(\"data/fish.csv\")\n\nThe data dictionary is below:\n\n\nvariable\ndescription\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\nVisualizing the model\nWe’re going to investigate the relationship between the weights and heights of fish.\n\nCreate an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\n\n\n# add code here\n\n\nIf you were to draw a a straight line to best represent the relationship between the heights and weights of fish, where would it go? Why?\n\nAdd response here.\n\nNow, let R draw the line for you.\n\n\n# add code here\n\n\nWhat types of questions can this plot help answer?\n\nAdd response here.\n\nWe can use this line to make predictions. Predict what you think the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm. Which prediction is considered extrapolation?\n\nAdd response here.\n\nWhat is a residual?\n\nAdd response here.\nModel fitting\n\n\nDemo: Fit a model to predict fish weights from their heights.\n\n\n# add code here\n\n\nPredict what the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm using this model.\n\n\n# add code here\n\n\n\nDemo: Calculate predicted weights for all fish in the data and visualize the residuals under this model.\n\n\n# add code here\n\nModel summary\n\n\nDemo: Display the model summary including estimates for the slope and intercept along with measurements of uncertainty around them. Show how you can extract these values from the model output.\n\n\n# add code here\n\n\n\nDemo: Write out your model using mathematical notation.\n\nAdd response here.\nCorrelation\nWe can also assess correlation between two quantitative variables.\n\nWhat is correlation? What are values correlation can take?\n\nAdd response here.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\nDemo: What is the correlation between heights and weights of fish?\n\n\n# add code here\n\nAdding a third variable\n\n\nDemo: Does the relationship between heights and weights of fish change if we take into consideration species? Plot two separate straight lines for the Bream and Roach species.\n\n\n# add code here\n\nFitting other models\n\n\nDemo: We can fit more models than just a straight line. Change the following code below to read method = \"loess\". What is different from the plot created before?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors.html",
    "href": "ae/ae-08-durham-climate-factors.html",
    "title": "AE 08: Durham climate + factors",
    "section": "",
    "text": "We will use the tidyverse package in this application exercise.\n\nlibrary(tidyverse)\n\n\nThe data come from https://www.usclimatedata.com/climate/durham/north-carolina/united-states/usnc0192 and are stored as durham-climate.csv in the data folder.\n\ndurham_climate &lt;- read_csv(\"data/durham-climate.csv\")\n\nAnd let’s take a look at the data.\n\ndurham_climate\n\n# A tibble: 12 × 4\n   month     avg_high_f avg_low_f precipitation_in\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n 1 January           49        28             4.45\n 2 February          53        29             3.7 \n 3 March             62        37             4.69\n 4 April             71        46             3.43\n 5 May               79        56             4.61\n 6 June              85        65             4.02\n 7 July              89        70             3.94\n 8 August            87        68             4.37\n 9 September         81        60             4.37\n10 October           71        47             3.7 \n11 November          62        37             3.39\n12 December          53        30             3.43"
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors.html#getting-started",
    "href": "ae/ae-08-durham-climate-factors.html#getting-started",
    "title": "AE 08: Durham climate + factors",
    "section": "",
    "text": "We will use the tidyverse package in this application exercise.\n\nlibrary(tidyverse)\n\n\nThe data come from https://www.usclimatedata.com/climate/durham/north-carolina/united-states/usnc0192 and are stored as durham-climate.csv in the data folder.\n\ndurham_climate &lt;- read_csv(\"data/durham-climate.csv\")\n\nAnd let’s take a look at the data.\n\ndurham_climate\n\n# A tibble: 12 × 4\n   month     avg_high_f avg_low_f precipitation_in\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n 1 January           49        28             4.45\n 2 February          53        29             3.7 \n 3 March             62        37             4.69\n 4 April             71        46             3.43\n 5 May               79        56             4.61\n 6 June              85        65             4.02\n 7 July              89        70             3.94\n 8 August            87        68             4.37\n 9 September         81        60             4.37\n10 October           71        47             3.7 \n11 November          62        37             3.39\n12 December          53        30             3.43"
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors.html#reorder",
    "href": "ae/ae-08-durham-climate-factors.html#reorder",
    "title": "AE 08: Durham climate + factors",
    "section": "Reorder",
    "text": "Reorder\nWhat’s wrong with the following plot?\nAdd your response here.\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 2,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  )\n\n\n\n\n\n\n\nFix the plot.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors.html#recode-and-reorder",
    "href": "ae/ae-08-durham-climate-factors.html#recode-and-reorder",
    "title": "AE 08: Durham climate + factors",
    "section": "Recode and reorder",
    "text": "Recode and reorder\nUpdate the plot above, coloring points based on season. Additionally:\n\nMake sure the legend is on top of the plot and the seasons appear in the legend in the order they appear in the plot (Winter, Spring, Summer, Fall).\n\nUse \"circle filled\" as the shape for points, set their size to 3 points, outline (stroke) to 1 point, and fill them in with the following colors:\n\nWinter: lightskyblue1\n\nSpring: chartreuse3\n\nSummer: gold2\n\nFall: lightsalmon4\n\n\n\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors.html#pivot",
    "href": "ae/ae-08-durham-climate-factors.html#pivot",
    "title": "AE 08: Durham climate + factors",
    "section": "Pivot",
    "text": "Pivot\nOverlay lines for both high and low temperatures on the same plot. Additionally, use different colors for the two lines – a darker color for high and a lighter color for low temperatures.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-06-majors-tidy-A.html",
    "href": "ae/ae-06-majors-tidy-A.html",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-06-majors-tidy-A.html#getting-started",
    "href": "ae/ae-06-majors-tidy-A.html#getting-started",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are available in the data folder.\n\nstatsci &lt;- read_csv(\"data/statsci.csv\")\n\nRows: 4 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): degree\ndbl (14): 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAnd let’s take a look at the data.\n\nstatsci\n\n# A tibble: 4 × 15\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statist…     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist…      2      2      4      1      3      6      3      4      4      1\n3 Statist…      2      6      1     NA      5      6      6      8      8     17\n4 Statist…      5      9      4     13     10     17     24     21     26     27\n# ℹ 4 more variables: `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;, `2024` &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-06-majors-tidy-A.html#pivoting",
    "href": "ae/ae-06-majors-tidy-A.html#pivoting",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "Pivoting",
    "text": "Pivoting\nPivot the statsci data frame longer such that\n\neach row represents a degree type / year combination,\n\nyear and number of graduates for that year are columns,\n\nyear is numerical,\n\nNAs in counts are replaced with 0s,\n\ndegree_type has levels BS, BS2, AB, and AB2 (in this order), and\nthe resulting data frame is saved as statsci_longer.\n\nReview the code below with your neighbor and come up with at least one question about the code.\n\nstatsci_longer &lt;- statsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n  )\n\nstatsci_longer\n\n# A tibble: 56 × 4\n   major               degree_type  year     n\n   &lt;chr&gt;               &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science AB2          2011     0\n 2 Statistical Science AB2          2012     1\n 3 Statistical Science AB2          2013     0\n 4 Statistical Science AB2          2014     0\n 5 Statistical Science AB2          2015     4\n 6 Statistical Science AB2          2016     4\n 7 Statistical Science AB2          2017     1\n 8 Statistical Science AB2          2018     0\n 9 Statistical Science AB2          2019     0\n10 Statistical Science AB2          2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "ae/ae-06-majors-tidy-A.html#plotting",
    "href": "ae/ae-06-majors-tidy-A.html#plotting",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "Plotting",
    "text": "Plotting\nStep 1: Basics\nLet’s start with a basic plot, nothing too fancy! Create a line plot of number of majors vs. year, where lines are colored by degree type, and the data are also represented as points on the lines.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\nWhat aspects of the plot need to be updated to go from the draft you created above to the goal plot from the slides.\n\nx-axis scale: need to go from 2012 to 2024 in increments of 2 years\nline colors\naxis labels: title, subtitle, x, y, caption\ntheme\nlegend position and border\nStep 2: Scales\nUpdate x-axis scale such that the years displayed go from 2012 to 2024 in increments of 2 years. Do this by adding on to your ggplot call from earlier.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2))\n\n\n\n\n\n\n\nStep 3: Colors\nUpdate line colors using the following level / color assignments. Once again, do this by adding on to your ggplot call from earlier.\n\n“BS” = “cadetblue4”\n“BS2” = “cadetblue3”\n“AB” = “lightgoldenrod4”\n“AB2” = “lightgoldenrod3”\n\nNote: A handy reference for named colors in R is http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf, though you can use HEX color codes as well.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  )\n\n\n\n\n\n\n\nStep 4: Labels and themes\nUpdate the plot labels (title, subtitle, x, y, and caption) and use theme_minimal(). Once again, do this by adding on to your ggplot call from earlier. Note: The link in the caption is https://registrar.duke.edu/registration/enrollment-statistics.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nStep 5: Legends and figure sizing via cell options\nFinally, adding to your pipeline you’ve developed so far, move the legend into the plot, make its background white, and its border gray. Additionally, in the cell options, set\n\n\nout-width: 100% – Output should span 100% of the width\n\nfig-width: 8 – Figure output should have a width of 8 inches\n\nfig-asp: 0.5 – Figure output should have an aspect ratio of 0.5, resulting in a height of 8 * 0.5 = 4 inches\n\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(0.1, 0.7),\n    legend.background = element_rect(fill = \"white\", color = \"gray\")\n  )"
  },
  {
    "objectID": "ae/ae-06-majors-tidy-A.html#render-commit-and-push",
    "href": "ae/ae-06-majors-tidy-A.html#render-commit-and-push",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz-A.html",
    "href": "ae/ae-02-bechdel-dataviz-A.html",
    "title": "AE 02: Bechdel + data visualization",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key.\nIn this mini-analysis, we use the data from the FiveThirtyEight story “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women.”\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz-A.html#getting-started",
    "href": "ae/ae-02-bechdel-dataviz-A.html#getting-started",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are stored as a CSV (comma-separated values) file in your repository’s data folder. Let’s read it from there and save it as an object called bechdel.\n\nbechdel &lt;- read_csv(\"data/bechdel.csv\")\n\nGet to know the data\nWe can use the glimpse() function to get an overview (or “glimpse”) of the data.\n\nglimpse(bechdel)\n\nRows: 1,615\nColumns: 7\n$ title       &lt;chr&gt; \"21 & Over\", \"Dredd 3D\", \"12 Years a Slave\", \"2 Guns\", \"42…\n$ year        &lt;dbl&gt; 2013, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n$ gross_2013  &lt;dbl&gt; 67878146, 55078343, 211714070, 208105475, 190040426, 18416…\n$ budget_2013 &lt;dbl&gt; 13000000, 45658735, 20000000, 61000000, 40000000, 22500000…\n$ roi         &lt;dbl&gt; 5.221396, 1.206305, 10.585703, 3.411565, 4.751011, 0.81851…\n$ binary      &lt;chr&gt; \"FAIL\", \"PASS\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"P…\n$ clean_test  &lt;chr&gt; \"notalk\", \"ok\", \"notalk\", \"notalk\", \"men\", \"men\", \"notalk\"…\n\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a movie.\n\nHow many observations (rows) are in the data set?\n\nThere are 1615 movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are 7 columns in the dataset.\nVariables of interest\nThe variables we’ll focus on are the following:\n\n\nroi: Return on investment, calculated as the ratio of the gross to budget.\n\nclean_test: Bechdel test result:\n\n\nok = passes test\ndubious\n\nmen = women only talk about men\n\nnotalk = women don’t talk to each other\n\nnowomen = fewer than two women\n\n\n\nbinary: Bechdel Test PASS vs FAIL binary\n\nWe will also use the year of release in data prep and title of movie to take a deeper look at some outliers.\nThere are a few other variables in the dataset, but we won’t be using them in this analysis."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz-A.html#bechdel-test-results",
    "href": "ae/ae-02-bechdel-dataviz-A.html#bechdel-test-results",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Bechdel test results",
    "text": "Bechdel test results\nVisualizing data with ggplot2\n\nggplot2 is the package and ggplot() is the function in this package that is used to create a plot.\n\n\nggplot() creates the initial base coordinate system, and we will add layers to that base. We first specify the data set we will use with data = bechdel.\n\n\nggplot(data = bechdel)\n\n\n\n\n\n\n\n\nThe mapping argument is paired with an aesthetic (aes()), which tells us how the variables in our data set should be mapped to the visual properties of the graph.\n\n\nggplot(data = bechdel, mapping = aes(x = clean_test))\n\n\n\n\n\n\n\nAs we previously mentioned, we often omit the names of the first two arguments in R functions. So you’ll often see this written as:\n\nggplot(bechdel, aes(x = clean_test))\n\n\n\n\n\n\n\nNote that the result is exactly the same.\n\nThe geom_xx function specifies the type of plot we want to use to represent the data. In the code below, we use geom_point which creates a plot where each observation is represented by a point.\n\n\nggplot(bechdel, aes(x = clean_test)) +\n  geom_bar()\n\n\n\n\n\n\n\nWhat types of movies are more common, those that pass or do not pass the test?\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz-A.html#return-on-investment",
    "href": "ae/ae-02-bechdel-dataviz-A.html#return-on-investment",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nLet’s take a look at return-on-investment (ROI) for movies that do and do not pass the Bechdel test.\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\nggplot(bechdel, aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n  )\n\nWarning: Removed 15 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n# A tibble: 3 × 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen   \n\n\nStep 2 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi &lt; ___ to get a better view of how the medians across the categories compare.\n\nggplot(bechdel, aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n  ) +\n  coord_cartesian(ylim = c(0, 16))\n\nWarning: Removed 15 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-12-modeling-fish-A.html",
    "href": "ae/ae-12-modeling-fish-A.html",
    "title": "AE 12: Modelling fish",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\n\n\nFor this application exercise, we will work with data on fish. The dataset we will use, called fish, is on two common fish species in fish market sales.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nfish &lt;- read_csv(\"data/fish.csv\")\n\nThe data dictionary is below:\n\n\nvariable\ndescription\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\nVisualizing the model\nWe’re going to investigate the relationship between the weights and heights of fish.\n\nCreate an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n\n\n\n\n\n\n\nIf you were to draw a a straight line to best represent the relationship between the heights and weights of fish, where would it go? Why?\n\nStart from the bottom and go up. Identify the first and last point and draw a line through most the others.\n\nNow, let R draw the line for you. Refer to the documentation at https://ggplot2.tidyverse.org/reference/geom_smooth.html. Specifically, refer to the method section.\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. lengths of fish\",\n    x = \"Head-to-tail lentgh (cm)\",\n    y = \"Weight of fish (grams)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWhat types of questions can this plot help answer?\n\nIs there a relationship between fish heights and weights of fish?\n\nWe can use this line to make predictions. Predict what you think the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm. Which prediction is considered extrapolation?\n\nAt 10 cm, we estimate a weight of 375 grams. At 15 cm, we estimate a weight of 600 grams At 20 cm, we estimate a weight of 975 grams. 20 cm would be considered extrapolation.\n\nWhat is a residual?\n\nDifference between predicted and observed.\nModel fitting\n\n\nDemo: Fit a model to predict fish weights from their heights.\n\n\nfish_hw_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ height, data = fish)\n\nfish_hw_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = weight ~ height, data = data)\n\nCoefficients:\n(Intercept)       height  \n    -288.42        60.92  \n\n\n\n\nYour turn (3 minutes): Predict what the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm using this model.\n\n\nx &lt;- c(10, 15, 20)\n-288 + 60.92 * x\n\n[1] 321.2 625.8 930.4\n\n\n\n\nDemo: Calculate predicted weights for all fish in the data and visualize the residuals under this model.\n\n\nfish_hw_aug &lt;- augment(fish_hw_fit, new_data = fish)\n\nggplot(fish_hw_aug, aes(x = height, y = weight)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +  \n  geom_segment(aes(xend = height, yend = .pred), color = \"gray\") +  \n  geom_point(aes(y = .pred), shape = \"circle open\") + \n  theme_minimal() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    subtitle = \"Residuals\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nModel summary\n\n\nDemo: Display the model summary including estimates for the slope and intercept along with measurements of uncertainty around them. Show how you can extract these values from the model output.\n\n\nfish_hw_tidy &lt;- tidy(fish_hw_fit)\nfish_hw_tidy\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -288.      34.0      -8.49 1.83e-11\n2 height          60.9      2.64     23.1  2.40e-29\n\n\n\n\nDemo: Write out your model using mathematical notation.\n\n\\(\\widehat{weight} = -288 + 60.9 \\times height\\)\nCorrelation\nWe can also assess correlation between two quantitative variables.\n\nWhat is correlation? What are values correlation can take?\n\nStrength and direction of a linear relationship. It’s bounded by -1 and 1.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\nDemo: What is the correlation between heights and weights of fish?\n\n\nfish |&gt;\n  summarize(r = cor(height, weight))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.954\n\n\nAdding a third variable\n\n\nDemo: Does the relationship between heights and weights of fish change if we take into consideration species? Plot two separate straight lines for the Bream and Roach species.\n\n\nggplot(fish, \n       aes(x = height, y = weight, color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nFitting other models\n\n\nDemo: We can fit more models than just a straight line. Change the following code below to read method = \"loess\". What is different from the plot created before?\n\n\nggplot(fish, \n       aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"loess\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "ae/ae-14-modeling-penguins-multi.html",
    "href": "ae/ae-14-modeling-penguins-multi.html",
    "title": "AE 14: Modelling penguins with multiple predictors",
    "section": "",
    "text": "In this application exercise we will continue to study penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "ae/ae-14-modeling-penguins-multi.html#additive-vs.-interaction-models",
    "href": "ae/ae-14-modeling-penguins-multi.html#additive-vs.-interaction-models",
    "title": "AE 14: Modelling penguins with multiple predictors",
    "section": "Additive vs. interaction models",
    "text": "Additive vs. interaction models\n\n\nYour turn: Run the two chunks of code below and create two separate plots. How are the two plots different than each other? Which plot does the model we fit above represent?\n\n# Plot A\nggplot(\n  penguins, \n  aes(x = flipper_length_mm, y = body_mass_g, color = island)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Plot A - Interaction model\") +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n# Plot B\nbm_fl_island_aug &lt;- augment(bm_fl_island_fit, new_data = penguins)\nggplot(\n  bm_fl_island_aug, \n  aes(x = flipper_length_mm, y = body_mass_g, color = island)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(aes(y = .pred), method = \"lm\") +\n  labs(title = \"Plot B - Additive model\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nError in eval(expr, envir, enclos): object 'bm_fl_island_fit' not found\n\n\n\n\nError in eval(expr, envir, enclos): object 'bm_fl_island_aug' not found\n\n\n\nAdd response here.\n\n\nYour turn: Interpret the slope coefficient for flipper length in the context of the data and the research question.\n\nAdd response here.\n\n\nDemo: Predict the body mass of a Dream island penguin with a flipper length of 200 mm based on the additive model.\n\n\n# add code here\n\n\n\nReview: Look back at Plot B. What assumption does the additive model make about the slopes between flipper length and body mass for each of the three islands?\n\nAdd response here.\n\n\nDemo: Now fit the interaction model represented in Plot A and write the estimated regression model.\n\n\n# add code here\n\n\\[\nadd~math~text~here\n\\]\n\n\nReview: What does modeling body mass with an interaction effect get us that without doing so does not?\n\nAdd response here.\n\n\nYour turn: Predict the body mass of a Dream island penguin with a flipper length of 200 mm based on the interaction model.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-14-modeling-penguins-multi.html#choosing-a-model",
    "href": "ae/ae-14-modeling-penguins-multi.html#choosing-a-model",
    "title": "AE 14: Modelling penguins with multiple predictors",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\n# add code here\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-13-modeling-penguins.html",
    "href": "ae/ae-13-modeling-penguins.html",
    "title": "AE 11: Modelling penguins",
    "section": "",
    "text": "In this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\nPlease read the following context and take a glimpse at the data set before we get started.\n\nThis data set comprising various measurements of three different penguin species, namely Adelie, Gentoo, and Chinstrap. The rigorous study was conducted in the islands of the Palmer Archipelago, Antarctica. These data were collected from 2007 to 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data set is called penguins.\n\n\n# add code here\n\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass. First, we are going to investigate the relationship between a penguins’ flipper lengths and their body masses.\n\n\nQuestion: Based on our research focus, which variable is the response variable?\n\nAdd response here\n\n\nDemo: Visualize the relationship between flipper length and body mass of penguins.\n\n\n# add code here \n\nCorrelation\n\n\nYour turn (5 minutes):\n\n\nWhat is correlation? What values can correlation take?\nStrength and direction of a linear relationship. It’s bounded by -1 and 1.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\n\n\nDemo: What is the correlation between flipper length and body mass of penguins?\n\n\n# add code here\n\nDefining, fitting, and summarizing a model\n\n\nDemo: Write the population model below that explains the relationship between body mass and flipper length.\n\n\\[\nadd~math~text~here\n\\]\n\n\nDemo: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\n# add code here\n\n\\[\nadd~math~text~here\n\\]\n\n\nYour turn: Interpret the slope and the intercept in the context of the data.\n\nIntercept: Add your response here\nSlopes: Add your response here\n\n\nYour turn: Recreate the visualization from above, this time adding a regression line to the visualization geom_smooth(method = \"lm\").\n\n\n# add code here\n\n\n\nDemo: What is the estimated body mass for a penguin with a flipper length of 210?\n\n\n# add code here\n\n\n\nYour turn: What is the estimated body mass for a penguin with a flipper length of 100?\n\n\n# add code here\n\nAnother model\n\n\nDemo: A different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\nAdd response here\n\n\nDemo: Make an appropriate visualization to investigate this relationship below. Additionally, calculate the mean body mass by island.\n\n\n# add code here\n\n\n# add code here\n\n\n\nDemo: Change the geom of your previous plot to geom_point(). Use this plot to think about how R models these data.\n\n\n# add code here\n\n\n\nYour turn: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\n# add code here\n\n\\[\nadd~math~text~here\n\\]\n\n\nDemo: Interpret each coefficient in context of the problem.\n\nIntercept: Add your response here\nSlopes: Add your response here\n\n\nDemo: What is the estimated body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II.html",
    "href": "ae/ae-05-gerrymander-explore-II.html",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "",
    "text": "We’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\nlibrary(ggbeeswarm)\n\n\nThe data are availale in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II.html#getting-started",
    "href": "ae/ae-05-gerrymander-explore-II.html#getting-started",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "",
    "text": "We’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\nlibrary(ggbeeswarm)\n\n\nThe data are availale in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II.html#congressional-districts-per-state",
    "href": "ae/ae-05-gerrymander-explore-II.html#congressional-districts-per-state",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "Congressional districts per state",
    "text": "Congressional districts per state\nWhich state has the most congressional districts? How many congressional districts are there in this state?\nAdd your response here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II.html#gerrymandering-and-flipping",
    "href": "ae/ae-05-gerrymander-explore-II.html#gerrymandering-and-flipping",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "Gerrymandering and flipping",
    "text": "Gerrymandering and flipping\nIs a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering? Support your answer with a visualization and summary statistics.\nAdd your response here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II.html#aesthetic-mappings",
    "href": "ae/ae-05-gerrymander-explore-II.html#aesthetic-mappings",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\nRecreate the following visualization, and then improve it.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II.html#render-commit-and-push",
    "href": "ae/ae-05-gerrymander-explore-II.html#render-commit-and-push",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors-A.html",
    "href": "ae/ae-08-durham-climate-factors-A.html",
    "title": "AE 08: Durham climate + factors",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors-A.html#getting-started",
    "href": "ae/ae-08-durham-climate-factors-A.html#getting-started",
    "title": "AE 08: Durham climate + factors",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe will use the tidyverse package in this application exercise.\n\nlibrary(tidyverse)\n\nData\nThe data come from https://www.usclimatedata.com/climate/durham/north-carolina/united-states/usnc0192 and are stored as durham-climate.csv in the data folder.\n\ndurham_climate &lt;- read_csv(\"data/durham-climate.csv\")\n\nAnd let’s take a look at the data.\n\ndurham_climate\n\n# A tibble: 12 × 4\n   month     avg_high_f avg_low_f precipitation_in\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n 1 January           49        28             4.45\n 2 February          53        29             3.7 \n 3 March             62        37             4.69\n 4 April             71        46             3.43\n 5 May               79        56             4.61\n 6 June              85        65             4.02\n 7 July              89        70             3.94\n 8 August            87        68             4.37\n 9 September         81        60             4.37\n10 October           71        47             3.7 \n11 November          62        37             3.39\n12 December          53        30             3.43"
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors-A.html#reorder",
    "href": "ae/ae-08-durham-climate-factors-A.html#reorder",
    "title": "AE 08: Durham climate + factors",
    "section": "Reorder",
    "text": "Reorder\nWhat’s wrong with the following plot?\nMonths are out of order.\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 2,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  )\n\n\n\n\n\n\n\nFix the plot.\n\ndurham_climate &lt;- durham_climate |&gt;\n  mutate(month = fct_relevel(month, month.name))\n\nggplot(\n  durham_climate,\n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 2,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  )"
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors-A.html#recode-and-reorder",
    "href": "ae/ae-08-durham-climate-factors-A.html#recode-and-reorder",
    "title": "AE 08: Durham climate + factors",
    "section": "Recode and reorder",
    "text": "Recode and reorder\nUpdate the plot above, coloring points based on season. Additionally:\n\nMake sure the legend is on top of the plot and the seasons appear in the legend in the order they appear in the plot (Winter, Spring, Summer, Fall).\n\nUse \"circle filled\" as the shape for points, set their size to 3 points, outline (stroke) to 1 point, and fill them in with the following colors:\n\nWinter: lightskyblue1\n\nSpring: chartreuse3\n\nSummer: gold2\n\nFall: lightsalmon4\n\n\n\n\n\ndurham_climate &lt;- durham_climate |&gt;\n  mutate(\n    season = case_when(\n      month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      month %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n      month %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n      month %in% c(\"September\", \"October\", \"November\") ~ \"Fall\",\n    ),\n    season = fct_relevel(season, \"Winter\", \"Spring\", \"Summer\", \"Fall\")\n  )\n\nggplot(\n  durham_climate,\n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 3, stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\",\n    fill = \"Season\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "ae/ae-08-durham-climate-factors-A.html#pivot",
    "href": "ae/ae-08-durham-climate-factors-A.html#pivot",
    "title": "AE 08: Durham climate + factors",
    "section": "Pivot",
    "text": "Pivot\nOverlay lines for both high and low temperatures on the same plot. Additionally, use different colors for the two lines – a darker color for high and a lighter color for low temperatures.\n\ndurham_climate |&gt;\n  pivot_longer(\n    cols = c(avg_high_f, avg_low_f),\n    names_to = \"temp_type\",\n    names_prefix = \"avg_\",\n    values_to = \"avg_temp_f\"\n  ) |&gt;\n  mutate(temp_type = str_remove(temp_type, \"_f\")) |&gt;\n  ggplot(aes(x = month, y = avg_temp_f, group = temp_type, color = temp_type)) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 3, stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) +\n  scale_color_manual(\n    values = c(\n      \"high\" = \"gray20\",\n      \"low\" = \"gray70\"\n    )\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average temperature (F)\",\n    title = \"Durham climate\",\n    fill = \"Season\",\n    color = \"Type\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "ae/ae-17-forest-classification.html",
    "href": "ae/ae-17-forest-classification.html",
    "title": "AE 17: Forest classification",
    "section": "",
    "text": "In this application exercise, we will\nWe will use tidyverse and tidymodels for data exploration and modeling, respectively, and the forested package for the data.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)\nRemember from the lecture that the forested dataset contains information on whether a plot is forested (Yes) or not (No) as well as numerical and categorical features of that plot.\nglimpse(forested)\n\nRows: 7,107\nColumns: 19\n$ forested         &lt;fct&gt; Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005,…\n$ elevation        &lt;dbl&gt; 881, 113, 164, 299, 806, 736, 636, 224, 52, 2240, 104…\n$ eastness         &lt;dbl&gt; 90, -25, -84, 93, 47, -27, -48, -65, -62, -67, 96, -4…\n$ northness        &lt;dbl&gt; 43, 96, 53, 34, -88, -96, 87, -75, 78, -74, -26, 86, …\n$ roughness        &lt;dbl&gt; 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 190, 95, 212…\n$ tree_no_tree     &lt;fct&gt; Tree, Tree, Tree, No tree, Tree, Tree, No tree, Tree,…\n$ dew_temp         &lt;dbl&gt; 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6.39, 6.50,…\n$ precip_annual    &lt;dbl&gt; 466, 1710, 1297, 2545, 609, 539, 702, 1195, 1312, 103…\n$ temp_annual_mean &lt;dbl&gt; 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61, 10.45, 10…\n$ temp_annual_min  &lt;dbl&gt; -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.76, 1.11, …\n$ temp_annual_max  &lt;dbl&gt; 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 14.23, 15.3…\n$ temp_january_min &lt;dbl&gt; -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, 5.54, 6.20…\n$ vapor_min        &lt;dbl&gt; 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 172, 162, 70…\n$ vapor_max        &lt;dbl&gt; 1194, 938, 754, 1164, 1254, 1331, 1275, 944, 892, 549…\n$ canopy_cover     &lt;dbl&gt; 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74, 66, 83, 6…\n$ lon              &lt;dbl&gt; -118.6865, -123.0825, -122.3468, -121.9144, -117.8841…\n$ lat              &lt;dbl&gt; 48.69537, 47.07991, 48.77132, 45.80776, 48.07396, 48.…\n$ land_type        &lt;fct&gt; Tree, Tree, Tree, Tree, Tree, Tree, Non-tree vegetati…"
  },
  {
    "objectID": "ae/ae-17-forest-classification.html#fit",
    "href": "ae/ae-17-forest-classification.html#fit",
    "title": "AE 17: Forest classification",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on a subset of predictors of your choice. Name the model forested_custom_fit and display a tidy output of the model.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-17-forest-classification.html#predict",
    "href": "ae/ae-17-forest-classification.html#predict",
    "title": "AE 17: Forest classification",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-17-forest-classification.html#evaluate",
    "href": "ae/ae-17-forest-classification.html#evaluate",
    "title": "AE 17: Forest classification",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\n# add code here\n\nAnother commonly used display of this information is a confusion matrix. Create this using the conf_mat() function. You will need to review the documentation for the function to determine how to use it.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-17-forest-classification.html#sensitivity-specificity-roc-curve",
    "href": "ae/ae-17-forest-classification.html#sensitivity-specificity-roc-curve",
    "title": "AE 17: Forest classification",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-17-forest-classification.html#fit-1",
    "href": "ae/ae-17-forest-classification.html#fit-1",
    "title": "AE 17: Forest classification",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on all predictors available. Name the model forested_full_fit and display a tidy output of the model.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-17-forest-classification.html#predict-1",
    "href": "ae/ae-17-forest-classification.html#predict-1",
    "title": "AE 17: Forest classification",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-17-forest-classification.html#evaluate-1",
    "href": "ae/ae-17-forest-classification.html#evaluate-1",
    "title": "AE 17: Forest classification",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-17-forest-classification.html#sensitivity-specificity-roc-curve-1",
    "href": "ae/ae-17-forest-classification.html#sensitivity-specificity-roc-curve-1",
    "title": "AE 17: Forest classification",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-15-modeling-loans-A.html",
    "href": "ae/ae-15-modeling-loans-A.html",
    "title": "AE 15: Modelling loan interest rates",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this application exercise we will be studying loan interest rates. The dataset is one you’ve come across before in your reading – the dataset about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nBefore we use the dataset, we’ll make a few transformations to it.\nAdd response here.\nloans &lt;- loans_full_schema |&gt;\n  mutate(\n    credit_util = total_credit_utilized / total_credit_limit,\n    bankruptcy = as.factor(if_else(public_record_bankrupt == 0, 0, 1)),\n    verified_income = droplevels(verified_income),\n    homeownership = str_to_title(homeownership),\n    homeownership = fct_relevel(homeownership, \"Rent\", \"Mortgage\", \"Own\")\n  ) |&gt;\n  rename(credit_checks = inquiries_last_12m) |&gt;\n  select(\n    interest_rate, loan_amount, verified_income, \n    debt_to_income, credit_util, bankruptcy, term, \n    credit_checks, issue_month, homeownership\n  )\nHere is a glimpse at the data:\nglimpse(loans)\n\nRows: 10,000\nColumns: 10\n$ interest_rate   &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, …\n$ loan_amount     &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 2…\n$ verified_income &lt;fct&gt; Verified, Not Verified, Source Verified, Not Verified,…\n$ debt_to_income  &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, …\n$ credit_util     &lt;dbl&gt; 0.54759517, 0.15003472, 0.66134832, 0.19673228, 0.7549…\n$ bankruptcy      &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, …\n$ term            &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, 60, 60, 36, 60…\n$ credit_checks   &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8, 6, 0, 0, 4, 6, …\n$ issue_month     &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-2018, Mar-2018, Jan-…\n$ homeownership   &lt;fct&gt; Mortgage, Rent, Rent, Rent, Rent, Own, Mortgage, Mortg…"
  },
  {
    "objectID": "ae/ae-15-modeling-loans-A.html#main-effects-model",
    "href": "ae/ae-15-modeling-loans-A.html#main-effects-model",
    "title": "AE 15: Modelling loan interest rates",
    "section": "Main effects model",
    "text": "Main effects model\n\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, without an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\nrate_util_home_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util + homeownership, data = loans)\n\ntidy(rate_util_home_fit)\n\n# A tibble: 4 × 5\n  term                  estimate std.error statistic   p.value\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              9.93      0.140    70.8   0        \n2 credit_util              5.34      0.207    25.7   2.20e-141\n3 homeownershipMortgage    0.696     0.121     5.76  8.71e-  9\n4 homeownershipOwn         0.128     0.155     0.827 4.08e-  1\n\n\n\\[\n\\widehat{interest~rate} = 9.93 + 5.34 \\times credit~util + 0.696 \\times Mortgage + 0.128 \\times Own\n\\]\n\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.93 + 5.34 \\times credit~util\\)\n\nMortgage: \\(\\widehat{interest~rate} = 10.626 + 5.34 \\times credit~util\\)\n\nOwn: \\(\\widehat{interest~rate} = 10.058 + 5.34 \\times credit~util\\)\n\n\n\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nThe same."
  },
  {
    "objectID": "ae/ae-15-modeling-loans-A.html#interaction-effects-model",
    "href": "ae/ae-15-modeling-loans-A.html#interaction-effects-model",
    "title": "AE 15: Modelling loan interest rates",
    "section": "Interaction effects model",
    "text": "Interaction effects model\n\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, with an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\nrate_util_home_int_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util * homeownership, data = loans)\n\ntidy(rate_util_home_int_fit)\n\n# A tibble: 6 × 5\n  term                              estimate std.error statistic  p.value\n  &lt;chr&gt;                                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                          9.44      0.199     47.5  0       \n2 credit_util                          6.20      0.325     19.1  1.01e-79\n3 homeownershipMortgage                1.39      0.228      6.11 1.04e- 9\n4 homeownershipOwn                     0.697     0.316      2.20 2.75e- 2\n5 credit_util:homeownershipMortgage   -1.64      0.457     -3.58 3.49e- 4\n6 credit_util:homeownershipOwn        -1.06      0.590     -1.80 7.24e- 2\n\n\n\\[\n\\widehat{interest~rate} = 9.44 + 6.20 \\times credit~util + 1.39 \\times Mortgage + 0.697 \\times Own - 1.64 \\times credit_util:Mortgage - 1.06 \\times credit_util:Own\n\\]\n\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.44 + 6.20 \\times credit~util\\)\n\nMortgage: \\(\\widehat{interest~rate} = 10.83 + 4.56 \\times credit~util\\)\n\nOwn: \\(\\widehat{interest~rate} = 10.137 + 5.14 \\times credit~util\\)\n\n\n\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nDifferent."
  },
  {
    "objectID": "ae/ae-15-modeling-loans-A.html#choosing-a-model",
    "href": "ae/ae-15-modeling-loans-A.html#choosing-a-model",
    "title": "AE 15: Modelling loan interest rates",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\nglance(rate_util_home_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0682        0.0679  4.83      244. 1.25e-152     3 -29926. 59861. 59897.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(rate_util_home_int_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0694        0.0689  4.83      149. 4.79e-153     5 -29919. 59852. 59903.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables).\n\n\nQuestion: Based on the adjusted \\(R^2\\)s of these two models, which one do we prefer?\n\nThe interaction effects model, though just barely."
  },
  {
    "objectID": "ae/ae-03-bechdel-data-viz-transform-A.html",
    "href": "ae/ae-03-bechdel-data-viz-transform-A.html",
    "title": "AE 03: Bechdel + data visualization and transformation",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key.\nIn this mini-analysis, we’ll continue our exploration of the bechdel dataset, which contains information on whether the movies in the data pass the Bechdel test (a measure of the representation of women in fiction)."
  },
  {
    "objectID": "ae/ae-03-bechdel-data-viz-transform-A.html#getting-started",
    "href": "ae/ae-03-bechdel-data-viz-transform-A.html#getting-started",
    "title": "AE 03: Bechdel + data visualization and transformation",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are stored as a CSV (comma-separated values) file in your repository’s data folder. Let’s read it from there and save it as an object called bechdel.\n\nbechdel &lt;- read_csv(\"data/bechdel.csv\")\n\nGet to know the data\nWe can use the glimpse() function to get an overview (or “glimpse”) of the data.\n\nglimpse(bechdel)\n\nRows: 1,615\nColumns: 7\n$ title       &lt;chr&gt; \"21 & Over\", \"Dredd 3D\", \"12 Years a Slave\", \"2 Guns\", \"42…\n$ year        &lt;dbl&gt; 2013, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n$ gross_2013  &lt;dbl&gt; 67878146, 55078343, 211714070, 208105475, 190040426, 18416…\n$ budget_2013 &lt;dbl&gt; 13000000, 45658735, 20000000, 61000000, 40000000, 22500000…\n$ roi         &lt;dbl&gt; 5.221396, 1.206305, 10.585703, 3.411565, 4.751011, 0.81851…\n$ binary      &lt;chr&gt; \"FAIL\", \"PASS\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"P…\n$ clean_test  &lt;chr&gt; \"notalk\", \"ok\", \"notalk\", \"notalk\", \"men\", \"men\", \"notalk\"…\n\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a movie.\n\nHow many observations (rows) are in the data set?\n\nThere are 1615 movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are 7 columns in the dataset."
  },
  {
    "objectID": "ae/ae-03-bechdel-data-viz-transform-A.html#bechdel-test-results",
    "href": "ae/ae-03-bechdel-data-viz-transform-A.html#bechdel-test-results",
    "title": "AE 03: Bechdel + data visualization and transformation",
    "section": "Bechdel test results",
    "text": "Bechdel test results\nVisualizing data with ggplot2\n\nCreate a bar plot of the clean_test variable:\n\n\nok = passes test\ndubious\n\nmen = women only talk about men\n\nnotalk = women don’t talk to each other\n\nnowomen = fewer than two women\n\n\nggplot(bechdel, aes(x = clean_test)) +\n  geom_bar() +\n  labs(\n    x = \"Bechdel test result\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\nWhat types of movies are more common, those that pass or do not pass the test?\nIf we consider “dubious” to be no, movies that don’t pass the test are more common.\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-03-bechdel-data-viz-transform-A.html#return-on-investment",
    "href": "ae/ae-03-bechdel-data-viz-transform-A.html#return-on-investment",
    "title": "AE 03: Bechdel + data visualization and transformation",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nLet’s take a look at return-on-investment (ROI) for movies that do and do not pass the Bechdel test.\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\nggplot(bechdel, aes(x = roi, y = clean_test, color = binary)) +\n  geom_boxplot() +\n  labs(\n    x = \"Return on investment\",\n    y = \"Bechdel test result\",\n    color = \"Pass / Fail\"\n  )\n\n\n\n\n\n\n\nStep 2 - Demo\nWhat are the movies with very high returns on investment?\n\nbechdel |&gt;\n  filter(roi &gt; 400)\n\n# A tibble: 3 × 7\n  title                    year gross_2013 budget_2013   roi binary clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 Paranormal Activity      2007  339424558      505595  671. FAIL   dubious   \n2 The Blair Witch Project  1999  543776715      839077  648. PASS   ok        \n3 El Mariachi              1992    6778946       11622  583. FAIL   nowomen   \n\n\nStep 3 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi &lt; ___ to get a better view of how the medians across the categories compare.\n\nggplot(bechdel, aes(x = roi, y = clean_test, color = binary)) +\n  geom_boxplot() +\n  labs(\n    x = \"Return on investment\",\n    y = \"Bechdel test result\",\n    color = \"Pass / Fail\"\n  ) +\n  coord_cartesian(xlim = c(0, 16))\n\nWarning: Removed 15 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?\nMovies that pass the Bechdel test typically have an higher return-on-investment than those that do not.\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-09-age-gaps-sales-import-A.html",
    "href": "ae/ae-09-age-gaps-sales-import-A.html",
    "title": "AE 09: Age gaps + sales + import",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-09-age-gaps-sales-import-A.html#getting-started",
    "href": "ae/ae-09-age-gaps-sales-import-A.html#getting-started",
    "title": "AE 09: Age gaps + sales + import",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe will use the following two packages in this application exercise.\n\n\ntidyverse: For data import, wrangling, and visualization.\n\nreadxl: For importing data from Excel.\n\n\nlibrary(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "ae/ae-09-age-gaps-sales-import-A.html#part-1-hollywood-relationships",
    "href": "ae/ae-09-age-gaps-sales-import-A.html#part-1-hollywood-relationships",
    "title": "AE 09: Age gaps + sales + import",
    "section": "Part 1: Hollywood relationships",
    "text": "Part 1: Hollywood relationships\nLoad the data from age-gaps.csv in your data and assign it to age_gaps. Confirm that this new object appears in your Environment tab. Click on the name of the object in your Environment tab to pop open the data in the data viewer.\n\nage_gaps &lt;- read_csv(\"data/age-gaps.csv\")\n\nRows: 1155 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): movie_name, director, actor_1_name, actor_2_name, character_1_gend...\ndbl  (5): release_year, age_difference, couple_number, actor_1_age, actor_2_age\ndate (2): actor_1_birthdate, actor_2_birthdate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCreate a subset of the data frame for heterosexual relationships on screen.\n\nage_gaps_heterosexual &lt;- age_gaps |&gt;\n  filter(character_1_gender != character_2_gender)\n\nSplit the data for heterosexual relationships into three – where woman is older, where man is older, where they are the same age. Save these subsets as two appropriately named data frames. Remember: Use concise and evocative names. Confirm that these new objects appear in your Environment tab and that the sum of the number of observations in the two new data frames add to the number of observations in the original data frame.\n\nage_gaps_heterosexual &lt;- age_gaps_heterosexual |&gt;\n  mutate(\n    older = case_when(\n      character_1_gender == \"woman\" & actor_1_age &gt; actor_2_age ~ \"woman older\",\n      character_2_gender == \"woman\" & actor_2_age &gt; actor_1_age ~ \"woman older\",\n      character_1_gender == \"man\"   & actor_1_age &gt; actor_2_age ~ \"man older\",\n      character_2_gender == \"man\"   & actor_2_age &gt; actor_1_age ~ \"man older\",\n      actor_1_age == actor_2_age ~ \"same age\"\n    )\n  )\n\nwoman_older &lt;- age_gaps_heterosexual |&gt; filter(older == \"woman older\")\nman_older   &lt;- age_gaps_heterosexual |&gt; filter(older == \"man older\")\nsame_age    &lt;- age_gaps_heterosexual |&gt; filter(older == \"same age\")\n\n(nrow(woman_older) + nrow(man_older) + nrow(same_age)) == nrow(age_gaps_heterosexual)\n\n[1] TRUE\n\n\nWrite out the three new datasets you created into the data folder:\n\nwrite_csv(woman_older, file = \"data/woman-older.csv\")\nwrite_csv(man_older, file = \"data/man-older.csv\")\nwrite_csv(same_age, file = \"data/same-age.csv\")"
  },
  {
    "objectID": "ae/ae-09-age-gaps-sales-import-A.html#part-2-sales",
    "href": "ae/ae-09-age-gaps-sales-import-A.html#part-2-sales",
    "title": "AE 09: Age gaps + sales + import",
    "section": "Part 2: Sales",
    "text": "Part 2: Sales\nSales data are stored in an Excel file that looks like the following:\n\nRead in the Excel file called sales.xlsx from the data-raw/ folder such that it looks like the following.\n\n\nsales_raw &lt;- read_excel(\n  \"data/sales.xlsx\", \n  skip = 3,\n  col_names = c(\"id\", \"n\")\n  )\n\nStretch goal: Manipulate the sales data such such that it looks like the following.\n\n\nsales &lt;- sales_raw |&gt;\n  mutate(\n    is_brand_name = str_detect(id, \"Brand\"),\n    brand = if_else(is_brand_name, id, NA)\n  ) |&gt;\n  fill(brand) |&gt;\n  filter(!is_brand_name) |&gt;\n  select(brand, id, n)\n\nsales\n\n# A tibble: 7 × 3\n  brand   id    n    \n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;\n1 Brand 1 1234  8    \n2 Brand 1 8721  2    \n3 Brand 1 1822  3    \n4 Brand 2 3333  1    \n5 Brand 2 2156  3    \n6 Brand 2 3987  6    \n7 Brand 2 3216  5    \n\n\nWhy should we bother with writing code for reading the data in by skipping columns and assigning variable names as well as cleaning it up in multiple steps instead of opening the Excel file and editing the data in there to prepare it for a clean import?\nBecause the code allows us to struggle once and re-use for future datasets and leaves a transparent trail of our modifications while manipulating the data in Excel directly is neither reproducible nor reusable."
  },
  {
    "objectID": "ae/ae-03-bechdel-data-viz-transform.html",
    "href": "ae/ae-03-bechdel-data-viz-transform.html",
    "title": "AE 03: Bechdel + data visualization and transformation",
    "section": "",
    "text": "In this mini-analysis, we’ll continue our exploration of the bechdel dataset, which contains information on whether the movies in the data pass the Bechdel test (a measure of the representation of women in fiction)."
  },
  {
    "objectID": "ae/ae-03-bechdel-data-viz-transform.html#getting-started",
    "href": "ae/ae-03-bechdel-data-viz-transform.html#getting-started",
    "title": "AE 03: Bechdel + data visualization and transformation",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are stored as a CSV (comma-separated values) file in your repository’s data folder. Let’s read it from there and save it as an object called bechdel.\n\nbechdel &lt;- read_csv(\"data/bechdel.csv\")\n\nGet to know the data\nWe can use the glimpse() function to get an overview (or “glimpse”) of the data.\n\n# add code here\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a movie.\n\nHow many observations (rows) are in the data set?\n\nThere are 1615 movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are 7 columns in the dataset."
  },
  {
    "objectID": "ae/ae-03-bechdel-data-viz-transform.html#bechdel-test-results",
    "href": "ae/ae-03-bechdel-data-viz-transform.html#bechdel-test-results",
    "title": "AE 03: Bechdel + data visualization and transformation",
    "section": "Bechdel test results",
    "text": "Bechdel test results\nVisualizing data with ggplot2\n\nCreate a bar plot of the clean_test variable:\n\n\nok = passes test\ndubious\n\nmen = women only talk about men\n\nnotalk = women don’t talk to each other\n\nnowomen = fewer than two women\n\n\n# add code here\n\nWhat types of movies are more common, those that pass or do not pass the test?\nAdd your response here.\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-03-bechdel-data-viz-transform.html#return-on-investment",
    "href": "ae/ae-03-bechdel-data-viz-transform.html#return-on-investment",
    "title": "AE 03: Bechdel + data visualization and transformation",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nLet’s take a look at return-on-investment (ROI) for movies that do and do not pass the Bechdel test.\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\n# add code here\n\nStep 2 - Demo\nWhat are the movies with very high returns on investment?\n\n# add code here\n\nStep 3 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi &lt; ___ to get a better view of how the medians across the categories compare.\n\n# add code here\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?\nAdd your response here.\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-13-modeling-penguins-A.html",
    "href": "ae/ae-13-modeling-penguins-A.html",
    "title": "AE 13: Modelling penguins",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\n\n\nIn this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\nPlease read the following context and take a glimpse at the data set before we get started.\n\nThis data set comprising various measurements of three different penguin species, namely Adelie, Gentoo, and Chinstrap. The rigorous study was conducted in the islands of the Palmer Archipelago, Antarctica. These data were collected from 2007 to 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data set is called penguins.\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass. First, we are going to investigate the relationship between a penguins’ flipper lengths and their body masses.\n\n\nQuestion: Based on our research focus, which variable is the response variable?\n\nBody mass.\n\n\nDemo: Visualize the relationship between flipper length and body mass of penguins.\n\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nCorrelation\n\n\nYour turn (5 minutes):\n\n\nWhat is correlation? What values can correlation take?\nStrength and direction of a linear relationship. It’s bounded by -1 and 1.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\n\n\nDemo: What is the correlation between flipper length and body mass of penguins?\n\n\n# option 1\npenguins |&gt;\n  summarize(r = cor(flipper_length_mm, body_mass_g, use = \"complete.obs\"))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.871\n\n# option 2\npenguins |&gt;\n  drop_na(flipper_length_mm, body_mass_g) |&gt;\n  summarize(r = cor(flipper_length_mm, body_mass_g))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.871\n\n\nDefining, fitting, and summarizing a model\n\n\nDemo: Write the population model below that explains the relationship between body mass and flipper length.\n\n\\[\nbody~mass = \\beta_0 + \\beta_1 \\times flipper~length + \\epsilon\n\\]\n\n\nDemo: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\nbm_fl_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\ntidy(bm_fl_fit)\n\n# A tibble: 2 × 5\n  term              estimate std.error statistic   p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\n\\[\n\\widehat{body~mass} = -5781 + 49.7 \\times flipper~length\n\\]\n\n\nYour turn: Interpret the slope and the intercept in the context of the data.\n\nIntercept: Penguins with 0 flipper length are expected, on average, to weigh 5,781 grams.\nSlopes: For each additional millimeter of a penguin;s flipper length, the weight of their penguin is expected to be higher, on average, by 49.7 grams.\n\n\nYour turn: Recreate the visualization from above, this time adding a regression line to the visualization geom_smooth(method = \"lm\").\n\n\nggplot(\n  penguins,\n  aes(x = flipper_length_mm, y = body_mass_g)\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nDemo: What is the estimated body mass for a penguin with a flipper length of 210?\n\n\npenguin_flipper_210 &lt;- tibble(flipper_length_mm = 210)\n\nbm_fl_fit |&gt;\n  predict(new_data = penguin_flipper_210)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 4653.\n\n\n\n\nYour turn: What is the estimated body mass for a penguin with a flipper length of 100?\n\nBut we shouldn’t do this prediction based on this model since 100 mm is outside of the range of the data (extrapolation).\n\npenguin_flipper_100 &lt;- tibble(flipper_length_mm = 100)\n\nbm_fl_fit |&gt;\n  predict(new_data = penguin_flipper_100)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 -812.\n\n\nAnother model\n\n\nDemo: A different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\nPredictor is categorical.\n\n\nDemo: Make an appropriate visualization to investigate this relationship below. Additionally, calculate the mean body mass by island.\n\n\nggplot(penguins, aes(x = island, y = body_mass_g)) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\npenguins |&gt;\n  group_by(island) |&gt;\n  summarize(mean_bm = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 3 × 2\n  island    mean_bm\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Biscoe      4716.\n2 Dream       3713.\n3 Torgersen   3706.\n\n\n\n\nDemo: Change the geom of your previous plot to geom_point(). Use this plot to think about how R models these data.\n\n\nggplot(penguins, aes(x = island, y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nYour turn: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\nbm_island_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ island, data = penguins)\n\ntidy(bm_island_fit)\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        4716.      48.5      97.3 8.93e-250\n2 islandDream       -1003.      74.2     -13.5 1.42e- 33\n3 islandTorgersen   -1010.     100.      -10.1 4.66e- 21\n\n\n\n\nDemo: Interpret each coefficient in context of the problem.\n\nIntercept: Penguins from Biscoe island are expected to weigh, on average, 4,716 grams.\n\nSlopes:\n\nPenguins from Dream island are expected to weigh, on average, 1,003 grams less than those from Biscoe island.\nPenguins from Torgersen island are expected to weigh, on average, 1,010 grams less than those from Biscoe island.\n\n\n\n\nDemo: What is the estimated body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands?\n\n\nthree_penguins &lt;- tibble(\n  island = c(\"Biscoe\", \"Dream\", \"Torgersen\")\n)\nbm_island_fit |&gt;\n  predict(new_data = three_penguins)\n\n# A tibble: 3 × 1\n  .pred\n  &lt;dbl&gt;\n1 4716.\n2 3713.\n3 3706."
  },
  {
    "objectID": "ae/ae-14-modeling-penguins-multi-A.html",
    "href": "ae/ae-14-modeling-penguins-multi-A.html",
    "title": "AE 14: Modelling penguins with multiple predictors",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this application exercise we will continue to study penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "ae/ae-14-modeling-penguins-multi-A.html#additive-vs.-interaction-models",
    "href": "ae/ae-14-modeling-penguins-multi-A.html#additive-vs.-interaction-models",
    "title": "AE 14: Modelling penguins with multiple predictors",
    "section": "Additive vs. interaction models",
    "text": "Additive vs. interaction models\n\n\nYour turn: Run the two chunks of code below and create two separate plots. How are the two plots different than each other? Which plot does the model we fit above represent?\n\n# Plot A\nggplot(\n  penguins, \n  aes(x = flipper_length_mm, y = body_mass_g, color = island)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Plot A - Interaction model\") +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n# Plot B\nbm_fl_island_aug &lt;- augment(bm_fl_island_fit, new_data = penguins)\nggplot(\n  bm_fl_island_aug, \n  aes(x = flipper_length_mm, y = body_mass_g, color = island)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(aes(y = .pred), method = \"lm\") +\n  labs(title = \"Plot B - Additive model\") +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nPlot B represents the model we fit.\n\n\nYour turn: Interpret the slope coefficient for flipper length in the context of the data and the research question.\n\nFor every 1 millimeter the flipper is longer, we expect body mass to be higher, on average, by 44.5 grams, holding all else (the island) constant. In other words, this is true for penguins in a given island, regardless of the island.\n\n\nDemo: Predict the body mass of a Dream island penguin with a flipper length of 200 mm based on the additive model.\n\n\npenguin_200_Dream &lt;- tibble(\n  flipper_length_mm = 200,\n  island = \"Dream\"\n)\n\npredict(bm_fl_island_fit, new_data = penguin_200_Dream)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 4021.\n\n\n\n\nReview: Look back at Plot B. What assumption does the additive model make about the slopes between flipper length and body mass for each of the three islands?\n\nThe additive model assumes the same slope between body mass and flipper length for all three islands.\n\n\nDemo: Now fit the interaction model represented in Plot A and write the estimated regression model.\n\n\nbm_fl_island_int_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ flipper_length_mm * island, data = penguins)\n\ntidy(bm_fl_island_int_fit)\n\n# A tibble: 6 × 5\n  term                              estimate std.error statistic  p.value\n  &lt;chr&gt;                                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                        -5464.     431.      -12.7  2.51e-30\n2 flipper_length_mm                     48.5      2.05     23.7  1.66e-73\n3 islandDream                         3551.     969.        3.66 2.89e- 4\n4 islandTorgersen                     3218.    1680.        1.92 5.62e- 2\n5 flipper_length_mm:islandDream        -19.4      4.94     -3.93 1.03e- 4\n6 flipper_length_mm:islandTorgersen    -17.4      8.73     -1.99 4.69e- 2\n\n\n\\[\n\\widehat{body~mass} = -5464 \\\\\n+ 48.5 \\times flipper~length \\\\\n+ 3551 \\times Dream + 3218 \\times Torgersen \\\\\n- 19.4 \\times flipper~length*Dream - 17.4 \\times flipper~length*Torgersen\n\\]\n\n\nReview: What does modeling body mass with an interaction effect get us that without doing so does not?\n\nThe interaction effect allows us to model the rate of change in estimated body mass as flipper length increases as different in the three islands.\n\n\nYour turn: Predict the body mass of a Dream island penguin with a flipper length of 200 mm based on the interaction model.\n\n\npredict(bm_fl_island_int_fit, new_data = penguin_200_Dream)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 3915."
  },
  {
    "objectID": "ae/ae-14-modeling-penguins-multi-A.html#choosing-a-model",
    "href": "ae/ae-14-modeling-penguins-multi-A.html#choosing-a-model",
    "title": "AE 14: Modelling penguins with multiple predictors",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\nglance(bm_fl_island_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.774         0.772  383.      386. 7.60e-109     3 -2517. 5045. 5064.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(bm_fl_island_int_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.786         0.783  374.      246. 4.55e-110     5 -2508. 5031. 5057.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables)."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html",
    "href": "ae/ae-02-bechdel-dataviz.html",
    "title": "AE 02: Bechdel + data visualization",
    "section": "",
    "text": "In this mini-analysis, we use the data from the FiveThirtyEight story “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women.”\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#getting-started",
    "href": "ae/ae-02-bechdel-dataviz.html#getting-started",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are stored as a CSV (comma-separated values) file in your repository’s data folder. Let’s read it from there and save it as an object called bechdel.\n\nbechdel &lt;- read_csv(\"data/bechdel.csv\")\n\nGet to know the data\nWe can use the glimpse() function to get an overview (or “glimpse”) of the data.\n\n# add code here\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a ___.\n\nHow many observations (rows) are in the data set?\n\nThere are ___ movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are ___ columns in the dataset.\nVariables of interest\nThe variables we’ll focus on are the following:\n\n\nroi: Return on investment, calculated as the ratio of the gross to budget.\n\nclean_test: Bechdel test result:\n\n\nok = passes test\ndubious\n\nmen = women only talk about men\n\nnotalk = women don’t talk to each other\n\nnowomen = fewer than two women\n\n\n\nbinary: Bechdel Test PASS vs FAIL binary\n\nWe will also use the year of release in data prep and title of movie to take a deeper look at some outliers.\nThere are a few other variables in the dataset, but we won’t be using them in this analysis."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#bechdel-test-results",
    "href": "ae/ae-02-bechdel-dataviz.html#bechdel-test-results",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Bechdel test results",
    "text": "Bechdel test results\nVisualizing data with ggplot2\n\nggplot2 is the package and ggplot() is the function in this package that is used to create a plot.\n\n\nggplot() creates the initial base coordinate system, and we will add layers to that base. We first specify the data set we will use with data = bechdel.\n\n\nggplot(data = bechdel)\n\n\n\n\n\n\n\n\nThe mapping argument is paired with an aesthetic (aes()), which tells us how the variables in our data set should be mapped to the visual properties of the graph.\n\n\nggplot(data = bechdel, mapping = aes(x = clean_test))\n\n\n\n\n\n\n\nAs we previously mentioned, we often omit the names of the first two arguments in R functions. So you’ll often see this written as:\n\nggplot(bechdel, aes(x = clean_test))\n\n\n\n\n\n\n\nNote that the result is exactly the same.\n\nThe geom_xx function specifies the type of plot we want to use to represent the data. In the code below, we use geom_point which creates a plot where each observation is represented by a point.\n\n\nggplot(bechdel, aes(x = clean_test)) +\n  geom_bar()\n\n\n\n\n\n\n\nWhat types of movies are more common, those that pass or do not pass the test?\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#return-on-investment",
    "href": "ae/ae-02-bechdel-dataviz.html#return-on-investment",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nLet’s take a look at return-on-investment (ROI) for movies that do and do not pass the Bechdel test.\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\n# add code here\n\nWhat are those movies with very high returns on investment?\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n# A tibble: 3 × 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen   \n\n\nStep 2 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi &lt; ___ to get a better view of how the medians across the categories compare.\n\n# add code here\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-07-taxes-join.html",
    "href": "ae/ae-07-taxes-join.html",
    "title": "AE 07: Sales taxes + data joining",
    "section": "",
    "text": "We’ll use the tidyverse package for this analysis.\n\n# add code here\n\n\nThe data are available in the data folder:\n\nsales-taxes.csv\nus-regions.csv\n\n\n# add code here\n\nAnd let’s take a look at the data.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-07-taxes-join.html#getting-started",
    "href": "ae/ae-07-taxes-join.html#getting-started",
    "title": "AE 07: Sales taxes + data joining",
    "section": "",
    "text": "We’ll use the tidyverse package for this analysis.\n\n# add code here\n\n\nThe data are available in the data folder:\n\nsales-taxes.csv\nus-regions.csv\n\n\n# add code here\n\nAnd let’s take a look at the data.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-07-taxes-join.html#joining",
    "href": "ae/ae-07-taxes-join.html#joining",
    "title": "AE 07: Sales taxes + data joining",
    "section": "Joining",
    "text": "Joining\nJoin the sales tax data with region data and save the joined data frame as a new data frame, not overwriting either data frame that goes into the join.\n\n# add code here\n\nCalculate the average sales tax of states in each region. What is surprising in the output?\n\n# add code here\n\nIdentify the state with NA for region.\n\n# add code here\n\nApply a fix for the NA in region, and calculate the mean sales taxes for regions again. Display the results in ascending order of mean sales tax.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-07-taxes-join.html#render-commit-and-push",
    "href": "ae/ae-07-taxes-join.html#render-commit-and-push",
    "title": "AE 07: Sales taxes + data joining",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "lab/lab-3.html",
    "href": "lab/lab-3.html",
    "title": "Lab 3",
    "section": "",
    "text": "In this lab you’ll build the data wrangling and visualization skills you’ve developed so far and data tidying and joining to your repertoire.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you have not yet done those, you should go back and review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nBe able to pivot/reshape data using tidyr\n\nContinue developing your data wrangling skills using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-3 repo from GitHub, open your lab-3.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment."
  },
  {
    "objectID": "lab/lab-3.html#learning-objectives",
    "href": "lab/lab-3.html#learning-objectives",
    "title": "Lab 3",
    "section": "",
    "text": "By the end of the lab, you will…\n\nBe able to pivot/reshape data using tidyr\n\nContinue developing your data wrangling skills using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub"
  },
  {
    "objectID": "lab/lab-3.html#getting-started",
    "href": "lab/lab-3.html#getting-started",
    "title": "Lab 3",
    "section": "",
    "text": "Log in to RStudio, clone your lab-3 repo from GitHub, open your lab-3.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding."
  },
  {
    "objectID": "lab/lab-3.html#packages",
    "href": "lab/lab-3.html#packages",
    "title": "Lab 3",
    "section": "",
    "text": "In this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document."
  },
  {
    "objectID": "lab/lab-3.html#guidelines",
    "href": "lab/lab-3.html#guidelines",
    "title": "Lab 3",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment."
  },
  {
    "objectID": "lab/lab-3.html#part-1",
    "href": "lab/lab-3.html#part-1",
    "title": "Lab 3",
    "section": "Part 1",
    "text": "Part 1\nInflation across the world\nFor this part of the analysis you will work with inflation data from various countries in the world over the last 30 years.\n\ncountry_inflation &lt;- read_csv(\"data/country-inflation.csv\")\n\nQuestion 1\nGet to know the data.\n\nglimpse() at the country_inflation data frame and answer the following questions based on the output. How many rows does country_inflation have and what does each row represent? How many columns does country_inflation have and what does each column represent?\nDisplay a list of the unique countries included in the dataset. Hint: Another word for “unique” is distinct().\n\n\n\n\n\n\n\nTip\n\n\n\nA function that can be useful for part (b) is pull(). Check out its documentation for examples of usage.\n\n\nQuestion 2\nWhich countries had the top three highest inflation rates in 2023? Your output should be a data frame with two columns, country and 2023, with inflation rates in descending order, and three rows for the top three countries. Briefly comment on how the inflation rates for these countries compare to the inflation rate for United States in that year.\n\n\n\n\n\n\nTip\n\n\n\nColumn names that are numbers are not considered “proper” in R, therefore to select them you’ll need to surround them with backticks, e.g. select( ` 1993 ` ).\n\n\nQuestion 3\nIn a single pipeline,\n\ncalculate the ratio of the inflation in 2023 and inflation in 1993 for each country and store this information in a new column called inf_ratio,\nselect the variables country and inf_ratio, and\nstore the result in a new data frame called country_inflation_ratios.\n\nThen, in two separate pipelines,\n\narrange country_inflation_ratios in increasing order of inf_ratio and\narrange country_inflation_ratios in decreasing order of inf_ratio.\n\nWhich country’s inflation increase is the largest over this time period and by how much? Which country’s inflation decrease is the largest over this time period and by how much?\n\n\n\n\n\n\nTip\n\n\n\nFor this question you’ll once again need to use variables whose names are numbers (years) in your pipeline. Make sure to surround the names of such variables with backticks (`).\n\n\nQuestion 4\nReshape (pivot) country_inflation such that each row represents a country/year combination, with columns country, year, and annual_inflation. Then, display the resulting data frame and state how many rows and columns it has.\nRequirements:\n\nYour code must use one of pivot_longer() or pivot_wider(). There are other ways you can do this reshaping move in R, but this question requires solving this problem by pivoting.\nIn your pivot_*() function, you must use names_transform = as.numeric as an argument to transform the variable type to numeric as you pivot the data so that in the resulting data frame the year variable is numeric.\nThe resulting data frame must be saved as something other than country_inflation so you (1) can refer to this data frame later in your analysis and (2) do not overwrite country_inflation. Use a short but informative name.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe remaining questions in Part 1 require the use of the pivoted data frame from Question 4.\n\n\n\nIf you haven’t yet done so, now is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n\nQuestion 5\nUse a separate, single pipeline to answer each of the following questions.\nRequirement: Your code must use the filter() function for each part, not arrange().\n\nWhat is the highest inflation rate observed between 1993 and 2023? The output of the pipeline should be a data frame with one row and three columns. In addition to code and output, your response should include a single sentence stating the country and year.\nWhat is the lowest inflation rate observed between 1993 and 2023? The output of the pipeline should be a data frame with one row and three columns. In addition to code and output, your response should include a single sentence stating the country and year.\nPutting (a) and (b) together: What are the highest and the lowest inflation rates observed between 1993 and 2023? The output of the pipeline should be a data frame with two rows and three columns.\nQuestion 6\na. Create a vector called countries_of_interest which contains the names of up to five countries you want to visualize the inflation rates for over the years. For example, if these countries are Türkiye and United States, you can express this as follows:\n\ncountries_of_interest &lt;- c(\"Türkiye\", \"United States\")\n\nIf they are Türkiye, United States, and Chile, you can express this as follows:\n\ncountries_of_interest &lt;- c(\n  \"Türkiye\", \"United States\", \"Chile\"\n)\n\nSo on and so forth… Then, in 1-2 sentences, state why you chose these countries.\n\n\n\n\n\n\nNote\n\n\n\nYour countries_of_interest should consist of no more than five countries. Make sure that the spelling of your countries matches how they appear in the dataset.\n\n\nb. In a single pipeline, filter your reshaped dataset to include only the countries_of_interest from part (a), and save the resulting data frame with a new name so you (1) can refer to this data frame later in your analysis and (2) do not overwrite the data frame you’re starting with. Use a short but informative name. Then, in a new pipeline, find the distinct() countries in the data frame you created.\n\n\n\n\n\n\nTip\n\n\n\nThe number of distinct countries in the filtered data frame you created in part (b) should equal the number of countries you chose in part (a). If it doesn’t, you might have misspelled a country name or made a mistake in filtering for these countries. Go back and correct your work.\n\n\nQuestion 7\nUsing your data frame from the previous question, create a plot of annual inflation vs. year for these countries. Then, in a few sentences, describe the patterns you observe in the plot, particularly focusing on anything you find surprising or not surprising, based on your knowledge (or lack thereof) of these countries economies.\nRequirements for the plot:\n\nData should be represented with points as well as lines connecting the points for each country.\nEach country should be represented by a different color line and different color and shape points.\nAxes and legend should be properly labeled.\nThe plot should have an appropriate title (and optionally a subtitle).\nPlot should be customized in at least one way – you could use a different than default color scale, or different than default theme, or some other customization.\n\n\nNow is another good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "lab/lab-3.html#part-2",
    "href": "lab/lab-3.html#part-2",
    "title": "Lab 3",
    "section": "Part 2",
    "text": "Part 2\nInflation in the US\nThe OECD defines inflation as follows:\n\nInflation is a rise in the general level of prices of goods and services that households acquire for the purpose of consumption in an economy over a period of time.\nThe main measure of inflation is the annual inflation rate which is the movement of the Consumer Price Index (CPI) from one month/period to the same month/period of the previous year expressed as percentage over time.\nSource: OECD CPI FAQ\n\nCPI is broken down into 12 expenditures such as food, housing, health, etc. Your goal in this part is to create another time series plot of annual inflation, this time for US only.\nThe data you will need to create this visualization is spread across two files:\n\n\nus-inflation.csv: Annual inflation rate for the US for 12 CPI expenditures. Each expenditure is identified by an ID number.\n\ncpi-expenditures.csv: A “lookup table” of CPI expenditure ID numbers and their descriptions.\n\nLet’s load both of these files.\n\nus_inflation &lt;- read_csv(\"data/us-inflation.csv\")\ncpi_expenditures &lt;- read_csv(\"data/cpi-expenditures.csv\")\n\nQuestion 8\na. How many columns and how many rows does the us_inflation dataset have? What are the variables in it? Which years do these data span? Write a brief (1-2 sentences) narrative summarizing this information.\nb. How many columns and how many rows does the cpi_expenditures dataset have? What are the variables in it? Write a brief (1-2 sentences) narrative summarizing this information.\nc. Create a new dataset by joining the us_inflation dataset with the cpi_expenditure_id dataset.\n\nDetermine which type of join is the most appropriate one and use that.\nNote that the two datasets don’t have a variable with a common name, though they do have variables that contain common information but are named differently. You will need to first figure out which variables those are, and then define the by argument and use the join_by() function to indicate these variables to join the datasets by.\nUse a short but informative name for the joined dataset, and do not overwrite either of the datasets that go into creating it.\n\nThen, find the number of rows and columns of the resulting dataset and report the names of its columns. Add a brief (1-2 sentences) narrative summarizing this information.\nQuestion 9\na. Create a vector called expenditures_of_interest which contains the descriptions or IDs of CPI expenditures you want to visualize. Your expenditures_of_interest should consist of no more than five expenditures. If you’re using descriptions, make sure that the spelling of your expenditures matches how they appear in the dataset. Then, in 1-2 sentences, state why you chose these expenditures.\n\n\n\n\n\n\nTip\n\n\n\nRefer back to the guidance provided in Question 6 if you’re not sure how to create this vector.\n\n\nb. In a single pipeline, filter your joined dataset to include only the expenditures_of_interest from part (a), and save the resulting data frame with a new name so you (1) can refer to this data frame later in your analysis and (2) do not overwrite the data frame you’re starting with. Use a short but informative name. Then, in a new pipeline, find the distinct() expenditures in the data frame you created.\nQuestion 10\nUsing your data frame from the previous question, create a plot of annual inflation vs. year for these expenditures. Then, in a few sentences, describe the patterns you observe in the plot, particularly focusing on anything you find surprising or not surprising, based on your knowledge (or lack thereof) of inflation rates in the US over the last decade.\n\nData should be represented with points as well as lines connecting the points for each expenditure.\nEach expenditure should be represented by a different color line and different color and shape points.\nAxes and legend should be properly labeled.\nThe plot should have an appropriate title (and optionally a subtitle).\nPlot should be customized in at least one way – you could use a different than default color scale, or different than default theme, or some other customization.\nIf your legend has labels that are too long, you can try moving the legend to the bottom and stack the labels vertically. Hint: The legend.position and legend.direction arguments of the theme() functions will be useful.\n\n\nggplot(...) +\n  ... +\n  theme(\n    legend.position = \"bottom\", \n    legend.direction = \"vertical\"\n  )\n\n\nIf you haven’t yet done so since Part 1, now is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "lab/lab-3.html#submission",
    "href": "lab/lab-3.html#submission",
    "title": "Lab 3",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered “on time”.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope"
  },
  {
    "objectID": "lab/lab-3.html#grading-and-feedback",
    "href": "lab/lab-3.html#grading-and-feedback",
    "title": "Lab 3",
    "section": "Grading and feedback",
    "text": "Grading and feedback\n\nSome of the questions will be graded for accuracy.\nSome will be graded for completion.\nThere are also workflow points, for coding style, for committing at least three times as you work through your lab, and for overall organization.\nYou’ll receive feedback on your lab on Gradescope within a week."
  },
  {
    "objectID": "lab/lab-6.html",
    "href": "lab/lab-6.html",
    "title": "Lab 6",
    "section": "",
    "text": "In this lab you’ll start your practice of statistical modeling. You’ll fit models, interpret model output, and make decisions about your data and research question based on the model results. And you’ll wrap up the lab revisiting the topic of data science ethics.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nFit, interpret, and make predictions with models with multiple predictors.\nPerform model selection.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-6 repo from GitHub, open your lab-6.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-6. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-6.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-6.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\ntidymodels package for modeling in a “tidy” way, and\n\nopenintro package for the dataset for Part 1.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-6.html#learning-objectives",
    "href": "lab/lab-6.html#learning-objectives",
    "title": "Lab 6",
    "section": "",
    "text": "By the end of the lab, you will…\n\nFit, interpret, and make predictions with models with multiple predictors.\nPerform model selection.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub"
  },
  {
    "objectID": "lab/lab-6.html#getting-started",
    "href": "lab/lab-6.html#getting-started",
    "title": "Lab 6",
    "section": "",
    "text": "Log in to RStudio, clone your lab-6 repo from GitHub, open your lab-6.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-6. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-6.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-6.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding."
  },
  {
    "objectID": "lab/lab-6.html#packages",
    "href": "lab/lab-6.html#packages",
    "title": "Lab 6",
    "section": "",
    "text": "In this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\ntidymodels package for modeling in a “tidy” way, and\n\nopenintro package for the dataset for Part 1.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document."
  },
  {
    "objectID": "lab/lab-6.html#guidelines",
    "href": "lab/lab-6.html#guidelines",
    "title": "Lab 6",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-6.html#question-1",
    "href": "lab/lab-6.html#question-1",
    "title": "Lab 6",
    "section": "Question 1",
    "text": "Question 1\nIn this question you’ll prepare the dataset you’ll use in this part.\n\nRead: Read the data and save it as an object called gapminder_raw.\nFilter: For our analysis, we will only be working with data from 2023. Filter the data set so only values from the year 2023 are included. Save this data set as gapminder_raw_23 and use it for the remainder of this exercise and the following.\nGlimpse: Glimpse at gapminder_raw_23 and list the variables and their types. Comment on any unexpected features in the data.\nClean: First, figure out why gdp_percap is read in as a character variable and describe your findings in one sentence. Then, clean the gdp_percap variable and convert it to numeric values. Save the resulting data frame as gapminder_23."
  },
  {
    "objectID": "lab/lab-6.html#question-2",
    "href": "lab/lab-6.html#question-2",
    "title": "Lab 6",
    "section": "Question 2",
    "text": "Question 2\nWe are interested in learning more about life expectancy in countries, and we’ll start by exploring the relationship between life expectancy and GDP. Create two visualizations:\n\nScatter plot of life_exp vs. gdp_percap\nScatter plot of life_exp_log vs. gdp_percap, where life_exp_log is a new variable you add to the data set by taking the natural log of life_exp.\n\nFirst describe the relationship between each pair of the variables. Then, comment on which relationship would be better modeled using a linear model, and explain your reasoning.\n\n\n\n\n\n\nNote\n\n\n\nThe question isn’t asking which of these relationships is clearly linear, but instead which would be better modeled using a linear model."
  },
  {
    "objectID": "lab/lab-6.html#question-3",
    "href": "lab/lab-6.html#question-3",
    "title": "Lab 6",
    "section": "Question 3",
    "text": "Question 3\n\nData Prep: What happens when you take the natural log of 0? Remove rows of your data set where life_expectancy = 0, justifying why this is helpful.\nModel fitting: Fit a linear model predicting log life expectancy from gross domestic product. Display the tidy summary.\n\nModel evaluation:\n\nCalculate the R-squared of the model using two methods and confirm that the values match: first method is using glance() and the other method is based on the value of the correlation coefficient between the two variables.\nInterpret R-squared in the context of the data and the research question."
  },
  {
    "objectID": "lab/lab-6.html#question-4",
    "href": "lab/lab-6.html#question-4",
    "title": "Lab 6",
    "section": "Question 4",
    "text": "Question 4\nNext, we want to examine if the relationship between life expectancy and GDP that we observed in the previous exercise holds across all continents in our data. We’ll continue to work with logged life expectancy (life_exp_log) and data from 2023.\n\nJustification: Create a scatter plot of life_exp_log vs. gdp_percap, where the points are colored by continent. Do you think the trend between life_exp_log and gdp_percap is different for different continents? Justify your answer with specific features of the plot.\n\nModel fitting and interpretation:\n\nRegardless of your answer in part (a), fit an additive model (main effects) that predicts life_exp_log from GDP per capita and continent (with Africas as the baseline level). Display a tidy summary of the model output.\nInterpret the intercept of the model, making sure that your interpretation is in the units of the original data (not on log scale).\nInterpret the slope of the model, making sure that your interpretation is in the units of the original data (not on log scale).\n\n\nPrediction: Predict the life expectacy of a country in Asia where the average GDP per capita is $70,000. Do this using R functions, not by manually plugging in numbers."
  },
  {
    "objectID": "lab/lab-6.html#question-5",
    "href": "lab/lab-6.html#question-5",
    "title": "Lab 6",
    "section": "Question 5",
    "text": "Question 5\nCommunication is a critical yet often overlooked part of data science. When we engage with our audience and capture their interest, we can ultimately better communicate what we are trying to share.\nPlease watch the following video: Hans Rosling: 200 years in 4 minutes.\nThen, write a paragraph (4-5 sentences) addressing the following:\n\nWhat did you enjoy about the presentation of data? What did you find interesting\nWere there any aspects of the presentation that were hard to follow? If so, what?\nWhat are your general take-aways from this presentation?\nWhat are your general take-aways from how this presentation was given?"
  },
  {
    "objectID": "lab/lab-6.html#question-6",
    "href": "lab/lab-6.html#question-6",
    "title": "Lab 6",
    "section": "Question 6",
    "text": "Question 6\n\nRead in the data. Then, create a scatter plot that investigates the relationship between the number of bikes rented and the temperature outside. Include a straight line of best fit to help discuss the discovered relationship. Summarize your findings in at most 4 sentences.\nAnother researcher suggests to look at the relationship between bikes rented and temperature by each of the four months of interest. Recreate your plot in part a, and color the points by month. Include a straight line for each of the four months to help discuss each month’s relationship between bikes rented and temperature. Summarize your findings in at most 4 sentences.\n\nWatch the following video on Simpson’s Paradox here. After you do, please answer the following questions.\n\nIn your own words, summarize Simpson’s Paradox in at most 4 sentences.\nCompare and contrast your findings from part (a) and part (b). What’s different?\nThink critically about your answer to part d. What other context from this study could be creating this paradox? That is, identify a potential confounding variable in this study. Be sure to justify how your example could be a potential confounding variable by relating it back to both bike rentals and temperature."
  },
  {
    "objectID": "lab/lab-6.html#question-7",
    "href": "lab/lab-6.html#question-7",
    "title": "Lab 6",
    "section": "Question 7",
    "text": "Question 7\na. Let’s begin by taking a look at the squat lifting records.\n\nStart with the ipf data frame.\nFirst, remove any observations that are negative for squat.\nNext, create a new column called best3_squat_lbs that converts the record from kilograms to pounds.\n\nYou may need to google the conversion formula. Save your data frame as ipf_squat. Report the number of rows and columns of this new data frame using inline code.\nb. Using the ipf_squat data frame you created in part (a), create a scatter plot to investigate the relationship between squat (in lbs) and age. Age should be on the x-axis. Adjust the alpha level of your points to get a better sense of the density of the data. Add a linear trend-line. Summarize the trend you observe in at most 4 sentences.\nc. Write down the linear population model to predict lift squat lbs from age. Next, fit the linear model, and save it as age_fit. Re-write your previous equation replacing the population parameters with the numeric estimates. This is called the “fitted” linear model. Interpret each estimate of \\(\\beta\\). Are the interpretations sensible?"
  },
  {
    "objectID": "lab/lab-6.html#question-8",
    "href": "lab/lab-6.html#question-8",
    "title": "Lab 6",
    "section": "Question 8",
    "text": "Question 8\na. Building on your ipf_squat data frame from the previous question, create a new column called age2 that takes the age of each lifter and squares it. Save it to your data frame ipf_squat. Next, plot squat in lbs vs age2 and add a linear best fit line. How does the fit of the model compare to the one from earlier?\n\n\n\n\n\n\nTip\n\n\n\nTo raise a value to a power, use ^ in R, e.g.: 2 ^ 2 gives you 4, 2 ^ 3 gives you 8, etc.\n\n\nb. One metric to assess the fit of a model is the correlation squared, also known as \\(R^2\\). Fit the age\\(^2\\) model and save the object as age2_fit. Compare \\(R^2\\) of the new model (squat vs. age\\(^2\\)) to the \\(R^2\\) of the earlier model (squat vs. age). Which has a higher \\(R^2\\)?"
  },
  {
    "objectID": "lab/lab-6.html#question-9",
    "href": "lab/lab-6.html#question-9",
    "title": "Lab 6",
    "section": "Question 9",
    "text": "Question 9\nStart over with the ipf data frame.\nNext, let’s turn our attention to dead lifting records. Recreate the plot below. Make sure axes and title labels are exactly matching, including spelling, capitalization, etc. Based on the plot below, which impacts deadlift weight more, age category or sex?\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou will need to create a couple of new columns. One to classify age appropriately and one to convert best3deadlift_kg to the plotted units (lbs). Notice that there are no negative deadlift values on the x-axis."
  },
  {
    "objectID": "lab/lab-6.html#question-10",
    "href": "lab/lab-6.html#question-10",
    "title": "Lab 6",
    "section": "Question 10",
    "text": "Question 10\na. Start over with the ipf data frame.\nFinally, let’s turn our attention to bench press records.\nTo begin, remove any observations that are negative for bench press, create two new columns: best3bench_lbs and bodyweight_lbs. Save the result in a new data frame called ipf_bench.\nThen, create a scatter plot to investigate the relationship between best bench press (in lbs) and the lifter’s bodyweight (in lbs). Bodyweight should be on the x-axis. Add a linear trend-line. Be sure to label all axes and give the plot a title. Comment on what you observe.\nb. Fit the linear model displayed in part (a) and write down the fitted model equation only, replacing \\(\\hat{\\beta}\\)s with their fitted estimates. Interpret the \\(\\hat{\\beta}\\)s (intercept and slope). Report \\(R^2\\). Is body weight an important predictor of bench press ability? Why or why not?"
  },
  {
    "objectID": "lab/lab-6.html#footnotes",
    "href": "lab/lab-6.html#footnotes",
    "title": "Lab 6",
    "section": "Footnotes",
    "text": "Footnotes\n\nData subset from Progress in Artificial Intelligence, 2013.↩︎"
  },
  {
    "objectID": "lab/lab-4.html",
    "href": "lab/lab-4.html",
    "title": "Lab 4",
    "section": "",
    "text": "In this lab, you’ll review topics you’ve worked with in previous labs, practice importing data, and dive into the concepts of data types and classes.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nLearn to read data in from Excel spreadsheets\nGain more experience with joining and pivoting data frames\nReview Quarto cell options\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-4 repo from GitHub, open your lab-4.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-4. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-4.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-4.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\nreadxl package for reading in Excel files,\n\njanitor package for cleaning up variable names, and\n\npalmerpenguins and datasauRus packages for some datasets\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(palmerpenguins)\nlibrary(datasauRus)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nStarting with this lab, you are expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-4.html#learning-objectives",
    "href": "lab/lab-4.html#learning-objectives",
    "title": "Lab 4",
    "section": "",
    "text": "By the end of the lab, you will…\n\nLearn to read data in from Excel spreadsheets\nGain more experience with joining and pivoting data frames\nReview Quarto cell options\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub"
  },
  {
    "objectID": "lab/lab-4.html#getting-started",
    "href": "lab/lab-4.html#getting-started",
    "title": "Lab 4",
    "section": "",
    "text": "Log in to RStudio, clone your lab-4 repo from GitHub, open your lab-4.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-4. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-4.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-4.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding."
  },
  {
    "objectID": "lab/lab-4.html#packages",
    "href": "lab/lab-4.html#packages",
    "title": "Lab 4",
    "section": "",
    "text": "In this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\nreadxl package for reading in Excel files,\n\njanitor package for cleaning up variable names, and\n\npalmerpenguins and datasauRus packages for some datasets\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(palmerpenguins)\nlibrary(datasauRus)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document."
  },
  {
    "objectID": "lab/lab-4.html#guidelines",
    "href": "lab/lab-4.html#guidelines",
    "title": "Lab 4",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nStarting with this lab, you are expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-4.html#part-1---team-usa-at-the-olympics",
    "href": "lab/lab-4.html#part-1---team-usa-at-the-olympics",
    "title": "Lab 4",
    "section": "Part 1 - Team USA at the Olympics",
    "text": "Part 1 - Team USA at the Olympics\nFor this part, you’ll work with data from the rosters of Team USA from the 2020 and 2024 Olympics. The data come from https://www.teamusa.com and the rosters for the two games are in a single Excel file (team-usa.xlsx in your data folder), accross two separate spreadsheets within that file. Figure 1 shows screenshots of these spreadsheets.\n\n\n\n\n\n\nTeam USA 2020\n\n\n\n\n\nTeam USA 2024\n\n\n\n\n\nFigure 1: Excel file with two sheets for rosters of Team USA 2020 and 2024.\n\n\nYour goal is to answer questions about athletes who competed in both games and only one of the games.\nQuestion 1\n\nRead data from the two sheets of team-usa.xlsx as two separate data frames called team_usa_2020 and team_usa_2024.\n\n\n\n\n\n\n\nTip\n\n\n\nThe names of the sheets are shown in the screenshots in Figure 1, or you can use the excel_sheets() function to discover them. Additionally, note that the first row of the sheets contain a logo and a title describing the contents of the data, and not the header row containing variable names.\n\n\n\nRead the documentation for the clean_names() function from the janitor package at https://sfirke.github.io/janitor/reference/clean_names.html. Use this function to “clean” the variable names of team_usa_2020 and team_usa_2024 and save the data frames with the new variable names.\n\nCreate a new variable in both of the datasets called name that:\n\n\npaste()s together the first_name and last_name variables with a space in between and\nis the first variable in the resulting data frame.\n\n\nUsing the appropriate *_join() function, determine how many athletes participated in both Olympic Games?\n\n\n\n\n\n\n\nImportant\n\n\n\nYour answer to this question, based on the data frames you created, should be 0, even if it doesn’t make sense in context of actual Olympic athletes.\n\n\nQuestion 2\nIf you have even a passing knowledge of the Olympic Games, you might know that there are some athletes that participated in both the 2020 and 2024 games, e.g., Simone Biles, Katie Ledecky, etc.\n\nThe reason why athlete names didn’t match across the two data frames is that in one data frame, names are in UPPER CASE, and in the other, they’re in Title Case. Update the 2020 data frame to make name all upper case. Display the first 10 rows of team_usa_2020 with upper case names.\n\n\n\n\n\n\n\nImportant\n\n\n\nYour answer must use the str_to_upper() function.\n\n\n\nLet’s try that question again: How many athletes participated in both Olympic Games?\nHow many athletes participated in the 2020 Olympic Games but not the 2024 Olympic Games? How many athletes participated in the 2024 Olympic Games but not the 2020 Olympic Games?"
  },
  {
    "objectID": "lab/lab-4.html#part-2---datasaurus",
    "href": "lab/lab-4.html#part-2---datasaurus",
    "title": "Lab 4",
    "section": "Part 2 - DatasauRus",
    "text": "Part 2 - DatasauRus\nThe data frame you will be working with in this part is called datasaurus_dozen and it’s in the datasauRus package. This single data frame contains 13 datasets, designed to show us why data visualization is important and how summary statistics alone can be misleading. The different datasets are marked by the dataset variable, as shown in Figure 2.\n\n\n\n\n\nFigure 2: The `datasaurus_dozen` data frame stacks 13 datasets on top of each other. This figure shows the first three datasets.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf it’s confusing that the data frame is called datasaurus_dozen when it contains 13 datasets, you’re not alone! Have you heard of a baker’s dozen?\n\n\nHere is a peek at the top 10 rows of the dataset:\n\ndatasaurus_dozen\n\n# A tibble: 1,846 × 3\n   dataset     x     y\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 dino     55.4  97.2\n 2 dino     51.5  96.0\n 3 dino     46.2  94.5\n 4 dino     42.8  91.4\n 5 dino     40.8  88.3\n 6 dino     38.7  84.9\n 7 dino     35.6  79.9\n 8 dino     33.1  77.6\n 9 dino     29.0  74.5\n10 dino     26.2  71.4\n# ℹ 1,836 more rows\n\n\nQuestion 3\nIn a single pipeline, calculate the mean of x, mean of y, standard deviation of x, standard deviation of y, and the correlation between x and y for each level of the dataset variable. Then, in 1-2 sentences, comment on how these summary statistics compare across groups (datasets).\n\n\n\n\n\n\nTip\n\n\n\nThere are 13 groups but tibbles only print out 10 rows by default. To display all rows, add print(n = 13) as the last step of your pipeline.\n\n\nQuestion 4\nCreate a scatterplot of y versus x and color and facet it by dataset. Then, in 1-2 sentences, how these plots compare across groups (datasets). How does your response in this question compare to your response to the previous question and what does this say about using visualizations and summary statistics when getting to know a dataset?\n\n\n\n\n\n\nTip\n\n\n\nWhen you both color and facet by the same variable, you’ll end up with a redundant legend. Turn off the legend by adding show.legend = FALSE to the geom creating the legend.\n\n\n\nRender, commit, and push your changes. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "lab/lab-4.html#part-3---medical-marijuana-in-nc",
    "href": "lab/lab-4.html#part-3---medical-marijuana-in-nc",
    "title": "Lab 4",
    "section": "Part 3 - Medical marijuana in NC",
    "text": "Part 3 - Medical marijuana in NC\nSurveyUSA polled 900 NC adults between September 4-7, 2024. Of the 900 NC adults, 771 were identified by SurveyUSA as being registered to vote.1 The following question was asked to these 771 adults:\n\nShould the use of marijuana for medical use remain against the law in North Carolina? Or be legalized?\n\nResponses were broken down into the following categories:\n\n\nVariable\nLevels\n\n\n\nAge\n18-49; 50+\n\n\nOpinion\nRemain Against The Law; Be Made Legal; Not Sure\n\n\n\nOf the 771 responses, 391 were between the ages of 18-49. Of the individuals that are between 18-49, 59 individuals responded that they think medical marijuana should remain against the law, 292 said it should be made legal, and the remainder were not sure. Of the individuals that are 50+, 67 individuals responded that they think medical marijuana should remain against the law, 245 said it should be made legal, and the remainder were not sure.\nQuestion 5\n\n\nFill in the code below to create a two-way table that summarizes these data.\n\nsurvey_counts &lt;- tibble( \n  age = c(),\n  opinion = c(),\n  n = c()\n  )\n\nsurvey_counts |&gt;\n  pivot_wider( \n    names_from = ___,\n    values_from = ___\n  )\n\n\n\nFor parts b-d below, use a single pipeline starting with survey_counts, calculate the desired proportions, and make sure the result is an ungrouped data frame with a column for relevant counts, a column for relevant proportions, and a column for the groups you’re interested in.\n\nCalculate the proportions of 18-49 year olds and 50+ year-olds in this sample.\nCalculate the proportions of those who think medical marijuana should remain against the law, should be made legal, and who are not sure.\n\nCalculate the proportions of individuals in this sample who think medical marijuana should remain against the law, should be made legal, and who are not sure\n\namong those who are 18-49 years old and\namong those who are 50+ years old.\n\n\nQuestion 6\n\n\nCreate a visualization that can be used to evaluate the relationship between age and opinion on legalizing medical marijuana in North Carolina based on this survey’s results.\n\n\n\n\n\n\nTip\n\n\n\nYour visualization should display the proportions you calculated in Question 5d.\n\n\n\nBased on your calculations so far, as well as your visualization, write 1-2 sentences that describe the relationship, in this sample, between age and opinion on legalizing medical marijuana in North Carolina.\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "lab/lab-4.html#part-4---mtcars",
    "href": "lab/lab-4.html#part-4---mtcars",
    "title": "Lab 4",
    "section": "Part 4 - mtcars\n",
    "text": "Part 4 - mtcars\n\nIn this part, you’ll work with one of the most basic and overused datasets in R: mtcars. The data in this dataset come from the 1974 Motor Trend US magazine (so, yes, they’re old!) and provide information on fuel efficiency and other car characteristics.\nQuestion 7\nSince the dataset is used in many code examples, it’s not unexpected that some analyses of the data are good and some not so much.\n\n\n\n\n\n\nTip\n\n\n\nFor both parts of this question, you should review the data dictionary that is in the documentation for the dataset which you can find at https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html or by typing ?mtcars in your Console.\n\n\na. You come across the following visualization of these data. First, determine what is wrong with this visualization and describe it in one sentence. Then, fix and improve the visualization. As part of your improvement, make sure your legend\n\nis on top of the plot,\nis informative, and\nlists levels in the order they appear in the plot.\n\n\nggplot(mtcars, aes(x = wt, y = mpg, color = am)) +\n  geom_point() +\n  labs(\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\"\n  )\n\nb. Update your plot from part (a) further, this time using different shaped points for cars with V-shaped and straight engines. Once again, some requirements for your legend – it should be informative and on the right of the plot.\nQuestion 8\nYour task is to make your plot from Question 7b as ugly and as ineffective as possible. Change colors, axes, fonts, themes, or anything else you can think of in the code chunk below. You can also search online for other themes, fonts, etc. that you want to tweak. Try to make it as ugly as possible, the sky is the limit! You must make at least 5 updates to the plot.\nYour answer must include\n\na list of the at least 5 updates you’ve made to your plot from Question 7b, and\n1-2 sentence explanation of why the plot you created is ugly (to you, at least) and ineffective.\n\n\nRender, commit, and push your work so far. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "lab/lab-4.html#part-5---all-about-quarto",
    "href": "lab/lab-4.html#part-5---all-about-quarto",
    "title": "Lab 4",
    "section": "Part 5 - All about Quarto",
    "text": "Part 5 - All about Quarto\nQuestion 9\nYou have the following code chunk:\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nAdd the following code cell options, one at a time, and set each to false and then to true. After each value, render your document and observe its effect. Ultimately, choose the values that are the most appropriate for this code cell. Based on the behaviors you observe, describe what each code cell option does.\n\necho\nwarning\neval\nQuestion 10\n\nYou have the following code cell again.\n\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nAdd fig-width and fig-asp as code chunk options. Try setting fig-width to values between 1 and 10. Try setting fig-asp to values between 0.1 and 1. Re-render the document after each value and observe its effect. Ultimately, choose values that make the plot look visually pleasing in the rendered document. Based on the behavior you observe, describe what each chunk option does.\n\n\n\n\n\n\nTip\n\n\n\nNow that you’ve had more practice with figure sizing in Quarto documents, review all of the plots you made in this lab and adjust their widths and aspect rations to improve how they look in your rendered document.\n\n\nb. You have the following code cell, but look carefully, it’s not exactly the same!\n\ngplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nAdd error as a code chunk option and set it to false and then set it to true. After each value, render your document and observe its effect. Ultimately, choose the value that allows you to render your document without altering the code. Based on the behavior you observe, describe what this code chunk option does.\n\n\n\n\n\n\nTip\n\n\n\nReading the documentation might also be helpful.\n\n\n\nRender, commit, and push your work. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "lab/lab-4.html#footnotes",
    "href": "lab/lab-4.html#footnotes",
    "title": "Lab 4",
    "section": "Footnotes",
    "text": "Footnotes\n\nFull survey results can be found at https://www.surveyusa.com/client/PollReport.aspx?g=c6995e17-3837-413e-ac98-3684e1c74dc1.↩︎"
  },
  {
    "objectID": "lab/lab-1.html",
    "href": "lab/lab-1.html",
    "title": "Lab 1",
    "section": "",
    "text": "This lab will introduce you to the course computing workflow. The main goal is to reinforce our demo of R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\n\n\n\n\n\n\nNote\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface, commonly referred to as an integrated development environment or an IDE, for short.\n\n\nAn additional goal is to reinforce Git and GitHub, the version control, web hosting, and collaboration systems that we will be using throughout the course.\n\n\n\n\n\n\nNote\n\n\n\nGit is a version control system (like “Track Changes” features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\n\n\n\n\n\n\nWarning\n\n\n\nThis lab assumes that you have already completed Lab 0. If you have not, please\n\ngo back and do that first before proceeding and\nlet your TA know as they will need to set up a Lab 1 repository for you before you can complete this lab.\n\n\n\n\nBy the end of the lab, you will…\n\nBe familiar with the workflow using R, RStudio, Git, and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using Git and GitHub\nBe able to create data visualizations using ggplot2\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file.\n\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-1.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human-friendly data representation for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document.\nIf you get a popup window error, click “Try again”.\nExamine the rendered document and make sure your name is updated in the document.\n\n\n\nGo to the Git pane in RStudio. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. If you have rendered the document, you should also see its output, a PDF file, listed there.\n\n\nClick on it to select it in this list and then click on Diff.\nThis shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\n\n\nIf you’re happy with these changes, prepare the changes to be pushed to your remote repository.\n\nFirst, stage your changes by checking the appropriate box on the files you want to prepare.\nNext, write a meaningful commit message (for instance, “Updated author name”) in the Commit message box.\nFinally, click Commit. Note that every commit needs to have a commit message associated with it.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration (e.g., restoring a previous version of your document).\nIn the first few assignments, we will tell you exactly when to commit and, in some cases, what commit message to use. As the semester progresses, we will let you make these decisions.\n\n\n\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\n\nIn the Git pane, click on Push.\nThen, make sure all the changes went to GitHub. Go to your GitHub repo in your browser and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub, and you’re good to go!\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you don’t see your update, go back to Step 4. Remember that in order to push your changes to GitHub, you must have staged (checked boxes) your commit (with a commit message) to be pushed and then click on Push.\n\n\n\nIn this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.\n\n\nThe tidyverse is a meta-package. When you load it you get nine packages loaded for you:\n\n\ndplyr: for data wrangling\n\nforcats: for dealing with factors\n\nggplot2: for data visualization\n\nlubridate: for dealing with dates\n\npurrr: for iteration with functional programming\n\nreadr: for reading and writing data\n\nstringr: for string manipulation\n\ntibble: for modern, tidy data frames\n\ntidyr: for data tidying and rectangling\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment."
  },
  {
    "objectID": "lab/lab-1.html#learning-objectives",
    "href": "lab/lab-1.html#learning-objectives",
    "title": "Lab 1",
    "section": "",
    "text": "By the end of the lab, you will…\n\nBe familiar with the workflow using R, RStudio, Git, and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using Git and GitHub\nBe able to create data visualizations using ggplot2"
  },
  {
    "objectID": "lab/lab-1.html#getting-started",
    "href": "lab/lab-1.html#getting-started",
    "title": "Lab 1",
    "section": "",
    "text": "Go to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file.\n\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-1.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human-friendly data representation for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document.\nIf you get a popup window error, click “Try again”.\nExamine the rendered document and make sure your name is updated in the document.\n\n\n\nGo to the Git pane in RStudio. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. If you have rendered the document, you should also see its output, a PDF file, listed there.\n\n\nClick on it to select it in this list and then click on Diff.\nThis shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\n\n\nIf you’re happy with these changes, prepare the changes to be pushed to your remote repository.\n\nFirst, stage your changes by checking the appropriate box on the files you want to prepare.\nNext, write a meaningful commit message (for instance, “Updated author name”) in the Commit message box.\nFinally, click Commit. Note that every commit needs to have a commit message associated with it.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration (e.g., restoring a previous version of your document).\nIn the first few assignments, we will tell you exactly when to commit and, in some cases, what commit message to use. As the semester progresses, we will let you make these decisions.\n\n\n\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\n\nIn the Git pane, click on Push.\nThen, make sure all the changes went to GitHub. Go to your GitHub repo in your browser and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub, and you’re good to go!\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you don’t see your update, go back to Step 4. Remember that in order to push your changes to GitHub, you must have staged (checked boxes) your commit (with a commit message) to be pushed and then click on Push."
  },
  {
    "objectID": "lab/lab-1.html#packages",
    "href": "lab/lab-1.html#packages",
    "title": "Lab 1",
    "section": "",
    "text": "In this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.\n\n\nThe tidyverse is a meta-package. When you load it you get nine packages loaded for you:\n\n\ndplyr: for data wrangling\n\nforcats: for dealing with factors\n\nggplot2: for data visualization\n\nlubridate: for dealing with dates\n\npurrr: for iteration with functional programming\n\nreadr: for reading and writing data\n\nstringr: for string manipulation\n\ntibble: for modern, tidy data frames\n\ntidyr: for data tidying and rectangling"
  },
  {
    "objectID": "lab/lab-1.html#guidelines",
    "href": "lab/lab-1.html#guidelines",
    "title": "Lab 1",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment."
  },
  {
    "objectID": "lab/lab-1.html#part-1",
    "href": "lab/lab-1.html#part-1",
    "title": "Lab 1",
    "section": "Part 1",
    "text": "Part 1\nLet’s take a trip to the Midwest!\nWe will use the midwest data frame for this lab. It is part of the ggplot2 R package, so the midwest data set is automatically loaded when you load the tidyverse package.\nThe data contains demographic characteristics of counties in the Midwest region of the United States.\nBecause the data set is part of the ggplot2 package, you can read documentation for the data set, including variable definitions by typing ?midwest in the Console or searching for midwest in the Help pane.\nQuestion 1\nVisualize the distribution of population density of counties using a histogram with geom_histogram() with four separate binwidths: a binwidth of 100, a binwidth of 1,000, a binwidth of 10,000, and a binwidth of 100,000. For example, you can create the first plot with:\n\nggplot(midwest, aes(x = popdensity)) +\n  geom_histogram(binwidth = 100) +\n  labs(\n    x = \"Population density\",\n    y = \"Count\",\n    title = \"Population density of Midwestern counties\",\n    subtitle = \"Binwidth = 100\"\n  )\n\nYou will need to make four different histograms. Make sure to set informative titles and axis labels for each of your plots. Then, comment on which binwidth is most appropriate for these data and why.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 1”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 2\nVisualize the distribution of population density of counties again, this time using a boxplot with geom_boxplot(). Make sure to set informative titles and axis labels for your plot. Then, using information as needed from the box plot as well as the histogram from Question 1, describe the distribution of population density of counties and comment on any potential outliers, making sure to identify at least one county that is a clear outlier by name in your narrative and commenting on whether it makes sense to you that this county is an outlier. You can use the data viewer to identify the outliers interactively, you do not have to write code to identify them.\n\n\n\n\n\n\nImportant\n\n\n\nIn describing a distribution, make sure to mention shape, center, spread, and any unusual observations.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 2”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 3\nCreate a scatterplot of the percentage below poverty (percbelowpoverty on the y-axis) versus percentage of people with a college degree (percollege on the x-axis), where the color and shape of points are determined by state. Make sure to set informative titles, axis, and legend labels for your plot. First, describe the overall relationship between percentage of people with a college degree and percentage below poverty in Midwestern states, making sure to identify at least one county that is a clear outlier by name in your narrative. You can use the data viewer to identify the outliers interactively, you do not have to write code to identify them. Then, comment on whether you can identify how this relationship varies across states.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 3”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 4\nNow, let’s examine the relationship between the same two variables, once again using different colors and shapes to represent each state, and using a separate plot for each state, i.e., with faceting with facet_wrap(). In addition to points (geom_point()), represent the data with a smooth curve fit to the data with geom_smooth(), with the argument se = FALSE. Make sure to set informative titles, axis, and legend labels for your plot. Which plot do you prefer - this plot or the plot in Question 3? Briefly explain your choice.\n\n\n\n\n\n\nNote\n\n\n\nse = FALSE removes the confidence bands around the line. These bands show the uncertainty around the smooth curve. We’ll discuss uncertainty around estimates later in the course and bring these bands back then.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 4”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 5\nDo some states have counties that tend to be geographically larger than others?\nTo explore this question, create side-by-side boxplots of area (area) of a county based on state (state). How do typical county area sizes compare across states? How do variabilities of county sizes compare across states? Which state has the single largest county? Identify the name of this county. You can use the data viewer to identify it interactively, you do not have to write code.\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nOnce again, make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\nQuestion 6\nDo some states have a higher percentage of their counties located in a metropolitan area?\nCreate a segmented bar chart with one bar per state and the bar filled with colors according to the value of metro – one color indicating Yes and the other color indicating No for whether a county is considered to be a metro area. The y-axis of the segmented barplot should range from 0 to 1, indicating proportions. Compare the percentage of counties in metro areas across the states based on this plot. Make sure to supplement your narrative with rough estimates of these percentages.\n\n\n\n\n\n\nHint\n\n\n\nFor this question, you should begin with the data wrangling pipeline below. We will learn more about data wrangling in the coming weeks, so this is a mini-preview. This pipeline creates a new variable called metro based on the value of the existing variable called inmetro. If the value of inmetro is equal to 1 (inmetro == 1), it sets the value of metro to \"Yes\", and if not, it sets the value of metro to \"No\". The resulting data frame is assigned back to midwest, overwriting the existing midwest data frame with a version that includes the new metro variable.\n\nmidwest &lt;- midwest |&gt;\n  mutate(metro = if_else(inmetro == 1, \"Yes\", \"No\"))\n\n\n\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nAnd once again, make sure to commit and push all changed files so that your Git pane is empty afterward. We keep repeating this because it’s important and because we see students forget to do this. So take a moment to make sure you’re following along with the version control instructions.\n\nQuestion 7\nRecreate the plot below, and then give it a title. Then, identify at least one county that is a clear outlier in Wisconsin (WI) by name. You can use the data viewer to identify them interactively, you do not have to write code. Comment on the population composition of this county by investigating the percentage of other races living there.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe ggplot2 reference for themes will be helpful in determining the theme.\nThe size of the points is 2.\nThe transparency (alpha) of the points is 0.5.\nYou can put line breaks in labels with \\n.\n\n\n\n\nRender, commit, and push your final changes to GitHub with a meaningful commit message.\nMake sure to commit and push all changed files so that your Git pane is empty afterwards."
  },
  {
    "objectID": "lab/lab-1.html#part-2",
    "href": "lab/lab-1.html#part-2",
    "title": "Lab 1",
    "section": "Part 2",
    "text": "Part 2\nEnough about the Midwest!\nIn this part we will use a new, more recent, and potentially more relevant dataset on counties in North Carolina.\nThis dataset is stored in a file called nc-county.csv in the data folder of your project/repository.\nYou can read this file into R with the following code:\n\nnc_county &lt;- read_csv(\"data/nc-county.csv\")\n\nThis will read the CSV (comma separated values) file from the data folder and store the dataset as a data frame called nc_county in R.\nThe variables in the dataset and their descriptions are as follows:\n\n\ncounty: Name of county.\n\nstate_abb: State abbreviation (NC).\n\nstate_name: State name (North Carolina).\n\nland_area_m2: Land area of county in meters-squared, based on the 2020 census.\n\nland_area_mi2: Land area of county in miles-squared, based on the 2020 census.\n\npopulation: Population of county, based on the 2020 census.\n\ndensity: Population density calculated as population divided by land area in miles-squared.\n\nIn addition to being more recent and more relevant, this dataset is also more complete in the sense that we know the units of population density: people per mile-squared!\nQuestion 8\nFirst, guess what the relationship between population density and land area might be – positive? negative? no relationship?\nThen, make a scatter plot of population density (density on the y-axis) vs. land area in miles-squared (land_area_mi2 on the x-axis). Make sure to set an informative title and axis labels for your plot. Describe the relationship. Was your guess correct?\nQuestion 9\nNow make a scatter plot of population density (density on the y-axis) vs. land area in meters-squared (land_area_m2 on the x-axis). Make sure to set an informative title and axis labels for your plot. Comment on how this scatterplot compares to the one in Exercise 8 — is the relationship displayed same or different. Explain why.\nQuestion 10\nDid you select your pages on Gradescope? You don’t need to write an answer for this question, if you select your pages when you upload your lab to Gradescope, you’ll get full points on this question. Otherwise, you’ll get a 0 on this question.2"
  },
  {
    "objectID": "lab/lab-1.html#submission",
    "href": "lab/lab-1.html#submission",
    "title": "Lab 1",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered “on time”.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope"
  },
  {
    "objectID": "lab/lab-1.html#grading-and-feedback",
    "href": "lab/lab-1.html#grading-and-feedback",
    "title": "Lab 1",
    "section": "Grading and feedback",
    "text": "Grading and feedback\n\nSome of the questions will be graded for accuracy.\nSome will be graded for completion.\nQuestion 10 is just asking you to select your pages on Gradescope, and you get points for following the instructions!\nThere are also workflow points, for coding style, for committing at least three times as you work through your lab, and for overall organization.\nYou’ll receive feedback on your lab on Gradescope within a week.\n\nGood luck, and have fun with it!"
  },
  {
    "objectID": "lab/lab-1.html#footnotes",
    "href": "lab/lab-1.html#footnotes",
    "title": "Lab 1",
    "section": "Footnotes",
    "text": "Footnotes\n\nRemember, haikus not novellas when writing code!↩︎\nWe’re assigning points to this seemingly trivial task because not selecting your pages and questions will greatly slow down the grading. So we want to make sure you’re properly motivated to complete this task!↩︎"
  },
  {
    "objectID": "lab/lab-8.html",
    "href": "lab/lab-8.html",
    "title": "Lab 8",
    "section": "",
    "text": "Before diving into the lab, let’s first check in on your project’s next steps.\n\n\nBefore Monday, Nov 25 - Between Milestones 3 and 4:\n\nRead the instructions for Milestone 4 and Milestone 5.\nBare minimum: Make substantial progress on your project write-up: Finish your introduction and exploratory data analysis (plots/summary statistics + their interpretations) + Write up methods you plan to use.\nIdeal: Start implementing the methods and get closer to answering your research question.\n\n\n\nOn Monday, Nov 25 - Milestone 4:\n\nPeer review of others’ projects in the lab.\nYou must be in the lab to participate in the peer review.\nIf you cannot be there physically due to Thanksgiving travel, make arrangements to Zoom in with the rest of your team who are in lab.\n\n\n\nAfter Monday, Nov 26: Work on write-up and presentation incorporating feedback from peers and meeting with TAs/instructor as needed during office hours for further feedback."
  },
  {
    "objectID": "lab/lab-8.html#learning-objectives",
    "href": "lab/lab-8.html#learning-objectives",
    "title": "Lab 8",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the lab, you will…\n\nTrain models on training data and test them on testing data to evaluate and compare their performances.\nPerform statistical inference with bootstrapping and hypothesis testing.\nRevisit two questions from previous assignments/assessments.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\n\n\n\n\n\n\nNote\n\n\n\nThis lab is due on **Tue, November 26 at 10:30 pm, i.e., right before Thanksgiving break begins."
  },
  {
    "objectID": "lab/lab-8.html#getting-started",
    "href": "lab/lab-8.html#getting-started",
    "title": "Lab 8",
    "section": "Getting started",
    "text": "Getting started\nLog in to RStudio, clone your lab-8 repo from GitHub, open your lab-8.qmd document, and get started!"
  },
  {
    "objectID": "lab/lab-8.html#packages",
    "href": "lab/lab-8.html#packages",
    "title": "Lab 8",
    "section": "Packages",
    "text": "Packages\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way and\n\ntidymodels package for modeling in a “tidy” way.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document."
  },
  {
    "objectID": "lab/lab-8.html#guidelines",
    "href": "lab/lab-8.html#guidelines",
    "title": "Lab 8",
    "section": "Guidelines",
    "text": "Guidelines\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-8.html#question-1",
    "href": "lab/lab-8.html#question-1",
    "title": "Lab 8",
    "section": "Question 1",
    "text": "Question 1\n\nRead the data in with read_csv().\nTransform the is_canceled variable to be a factor with “not canceled” (0) as the first level and “canceled” (1) as the second level. Confirm that you were able to successfully transform the variable by running levels(hotel$is_canceled).\nSplit the data into training (75%) and testing (25%) sets. Report the number of rows in the testing and training sets.\nFit a model to the training data predicting whether a reservation is canceled from hotel type (Resort or City Hotel) and at least two other predictors. Provide a tidy output of the model fit.\nMake predictions for the testing data. Then, in a single pipeline, calculate the false positive and negative rates. Make sure that your answer makes it clear which rates are which."
  },
  {
    "objectID": "lab/lab-8.html#question-2",
    "href": "lab/lab-8.html#question-2",
    "title": "Lab 8",
    "section": "Question 2",
    "text": "Question 2\n\nFit another model to the training data predicting whether a reservation is canceled from the variables you used in Question 1 plus one other predictor. State the new predictor and why you chose it.\nMake predictions for the testing data. Then, in a single pipeline, calculate the false positive and negative rates. Make sure that your answer makes it clear which rates are which."
  },
  {
    "objectID": "lab/lab-8.html#question-3",
    "href": "lab/lab-8.html#question-3",
    "title": "Lab 8",
    "section": "Question 3",
    "text": "Question 3\n\nWhat was the name you used for the model fit object for the model you created in Question 1? What about in Question 2?\n\nPlot the ROC curves of the models from Question 1 and Question 2 on the same plot, using different colors for each model and a legend that describes which model is represented with which color.\n\n\n\n\n\n\nTip\n\n\n\nSince the level of is_canceled we’re predicting is the second level, we need to set event_level = \"second\" when calculating the ROC curve.\n\n\n\nCalculate the AUC (area under the curve) for each model using the roc_auc() function.\n\n\nYou can review its documentation to figure out how this function works.\n\n\nBased on your findings so far, articulate which of the two models is preferable for predicting hotel cancellations and why."
  },
  {
    "objectID": "lab/lab-8.html#question-4",
    "href": "lab/lab-8.html#question-4",
    "title": "Lab 8",
    "section": "Question 4",
    "text": "Question 4\nLoad the lemurs data from your data folder and save it as lemurs. Then, report which “types” of lemurs are represented in the sample and how many of each. Note that this information is in the taxon variable. You should refer back to the linked data dictionary to understand what the different values of taxon mean. Your response should be a tibble with at least three columns, taxon, taxon_name (a new variable you create that contains the description of the taxon, e.g., EMON is Mongoose lemur), and n (number of lemurs with that taxon)."
  },
  {
    "objectID": "lab/lab-8.html#question-5",
    "href": "lab/lab-8.html#question-5",
    "title": "Lab 8",
    "section": "Question 5",
    "text": "Question 5\nWhat is the slope of the regression line for predicting weights of lemurs (weight_g) from the ages of lemurs (in years) when their weight was measured (age_at_wt_y)? Calculate and interpret a 95% bootstrap bootstrap confidence interval together with your point estimate. Don’t forget to set a seed and use 1,000 bootstrap samples (reps = 1000) when simulating your bootstrap distribution.\n\n\n\n\n\n\nTip\n\n\n\nBelow is a step-by-step recipe for constructing and visualizing a confidence interval. The code snippets shown are not “complete.” They include some blanks you need to fill in, and they are just intended to guide you in the right direction.\n\nStep 1: Calculate the point estimate for the slope and the intercept of the regression line.\n\n\nobs_fit &lt;- lemurs |&gt;\n  specify(weight_g ~ age_at_wt_y) |&gt;\n  fit()\n\n\nStep 2: Simulate a bootstrap distribution.\n\n\nset.seed(___)\n\nboot_dist &lt;- lemurs |&gt;\n  specify(weight_g ~ age_at_wt_y) |&gt;\n  generate(reps = ____, type = \"bootstrap\") |&gt;\n  fit()\n\n\nStep 3: Calculate the bounds of the confidence interval.\n\n\nconf_ints &lt;- \n  get_confidence_interval(\n    boot_dist, \n    level = ___, \n    point_estimate = obs_fit\n  )"
  },
  {
    "objectID": "lab/lab-8.html#question-6",
    "href": "lab/lab-8.html#question-6",
    "title": "Lab 8",
    "section": "Question 6",
    "text": "Question 6\nWhat are the slopes of the regression line for predicting weights of lemurs (weight_g) from the ages of lemurs (in years) when their weight was measured (age_at_wt_y) and their types (taxon)? Calculate and interpret a 95% bootstrap bootstrap confidence interval together with your point estimate. Don’t forget to set a seed and use 1,000 bootstrap samples (reps = 1000) when simulating your bootstrap distribution."
  },
  {
    "objectID": "lab/lab-8.html#question-7",
    "href": "lab/lab-8.html#question-7",
    "title": "Lab 8",
    "section": "Question 7",
    "text": "Question 7\nWhat is the median weight of red-bellied lemurs? What is the median weight of ring-tailed lemurs? What is the median weight of mongoose lemurs? Calculate and interpret a 95% bootstrap bootstrap confidence intervals together with your point estimates. Don’t forget to set a seed and use 1,000 bootstrap samples (reps = 1000) when simulating your bootstrap distribution."
  },
  {
    "objectID": "lab/lab-8.html#question-8",
    "href": "lab/lab-8.html#question-8",
    "title": "Lab 8",
    "section": "Question 8",
    "text": "Question 8\nDo female lemurs differ in weight from male lemurs, on average?\n\nConduct a hypothesis test to answer this question at 5% significance level. Clearly state your hypotheses in the context of the data and the research question, simulate a randomization distribution, find the p-value, and make a decision on your hypotheses based on this p-value. Provide a one-sentence conclusion for your hypothesis test in the context of the data and the research question. Don’t forget to set a seed and use 1,000 randomization samples (reps = 1000) when simulating your randomization distribution.\nBased on your answer to Part (a), would you expect a 95% confidence interval for the difference in means of female and male lemurs to include 0? Explain your reasoning.\nConstruct and interpret a 95% bootstrap confidence interval for the difference in means of female and male lemurs. Does it include 0? Does this align with your answer to Part (b)? Don’t forget to set a seed and use 1,000 bootstrap samples (reps = 1000) when simulating your bootstrap distribution."
  },
  {
    "objectID": "lab/lab-8.html#question-9",
    "href": "lab/lab-8.html#question-9",
    "title": "Lab 8",
    "section": "Question 9",
    "text": "Question 9\nChoose one question from a previous lab that you received lots of feedback on and/or lost many points on and improve it. First, write one sentence reminding us of the specific question and a few sentences on why you chose this specific question to improve and how you plan to improve it. Then, improve it."
  },
  {
    "objectID": "lab/lab-8.html#question-10",
    "href": "lab/lab-8.html#question-10",
    "title": "Lab 8",
    "section": "Question 10",
    "text": "Question 10\nChoose one question from the take-home midterm that you received lots of feedback on and/or lost many points on and improve it. First, write one sentence reminding us of the specific question and a few sentences on why you chose this specific question to improve and how you plan to improve it. Then, improve it."
  },
  {
    "objectID": "exam-review/midterm-review-A.html",
    "href": "exam-review/midterm-review-A.html",
    "title": "Midterm review",
    "section": "",
    "text": "b, c, f, g -\n\nThe blizzard_salary dataset has 409 rows.\nThe percent_incr variable is numerical and continuous.\nThe salary_type variable is categorical.\n\nFigure 1 - A shared x-axis makes it easier to compare summary statistics for the variable on the x-axis.\nc - It’s a value higher than the median for hourly but lower than the mean for salaried.\nb - There is more variability around the mean compared to the hourly distribution.\na, b, e - Pie charts and waffle charts are for visualizing distributions of categorical data only. Scatterplots are for visualizing the relationship between two numerical variables.\nc - mutate() is used to create or modify a variable.\na - \"Poor\", \"Successful\", \"High\", \"Top\"\nb - Option 2. The plot in Option 1 shows the number of employees with a given performance rating for each salary type while the plot in Option 2 gives the proportion of employees with a given performance rating for each salary type. In order to assess the relationship between these variables (e.g., how much more likely is a Top rating among Salaried vs. Hourly workers), we need the proportions, not the counts.\nThere may be some NAs in these two variables that are not visible in the plot.\nThe proportions under Hourly would go in the Hourly bar, and those under Salaried would go in the Salaried bar.\nc - filter(salary_type != \"Hourly\" & performance_rating == \"Poor\") - There are 5 observations for “not Hourly” “and” Poor.\na - arrange() - The result is arranged in increasing order of annual_salary, which is the default for arrange().\nc, d, e, f.\nPart 1: The following should be fixed:\n\nThere should be a | after # before label\nThere should be a : after label, not =\nThere shouldn’t be a space in the chunk label, it should be plot-blizzard\nThere should be spaces after commas in the code\nThere should be spaces on both sides of = in the code\nThere should be a space before +\ngeom_boxplot() should be on the next line and indented\nThere should be a + at the end of the geom_boxplot() line\nlabs() should be indented\n\nPart 2: The warning is caused by NA in the data. It means that 39 observations were NAs and are not plotted/represented on the plot.\nPart 1:\n\nRender: Run all of the code and render all of the text in the document and produce an output.\nCommit: Take a snapshot of your changes in Git with an appropriate message.\nPush: Send your changes off to GitHub.\n\nPart 2: c - Rendering or committing isn’t sufficient to send your changes to your GitHub repository, a push is needed. A pull is also not needed to view the changes in the browser."
  },
  {
    "objectID": "exam-review/final-review-A.html",
    "href": "exam-review/final-review-A.html",
    "title": "Final review",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "exam-review.html",
    "href": "exam-review.html",
    "title": "Exam reviews",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\n\n\n\n\nFinal review\n\n\nQuestions\n\n\n\n\nFinal review\n\n\nSuggested answers\n\n\n\n\nMidterm Review\n\n\nQuestions\n\n\n\n\nMidterm review\n\n\nSuggested answers\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Exam reviews"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point, and we want to make sure you can identify where that is so that you don’t get too frustrated and feel comfortable seeking help.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during the lecture or lab, feel free to ask it! There are likely other students with the same question, so asking will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#help-from-humans",
    "href": "course-support.html#help-from-humans",
    "title": "Course support",
    "section": "Help from humans",
    "text": "Help from humans\n\nOffice hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. Many questions are most effectively answered in person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by during office hours at least once during the first three weeks of class. If you have no questions, stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here.\nMy office hours will start in Week 1, TA office hours will start in Week 2.\n\n\nEd Discussion\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The course discussion forum, Ed Discussion, is the best venue for these! There is a chance another student has already asked a similar question, so please check the other posts on before asking a new question. If you know the answer to a question that is posted, I encourage you to respond!\nYou can access this tool on the course website toolbar – just click on the lifesaver icon.\n\n\nPeer tutoring\nMINT Peer Tutoring (Meaningful Interactive Tutoring) are small groups of 2-5 students in the same course who meet weekly with a Peer Tutor. This semester, Peer Tutor who will be leading MINT Peer Tutoring for STA 199 is Stanley Borden (stanley.borden@duke.edu).\nThe peer tutoring groups are a resource focused on allowing students to receive additional support for questions they have on the course content while still being part of a community of fellow learners. Peer tutors communicate with students in advance of the meetings so that they can be responsive to student needs during the group meetings. Some groups meet in person and some meet virtually.\n\nIn person, Wednesday 7:00 pm\nVirtual, Wednesday 8:05 pm\n\nFor more details and to see what other courses we offer services for, please visit their website: https://arc.duke.edu/peer-education\nSignups for MINT Peer Tutoring open the morning of Thursday, September 5th and groups start meeting on Monday, September 9th.\nNote that peer tutors are not directly affiliated with the course, however they tend to be students who have taken the course in the past.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#help-from-ai-chatbot",
    "href": "course-support.html#help-from-ai-chatbot",
    "title": "Course support",
    "section": "Help from AI: Chatbot",
    "text": "Help from AI: Chatbot\nThe course has a chatbot that has been trained specifically on the course textbooks. If you’re looking for AI-help, we strongly recommend starting here.\nYou can access this tool on the course website toolbar – just click on the lifesaver icon.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go to Ed Discussion), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr. Mine Çetinkaya-Rundel at mc301@duke.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 199” in the subject line. Barring extenuating circumstances, I will respond to STA 199 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#mental-health-and-well-being",
    "href": "course-support.html#mental-health-and-well-being",
    "title": "Course support",
    "section": "Mental health and well-being",
    "text": "Mental health and well-being\nDuke is committed to holistic student well-being, including mental, emotional, and physical health. The university offers resources to help students manage daily stress, encourage intentional self-care, and access just-in-time support. If you find you need support, your mental and/or emotional health concerns are impacting your day-to-day activities and your academic performance, or you need someone to talk to, the resources below are available to you:\n\nDukeReach: DukeReach provides comprehensive outreach services to support students in managing all aspects of well-being, including referrals and follow-up services for students who are experiencing significant challenges related to mental health, physical health, social adjustment, and/or a variety of other stressors. You can reach the DukeReach team at dukereach@duke.edu.\nCounseling and Psychological Services (CAPS): CAPS services include individual and group counseling services, psychiatric services, and workshops. CAPS also provides referrals to off-campus resources for specialized care. You can reach CAPS at (919) 660-1000.\nTimelyCare1: TimelyCare is an online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling.\nBC Fellows for Healthy Relationship: The BC Fellows meet with students individually and in groups, supporting the development of healthy relationships and building meaningful community in all areas of a student’s life.\nDukeLine: Students who want to connect anonymously with a Peer Coach can text 984-230-4888 from 5 to 11 p.m. daily. DukeLine offers in-the-moment anonymous, non-emergency text support from a peer.\nDuWell: DuWell provides Moments of Mindfulness (stress management and resilience building) and meditation programming (Koru workshop) to assist students in developing a daily emotional well-being practice. All are welcome, and no experience is necessary. You can reach DuWell at (919) 681-8421.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#course-costs",
    "href": "course-support.html#course-costs",
    "title": "Course support",
    "section": "Course costs",
    "text": "Course costs\n\nTextbooks: The textbooks for this course are freely available on the web.\nLaptops: Each student is expected to have a laptop they can bring to each lecture and lab.\n\nIf you are having difficulty with the costs associated with this course, here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Libraries: The library’s Top Textbook Program allows you to rent some textbooks for 3 hours at a time.\nDuke Link: You can reserve rental equipment from the Link for course-specific technology needs, such as a Digital Voice Recorder, HD Video Camera, TI-84 Plus CE, DSLR camera kit, Tripod, Shotgun Mic, iPad Mini 4, Handheld Projector, or GoPro.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-canvas",
    "href": "course-support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom and Canvas.\nNote that we will be using Canvas minimally in this course (primarily for announcements and the grade book). All assignment submissions will take place on Gradescope and GitHub, and conversations will take place on Ed Discussion.\nZoom will be used for online office hours and as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#footnotes",
    "href": "course-support.html#footnotes",
    "title": "Course support",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFormerly known as Blue Devils Care.↩︎",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "href": "course-faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I’d rather you didn’t, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.4.1: https://cran.r-project.org/\nDownload and install RStudio: https://posit.co/download/rstudio-desktop/\nInstall Quarto 1.5.56 or higher: https://quarto.org/docs/get-started/\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA198-199 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA198-199 under My reservations to access the RStudio instance you’ll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the Ed Discussions to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. If you’re still having trouble, follow the steps in the order given below:\n\nRestart your browser.\nMake sure there are no updates pending for your browser. If there are, install those updates and restart your browser again.\nRequest a restart of your container – To do so, select your container as you usually do and then, instead of Login, click on Request Restart. Read the warning in the next page, and then click once more to restart your container.\nClear your browser cache and restart your browser again.\nRestart your computer to ensure a fresh new connection.\nIf your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "ae.html",
    "href": "ae.html",
    "title": "Application exercises",
    "section": "",
    "text": "All application exercises (AEs) are due by the end of lecture (or, precisely, by 2 pm) on the day they’re covered in lecture. To submit your AE, make at least one change to your AE, commit and then push your change to your AE repo. AEs are graded for engagement, not accuracy.\n\n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\n\n\n\n\nAE 00: UN Votes\n\n\n \n\n\n\n\nAE 01: Meet the penguins\n\n\n \n\n\n\n\nAE 02: Bechdel + data visualization\n\n\nSuggested answers\n\n\n\n\nAE 02: Bechdel + data visualization\n\n\n \n\n\n\n\nAE 03: Bechdel + data visualization and transformation\n\n\nSuggested answers\n\n\n\n\nAE 03: Bechdel + data visualization and transformation\n\n\n \n\n\n\n\nAE 04: Gerrymandering + data exploration I\n\n\nSuggested answers\n\n\n\n\nAE 04: Gerrymandering + data exploration I\n\n\n \n\n\n\n\nAE 05: Gerrymandering + data exploration II\n\n\nSuggested answers\n\n\n\n\nAE 05: Gerrymandering + data exploration II\n\n\n \n\n\n\n\nAE 06: StatSci majors + data tidying\n\n\nSuggested answers\n\n\n\n\nAE 06: StatSci majors + data tidying\n\n\n \n\n\n\n\nAE 07: Sales taxes + data joining\n\n\nSuggested answers\n\n\n\n\nAE 07: Sales taxes + data joining\n\n\n \n\n\n\n\nAE 08: Durham climate + factors\n\n\nSuggested answers\n\n\n\n\nAE 08: Durham climate + factors\n\n\n \n\n\n\n\nAE 09: Age gaps + sales + import\n\n\nSuggested answers\n\n\n\n\nAE 09: Age gaps + sales + import\n\n\n \n\n\n\n\nAE 10: Opinion articles in The Chronicle\n\n\nSuggested answers\n\n\n\n\nAE 10: Opinion articles in The Chronicle\n\n\n \n\n\n\n\nAE 11: UN Votes - Revisit + Chat GPT adventures\n\n\n \n\n\n\n\nAE 12: Modelling fish\n\n\nSuggested answers\n\n\n\n\nAE 12: Modelling fish\n\n\n \n\n\n\n\nAE 13: Modelling penguins\n\n\nSuggested answers\n\n\n\n\nAE 13: Modelling penguins\n\n\n \n\n\n\n\nAE 14: Modelling penguins with multiple predictors\n\n\nSuggested answers\n\n\n\n\nAE 14: Modelling penguins with multiple predictors\n\n\n \n\n\n\n\nAE 15: Modelling loan interest rates\n\n\nSuggested answers\n\n\n\n\nAE 15: Modelling loan interest rates\n\n\n \n\n\n\n\nAE 16: Building a spam filter\n\n\nSuggested answers\n\n\n\n\nAE 16: Building a spam filter\n\n\n \n\n\n\n\nAE 17: Forest classification\n\n\nSuggested answers\n\n\n\n\nAE 17: Forest classification\n\n\n \n\n\n\n\nAE 18: Houses in Duke Forest\n\n\nSuggested answers\n\n\n\n\nAE 18: Houses in Duke Forest\n\n\n \n\n\n\n\n\nNo matching items\n\n\n  \n\n\n\nMore AEs to be added as the semester progresses.",
    "crumbs": [
      "Application exercises"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Course GitHub organization\n🔗 on GitHub\n\n\n\nRStudio containers\n🔗 on Duke Container Manager\n\n\n\nOffice hours\n🔗 on Google Sheets\n\n\n\nEd Discussion\n🔗 on Canvas\n\n\n\nGradescope\n🔗 on Canvas\n\n\n\nGradebook\n🔗 on Canvas\n\n\n\nTexbooks\n🔗 R for Data Science\n🔗 Introduction to Modern Statistics\n\n\n\nPackage documentation\n🔗 ggplot2: ggplot2.tidyverse.org\n🔗 dplyr: dplyr.tidyverse.org\n🔗 tidyr: tidyr.tidyverse.org\n🔗 forcats: forcats.tidyverse.org\n🔗 stringr: stringr.tidyverse.org\n🔗 lubridate: lubridate.tidyverse.org\n🔗 readr: readr.tidyverse.org\n🔗 readxl: readxl.tidyverse.org",
    "crumbs": [
      "Course information",
      "Useful links"
    ]
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "",
    "text": "By the end of the semester, you will…\n\nlearn to explore, visualize, and analyze data in a reproducible and shareable manner using R and RStudio\ngain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization\nwork on problems and case studies inspired by and based on real-world questions and data\nlearn to communicate results through written assignments and project presentation effectively",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-learning-objectives",
    "href": "course-syllabus.html#course-learning-objectives",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "",
    "text": "By the end of the semester, you will…\n\nlearn to explore, visualize, and analyze data in a reproducible and shareable manner using R and RStudio\ngain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization\nwork on problems and case studies inspired by and based on real-world questions and data\nlearn to communicate results through written assignments and project presentation effectively",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-materials",
    "href": "course-syllabus.html#course-materials",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Course materials",
    "text": "Course materials\n\nTextbooks\nAll books are freely available online.\n\nR for Data Science, 2e, Wickham, Çetinkaya-Rundel, Grolemund. O’Reilly, 2nd edition, 2023. Hard copy available on Amazon.\nIntroduction to Modern Statistics, Çetinkaya-Rundel, Hardin. OpenIntro Inc., 2nd Edition, 2023. Hard copy available on Amazon.\n\n\n\nComputing\nYou will need a laptop you can bring to lecture and lab for this course. We will use the statistical software R. Students will be able to access R through Docker containers provided by Duke Office of Information Technology. See the computing page for more information.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-community",
    "href": "course-syllabus.html#course-community",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Course community",
    "text": "Course community\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. I intend to present materials and activities that respect diversity and align with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives, and experiences and honors their identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If anything was said in class (by anyone) that made you feel uncomfortable, please let me or a teaching team member know.\n\n\n\nPersonal pronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. You can update your gender pronouns in Duke Hub and learn more about personal pronouns at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf any portion of the course is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students can engage with their courses and related assignments. Students should contact the SDAO to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website: sta199-f24.github.io.\nAnnouncements will periodically be emailed through Canvas Announcements. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nEmail\nIf you have questions about assignment extensions, accommodations, or any other matter not appropriate for the class discussion forum, please email me directly at mc301@duke.edu. If you do so, please include “STA 199” in the subject line. Barring extenuating circumstances, I will respond to STA 199 emails within 48 hours, Monday through Friday. Response time may be slower for emails sent Friday evening through Sunday.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#five-tips-for-success",
    "href": "course-syllabus.html#five-tips-for-success",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success in this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TAs and I will help you by providing you with materials answering questions, and setting a pace, but for this to work, you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the lab, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the lab. The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material and imagine how they might be changed (to make questions for an exam, for example).\nDon’t procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#getting-help",
    "href": "course-syllabus.html#getting-help",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Getting help",
    "text": "Getting help\n\nIf you have a question during the lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking, you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum, Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on the forum before adding a new question. If you know the answer to a question, I encourage you to respond!\n\nCheck out the Support tab for more resources.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-components",
    "href": "course-syllabus.html#course-components",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Course components",
    "text": "Course components\n\nLectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and use them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will work on various tasks and activities throughout each lecture and lab. You are expected to prepare for class by completing assigned readings, attending lectures and lab sessions, and meaningfully contributing to in-class exercises and discussions. Additionally, most lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop (or Chromebook) to each class so that you can participate in the in-class exercises. Please ensure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone. A tablet also works, but the user experience will be much smoother on a laptop.\n\n\nTeams\nYou will be assigned to a team early on in the semester. You are encouraged to sit with your teammates in lectures, and you will also work with them in some of the lab sessions. All team members are expected to contribute equally to the completion of the project, and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to any project component will result in a penalty to your mark relative to the team’s overall mark.\nYou are expected to use the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as a metric (one of several) of each team member’s relative contribution to each project.\n\n\nActivities & Assessment\nYou will be assessed based on five components: application exercises, labs, exams, project, and teamwork.\n\nLabs\nIn labs, you will apply what you’ve learned in the videos and during lectures to complete data analysis tasks. You may discuss lab assignments with other students; however, the lab should be completed and submitted individually. Lab assignments must be typed up using Quarto, all work must be pushed to your GitHub repository for the lab, and the lab’s PDF output must be submitted on Gradescope by the deadline.\nLabs are due at 8:30 am ET on the indicated due date (generally the Monday after the lab).\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nExams\nThis course will have two exams: a midterm and a final. The midterm will include an in-class component (with a cheat sheet) and an open-note take-home component, while the final will include only an in-class component (with a cheat sheet).\nYou can demonstrate what you’ve learned in the course thus far through these exams. The exams will focus on both conceptual understanding of the content and application through analysis and computational tasks. The exam’s content will be related to the content in videos and reading assignments, lectures, application exercises, and labs.\nMore details about the exams will be given during the semester.\n\n\nProject\nThe project aims to apply what you’ve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed in teams, and each team will present their work in the last lab session of the semester. The write-up will be due on the same day.\nYou cannot pass this course if you have not completed the project.\nMore information about the project will be provided during the semester.\n\n\nApplication exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises allow you to apply the statistical concepts and code introduced in the preparation materials. These AEs are due by 2 pm ET on the day of the lecture they are covered. To submit the AEs, you only need to push your work to your GitHub repo.\nBecause these AEs are for practice, they will be graded based on attempt, i.e., a good-faith effort has been made in attempting all parts.\nSuccessful on-time completion of at least 70% of AEs will result in full credit for AEs in the final course grade.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nLabs\n35%\n\n\nProject\n20%\n\n\nMidterm\n20%\n\n\nFinal\n20%\n\n\nApplication Exercises\n5%\n\n\n\nWhile there are no specific points allocated to attendance, we will record your attendance periodically throughout the semester. This information will be used as “extra credit” if you’re in between two grades and a minor bump would help.\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Course policies",
    "text": "Course policies\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard and the practices specific to this course.\n\n\n\n\nAcademic honesty\nTL;DR: Don’t cheat!\nPlease abide by the following as you work on assignments in this course:\n\nCollaboration: Only work that is clearly assigned as teamwork should be completed collaboratively.\n\nYou may discuss lab assignments with other students; however, you may not directly share (or copy) code or write-up with other students. For team assignments, you may collaborate freely within your team. You may discuss the assignment with other teams; however, you may not directly share (or copy) code or write-up with another team. Unauthorized sharing (or copying) of the code or write-up will be considered a violation for all students involved.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nCollaboration within teams is not only allowed but expected for the project. Communication between teams at a high level is also allowed; however, you may not share code or project components across teams.\nOn individual assignments, you may not directly share work (including code) with another student in this class; on team assignments, you may not directly share work (including code) with another team.\n\nOnline resources: I am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g., StackOverflow), but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of generative artificial intelligence (AI): You should treat generative AI, such as ChatGPT, like other online resources. Two guiding principles govern how to use AI in this course:\n\nCognitive dimension: Working with AI should not reduce your thinking ability. We will practice using AI to facilitate—rather than hinder—learning.\nEthical dimension: Students using AI should be transparent about their use and ensure it aligns with academic integrity.\n\n\n AI tools for code: You may use the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines to cite AI-generated content. The bare minimum citation must include the AI tool you’re using (e.g., ChatGPT) and your prompt. The prompt you use cannot be copied and pasted directly from the assignment; you must create a prompt yourself.\n AI tools for narrative: Unless instructed otherwise, you may not use generative AI to generate a narrative that you then copy-paste verbatim into an assignment or edit and then insert into your assignment.\n AI tools for learning: You’re welcomed to ask AI tools questions that might help your learning and understanding in this course.\n\nIn general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content. Identifying AI-generated content is fairly straightforward. Any code identified as AI-generated but not cited as such and any narrative identified as AI-generated will be considered plagiarism and treated as such.\n\nIf you are unsure if using a particular resource complies with the academic honesty policy, please ask a teaching team member.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects, and more). Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will\n\nautomatically results in a 0 for the relevant portion or the entire assignment,\ncan further impact your overall course grade, and\nwill be reported to the Office of Student Conduct & Community Standards for further action.\n\n\n\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback in a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest lab assignment will be dropped to accommodate such circumstances.\n\nLabs may be submitted up to 3 days late. A 5% deduction will be applied for each 24-hour period during which the assignment is late.\nNo late work is accepted for application exercises since these are designed to help you prepare for other assessments in the course.\nNo late work is accepted for exams.\nNo late work is accepted for projects.\n\n\n\nWaiver for extenuating circumstances\nIf circumstances prevent you from completing a lab by the stated due date, you may email the course coordinator, Dr. Mary Knox, before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide an explanation. This waiver may only be used once a semester, so only use it for a truly extenuating circumstance.\nIf circumstances have a longer-term impact on your academic performance, please let your academic dean know. They can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade requests\nRegrade requests must be submitted on Gradescope within a week after an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Regrade requests are also not a mechanism for asking for clarification on feedback, those questions should be brought to office hours. Note that by submitting a regrade request, the entire assignment may be regraded, which could potentially result in losing points.\nNo grades will be changed after the final exam has been administered.\n\n\nAttendance policy\nEvery student is expected to attend and participate in lecture and labs. There may be times, however, when you cannot attend class. Lecture recordings are available upon request for students who have an excused absence. See the Lecture recording request policy for more detail. If you miss a lecture, make sure to review the material and complete the application exercise, if applicable, before the next lecture. Labs dedicated to completing the lab assignment and collaborating with your lab team. If you miss a lab session, make sure to communicate with your lab TA and teammates about how you can make up your contribution. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your lab TA and teammates ahead of time.\nMore details on Trinity attendance policies are available here.\n\n\nLecture recording request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week after the lecture date. To request a particular lecture’s video, please fill out the form at the link below. Please submit the form within 24 hours of missing lecture to ensure you have sufficient time to watch the recording. Please also make sure that any official documentation, such as STINFs, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\n🔗 https://forms.office.com/r/kJ6cWGE1Mp\nAbout one week before each exam, the class recordings will be available to all students. These recordings will be available until the start of the exam.\n\n\n\n\n\n\nClick here for syllabus bounty!\n\n\n\n\n\nIf you’ve read this far in the syllabus, post a picture of your pet if you have one or your favorite meme on ed in this thread! If you’re willing, share the name of your pet too!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#accommodations",
    "href": "course-syllabus.html#accommodations",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Important dates",
    "text": "Important dates\n\nAug 26: Classes begin\nSep 2: Labor Day\nSep 6: Drop/add ends\nOct 7: Project milestone 1 – working collaboratively due\nOct 8: Midterm in-class + take-home released\nOct 11: Midterm take-home due\nOct 14-15: Fall break\nOct 28: Project milestone 2 – proposals due\nNov 8: Last day to withdraw with W\nNov 15: Project milestone 3 - improvement and progress due\nNov 25: Project milestone 4 – peer review due\nNov 27-29: Thanksgiving break\nDec 5: Project milestone 5 - writeup and presentation due\nDec 6: Classes end\nDec 12: Final exam\n\nLab deadlines are listed on the course schedule.\nFor more important dates, see the full Duke Academic Calendar.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "lab.html",
    "href": "lab.html",
    "title": "Labs",
    "section": "",
    "text": "More labs to be added as the semester progresses.\n\n\n\n\n\n\n\n\n\nNo.\n\n\nTitle\n\n\nDue date\n\n\n\n\n\n\nLab 0\n\n\nHello, World and STA 199!\n\n\nEnd of lab on Mon, Aug 26\n\n\n\n\nLab 1\n\n\nFrom the Midwest to North Carolina\n\n\nDue Mon, Sep 16 at 8:30 am\n\n\n\n\nLab 2\n\n\nRevisiting the Midwest\n\n\nDue Mon, Sep 23 at 8:30 am\n\n\n\n\nLab 3\n\n\nInflation everywhere\n\n\nDue Mon, Sep 30 at 8:30 am\n\n\n\n\nLab 4\n\n\nEverything so far I\n\n\nMon, Oct 7 at 8:30 am\n\n\n\n\nLab 5\n\n\nVisualize, model, interpret\n\n\nMon, Nov 4 at 8:30 am\n\n\n\n\nLab 6\n\n\nVisualize, model, interpret again\n\n\nMon, Nov 11 at 8:30 am\n\n\n\n\nLab 7\n\n\nExplore and classify\n\n\nMon, Nov 18 at 8:30 am\n\n\n\n\nLab 8\n\n\nEverything so far II\n\n\nTue, Nov 26 at 10:30 pm\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Labs"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "STA 199Fall 2024",
    "section": "",
    "text": "Intro to data science and statistical thinking. Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, all in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language. No statistical or computing background is necessary. Not open to students who have taken a 100-level Statistical Science course, Statistical Science 210, or a Statistical Science course numbered 300 or above.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#overview",
    "href": "course-overview.html#overview",
    "title": "STA 199Fall 2024",
    "section": "",
    "text": "Intro to data science and statistical thinking. Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, all in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language. No statistical or computing background is necessary. Not open to students who have taken a 100-level Statistical Science course, Statistical Science 210, or a Statistical Science course numbered 300 or above.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#meetings",
    "href": "course-overview.html#meetings",
    "title": "STA 199Fall 2024",
    "section": "Meetings",
    "text": "Meetings\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nBiological Sciences 111\nTue & Thur 11:45 am - 1:00 pm\n\n\nLab 01\nPerkins LINK 087 (Classroom 3)\nMon 8:30 - 9:45 am\n\n\nLab 02\nPerkins LINK 087 (Classroom 3)\nMon 10:05 - 11:20 am\n\n\nLab 03\nPerkins LINK 071 (Classroom 5)\nMon 10:05 - 11:20 am\n\n\nLab 04\nPerkins LINK 087 (Classroom 3)\nMon 11:45 am - 1:00 pm\n\n\nLab 05\nPerkins LINK 071 (Classroom 5)\nMon 11:45 am - 1:00 pm\n\n\nLab 06\nPerkins LINK 087 (Classroom 3)\nMon 1:25 - 2:40 pm\n\n\nLab 07\nPerkins LINK 071 (Classroom 5)\nMon 1:25 - 2:40 pm\n\n\nLab 08\nPerkins LINK 087 (Classroom 3)\nMon 3:05 - 4:20 pm\n\n\nLab 09\nOld Chemistry 201\nMon 3:05 - 4:20 pm\n\n\nLab 10\nPerkins LINK 087 (Classroom 3)\nMon 4:40 - 5:55 pm",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "coding-principles-oh.html",
    "href": "coding-principles-oh.html",
    "title": "Intro to Coding Principles",
    "section": "",
    "text": "library(tidyverse)",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#definition",
    "href": "coding-principles-oh.html#definition",
    "title": "Intro to Coding Principles",
    "section": "Definition",
    "text": "Definition\nSo what even is a variable, in the first place? There are many possible definitions:\n\nAnything you assign!\nPractically speaking, variables are a way for you to store data without having to type it out every time.\nThey allow you to manipulate data with the help of pre-built functions (more on that later).\nThey can also be changed - hence the name “variable”.\n\nWhat are some examples of variables?\n\nThe simplest is a single value - like in math. I could say “x = 10”.\nIt might also be a vector - essentially a list of values. For example, I might just store every name in this class in a vector.\nMost frequently, your variables will be your entire data frames.",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#assignment-saving",
    "href": "coding-principles-oh.html#assignment-saving",
    "title": "Intro to Coding Principles",
    "section": "Assignment & Saving",
    "text": "Assignment & Saving\nOk, these seem pretty useful - so how do we use them? In math and most programming languages, you use the “=” operator. This is also possible to do in R:\n\nx = 10\nx\n\n[1] 10\n\n\nHowever, in R, we prefer to use the “&lt;-” operator, to avoid confusion between variable assignment and function arguments. Here’s how that looks:\n\ny &lt;- 15\ny\n\n[1] 15\n\n\nSaving Changes\nSuppose you run a function on a variable. By default, R will show you the output of this function, but it will not actually modify your variable. For example, let’s look at the midwest data set:\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow, let’s run a function that “changes” the data frame. We can use select() to look only at the county column:\n\nmidwest |&gt;\n  select(county)\n\n# A tibble: 437 × 1\n   county   \n   &lt;chr&gt;    \n 1 ADAMS    \n 2 ALEXANDER\n 3 BOND     \n 4 BOONE    \n 5 BROWN    \n 6 BUREAU   \n 7 CALHOUN  \n 8 CARROLL  \n 9 CASS     \n10 CHAMPAIGN\n# ℹ 427 more rows\n\n\nCool change! So, just to make sure, let’s look at the midwest data frame one more time.\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow wait a minute - what happened here? I clearly told it to select the county column, and it did! So why is it that, when I went to look at the midwest data frame again, it had all of the columns, not just the one that I selected?\nThe answer is that we never saved midwest back to a variable! By default, R will show the output, but not modify the data frame unless I want it to. Let’s look at a couple ways we can do that:\n\nmidwest &lt;- midwest |&gt;\n  select(county)\n\nmidwest\n\n# A tibble: 437 × 1\n   county   \n   &lt;chr&gt;    \n 1 ADAMS    \n 2 ALEXANDER\n 3 BOND     \n 4 BOONE    \n 5 BROWN    \n 6 BUREAU   \n 7 CALHOUN  \n 8 CARROLL  \n 9 CASS     \n10 CHAMPAIGN\n# ℹ 427 more rows\n\n\nThe first option is to simply overwrite the variable. This is useful if you’re never going to need those data in their original form - it saves you some confusion in that case.\nHowever, what if later on I decide I did need those data after all? Perhaps I wanted population density data. I go to try and find this variable in the midwest data set, because that’s where I know it’s stored…\n\nmidwest |&gt;\n  select(popdensity)\n\nError in `select()`:\n! Can't select columns that don't exist.\n✖ Column `popdensity` doesn't exist.\n\n\n…but the variable is gone! This is a common point of confusion for students in STA 199, so it’s important to understand what you’re doing whenever you modify your data in-place like this - you’re overwriting the existing data.\nWe have a couple of options here. If we were loading these data from a .csv file, we could go back to the top of the document. Or, we could do something more effective: Go to Environment, click the little broom icon, and select “yes”.\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow the second option: let’s try making the modification a little more carefully: saving the data to a new variable.\n\nmidwest_counties &lt;- midwest |&gt;\n  select(county)\n\nmidwest_counties\n\n# A tibble: 437 × 1\n   county   \n   &lt;chr&gt;    \n 1 ADAMS    \n 2 ALEXANDER\n 3 BOND     \n 4 BOONE    \n 5 BROWN    \n 6 BUREAU   \n 7 CALHOUN  \n 8 CARROLL  \n 9 CASS     \n10 CHAMPAIGN\n# ℹ 427 more rows\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow we have two data frames: the new data frame midwest_counties, which contains our modifications from the data pipeline above, and the original data frame midwest, which has not been changed. Both of these are useful operations, and you will undoubtedly use both this semester! However, keep this distinction in mind when you’re mutating your data - don’t remove anything you think you’ll need later.",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#variable-examples",
    "href": "coding-principles-oh.html#variable-examples",
    "title": "Intro to Coding Principles",
    "section": "Variable Examples",
    "text": "Variable Examples\n\nx &lt;- 10\nx\n\n[1] 10\n\ny &lt;- c(3, 5)\ny\n\n[1] 3 5\n\nz &lt;- midwest\nz\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#examples",
    "href": "coding-principles-oh.html#examples",
    "title": "Intro to Coding Principles",
    "section": "Examples",
    "text": "Examples\nEvery column in a data frame will have a particular data type - sort of a way that R recognizes, classifies, and interacts with the data. Let’s look at an example, using the convenient glimpse function:\n\nglimpse(midwest)\n\nRows: 437\nColumns: 28\n$ PID                  &lt;int&gt; 561, 562, 563, 564, 565, 566, 567, 568, 569, 570,…\n$ county               &lt;chr&gt; \"ADAMS\", \"ALEXANDER\", \"BOND\", \"BOONE\", \"BROWN\", \"…\n$ state                &lt;chr&gt; \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"…\n$ area                 &lt;dbl&gt; 0.052, 0.014, 0.022, 0.017, 0.018, 0.050, 0.017, …\n$ poptotal             &lt;int&gt; 66090, 10626, 14991, 30806, 5836, 35688, 5322, 16…\n$ popdensity           &lt;dbl&gt; 1270.9615, 759.0000, 681.4091, 1812.1176, 324.222…\n$ popwhite             &lt;int&gt; 63917, 7054, 14477, 29344, 5264, 35157, 5298, 165…\n$ popblack             &lt;int&gt; 1702, 3496, 429, 127, 547, 50, 1, 111, 16, 16559,…\n$ popamerindian        &lt;int&gt; 98, 19, 35, 46, 14, 65, 8, 30, 8, 331, 51, 26, 17…\n$ popasian             &lt;int&gt; 249, 48, 16, 150, 5, 195, 15, 61, 23, 8033, 89, 3…\n$ popother             &lt;int&gt; 124, 9, 34, 1139, 6, 221, 0, 84, 6, 1596, 20, 7, …\n$ percwhite            &lt;dbl&gt; 96.71206, 66.38434, 96.57128, 95.25417, 90.19877,…\n$ percblack            &lt;dbl&gt; 2.57527614, 32.90043290, 2.86171703, 0.41225735, …\n$ percamerindan        &lt;dbl&gt; 0.14828264, 0.17880670, 0.23347342, 0.14932156, 0…\n$ percasian            &lt;dbl&gt; 0.37675897, 0.45172219, 0.10673071, 0.48691813, 0…\n$ percother            &lt;dbl&gt; 0.18762294, 0.08469791, 0.22680275, 3.69733169, 0…\n$ popadults            &lt;int&gt; 43298, 6724, 9669, 19272, 3979, 23444, 3583, 1132…\n$ perchsd              &lt;dbl&gt; 75.10740, 59.72635, 69.33499, 75.47219, 68.86152,…\n$ percollege           &lt;dbl&gt; 19.63139, 11.24331, 17.03382, 17.27895, 14.47600,…\n$ percprof             &lt;dbl&gt; 4.355859, 2.870315, 4.488572, 4.197800, 3.367680,…\n$ poppovertyknown      &lt;int&gt; 63628, 10529, 14235, 30337, 4815, 35107, 5241, 16…\n$ percpovertyknown     &lt;dbl&gt; 96.27478, 99.08714, 94.95697, 98.47757, 82.50514,…\n$ percbelowpoverty     &lt;dbl&gt; 13.151443, 32.244278, 12.068844, 7.209019, 13.520…\n$ percchildbelowpovert &lt;dbl&gt; 18.011717, 45.826514, 14.036061, 11.179536, 13.02…\n$ percadultpoverty     &lt;dbl&gt; 11.009776, 27.385647, 10.852090, 5.536013, 11.143…\n$ percelderlypoverty   &lt;dbl&gt; 12.443812, 25.228976, 12.697410, 6.217047, 19.200…\n$ inmetro              &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0…\n$ category             &lt;chr&gt; \"AAR\", \"LHR\", \"AAR\", \"ALU\", \"AAR\", \"AAR\", \"LAR\", …\n\n\nNext to the data, we can see various designations - &lt;int&gt;, &lt;dbl&gt;, &lt;chr&gt;, etc. These are data types. But what exactly is the difference?\nDouble/Numeric\nThe dbl data type, which is the default implementation of the numeric class, stands for double - meaning “double-precision floating-point format”. It’s pretty clear that double is an easier word to remember! This allows you to store numbers with a lot of decimal points (but not infinite!). For example, let’s look at \\(\\pi\\), which is built in as pi in R:\n\npi\n\n[1] 3.141593\n\nclass(pi)\n\n[1] \"numeric\"\n\n\nHere, we use the class() function to determine what data type R is using to store our variables. In this case, we can see that R stores pi as a default numeric variable, which is implemented as a double. In general, whenever you work with numbers, they will be doubles, and for purposes of STA 199 there is no issue with this.\nInteger\nThe int data type means integer - as in, the mathematical concept of an integer. All data represented as integers will be whole numbers. This data type is not capable of storing decimal places, so if you try to do decimal operations with it, R will implicitly cast it to another data type. Implicitly means that it does this without us telling it to. Let’s take a look at a couple of examples:\n\na &lt;- 3\nclass(a)\n\n[1] \"numeric\"\n\n\nBy default, R will treat all numbers as the numeric class. If you want to explicitly tell R that your number is an integer, follow the number with “L”:\n\na &lt;- 3L\nclass(a)\n\n[1] \"integer\"\n\n\nNow, let’s say we want to divide this number by 2:\n\nb &lt;- a / 2\nclass(b)\n\n[1] \"numeric\"\n\n\nSince 3 is not divisible by 2, the output is a decimal. However, since we have performed a decimal operation, rather than trying to guess whether to round up or down, R simply implicitly casts it back to numeric.\nLogical/Boolean\nWhile there isn’t an example in this data frame, there is a data type called logical - which represents true/false.\n\nc &lt;- TRUE\nclass(c)\n\n[1] \"logical\"\n\n\nIn R, you need to type out TRUE/FALSE in all caps for it to be recognized. Under the hood, R stores these values as “FALSE = 0” and “TRUE = 1”, which means that if you want to find the percentage of TRUE in your data, you can just take the average:\n\nd &lt;- c(TRUE, FALSE, TRUE)\nmean(d)\n\n[1] 0.6666667\n\n\nCharacter/String\nThe chr data type represents all characters and strings in R. Unlike some languages, R does not differentiate between these. In general, strings are used to represent words and categorical data, for example:\n\nplace &lt;- \"Durham, NC\"\nclass(place)\n\n[1] \"character\"\n\n\nHowever, there is an important point of caution here. Sometimes, when you load in a data frame, there will be columns that should be represented as numbers, but are accidentally represented as strings. If you’re not careful, this can have consequences. For example, consider the following:\n\n0 == 00\n\n[1] TRUE\n\n\"0\" == \"00\"\n\n[1] FALSE\n\n\nIn R, the numbers 0 and 00 represent the same thing! However, when they are strings, they do not. R treats numbers differently than it does strings, so it’s important to pay attention to which one you are actually implementing. You might also run into issues with some of your operations - for example, if you try to take the average of a column of strings, R has no idea what to do and will throw an error.\nNote: pay attention to the usage of two equal signs here, rather than just one. Why did we do this? (More on this shortly.)",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#casting",
    "href": "coding-principles-oh.html#casting",
    "title": "Intro to Coding Principles",
    "section": "Casting",
    "text": "Casting\nSo what is the solution to this problem? The answer is called casting, which means changing the data type. You do this using the as.character(), as.numeric(), and as.logical() commands. Let’s look at an example:\n\ne &lt;- \"00\"\nclass(e)\n\n[1] \"character\"\n\ne\n\n[1] \"00\"\n\ne &lt;- as.numeric(e)\nclass(e)\n\n[1] \"numeric\"\n\ne\n\n[1] 0\n\ne &lt;- as.logical(e)\nclass(e)\n\n[1] \"logical\"\n\ne\n\n[1] FALSE\n\ne &lt;- as.character(e)\nclass(e)\n\n[1] \"character\"\n\ne\n\n[1] \"FALSE\"\n\ne &lt;- as.numeric(e) # What happened?\n\nWarning: NAs introduced by coercion\n\ne\n\n[1] NA\n\n\nBe mindful with your casting - you can lose information along the way!\nNote: NA is a specific type in R. It essentially means “nothing” or “this value has not been declared”. You cannot use == to check whether a value is NA. Instead, you must use is.na().",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#equals",
    "href": "coding-principles-oh.html#equals",
    "title": "Intro to Coding Principles",
    "section": "Equals",
    "text": "Equals\nThe first Boolean operator is “equals”. This is a place where it is easy to get confused. We use the single equals sign, =, to denote assignment - essentially, telling R “this thing takes this value.” We use the double equals sign, ==, to denote comparison - essentially, asking R “are these two values equal?” It is important to keep these two things distinct - if you want to check equality, or filter for a specific value, you always need to use the double equals sign!\n\nmidwest |&gt;\n  filter(county = \"Cook\")\n\nError in `filter()`:\n! We detected a named input.\nℹ This usually means that you've used `=` instead of `==`.\nℹ Did you mean `county == \"Cook\"`?\n\n\nHere’s an example of where a single equals sign is incorrect, and R returns an error. Fortunately, it has a very helpful suggestion in the error message! Let’s replace that with the double equals:\n\nmidwest |&gt;\n  filter(county == \"Cook\")\n\n# A tibble: 0 × 28\n# ℹ 28 variables: PID &lt;int&gt;, county &lt;chr&gt;, state &lt;chr&gt;, area &lt;dbl&gt;,\n#   poptotal &lt;int&gt;, popdensity &lt;dbl&gt;, popwhite &lt;int&gt;, popblack &lt;int&gt;,\n#   popamerindian &lt;int&gt;, popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;, …\n\n\nNow there’s no error message, but we also didn’t return any values. Why did this happen? When I use ==, I am checking whether these two strings are exactly equivalent, and that includes being case sensitive. If I view the data in the data frame, I see that all of the county names are actually in all caps. I can fix the string in my example…\n\nmidwest |&gt;\n  filter(county == \"COOK\")\n\n# A tibble: 1 × 28\n    PID county state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   576 COOK   IL    0.058  5105067     88018.  3204947  1317147         10289\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\n…and finally find Chicago!",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#and",
    "href": "coding-principles-oh.html#and",
    "title": "Intro to Coding Principles",
    "section": "And",
    "text": "And\nThe second Boolean operator is “and”. We use this when we want multiple conditions to be true. In R, to denote and, we use the single ampersand & (in some other languages, you use a double ampersand). When R sees this, it checks both statements, and only returns TRUE if both statements are true. Let’s look at an example, again using filter():\n\nmidwest |&gt;\n  filter(state == \"IL\")\n\n# A tibble: 102 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 92 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nUsing our == operator, we can find all of the counties in Illinois. Now, let’s find only the ones with a population density over 30,000:\n\nmidwest |&gt;\n  filter(state == \"IL\" & popdensity &gt;= 30000)\n\n# A tibble: 2 × 28\n    PID county  state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   576 COOK    IL    0.058  5105067     88018.  3204947  1317147         10289\n2   582 DU PAGE IL    0.02    781666     39083.   714905    15462           962\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow, the filter() statement is returning all of the rows from this data frame where BOTH the state is “IL” AND the population density is \\(\\geq\\) 30,000.",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#or",
    "href": "coding-principles-oh.html#or",
    "title": "Intro to Coding Principles",
    "section": "Or",
    "text": "Or\nThe third Boolean operator is “or”. We use this when we want at least one condition to be true. In R, to denote or, we use the vertical line | (again, in some other languages, you use a double line). When R sees this, it checks both statements, and returns TRUE if either (or both) of the statements are true. Let’s go back to our example:\n\nmidwest |&gt;\n  filter(state == \"IL\" | popdensity &gt;= 30000) |&gt;\n  arrange(desc(popdensity))\n\n# A tibble: 107 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   576 COOK    IL    0.058  5105067     88018.  3204947  1317147         10289\n 2  3021 MILWAU… WI    0.015   959275     63952.   718918   195470          6994\n 3  1278 WAYNE   MI    0.035  2111687     60334.  1212007   849109          8048\n 4  2026 CUYAHO… OH    0.026  1412140     54313.  1025756   350185          2533\n 5   582 DU PAGE IL    0.02    781666     39083.   714905    15462           962\n 6   711 MARION  IN    0.023   797159     34659.   615039   169654          1698\n 7  2039 HAMILT… OH    0.025   866228     34649.   672972   181145          1204\n 8   609 LAKE    IL    0.028   516418     18444.   450666    34771          1198\n 9   605 KANE    IL    0.029   317471     10947.   269675    19006           620\n10   661 Winneb… IL    0.03    252913      8430.   222439    23256           651\n# ℹ 97 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow, R returns all of the rows that are in Illinois, as well as all of the rows that are not in Illinois, but have a population density of at least 30,000.\nNote: Keep in mind that | is not exclusive. That means that | will return true if only one condition is true, but it will also return true if both conditions are true. If you want exactly one condition to be true, look up the operator XOR.",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#not",
    "href": "coding-principles-oh.html#not",
    "title": "Intro to Coding Principles",
    "section": "Not",
    "text": "Not\nThe fourth Boolean operator is “not”. We use this when we want to exclude certain values from the data or prevent something from happening. In R, to denote not, we use the exclamation mark !. Specifically, you place the !, also known as a bang sign, in front of the statement that you want to be false. The most frequent use of this is to say “not equals”, which is denoted != (note that it is only one equals sign now, not two!) Let’s look at an example:\n\nmidwest |&gt;\n  filter(state != \"IL\") |&gt;\n  arrange(desc(popdensity))\n\n# A tibble: 335 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1  3021 MILWAU… WI    0.015   959275     63952.   718918   195470          6994\n 2  1278 WAYNE   MI    0.035  2111687     60334.  1212007   849109          8048\n 3  2026 CUYAHO… OH    0.026  1412140     54313.  1025756   350185          2533\n 4   711 MARION  IN    0.023   797159     34659.   615039   169654          1698\n 5  2039 HAMILT… OH    0.025   866228     34649.   672972   181145          1204\n 6  2033 FRANKL… OH    0.034   961437     28278.   783714   152840          2056\n 7  1246 MACOMB  MI    0.028   717400     25621.   693686    10400          2639\n 8  2056 LUCAS   OH    0.021   462361     22017.   380155    68456          1164\n 9  2085 SUMMIT  OH    0.024   514990     21458.   446902    61185          1065\n10  2065 MONTGO… OH    0.027   573809     21252.   463551   101817          1065\n# ℹ 325 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nIn these data, all rows from Illinois have been removed. You can check this by commenting out the filter line, and observing the difference, or just noting that Cook County, IL (home of Chicago, the densest city in the midwest) is absent!",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#combining-boolean-operators",
    "href": "coding-principles-oh.html#combining-boolean-operators",
    "title": "Intro to Coding Principles",
    "section": "Combining Boolean Operators",
    "text": "Combining Boolean Operators\nYou can also combine multiple Boolean operators in more complex logical statements. We will not look at any examples here, because they can get very confusing, very quickly (and are generally unnecessary for this course). However, if you do want to combine Boolean operators, here are some things to keep in mind:\n\nParentheses: Just like in math, any statements that you put in parentheses will execute first. If I say “A and B or C”, it’s unclear exactly what I mean. If I would accept either (A and B) or (A and C), I would write A & (B | C), meaning I need at least one of B or C to be true. If I would accept either (A and B) or C, I would write (A & B) | C, meaning I need either (A and B) or C to be true.\nOrder of operations: Pay attention to the order in which your statements evaluate! If I write !(A & B), that means I need at least one of A or B to be false. If I write !A & !B, that means I need both A and B to be false. This can get confusing, so it’s best to write out your logic fully and work through a few examples by hand (or avoid layering these operators entirely).",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#definition-1",
    "href": "coding-principles-oh.html#definition-1",
    "title": "Intro to Coding Principles",
    "section": "Definition",
    "text": "Definition\nWhat is a function? A function is, essentially, a block of code that does something (so that you don’t have to implement it!). A function will always have a name, followed by open and closed parentheses (). Some functions do not take arguments. However, if they do, these arguments will go within the parentheses. Once R sees an opening parenthesis, it will not execute the code until it sees a closing parenthesis. Beware - when you start layering functions, such as using aes() inside of ggplot(), you need to pay attention to what your parentheses are around and make sure that they all close!",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#arguments",
    "href": "coding-principles-oh.html#arguments",
    "title": "Intro to Coding Principles",
    "section": "Arguments",
    "text": "Arguments\nArguments are the commands that you give to a function that tell it what to do. Most functions take at least one argument, and some can take arbitrarily many. Functions have a default order for (some of) their arguments. If you know this order, you do not have to explicitly name the arguments. If not, you must list them explicitly. Here are two examples:\n\n# Named Arguments\nggplot(\n  data = midwest, \n  mapping = aes(x = poptotal, y = popdensity, color = percwhite)\n  ) +\n  geom_point()\n\n\n\n\n\n\n# Unnamed Arguments\nggplot(\n  midwest, \n  aes(poptotal, popdensity, percwhite)\n  ) +\n  geom_point()\n\n\n\n\n\n\n\nIn ggplot, the first two arguments are always data and mapping, so it is common to drop these. However, in the second plot here, we lost our fill aesthetic. Why?\nWhen we look at the aes() documentation, we see that x is the first named argument and y is the second, but after that there are no named arguments. That means, while you can add more aesthetics, you must name them explicitly, since they do not appear by default.\nPipe Operator\nMany times in this class, you will see the symbol |&gt; used. This is known as the pipe operator, and it allows us to have a so-called “data pipeline”. This helps make code a lot more readable! Let’s take a look at why:\n\nhead(arrange(mutate(select(filter(midwest, state == \"IL\"), county, state, area, poptotal, inmetro), inmetro = as.logical(inmetro)), desc(poptotal)), 10)\n\n# A tibble: 10 × 5\n   county    state  area poptotal inmetro\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt; &lt;lgl&gt;  \n 1 COOK      IL    0.058  5105067 TRUE   \n 2 DU PAGE   IL    0.02    781666 TRUE   \n 3 LAKE      IL    0.028   516418 TRUE   \n 4 WILL      IL    0.05    357313 TRUE   \n 5 KANE      IL    0.029   317471 TRUE   \n 6 ST CLAIR  IL    0.04    262852 TRUE   \n 7 Winnebago IL    0.03    252913 TRUE   \n 8 MADISON   IL    0.045   249238 TRUE   \n 9 MCHENRY   IL    0.036   183241 TRUE   \n10 PEORIA    IL    0.038   182827 TRUE   \n\n\nTechnically, we can write our code in this manner! Strictly speaking, under the hood, the pipe operator is reconstructing your code into this format. However, this is nearly impossible to read (I’ve been coding in R for years, and I still ran into multiple errors trying to write this).\nWith the pipe operator, we can skip this and execute each function on its own line. By default, the pipe operator “pipes” your data into the first argument of a function - which, in the tidyverse, is almost always the “data” argument. This lets us write our data in a much neater pipeline, where you can see step-by-step what is happening to the data:\n\nmidwest |&gt;   # Operate on the midwest data frame\n  filter(state == \"IL\") |&gt;   # Filter for only the counties in Illinois\n  select(county, state, area, poptotal, inmetro) |&gt;   # Select only these five columns, and drop all others\n  mutate(inmetro = as.logical(inmetro)) |&gt;   # Cast inmetro to a logical type\n  arrange(desc(poptotal)) |&gt;   # Arrange the data frame by poptotal in descending order\n  head(10)   # Select the top 10 rows\n\n# A tibble: 10 × 5\n   county    state  area poptotal inmetro\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt; &lt;lgl&gt;  \n 1 COOK      IL    0.058  5105067 TRUE   \n 2 DU PAGE   IL    0.02    781666 TRUE   \n 3 LAKE      IL    0.028   516418 TRUE   \n 4 WILL      IL    0.05    357313 TRUE   \n 5 KANE      IL    0.029   317471 TRUE   \n 6 ST CLAIR  IL    0.04    262852 TRUE   \n 7 Winnebago IL    0.03    252913 TRUE   \n 8 MADISON   IL    0.045   249238 TRUE   \n 9 MCHENRY   IL    0.036   183241 TRUE   \n10 PEORIA    IL    0.038   182827 TRUE   \n\n\nMuch better, right? Remember, whenever you’re using the pipe operator (or the +, in ggplot, which is different!), you should start a new line of code. As long as you have a pipe operator, R is expecting another function, so it won’t execute only part of your code.\nNote: In this class, we focus on the base R pipe, which is denoted by |&gt;. However, when you’re debugging on the internet, you may come across the symbol %&gt;%, which is the magrittr pipe. There are some technical differences in these that generally go beyond the scope of this class, but they essentially serve the same purpose. Don’t be scared by the magrittr pipe when you’re doing your debugging!",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#definition-2",
    "href": "coding-principles-oh.html#definition-2",
    "title": "Intro to Coding Principles",
    "section": "Definition",
    "text": "Definition\nEvery time we start programming in this class, we run library(tidyverse). Why do we do this?\nLibraries are collections of functions, and running them means that we are loading those functions into our current R session. If you try to open up a fresh R session and run ggplot() immediately, you will get an error, because that function is not found. However, with the library, you can load in everything that you need, all at once. The tidyverse is especially cool, because it is actually a collection of libraries - libraryception!",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#environment",
    "href": "coding-principles-oh.html#environment",
    "title": "Intro to Coding Principles",
    "section": "Environment",
    "text": "Environment\nYour environment in R is basically the current instance of your program. When you run a library, it is part of your environment until you restart R, meaning you can call any of its functions at any time. When you create a variable, it is part of your environment until you restart R, meaning you can reference those variables at any time.\nWhen you use the containers, they do not regularly restart R. This can be a problem sometimes, when old code gets tangled up with new code! It is my personal recommendation that you (at a minimum) restart R and clear your environment every time you start a new project (AE, lab, etc). You can restart R by going to Session -&gt; Restart R, and clear your environment by going to the environment pane and clicking the broom icon.",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#rendering-quarto",
    "href": "coding-principles-oh.html#rendering-quarto",
    "title": "Intro to Coding Principles",
    "section": "Rendering Quarto",
    "text": "Rendering Quarto\nWhen you click the “Render” button for your .qmd file, what happens? R executes a program, called a “compiler”, that runs your entire .qmd file in a new environment. In other words, if you have loaded a library, or edited a variable, or done any number of things in the console (or even later in the .qmd file) without saving them in the .qmd file, and then you try to render, you will get an error because that function/variable/etc has not been defined in the rendering environment. This forces you to write reproducible code, and it’s the first thing to think about when you run into errors while rendering!",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#documentation",
    "href": "coding-principles-oh.html#documentation",
    "title": "Intro to Coding Principles",
    "section": "Documentation",
    "text": "Documentation\nUnless you have a function and its usage entirely memorized, you are going to be reading documentation. Documentation is useful, but it is dense, and can be hard to parse. Let’s look at an example of how we can look through documentation.\n\n?if_else\n\n?geom_point",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#errors",
    "href": "coding-principles-oh.html#errors",
    "title": "Intro to Coding Principles",
    "section": "Errors",
    "text": "Errors\nUnless you are the Roman God of Programming (and even then, I’m not too sure), you are going to encounter errors in your programming. These are completely natural, and nothing to be ashamed of - sometimes I write partial code, just to see where it will catch errors. However, some error messages are easier to understand than others. Let’s look through a couple of examples of common errors, and what I would do to interpret and fix them.",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#example-1",
    "href": "coding-principles-oh.html#example-1",
    "title": "Intro to Coding Principles",
    "section": "Example 1",
    "text": "Example 1\n\nmidwest |&gt;\n  sumarize(avg_pop_dens = mean(popdensity))\n\nError in sumarize(midwest, avg_pop_dens = mean(popdensity)): could not find function \"sumarize\"\n\n\n\n\n\n\n\n\nWhat’s wrong with this code?\n\n\n\n\n\nIn this case, we just have a simple spelling error! It may seem trivial, but this will constitute at least half of the errors that you have. Make this the first thing you check - you will never meet a programmer who doesn’t have a story of the time they spent at least 30 minutes debugging a function, just to realize it was a typo all along.",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#example-2",
    "href": "coding-principles-oh.html#example-2",
    "title": "Intro to Coding Principles",
    "section": "Example 2",
    "text": "Example 2\n\nggplot(midwest, aes(x = poptotal, y = popdensity,)) |&gt;\n  geom_point() |&gt;\n  labs(x = \"Total Population\", y = \"Population Density\")\n\nError in `geom_point()`:\n! `mapping` must be created by `aes()`.\nℹ Did you use `%&gt;%` or `|&gt;` instead of `+`?\n\n\n\n\n\n\n\n\nWhat’s wrong with this code?\n\n\n\n\n\nThis one should be pretty obvious, since it’s a common enough error that R gives an extremely helpful error message. When you’re building a ggplot object, you use + rather than |&gt; to add additional lines!\nThere’s a second error here, that R knew well enough to handle here, but which could become an issue in more complicated code chunks. Did anyone spot it?",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "coding-principles-oh.html#example-3",
    "href": "coding-principles-oh.html#example-3",
    "title": "Intro to Coding Principles",
    "section": "Example 3",
    "text": "Example 3\n\nggplot(midwest, aes(x = state, y = poptotal, fill = state)) +\n  geom_bar() +\n  theme_bw() +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\", scale = 1e-6)) +\n  labs(\n    x = \"State\",\n    y = \"Total Population\\n(Millions)\",\n    title = \"Total Population by State\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    panel.grid.major.x = element_blank(),\n    legend.position = \"none\"\n  ) +\n  scale_fill_viridis_d()\n\nError in `geom_bar()`:\n! Problem while computing stat.\nℹ Error occurred in the 1st layer.\nCaused by error in `setup_params()`:\n! `stat_count()` must only have an x or y aesthetic.\n\n\nThere’s a lot going on here, so it might not be obvious at first where the issue is! The error has something to do with the function stat_count(), but that’s not a function we used (explicitly) anywhere in this code. This is why you should iterate on your code, running it intermittently, so that you can catch errors when they pop up.\nMy first thought would be to run rlang::last_trace(), as suggested by the error message. This is sometimes helpful - it can reference certain functions and even lines of code, especially when you’re executing something more complex. Frequently, though, it’s too complicated to understand. In this case, I would certainly say I can’t make any sense of that.\nMy next thought is to google the error message. It can be a little tricky to know what to google from the error message. You want to look for anything that seems general enough that other people might have asked, but specific enough that it will apply to your situation. Let’s go line by line:\n\n“Error in geom_bar()”: Probably too general to bother googling. There are a lot of possible errors with geom_bar(), and it would take too long to look through them all to get to your specific problem!\n“Problem while computing stat.”: This is more helpful, because it gives a little more direction as to the source of the error, but it is still too general - what stat are we computing? What problem?\n“Error occured in the 1st layer”: This can be helpful for you, if you know the order of ggplot layers. However, it is probably not helpful to google, since people could have built their layers in a different order before encountering this error.\n“Caused by error in setup_params()”: Closer! This is getting more and more specific, and this might be good enough to google. However, it still doesn’t say what the error is, it just says that there was one.\n“stat_count() must only have an x or y aesthetic”: Bingo! This is the one we’re looking for, which tells us exactly what the issue is. Now, it may be possible to interpret manually, but let’s say you can’t. Here’s where we go now:\n\nI would copy-paste the entire final line into google. You don’t want to copy-paste the full error message, since that’s probably too specific, and you might not find any results. At the same time, you don’t want to copy-paste only a couple of words, since that might not be specific enough, and you could be stuck looking through a lot of links. If you google just that line, you are likely to find someone on stack exchange who has posted a question with this exact (or almost this exact) error message. You can also help your google out by throwing in some relevant key words:\n\nggplot\nR\nerror\n\nTake a couple minutes to google this, and see if you can figure out what’s wrong with the code! Then, remember to cite the source where you found this answer! In general, it’s okay to google your error messages for help, but not to use someone else’s solution without credit.\n\n\n\n\n\n\nWhat’s wrong with this code?\n\n\n\n\n\nI looked at https://stackoverflow.com/questions/61068031/error-stat-count-can-only-have-an-x-or-y-aesthetic for my answer. There’s a few different suggestions on this page, all of which could be useful! This page definitely suggests to me that the issue with my plot is in the geom_bar() line - which makes sense, since this is layer 1 of the plot. While they have a couple simple fixes, here’s the actual error I wrote: geom_bar() is expecting only one variable. If you want two variables, like this, you should use geom_col() instead.",
    "crumbs": [
      "Computing",
      "Coding principles"
    ]
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Dr. Mine Çetinkaya-Rundel (she/her) is Professor of the Practice and Director of Undergraduate Studies at the Department of Statistical Science at Duke University. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education, as well as pedagogical approaches for enhancing the retention of women and underrepresented minorities in STEM.\n\n\n\n\n\n\n\nOffice hours\nLocation\n\n\n\n\nTuesdays and Thursdays 1-1:30 pm (after class)\nBio Sci 111\n\n\nWednesdays 2-4 pm\nOld Chem 213",
    "crumbs": [
      "Course information",
      "Team"
    ]
  },
  {
    "objectID": "course-team.html#instructor",
    "href": "course-team.html#instructor",
    "title": "Teaching team",
    "section": "",
    "text": "Dr. Mine Çetinkaya-Rundel (she/her) is Professor of the Practice and Director of Undergraduate Studies at the Department of Statistical Science at Duke University. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education, as well as pedagogical approaches for enhancing the retention of women and underrepresented minorities in STEM.\n\n\n\n\n\n\n\nOffice hours\nLocation\n\n\n\n\nTuesdays and Thursdays 1-1:30 pm (after class)\nBio Sci 111\n\n\nWednesdays 2-4 pm\nOld Chem 213",
    "crumbs": [
      "Course information",
      "Team"
    ]
  },
  {
    "objectID": "course-team.html#teaching-assistants",
    "href": "course-team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\nEach TA holds office hours. Some TAs are also leaders or helpers for lab sections. Some TAs help out in lecture.\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Name\n        \n         \n          Role(s)\n        \n         \n          Section(s)\n        \n         \n          Office hours\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nName\n\n\nRole(s)\n\n\nSection(s)\n\n\nOffice hours\n\n\n\n\n\n\n\n\n\nAnmol Sapru\n\n\nLab helper\n\n\nM 3:05 PM - 4:20 PM (Sec 8)\n\n\n🔗\n\n\n\n\n\n\n\nAurora Liu\n\n\nLab helper\n\n\nM 8:30 AM - 9:45 AM (Sec 1)\n\n\n🔗\n\n\n\n\n\n\n\nAvery Hodges\n\n\nLab leader\n\n\nM 11:45 AM - 1:00 PM (Sec 4)\n\n\n🔗\n\n\n\n\n\n\n\nDav King\n\n\nLab leader\n\n\nM 3:05 PM - 4:20 PM (Sec 8)\n\n\n🔗\n\n\n\n\n\n\n\nDomenic Fenoglio\n\n\nLab leader\n\n\nM 1:25 PM - 2:40 PM (Sec 7)\n\n\n🔗\n\n\n\n\n\n\n\nEmily Jensen\n\n\nLab leader\n\n\nM 1:25 PM - 2:40 PM (Sec 6)\n\n\n🔗\n\n\n\n\n\n\n\nFederico Arboleda\n\n\nLab helper\n\n\nM 1:25 PM - 2:40 PM (Sec 7)\n\n\n🔗\n\n\n\n\n\n\n\nGrade Rade\n\n\nLab helper\n\n\nM 11:45 AM - 1:00 PM (Sec 4)\n\n\n🔗\n\n\n\n\n\n\n\nHyunjin Lee\n\n\nLab helper\n\n\nM 3:05 PM - 4:20 PM (Sec 9)\n\n\n🔗\n\n\n\n\n\n\n\nJanice Kim\n\n\nLab helper, Lecture helper\n\n\nM 4:40 PM - 5:55 PM (Sec 10)\n\n\n🔗\n\n\n\n\n\n\n\nJasmine Wang\n\n\nLab leader\n\n\nM 10:05 AM - 11:20 AM (Sec 2)\n\n\n🔗\n\n\n\n\n\n\n\nJohn Zito\n\n\nLab leader\n\n\nM 3:05 PM - 4:20 PM (Sec 9)M 4:40 PM - 5:55 PM (Sec 10)\n\n\n🔗\n\n\n\n\n\n\n\nJonathan Lin\n\n\nLab helper\n\n\nM 10:05 AM - 11:20 AM (Sec 3)\n\n\n🔗\n\n\n\n\n\n\n\nKareena Legare\n\n\nLab helper\n\n\nM 1:25 PM - 2:40 PM (Sec 6)\n\n\n🔗\n\n\n\n\n\n\n\nLiane Ma\n\n\n \n\n\n\n\n\n🔗\n\n\n\n\n\n\n\nLynn Kremers\n\n\nLab helper\n\n\nM 11:45 AM - 1:00 PM (Sec 5)\n\n\n🔗\n\n\n\n\n\n\n\nMarie Neubrander\n\n\nHead TA, Lab leader\n\n\nM 8:30 AM - 9:45 AM (Sec 1)M 10:05 AM - 11:20 AM (Sec 3)\n\n\n🔗\n\n\n\n\n\n\n\nNetra Mittal\n\n\nLab leader\n\n\nM 11:45 AM - 1:00 PM (Sec 5)\n\n\n🔗\n\n\n\n\n\n\n\nNoah Obuya\n\n\nLab helper\n\n\nM 10:05 AM - 11:20 AM (Sec 2)\n\n\n🔗\n\n\n\n\n\n\n\nSarah Wu\n\n\nLecture helper\n\n\n\n\n\n🔗\n\n\n\n\n\n\n\nSonya Eason\n\n\n \n\n\n\n\n\n🔗\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Course information",
      "Team"
    ]
  },
  {
    "objectID": "course-team.html#course-coordinator",
    "href": "course-team.html#course-coordinator",
    "title": "Teaching team",
    "section": "Course coordinator",
    "text": "Course coordinator\n\nDr. Mary Knox (she/her) is the course coordinator for this course. You can contact her (at mary.knox@duke.edu) with any questions regarding accommodations, missed work, extensions, etc., and registration.",
    "crumbs": [
      "Course information",
      "Team"
    ]
  },
  {
    "objectID": "exam-review/final-review.html",
    "href": "exam-review/final-review.html",
    "title": "Final review",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "exam-review/midterm-review.html",
    "href": "exam-review/midterm-review.html",
    "title": "Midterm Review",
    "section": "",
    "text": "Note\n\n\n\nSuggested answers can be found here, but resist the urge to peek before you go through it yourself.\nIn 2020, employees of Blizzard Entertainment circulated a spreadsheet to anonymously share salaries and recent pay increases amidst rising tension in the video game industry over wage disparities and executive compensation. (Source: Blizzard Workers Share Salaries in Revolt Over Pay)\nThe name of the data frame used for this analysis is blizzard_salary and the variables are:\nThe top ten rows of blizzard_salary are shown below:\n# A tibble: 409 × 4\n   percent_incr salary_type annual_salary performance_rating\n          &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n 1          1   Salaried               1  High              \n 2          1   Salaried               1  Successful        \n 3          1   Salaried               1  High              \n 4          1   Hourly             33987. Successful        \n 5         NA   Hourly             34798. High              \n 6         NA   Hourly             35360  &lt;NA&gt;              \n 7         NA   Hourly             37440  &lt;NA&gt;              \n 8          0   Hourly             37814. &lt;NA&gt;              \n 9          4   Hourly             41101. Top               \n10          1.2 Hourly             42328  &lt;NA&gt;              \n# ℹ 399 more rows"
  },
  {
    "objectID": "exam-review/midterm-review.html#question-1",
    "href": "exam-review/midterm-review.html#question-1",
    "title": "Midterm Review",
    "section": "Question 1",
    "text": "Question 1\nWhich of the following is correct? Choose all that apply.\n\nThe blizzard_salary dataset has 399 rows.\nThe blizzard_salary dataset has 4 columns.\nEach row represents a Blizzard Entertainment worker who filled out the spreadsheet.\nThe percent_incr variable is numerical and discrete.\nThe salary_type variable is numerical.\nThe annual_salary variable is numerical.\nThe performance_rating variable is categorical and ordinal."
  },
  {
    "objectID": "exam-review/midterm-review.html#question-2",
    "href": "exam-review/midterm-review.html#question-2",
    "title": "Midterm Review",
    "section": "Question 2",
    "text": "Question 2\nFigure 1 (a) and Figure 1 (b) show the distributions of annual salaries of hourly and salaried workers. The two figures show the same data, with the facets organized across rows and across columns. Which of the two figures is better for comparing the median annual salaries of hourly and salaried workers. Explain your reasoning.\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\nFigure 1: Distribution of annual salaries of Blizzard employees"
  },
  {
    "objectID": "exam-review/midterm-review.html#question-3",
    "href": "exam-review/midterm-review.html#question-3",
    "title": "Midterm Review",
    "section": "Question 3",
    "text": "Question 3\nSuppose your teammate wrote the following code as part of their analysis of the data.\nThey then printed out the results shown below. Unfortunately one of the numbers got erased from the printout. It’s indicated with _____ below.\n# A tibble: 2 × 3\n  salary_type mean_annual_salary median_annual_salary\n  &lt;chr&gt;                    &lt;dbl&gt;                &lt;dbl&gt;\n1 Hourly                  63003.               54246.\n2 Salaried                90183.               _____\nWhich of the following is the best estimate for that erased value?\n\n30,000\n50,000\n80,000\n100,000"
  },
  {
    "objectID": "exam-review/midterm-review.html#question-4",
    "href": "exam-review/midterm-review.html#question-4",
    "title": "Midterm Review",
    "section": "Question 4",
    "text": "Question 4\nWhich distribution of annual salaries has a higher standard deviation?\n\nHourly workers\nSalaried workers\nRoughly the same"
  },
  {
    "objectID": "exam-review/midterm-review.html#question-5",
    "href": "exam-review/midterm-review.html#question-5",
    "title": "Midterm Review",
    "section": "Question 5",
    "text": "Question 5\nWhich of the following alternate plots would also be useful for visualizing the distributions of annual salaries of hourly and salaried workers? Choose all that apply.\na. Box plots\nb. Density plots\nc. Pie charts\nd. Waffle charts\ne. Histograms\nf. Scatterplots"
  },
  {
    "objectID": "exam-review/midterm-review.html#questions-6-and-7",
    "href": "exam-review/midterm-review.html#questions-6-and-7",
    "title": "Midterm Review",
    "section": "Questions 6 and 7",
    "text": "Questions 6 and 7\nSuppose you made the bar plot shown in Figure 2 (a) to visualize the distribution of performance_rating and your teammate made the bar plot shown in Figure 2 (b).\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\nFigure 2: Distribution of performance rating\n\n\nYou made your bar plot without transforming the data in any way, while your friend did first transform the data with code like the following:\n\nblizzard_salary &lt;- blizzard_salary |&gt;\n  _(1)_(performance_rating = fct_relevel(performance_rating, _(2)_))\n\nQuestion 6: What goes in the blank (1)?\n\narrange()\nfilter()\nmutate()\nsummarize()\n\nQuestion 7: What goes in the blank (2)?\n\n\"Poor\", \"Successful\", \"High\", \"Top\"\n\"Successful\", \"High\", \"Top\"\n\"Top\", \"High\", \"Successful\", \"Poor\"\nPoor, Successful, High, Top"
  },
  {
    "objectID": "exam-review/midterm-review.html#questions-8---10",
    "href": "exam-review/midterm-review.html#questions-8---10",
    "title": "Midterm Review",
    "section": "Questions 8 - 10",
    "text": "Questions 8 - 10\nFinally, another teammate creates the following two plots.\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\nFigure 3: Distribution of salary type by performance rating\n\n\nQuestion 8: Your teammate asks you for help deciding which one to use in the final report for visualizing the relationship between performance rating and salary type. In 1-3 sentences, can you help them make a decision, justify your choice, and write the narrative that should go with the plot?\nQuestion 9: A friend with a keen eye points out that the number of observations in Figure 3 (a) seems lower than the total number of observations in blizzard_salary. What might be going on here? Explain your reasoning.\nQuestion 10: Below are the proportions of performance ratings for hourly and salaried workers. Place these values in the corresponding segments in Figure 3 (b).\n\n\n# A tibble: 4 × 3\n  performance_rating Hourly Salaried\n  &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1 High                0.2     0.384 \n2 Successful          0.686   0.521 \n3 Top                 0.114   0.0760\n4 Poor                0       0.0190"
  },
  {
    "objectID": "exam-review/midterm-review.html#questions-11-and-12",
    "href": "exam-review/midterm-review.html#questions-11-and-12",
    "title": "Midterm Review",
    "section": "Questions 11 and 12",
    "text": "Questions 11 and 12\nThe table below shows the distribution of salary_type and performance_rating.\n\n\n# A tibble: 2 × 6\n  salary_type  Poor Successful  High   Top  `NA`\n  &lt;chr&gt;       &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Hourly         NA         24     7     4    28\n2 Salaried        5        137   101    20    83\n\n\nThe pipeline below produces a data frame with a fewer number of rows than blizzard_salary.\n\nblizzard_salary |&gt;\n  filter(salary_type _(1)_ \"Hourly\" _(2)_ performance_rating == \"Poor\") |&gt;\n  _(3)_(annual_salary)\n\n\n\n# A tibble: 5 × 4\n  percent_incr salary_type annual_salary performance_rating\n         &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n1            0 Salaried            80000 Poor              \n2            3 Salaried            83000 Poor              \n3            0 Salaried           116000 Poor              \n4            0 Salaried           135219 Poor              \n5            0 Salaried           147500 Poor              \n\n\nQuestion 11: Which of the following goes in blanks (1) and (2)?\n\n\n\n(1)\n(2)\n\n\n\na.\n!=\n|\n\n\nb.\n==\n&\n\n\nc.\n!=\n&\n\n\nd.\n==\n|\n\n\n\nQuestion 12: Which function or functions go into blank (3)?\n\narrange()\nmutate()\norder()\nsort()"
  },
  {
    "objectID": "exam-review/midterm-review.html#question-13",
    "href": "exam-review/midterm-review.html#question-13",
    "title": "Midterm Review",
    "section": "Question 13",
    "text": "Question 13\nYou’re reviewing another team’s work and they made the following visualization:\n\n\n\n\n\n\n\n\nAnd they wrote the following interpretation for the relationship between annual salary and percent increase for Top performers:\n\nThe relationship is positive, having a higher salary results in a higher percent increase. There is one clear outlier.\n\nWhich of the following is/are the most accurate and helpful) peer review note for this interpretation. Choose all that apply.\n\nThe interpretation is complete and perfect, no changes needed!\nThe interpretation doesn’t mention the direction of the relationship.\nThe interpretation doesn’t mention the form of the relationship, which is linear.\nThe interpretation doesn’t mention the strength of the relationship, which is somewhat strong.\nThere isn’t a clear outlier in the plot. If any points stand out as potential outliers, more guidance should be given to the reader to identify them (e.g., salary and/or percent increase amount).\nThe interpretation is causal – we don’t know if the cause of the high percent increase is higher annual salary based on observational data. The causal direction might be the other way around, or there may be other factors contributing to the apparent relationship."
  },
  {
    "objectID": "exam-review/midterm-review.html#question-14",
    "href": "exam-review/midterm-review.html#question-14",
    "title": "Midterm Review",
    "section": "Question 14",
    "text": "Question 14\nBelow is some code and its output.\n```{r}\n# label=plot blizzard\n\nggplot(blizzard_salary,aes(x=performance_rating,y=percent_incr))+geom_boxplot()\nlabs(x=\"Performance rating\", y = \"Percent increase\")\n```\n\n\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n$x\n[1] \"Performance rating\"\n\n$y\n[1] \"Percent increase\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nPart 1: List at least 5 things that should be fixed or improved in the code.\nPart 2: What is the cause of the warning and what does it mean?"
  },
  {
    "objectID": "exam-review/midterm-review.html#question-15",
    "href": "exam-review/midterm-review.html#question-15",
    "title": "Midterm Review",
    "section": "Question 15",
    "text": "Question 15\nYou’re working on a data analysis on salaries of Blizzard employees in a Quarto document in a project version controlled by Git. You create a plot and write up a paragraph describing any patterns in it. Then, your teammate says “render, commit, and push”.\nPart 1: What do they mean by each of these three steps. In 1-2 sentences for each, explain in your own words what they mean.\n\nRender:\n\n\nCommit:\n\n\nPush:\n\nPart 2: Your teammate is getting impatient and they interrupt you after you rendered and committed and say “I still can’t see your changes in our shared GitHub repo when I look at it in my web browser.” Which of the following answers is the most accurate?\n\nI rendered my document, you should be seeing my changes on GitHub when you look at it in your web browser.\nI committed my changes, you should be seeing my changes on GitHub when you look at it in your web browser.\nI didn’t yet push my changes, it’s expected that you are not seeing them on GitHub when you look at it in your web browser. Wait until I push, and check again.\nYou need to pull to see my changes on GitHub in the web browser."
  },
  {
    "objectID": "exam-review/midterm-review.html#bonus",
    "href": "exam-review/midterm-review.html#bonus",
    "title": "Midterm Review",
    "section": "Bonus",
    "text": "Bonus\nPick a concept we introduced in class so far that you’ve been struggling with and explain it in your own words."
  },
  {
    "objectID": "lab/lab-2.html",
    "href": "lab/lab-2.html",
    "title": "Lab 2",
    "section": "",
    "text": "In this lab, you’ll continue to hone your data science workflow and integrate what you learned so far in the course (data visualization) with what’s coming up (data wrangling).\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed Lab 0 and Lab 1 and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review them before starting with this one.\n\n\n\nBy the end of the lab, you will…\n\nBe able to create transform data using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH (this might already be selected by default; if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-2.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-2.qmd, update the author field to your name, render your document, and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository and, in your browser, confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\nImportant\n\n\n\nIf you encounter any issues with the above steps, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the tidyverse package, a collection of packages for performing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in the lecture, your plots should include an informative title, axes and legends should have human-readable labels and aesthetic choices should be carefully considered.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nAs you complete the lab and other assignments in this course, remember to develop a sound workflow for reproducible data analysis. This assignment will periodically remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment."
  },
  {
    "objectID": "lab/lab-2.html#learning-objectives",
    "href": "lab/lab-2.html#learning-objectives",
    "title": "Lab 2",
    "section": "",
    "text": "By the end of the lab, you will…\n\nBe able to create transform data using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub"
  },
  {
    "objectID": "lab/lab-2.html#getting-started",
    "href": "lab/lab-2.html#getting-started",
    "title": "Lab 2",
    "section": "",
    "text": "Go to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH (this might already be selected by default; if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-2.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-2.qmd, update the author field to your name, render your document, and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository and, in your browser, confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\nImportant\n\n\n\nIf you encounter any issues with the above steps, flag a TA for help before proceeding."
  },
  {
    "objectID": "lab/lab-2.html#packages",
    "href": "lab/lab-2.html#packages",
    "title": "Lab 2",
    "section": "",
    "text": "In this lab, we will work with the tidyverse package, a collection of packages for performing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document."
  },
  {
    "objectID": "lab/lab-2.html#guidelines",
    "href": "lab/lab-2.html#guidelines",
    "title": "Lab 2",
    "section": "",
    "text": "As we’ve discussed in the lecture, your plots should include an informative title, axes and legends should have human-readable labels and aesthetic choices should be carefully considered.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nAs you complete the lab and other assignments in this course, remember to develop a sound workflow for reproducible data analysis. This assignment will periodically remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment."
  },
  {
    "objectID": "lab/lab-2.html#part-1",
    "href": "lab/lab-2.html#part-1",
    "title": "Lab 2",
    "section": "Part 1",
    "text": "Part 1\nAll about group_by()!\nUse the following data frame for Question 1 and Question 2:\n\ndf &lt;- tibble(\n  var_1 = c(10, 20, 30, 40, 50),\n  var_2 = c(\"Pizza\", \"Burger\", \"Pizza\", \"Pizza\", \"Burger\"),\n  var_3 = c(\"Apple\", \"Apple\", \"Pear\", \"Pear\", \"Banana\")\n)\n\ndf\n\n# A tibble: 5 × 3\n  var_1 var_2  var_3 \n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; \n1    10 Pizza  Apple \n2    20 Burger Apple \n3    30 Pizza  Pear  \n4    40 Pizza  Pear  \n5    50 Burger Banana\n\n\nQuestion 1\nGrouping by a single variable.\na. What does the following code chunk do? Run it, analyze the result, and articulate in words what arrange() does.\n\ndf |&gt;\n  arrange(var_2)\n\nb. What does the following code chunk do? Run it, analyze the result, and articulate in words what group_by() does. Also, comment on how it’s different from the arrange() in part (a).\n\ndf |&gt;\n  group_by(var_2)\n\nc. What does the following code chunk do? Run it, analyze the result, and articulate in words what the pipeline does.\n\ndf |&gt;\n  group_by(var_2) |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\nQuestion 2\nGrouping by two variables.\na. What does the following code chunk do? Run it, analyze the result, and articulate in words what the pipeline does. Then, comment on what the message says.\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\nb. What does the following code chunk do? Run it, analyze the result, and articulate in words what the pipeline does, especially mentioning what the .groups argument does. How is the output different from the one in part (a)?\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1), .groups = \"drop\")\n\nc. What do the following pipelines do? Run both, analyze their results, and articulate in words what each pipeline does. How are the outputs of the two pipelines different?\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1), .groups = \"drop\")\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  mutate(mean_var_1 = mean(var_1))\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answers for Questions 1 and 2”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward."
  },
  {
    "objectID": "lab/lab-2.html#part-2",
    "href": "lab/lab-2.html#part-2",
    "title": "Lab 2",
    "section": "Part 2",
    "text": "Part 2\nBack to the Midwest!\nIn this part, you will revisit and build on some of your findings from Lab 1, where you explored the midwest data frame. Remember that this data frame is bundled with the ggplot2 package and is automatically loaded when you load the tidyverse package. As a refresher, the data contains demographic characteristics of counties in the Midwest region of the United States. You can read the documentation for the data set, including variable definitions, by typing ?midwest in the Console or searching for midwest in the Help pane.\nQuestion 3\nCalculate the number of counties in each state and display your results in descending order of number of counties. Which state has the highest number of counties, and how many? Which state has the lowest number, and how many?\n\n\n\n\n\n\nNote\n\n\n\nThe number of counties in a state can change over time, so the values you see in this output may not be true today.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 3”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 4\nWhile two counties in a given state can’t have the same name, some county names might be shared across states. A classmate says “Look at that, there is a county called ___ in each state in this dataset!” In a single pipeline, discover all counties that could fill in the blanks. Your response should be a data frame with only the county names that could fill in the blank and the number of times they appear in the data.\n\n\n\n\n\n\nTip\n\n\n\nYou will want to use the filter() function in your answer, which requires a logical condition to describe what you want to filter for. For example, filter(x &gt; 2) means filter for values of x greater than 2, and filter(y &lt;= 3) means filter for values of y less than or equal to 3.\nThe table below is a summary of logical operators and how to articulate them in R.\n\n\noperator\ndefinition\n\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to\n\n\nx & y\n\nx AND y\n\n\n\n\nx | y\n\n\nx OR y\n\n\n\nis.na(x)\ntest if x is NA\n\n\n\n!is.na(x)\ntest if x is not NA\n\n\n\nx %in% y\ntest if x is in y\n\n\n\n!(x %in% y)\ntest if x is not in y\n\n\n\n!x\nnot x\n\n\n\n\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 4”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 5\nReturn to the following box plot of population densities where you were asked to identify at least one outlier.\n\n\n\n\n\n\n\n\nIn this question, we want you to revisit this box plot and identify the counties described in each section.\na. The counties with a population density higher than 25,000. Your code must use the filter() function.\nb. The county with the highest population density. Your code must use the max() function.\nAnswer using a single data wrangling pipeline for each part. Your response should be a data frame with five columns: county name, state name, population density, total population, and area, in this order. If your response has multiple rows, the data frame should be arranged in descending order of population density.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 5”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 6\nIn Lab 1 you were also asked to describe the distribution of population densities. The following is one acceptable description that touches on the shape, center, and spread of this distribution. Calculate the values that should go into the blanks.\n\nThe distribution of population density of counties is unimodal and extremely right-skewed. A typical Midwestern county has population density of ____ people per unit area. The middle 50% of the counties have population densities between ___ to ___ people per unit area.\n\n\n\n\n\n\n\nTip\n\n\n\nThink about which measures of center and spread are appropriate for skewed distributions.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 6”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 7\nAnother visualization from Lab 1 was the following, which showed the proportion of urban counties in each state.\n\n\n\n\n\n\n\n\nCalculate these proportions in a single data pipeline.\n\n\n\n\n\n\nTip\n\n\n\nRemember, you’ll first need to create a new variable called metro which takes on the value Yes if the value of inmetro is 1, and No otherwise. You can refer to Lab 1 if you need a refresher on how to do this.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 7”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 8\nReturn to the following scatter plot of percentage below poverty vs. percentage of people with a college degree, where the color and shape of points are determined by state where you were asked to identify at least one county that is a clear outlier by name.\n\n\n\n\n\n\n\n\na. In a single pipeline, identify the observations marked in the orange square in the upper left corner. Your answer should be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nb. In a single pipeline, identify the observations marked in the red square in the plot above. Your answer should again be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nc. Bring your answers from part (a) and part (b) together! In a single pipeline, and a single filter() statement, identify the observations marked in the red and orange square in the plot above. Your answer should again be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nd. Create a new variable in midwest called potential_outlier. This variable should take on the value:\n\nYes if the point is one the ones you identified in part (c), i.e., one of the points marked in the squares in the plot above.\nNo otherwise.\n\nThen, display the updated midwest data frame, with county, state, percentage below poverty, percentage college educated, potential_outlier as the selected variables, arranged in descending order of potential_outlier.\ne. Recreate the visualization above, i.e., a scatterplot of the percentage below poverty vs. the percentage of people with a college degree. However, color the points by the newly created potential_outlier variable instead of the state.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 8”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 9\na. In a single pipeline, calculate the total population for each state and save the resulting data frame as state_population. Then, display the data frame, state_population, in descending order of total population.\nb. Then, in a separate pipeline, calculate the proportion of the total population in each state. Once again, display the results in descending order of proportion of population.\n\n\n\n\n\n\nTip\n\n\n\nIn answering parts (a) and (b), you’ll create two new variables, one for the total population and the other for the proportion of total proportion. Make sure to give them “reasonable” names – short but evocative.\n\n\nc. Which Midwestern state is most populous, and what percent of the Midwest population lives there? Which is the least populous and what percent lives there?\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 9”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 10\nCalculate the average percentage below poverty for each state and save the resulting data frame as state_poverty with the columns state and mean_percbelowpoverty.\nThen, in a new pipeline, display the state_poverty data frame in ascending order of mean_percbelowpoverty. Which state has the lowest average percentage below poverty across its counties? Which state has the highest average percentage below poverty across its counties?\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 10”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward."
  },
  {
    "objectID": "lab/lab-2.html#submission",
    "href": "lab/lab-2.html#submission",
    "title": "Lab 2",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nTo be considered ” on time, ” you must turn in a PDF file to the Gradescope page by the submission deadline.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with each question. All the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope"
  },
  {
    "objectID": "lab/lab-2.html#grading-and-feedback",
    "href": "lab/lab-2.html#grading-and-feedback",
    "title": "Lab 2",
    "section": "Grading and feedback",
    "text": "Grading and feedback\n\nSome of the questions will be graded for accuracy.\nSome will be graded for completion.\nThere are also workflow points, for coding style, for committing at least three times as you work through your lab, and for overall organization.\nYou’ll receive feedback on your lab on Gradescope within a week."
  },
  {
    "objectID": "lab/lab-2.html#footnotes",
    "href": "lab/lab-2.html#footnotes",
    "title": "Lab 2",
    "section": "Footnotes",
    "text": "Footnotes\n\nRemember, haikus, not novellas, when writing code!↩︎"
  },
  {
    "objectID": "lab/lab-0.html",
    "href": "lab/lab-0.html",
    "title": "Lab 0",
    "section": "",
    "text": "This lab will set you up for the computing workflow and give you an opportunity to introduce yourselves to each other and the teaching team."
  },
  {
    "objectID": "lab/lab-0.html#access-r-and-rstudio",
    "href": "lab/lab-0.html#access-r-and-rstudio",
    "title": "Lab 0",
    "section": "Access R and RStudio",
    "text": "Access R and RStudio\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 to log into the Docker container. You should now see the RStudio environment.\n\nGo to https://cmgr.oit.duke.edu/containers and under Reservations available click on reserve STA 198-199 to reserve a container for yourself.\n\n\n\n\n\n\nNote\n\n\n\nA container is a self-contained instance of RStudio for you, and you alone. You will do all of your computing in your container.\n\n\nOnce you’ve reserved the container you’ll see that it will show up under My reservations.\nTo launch your container click on it under My reservations, then click Login, and then Start.1"
  },
  {
    "objectID": "lab/lab-0.html#create-a-github-account",
    "href": "lab/lab-0.html#create-a-github-account",
    "title": "Lab 0",
    "section": "Create a GitHub account",
    "text": "Create a GitHub account\nGo to https://github.com/ and walk through the steps for creating an account. You do not have to use your Duke email address, but I recommend doing so.2\n\n\n\n\n\n\nNote\n\n\n\nYou’ll need to choose a user name. I recommend reviewing the user name advice at https://happygitwithr.com/github-acct#username-advice before choosing a username.\n\n\n\n\n\n\n\n\nWhat if I already have a GitHub account?\n\n\n\n\n\nIf you already have a GitHub account, you do not need to create a new one for this course. Just log in to that account to make sure you still remember your username and password."
  },
  {
    "objectID": "lab/lab-0.html#set-up-your-ssh-key",
    "href": "lab/lab-0.html#set-up-your-ssh-key",
    "title": "Lab 0",
    "section": "Set up your SSH key",
    "text": "Set up your SSH key\nYou will authenticate GitHub using SSH (Secure Shell Protocol – it doesn’t really matter what this means for the purpose of this course). Below is an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nGo back to your RStudio container and type credentials::ssh_setup_github() into your console.\nR will ask “No SSH key found. Generate one now?” You should click 1 for yes.\nYou will generate a key. R will then ask “Would you like to open a browser now?” You should click 1 for yes.\nYou may be asked to provide your GitHub username and password to log into GitHub. After entering this information, you should paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta199).\n\nYou can find more detailed instructions here if you’re interested."
  },
  {
    "objectID": "lab/lab-0.html#configure-git-to-introduce-yourself",
    "href": "lab/lab-0.html#configure-git-to-introduce-yourself",
    "title": "Lab 0",
    "section": "Configure Git to introduce yourself",
    "text": "Configure Git to introduce yourself\nThere is one more thing we need to do before getting started on the assignment. Specifically, we need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\n\n\n\n\n\n\nNote\n\n\n\nYou’ll hear about 📦 packages a lot in the context of R – basically they’re how developers write functions and bundle them to distribute to the community (and more on this later too!).\n\n\nType the following lines of code in the console in RStudio filling in your name and the address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\"\n)\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"Mine Çetinkaya-Rundel\", \n  user.email = \"cetinkaya.mine@gmail.com\"\n)\n\n\n\n\n\n\n\nNote\n\n\n\nI used my gmail because that is the one I used to create my GitHub account. You should also be using the email address you used to create your GitHub account, it’s ok if it isn’t your Duke email.\n\n\nYou are now ready interact with GitHub via RStudio!\nIf you don’t do this, we won’t be able to tell who you are and give you points for the work you do…\n\n\n\n\n\n\nNote\n\n\n\nWell, a more accurate statement would be that we will be reaching out to you to get things right during the first few weeks of classes. But, it’s best if you can get it right today!\n\n\n\n\n\n\n\n\nNeed a recap? Watch this video!\n\n\n\n\n\nThe following video walks you through the steps outlined in the SSH key generation and Git configuration sections above."
  },
  {
    "objectID": "lab/lab-0.html#footnotes",
    "href": "lab/lab-0.html#footnotes",
    "title": "Lab 0",
    "section": "Footnotes",
    "text": "Footnotes\n\nYes, it’s too many steps. I don’t know why! But it works, and you’ll get used to it. Trust me, it beats downloading and installing everything you need on your computers!↩︎\nGitHub has some perks for students you can take advantage of later in the course or in your future work, and it helps to have a .edu address to get verified as a student.↩︎"
  },
  {
    "objectID": "lab/lab-5.html",
    "href": "lab/lab-5.html",
    "title": "Lab 5",
    "section": "",
    "text": "In this lab you’ll start your practice of statistical modeling. You’ll fit models, interpret model output, and make decisions about your data and research question based on the model results. And you’ll wrap up the lab revisiting the topic of data science ethics.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nFit linear regression models and interpret model coefficients in context of the data and research question.\nTransform data using a log-transformation for a better model fit.\nEvaluate the validity of a data visualization and correct any misleading mistakes.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-5 repo from GitHub, open your lab-5.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-5. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-5.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-5.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\ntidymodels package for modeling in a “tidy” way, and\n\nopenintro package for the dataset for Part 1.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-5.html#learning-objectives",
    "href": "lab/lab-5.html#learning-objectives",
    "title": "Lab 5",
    "section": "",
    "text": "By the end of the lab, you will…\n\nFit linear regression models and interpret model coefficients in context of the data and research question.\nTransform data using a log-transformation for a better model fit.\nEvaluate the validity of a data visualization and correct any misleading mistakes.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub"
  },
  {
    "objectID": "lab/lab-5.html#getting-started",
    "href": "lab/lab-5.html#getting-started",
    "title": "Lab 5",
    "section": "",
    "text": "Log in to RStudio, clone your lab-5 repo from GitHub, open your lab-5.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-5. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-5.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-5.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding."
  },
  {
    "objectID": "lab/lab-5.html#packages",
    "href": "lab/lab-5.html#packages",
    "title": "Lab 5",
    "section": "",
    "text": "In this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\ntidymodels package for modeling in a “tidy” way, and\n\nopenintro package for the dataset for Part 1.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document."
  },
  {
    "objectID": "lab/lab-5.html#guidelines",
    "href": "lab/lab-5.html#guidelines",
    "title": "Lab 5",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-5.html#question-1",
    "href": "lab/lab-5.html#question-1",
    "title": "Lab 5",
    "section": "Question 1",
    "text": "Question 1\nWe are interested in the impact of smoking during pregnancy. Since it is not possible to run a randomized controlled experiment to investigate this impact, we will instead use a data set has been of interest to medical researchers who are studying the relation between habits and practices of expectant mothers and the birth of their children. This is a random sample of 1,000 cases from a data set released in 2014 by the state of North Carolina. The data set is called births14, and it is included in the openintro package you loaded at the beginning of the assignment.\n\nCreate a version of the births14 data set dropping observations where there are NAs for habit. You can call this version births14_habitgiven.\nPlotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions. Create an appropriate plot displaying the relationship between weight and habit. In 2-3 sentences, discuss the relationship observed."
  },
  {
    "objectID": "lab/lab-5.html#question-2",
    "href": "lab/lab-5.html#question-2",
    "title": "Lab 5",
    "section": "Question 2",
    "text": "Question 2\n\nFit a linear model that predicts weight from habit and save the model object. Then, provide the tidy summary output.\nWrite the estimated least squares regression line below using proper notation.\n\n\n\n\n\n\n\nTip\n\n\n\nIf you need to type an equation using proper notation, type your answers in-between $$ and $$. You may use \\hat{example} to put a hat on a character.\n\n\n\nInterpret the intercept in the context of the data and the research question. Is the intercept meaningful in this context? Why or why not?\nInterpret the slope in the context of the data and the research question."
  },
  {
    "objectID": "lab/lab-5.html#question-3",
    "href": "lab/lab-5.html#question-3",
    "title": "Lab 5",
    "section": "Question 3",
    "text": "Question 3\n\nAnother researcher is interested in assessing the relationship between babies’ weights and mothers’ ages. Fit another linear model predicting weight to investigate this relationship and save the model object. Then, provide the tidy summary output.\nIn 2-3 sentences, explain how the regression line to model these data is fit, i.e., based on what criteria R determines the regression line.\nInterpret the intercept in the context of the data and the research question. Is the intercept meaningful in this context? Why or why not?\nInterpret the slope in the context of the data and the research question."
  },
  {
    "objectID": "lab/lab-5.html#question-4",
    "href": "lab/lab-5.html#question-4",
    "title": "Lab 5",
    "section": "Question 4",
    "text": "Question 4\nLet’s start by reading in the parasites data and examining the relationship between divergence_time and parsim.\n\nLoad the data and save the data frame as parasites.\nBased on the goals of the analysis, what is the response variable?\nVisualize the relationship between the two variables.\nUse the visualization to describe the relationship between the two variables."
  },
  {
    "objectID": "lab/lab-5.html#question-5",
    "href": "lab/lab-5.html#question-5",
    "title": "Lab 5",
    "section": "Question 5",
    "text": "Question 5\nNext, model this relationship.\n\nFit the model and write the estimated regression equation.\nInterpret the slope and the intercept in the context of the data.\nRecreate the visualization from Question 4, this time adding a regression line to the visualization.\nWhat do you notice about the prediction (regression) line that may be strange, particularly for very large divergence times?"
  },
  {
    "objectID": "lab/lab-5.html#question-6",
    "href": "lab/lab-5.html#question-6",
    "title": "Lab 5",
    "section": "Question 6",
    "text": "Question 6\nSince parsim takes values between 0 and 1, we want to transform this variable so that it can range between (−∞,+∞). This will be better suited for fitting a regression model (and interpreting predicted values!)\n\n\nUsing mutate, create a new variable transformed_parsim that is calculated as log(parsim/(1-parsim)). Add this variable to your data frame.\n\n\n\n\n\n\nNote\n\n\n\nlog() in R represents the nautral log.\n\n\n\nThen, visualize the relationship between divergence_time and transformed_parsim. Add a regression line to your visualization.\nWrite a 1-2 sentence description of what you observe in the visualization."
  },
  {
    "objectID": "lab/lab-5.html#question-7",
    "href": "lab/lab-5.html#question-7",
    "title": "Lab 5",
    "section": "Question 7",
    "text": "Question 7\nWhich variable is the strongest individual predictor of parasite similarity between species?\nTo answer this question, begin by fitting a linear regression model to each pair of variables. Do not report the model outputs in a tidy format but save each one as dt_model, dist_model, BM_model, and prec_model, respectively.\n\ndivergence_time and transformed_parsim\ndistance and transformed_parsim\nBMdiff and transformed_parsim\nprecdiff and transformed_parsim\n\n\nReport the slopes for each of these models. Use proper notation.\nTo answer the question of interest, would it be useful to compare the slopes in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?"
  },
  {
    "objectID": "lab/lab-5.html#question-8",
    "href": "lab/lab-5.html#question-8",
    "title": "Lab 5",
    "section": "Question 8",
    "text": "Question 8\nNow, what if we calculated \\(R^2\\) to help answer our question? To compare the explanatory power of each individual predictor, we will look at \\(R^2\\) between the models. \\(R^2\\) is a measure of how much of the variability in the response variable is explained by the model.\nAs you may have guessed from the name \\(R^2\\) can be calculated by squaring the correlation when we have a simple linear regression model. The correlation r takes values -1 to 1, therefore, \\(R^2\\) takes values 0 to 1. Intuitively, if r=1 or −1, then \\(R^2\\)=1, indicating the model is a perfect fit for the data. If r≈0 then \\(R^2\\)≈0, indicating the model is a very bad fit for the data.\nYou can calculate \\(R^2\\) using the glance function. For example, you can calculate \\(R^2\\) for dt_model using the code glance(dt_model)$r.squared.\n\nCalculate and report \\(R^2\\) for each model fit in the previous exercise.\nTo answer our question of interest, would it be useful to compare the \\(R^2\\) in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?"
  },
  {
    "objectID": "lab/lab-5.html#question-9",
    "href": "lab/lab-5.html#question-9",
    "title": "Lab 5",
    "section": "Question 9",
    "text": "Question 9\nThe following chart was shared by @GraphCrimes on X/Twitter on September 3, 2022.\n\n\n\n\n\nWhat is misleading about this graph?\nSuppose you wanted to recreate this plot, with improvements to avoid its misleading pitfalls from part (a). You would obviously need the data from the survey in order to be able to do that. How many observations would this data have? How many variables (at least) should it have, and what should those variables be?\nLoad the data for this survey from data/survation.csv. Confirm that the data match the percentages from the visualization. That is, calculate the percentages of public sector, private sector, don’t know for each of the services and check that they match the percentages from the plot."
  },
  {
    "objectID": "lab/lab-5.html#question-10",
    "href": "lab/lab-5.html#question-10",
    "title": "Lab 5",
    "section": "Question 10",
    "text": "Question 10\nCreate an improved version of the visualization. Your improved visualization:\n\nshould also be a stacked bar chart with services on the y-axis and presented in the same order as the original plot; sectors should create segments of the plot using the same colors (colors do not have to be exact) and appear in the same order as the original plot\nshould have the same legend location\nshould have the same title and caption\ndoes not need to have a bolded title or a gray background\n\nHow does the improved visualization look different than the original? Does it send a different message at a first glance?\n\n\n\n\n\n\nTip\n\n\n\nUse \\n to add a line break to your title. And note that since the title is very long, it might run off the page in your code. That’s ok!\nAdditionally, the colors used in the plot are gray, #FF3205, and #006697.\n\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "lab/lab-7.html",
    "href": "lab/lab-7.html",
    "title": "Lab 7",
    "section": "",
    "text": "In this lab you’ll start your practice of statistical modeling. You’ll fit models for classification, interpret model output, and make decisions about your data and research question based on the model results. And you’ll wrap up the lab sharing a statistics and/or data science experience.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nFit and interpret logistic regression models\nUnderstand the difference between odds, log odds, and probability of an event\nMake classification based on predicted probability of an event\nSee statistics and/or data science in action in the real world\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-7 repo from GitHub, open your lab-7.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-7. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-7.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-7.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\ntidymodels package for modeling in a “tidy” way, and\n\nopenintro package for the dataset for Part 1. TO DO: Check.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-7.html#learning-objectives",
    "href": "lab/lab-7.html#learning-objectives",
    "title": "Lab 7",
    "section": "",
    "text": "By the end of the lab, you will…\n\nFit and interpret logistic regression models\nUnderstand the difference between odds, log odds, and probability of an event\nMake classification based on predicted probability of an event\nSee statistics and/or data science in action in the real world\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub"
  },
  {
    "objectID": "lab/lab-7.html#getting-started",
    "href": "lab/lab-7.html#getting-started",
    "title": "Lab 7",
    "section": "",
    "text": "Log in to RStudio, clone your lab-7 repo from GitHub, open your lab-7.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-f24 organization on GitHub. Click on the repo with the prefix lab-7. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-7.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-7.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding."
  },
  {
    "objectID": "lab/lab-7.html#packages",
    "href": "lab/lab-7.html#packages",
    "title": "Lab 7",
    "section": "",
    "text": "In this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\ntidymodels package for modeling in a “tidy” way, and\n\nopenintro package for the dataset for Part 1. TO DO: Check.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document."
  },
  {
    "objectID": "lab/lab-7.html#guidelines",
    "href": "lab/lab-7.html#guidelines",
    "title": "Lab 7",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-7.html#question-1",
    "href": "lab/lab-7.html#question-1",
    "title": "Lab 7",
    "section": "Question 1",
    "text": "Question 1\n\nWhat type of variable is spam? What percent of the emails are spam?\nWhat type of variable is dollar - number of times a dollar sign or the word “dollar” appeared in the email? Visualize and describe its distribution, supporting your description with the appropriate summary statistics.\nFit a logistic regression model predicting spam from dollar. Then, display the tidy output of the model.\n\nUsing this model and the predict() function, predict the probability the email is spam if it contains 5 dollar signs. Based on this probability, how does the model classify this email?\n\n\n\n\n\n\nNote\n\n\n\nTo obtain the predicted probability, you can set the type argument in predict() to \"prob\"."
  },
  {
    "objectID": "lab/lab-7.html#question-2",
    "href": "lab/lab-7.html#question-2",
    "title": "Lab 7",
    "section": "Question 2",
    "text": "Question 2\n\nFit another logistic regression model predicting spam from dollar, winner (indicating whether “winner” appeared in the email), and urgent_subj (whether the word “urgent” is in the subject of the email). Then, display the tidy output of the model.\nUsing this model and the augment() function, classify each email in the email dataset as spam or not spam. Store the resulting data frame with an appropriate name and display the data frame as well.\n\nUsing your data frame from the previous part, determine, in a single pipeline, and using count(), the numbers of emails:\n\nthat are labelled as spam that are actually spam\nthat are not labelled as spam that are actually spam\nthat are labelled as spam that are actually not spam\nthat are not labelled as spam that are actually not spam\n\nStore the resulting data frame with an appropriate name and display the data frame as well.\n\nIn a single pipeline, and using mutate(), calculate the false positive and false negative rates. In addition to these numbers showing in your R output, you must write a sentence that explicitly states and identified the two rates."
  },
  {
    "objectID": "lab/lab-7.html#question-3",
    "href": "lab/lab-7.html#question-3",
    "title": "Lab 7",
    "section": "Question 3",
    "text": "Question 3\n\nFit another logistic regression model predicting spam from dollar and another variable you think would be a good predictor. Provide a 1-sentence justification for why you chose this variable. Display the tidy output of the model.\nUsing this model and the augment() function, classify each email in the email dataset as spam or not spam. Store the resulting data frame with an appropriate name and display the data frame as well.\n\nUsing your data frame from the previous part, determine, in a single pipeline, and using count(), the numbers of emails:\n\nthat are labelled as spam that are actually spam\nthat are not labelled as spam that are actually spam\nthat are labelled as spam that are actually not spam\nthat are not labelled as spam that are actually not spam\n\nStore the resulting data frame with an appropriate name and display the data frame as well.\n\nIn a single pipeline, and using mutate(), calculate the false positive and false negative rates. In addition to these numbers showing in your R output, you must write a sentence that explicitly states and identified the two rates.\nBased on the false positive and false negatives rates of this model, comment, in 1-2 sentences, on which model (one from Question 2 or Question 3) is preferable and why."
  },
  {
    "objectID": "lab/lab-7.html#question-4",
    "href": "lab/lab-7.html#question-4",
    "title": "Lab 7",
    "section": "Question 4",
    "text": "Question 4\nThe dataset, called hotels.csv, can be found in the data folder.\n\nRead it in with read_csv().\nTransform the is_canceled variable to be a factor with “not canceled” (0) as the first level and “canceled” (1) as the second level.\nExplore attributes of bookings and summarize your findings in 5 bullet points. You must provide a visualization or summary supporting each finding.\n\n\n\n\n\n\n\nNote\n\n\n\nThis is not meant to be an exhaustive exploration. We anticipate a wide variety of answers to this question."
  },
  {
    "objectID": "lab/lab-7.html#question-5",
    "href": "lab/lab-7.html#question-5",
    "title": "Lab 7",
    "section": "Question 5",
    "text": "Question 5\nUsing these data, one of our goals is to explore the following question:\n\nAre reservations earlier in the month or later in the month more likely to be cancelled?\n\n\nIn a single pipeline, calculate the mean arrival dates (arrival_date_day_of_month) for reservations that were cancelled and reservations that were not cancelled.\nIn your own words, explain why we can not use a linear model to model the relationship between if a hotel reservation was cancelled and the day of month for the booking.\nFit the appropriate model to predict whether a reservation was cancelled from arrival_date_day_of_month and display a tidy summary of the model output. Then, interpret the slope coefficient in context of the data and the research question.\nCalculate the probability that the hotel reservation is cancelled if it the arrival date date is on the 26th of the month. Based on this probability, would you predict this booking would be cancelled or not cancelled. Explain your reasoning for your classification."
  },
  {
    "objectID": "lab/lab-7.html#question-6",
    "href": "lab/lab-7.html#question-6",
    "title": "Lab 7",
    "section": "Question 6",
    "text": "Question 6\n\nFit another model to predict whether a reservation was cancelled from arrival_date_day_of_month and hotel type (Resort or City Hotel), allowing the relationship between arrival_date_day_of_month and is_canceled to vary based on hotel type. Display a tidy output of the model.\nInterpret the intercept in context of the data."
  },
  {
    "objectID": "lab/lab-7.html#question-7",
    "href": "lab/lab-7.html#question-7",
    "title": "Lab 7",
    "section": "Question 7",
    "text": "Question 7\n\nRead in the gss22.csv file that is in your data folder and save it as gss22. Report its number of rows and columns.\nCreate a new data frame called gss22_advfront that only contains the variables advfront, educ, and polviews. Then, use the drop_na() function to remove rows that contain NAs from this new data frame. Report the number of rows and columns of gss22_advfront. Additionally, report what percent of the observations were discarded at this step.\nRe-level the advfront variable such that it has two levels: \"Strongly agree\" and \"Agree\" combined into a new level called Agree and the remaining levels combined into”Not agree\". Then, re-order the levels in the following order: \"Agree\" and \"Not agree\". Finally, count() how many times each new level appears in the advfront variable.\n\n\n\n\n\n\n\nTip\n\n\n\nYou can do this in various ways. One option is to use the str_detect() function to detect the existence of words. Note that these sometimes show up with lowercase first letters and sometimes with upper case first letters. To detect either in the str_detect() function, you can use “[Aa]gree”. However, solve the problem however you like, this is just one option!\n\n\n\nCombine the levels of the polviews variable such that levels that have the word “liberal” in them are lumped into a level called \"Liberal\" and those that have the word conservative in them are lumped into a level called \"Conservative\". Then, re-order the levels in the following order: \"Conservative\" , \"Moderate\", and \"Liberal\". Finally, count() how many times each new level appears in the polviews variable."
  },
  {
    "objectID": "lab/lab-7.html#question-8",
    "href": "lab/lab-7.html#question-8",
    "title": "Lab 7",
    "section": "Question 8",
    "text": "Question 8\n\nFit a logistic regression model that predicts advfront from educ. Report the tidy output of the model.\nWrite out the estimated model in proper notation.\nUsing your estimated model, predict the probability of agreeing with the statement “Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.” (Agree in advfront) for someone with 7 years of education."
  },
  {
    "objectID": "lab/lab-7.html#question-9",
    "href": "lab/lab-7.html#question-9",
    "title": "Lab 7",
    "section": "Question 9",
    "text": "Question 9\n\nFit a new model that adds the additional explanatory variable of polviews to your model from Question 8. Report the tidy output of the model.\nNow, predict the probability of agreeing with the following statement “Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.” (Agree in advfront) for a Conservative person with 7 years of education."
  },
  {
    "objectID": "lab/lab-7.html#question-10",
    "href": "lab/lab-7.html#question-10",
    "title": "Lab 7",
    "section": "Question 10",
    "text": "Question 10\n\n\n\n\n\n\nWarning\n\n\n\nStart this question early, it’s not one you want to try to cram into the last night before the deadline!\n\n\nYou have two options for this exercise. Clearly indicate which option you choose. Then, summarize your experience in no more than 10 bullet points.\nInclude the following on your summary:\n\nName and brief description of what you did.\nSomething you found new, interesting, or unexpected\nHow the talk/podcast/interview/etc. connects to something we’ve done in class.\nCitation or link to web page for what you watched or who you interviewed.\n\nOption 1: Listen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nposit::conf 2024 talks\n\nuseR 2024 talks or user 2024 keynotes\n\nposit::conf 2023 talks\nrstudio::conf 2022 talks\nHarvard Data Science Review Podcast\nStats + Stories Podcast\nCasual Inference Podcast\nNot So Standard Deviations\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask your professor if you are unsure whether a particular podcast or video will count towards the statistics experience.\nOption 2: Talk with someone who uses statistics and/or data science in their daily work. This could include a professor, professional in industry, graduate student, etc."
  },
  {
    "objectID": "lab/lab-7.html#footnotes",
    "href": "lab/lab-7.html#footnotes",
    "title": "Lab 7",
    "section": "Footnotes",
    "text": "Footnotes\n\nSmith, Tom W, Peter Marsden, Michael Hout, and Jibum Kim. General Social Surveys, 1972-2016 [machine-readable data file] /Principal Investigator, Tom W. Smith; Co-Principal Investigator, Peter V. Marsden; Co-Principal Investigator, Michael Hout; Sponsored by National Science Foundation. -NORC ed.- Chicago: NORC at the University of Chicago [producer and distributor]. Data come from the gssr R Package, http://kjhealy.github.io/gssr.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 199: Introduction to Data Science and Statistical Thinking",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses and the timeline of topics and assignments might be updated throughout the semester.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWEEK\nDATE\nPREPARE\nTOPIC\nMATERIALS\nDUE\n\n\n\n1\nMon, Aug 26\n\nLab 0: Hello, World and STA 199!\n💻 lab 0\nLab 0 due at the end of lab session\n\n\n\nTue, Aug 27\n\nWelcome to STA 199\n🖥️ slides 00  🗒️ notes 00  ⌨️ ae 00\n\n\n\n\nThu, Aug 29\n📗 r4ds - intro  📘 ims - chp 1  🎥 Meet the toolkit :: R and RStudio  🎥 Meet the toolkit :: Quarto  🎥 Code along :: First data viz with UN Votes\nMeet the toolkit\n🖥️ slides 01  🗒️ notes 01  ⌨️ ae 01\n\n\n\n2\nMon, Sep 2\n\nNo lab - Labor Day\n\n\n\n\n\nTue, Sep 3\n📗 r4ds - chp 1  📘 ims - chp 4  🎥 Visualizing data  🎥 Building a plot step-by-step with ggplot2  🎥 Grammar of graphics  🎥 Code along :: First look at Palmer Penguins\nGrammar of data visualization\n🖥️ slides 02  🗒️ notes 02  ⌨️ ae 02  ✅ ae 02\n\n\n\n\nThu, Sep 5\n📗 r4ds - chp 2  📗 r4ds - chp 3.1-3.5  🎥 Grammar of data transformation  🎥 Code along :: Flights and pipes\nGrammar of data transformation\n🖥️ slides 03  🗒️ notes 03  ⌨️ ae 03  ✅ ae 03\n\n\n\n3\nMon, Sep 9\n\nLab 1: From the Midwest to North Carolina\n💻 lab 1  ✅ lab 1\n\n\n\n\nTue, Sep 10\n📗 r4ds - chp 3.6-3.7  🎥 Visualizing and summarizing categorical data  🎥 Visualizing and summarizing numerical data  🎥 Visualizing and summarizing relationships  🎥 Code along :: Star Wars characters\nExploring data I\n🖥️ slides 04  🗒️ notes 04  ⌨️ ae 04  ✅ ae 04\n\n\n\n\nThu, Sep 12\n📘 ims - chp 5  📘 ims - chp 6  🎥 Code along :: Diving deeper with Palmer Penguins\nExploring data II\n🖥️ slides 05  🗒️ notes 05  ⌨️ ae 05  ✅ ae 05\n\n\n\n4\nMon, Sep 16\n📗 r4ds - chp 4\nLab 2: Revisiting the Midwest\n💻 lab 2\nLab 1 at 8:30 am\n\n\n\nTue, Sep 17\n🎥 Tidy data  🎥 Tidying data  🎥 Code along :: Country populations over time  📗 r4ds - chp 5\nTidying data\n🖥️ slides 06  🗒️ notes 06  ⌨️ ae 06  ✅ ae 06\n\n\n\n\nThu, Sep 19\n🎥 Joining data  🎥 Code along :: Continent populations  📗 r4ds - chp 19.1-19.3\nJoining data\n🖥️ slides 07  🗒️ notes 07  ⌨️ ae 07  ✅ ae 07\n\n\n\n5\nMon, Sep 23\n\nLab 3: Inflation everywhere\n💻 lab 3\nLab 2 at 8:30 am\n\n\n\nTue, Sep 24\n🎥 Data types  🎥 Data classes  🎥 Code along :: That’s my type  📗 r4ds - chp 16\nData types and classes\n🖥️ slides 08  🗒️ notes 08  ⌨️ ae 08  ✅ ae 08\n\n\n\n\nThu, Sep 26\n🎥 Importing data  🎥 Code along :: Halving CO2 emissions  🎥 Code along :: Student survey  📗 r4ds - chp 7  📗 r4ds - chp 17.1 - 17.3\nImporting and recoding data\n🖥️ slides 09  🗒️ notes 09  ⌨️ ae 09  ✅ ae 09\n\n\n\n6\nMon, Sep 30\n\nLab 4: Everything so far I\n💻 lab 4\nLab 3 at 8:30 am\n\n\n\nTue, Oct 1\n🎥 Web scraping basics  🎥 Code along :: Scraping an eCommerce page  🎥 Code along :: Scraping many eCommerce pages  🎥 Web scraping considerations  📗 r4ds - chp 24.1 - 24.6  📗 r4ds - chp 25.1 - 25.2\nWeb scraping\n🖥️ slides 10  🗒️ notes 10  ⌨️ ae 10  ⌨️ ae 10  ✅ ae 10\n\n\n\n\nThu, Oct 3\n\nMidterm review\n🖥️ slides 11  🗒️ notes 11  📝 midterm review  ✅ midterm review\n\n\n\n7\nMon, Oct 7\n📝 Merge conflicts\nProject milestone 1 - Working collaboratively\n📓 project milestone 1\nLab 4 due at 8:30 am  Project milestone 1 at the end of lab session\n\n\n\nTue, Oct 8\n\nMidterm - In-class + take-home released\n\n\n\n\n\nThu, Oct 10\n\nWorking with generative AI tools\n🖥️ slides 12  🗒️ notes 12  ⌨️ ae 11\nMidterm course evaluation due midnight (optional)\n\n\n\nFri, Oct 11\n\n\n\nMidterm take-home due at 5:00 pm\n\n\n8\nMon, Oct 14\n\nNo lab - Fall Break\n\n\n\n\n\nTue, Oct 15\n\nNo lecture - Fall Break\n\n\n\n\n\nThu, Oct 17\n📕 mdsr - chp 8  📝 How to make a racist AI in R without really trying  🎥 Alberto Cairo - How charts lie  🎥 Joy Buolamwini - How I’m fighting bias in algorithms\nData science ethics\n🖥️ slides 13  🗒️ notes 13\n\n\n\n\nFri, Oct 18\n\n\n\nPeer evaluation 1 due by 5:00 pm\n\n\n9\nMon, Oct 21\n📝 Project description  📝 Tidyverse style guide - Chp 1-5\nProject milestone 2 - Project proposals\n📓 project milestone 2\n\n\n\n\nTue, Oct 22\n🎥 The language of models  📘 ims - chp 7.1\nThe language of models\n🖥️ slides 14  🗒️ notes 14  ⌨️ ae 12  ✅ ae 12\n\n\n\n\nThu, Oct 24\n🎥 Fitting and interpreting models  🎥 Modeling nonlinear relationships  📘 ims - chp 7.2\nLinear regression with a single predictor\n🖥️ slides 15  🗒️ notes 15  ⌨️ ae 13  ✅ ae 13\n\n\n\n10\nMon, Oct 28\n\nLab 5: Visualize, model, interpret\n💻 lab 5\nProject milestone 2 at 8:30 am\n\n\n\nTue, Oct 29\n🎥 Models with multiple predictors  🎥 More models with multiple predictors  📘 ims - chp 8.1-8.2\nLinear regression with multiple predictors I\n🖥️ slides 16  🗒️ notes 16  ⌨️ ae 14  ✅ ae 14\n\n\n\n\nThu, Oct 31\n📘 ims - chp 8.3-8.5\nLinear regression with multiple predictors II\n🖥️ slides 17  🗒️ notes 17  ⌨️ ae 15\n\n\n\n\nFri, Nov 1\n\n\n\nPeer evaluation 2 due by 5:00 pm\n\n\n11\nMon, Nov 4\n\nLab 6: Visualize, model, interpret again\n💻 lab 6\nLab 5 at 8:30 am\n\n\n\nTue, Nov 5\n🎥 Logistic regression\nModel selection and overfitting\n🖥️ slides 18  🗒️ notes 18  ⌨️ ae 15 - Continue  ✅ ae 15\n\n\n\n\nThu, Nov 7\n📘 ims - chp 9\nLogistic regression\n🖥️ slides 19  🗒️ notes 19  ⌨️ ae 16  ✅ ae 16\n\n\n\n12\nMon, Nov 11\n\nLab 7: Explore and classify\n💻 lab 7\nLab 6 at 8:30 am\n\n\n\nTue, Nov 12\n🎥 Prediction and overfitting\nEvaluating models\n🖥️ slides 20  🗒️ notes 20  ⌨️ ae 17  ✅ ae 17\n\n\n\n\nThu, Nov 14\n🎥 Quantifying uncertainty  🎥 Bootstrapping  📘 ims - chp 12\nQuantifying uncertainty with bootstrap intervals\n🖥️ slides 21  🗒️ notes 21\n\n\n\n\nFri, Nov 15\n\n\n\nProject milestone 3 - Improvement and progress at 5:00 pm\n\n\n13\nMon, Nov 18\n\nLab 8: Everything so far II\n💻 lab 8\nLab 7 at 8:30 am\n\n\n\nTue, Nov 19\n📘 ims - chp 11\nMaking decisions with randomization tests\n🖥️ slides 22  🗒️ notes 22  ⌨️ ae 18\n\n\n\n\nThu, Nov 21\n\nInference overview\nTo be posted\n\n\n\n\nFri, Nov 22\n\n\n\nPeer evaluation 3 due by 5:00 pm\n\n\n14\nMon, Nov 25\nTo be posted\nProject milestone 4 - Peer review\n📓 project milestone 4\nProject milestone 4 at the end of lab session\n\n\n\nTue, Nov 26\nTo be posted\nCommunicating data science results effectively  Customizing Quarto reports and presentations\n\nLab 8 at 10:30 pm\n\n\n\nThu, Nov 28\nTo be posted\nNo lecture - Thanksgiving\n\n\n\n\n15\nMon, Dec 2\nTo be posted\nProject milestone 5 - Work on writeup and presentations\n📓 project milestone 5\n\n\n\n\nTue, Dec 3\nTo be posted\nLooking further: Interactive web applications with Shiny\nTo be posted\n\n\n\n\nThu, Dec 5\nTo be posted\nFinal review\n📝 final review  ✅ final review\nProject milestone 5 - Writeup and presentation videos by 5:00 pm\n\n\n\nFri, Dec 6\nTo be posted\n\n\nPeer evaluation 4 due by 5:00 pm\n\n\n16\nThu, Dec 12\nTo be posted\nFinal (9 am - 12 pm)",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "ae/ae-01-meet-the-penguins.html",
    "href": "ae/ae-01-meet-the-penguins.html",
    "title": "AE 01: Meet the penguins",
    "section": "",
    "text": "For this application exercise, we’ll use the tidyverse and palmerpenguins packages.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\nThe dataset we will visualize is called penguins. Let’s glimpse() at it.\n\n\nYour turn: Replace #add code here with the code for “glimpse”ing at the data penguins data frame – glimpse(penguins). Render the document and view the output.\n\n\n# add code here\n\n\n\nDemo: First, replace the blank below with the number of rows in the penguins data frame based on the output of the chunk below. Then, replace it with “inline code” and render again.\n\n\nnrow(penguins)\n\n[1] 344\n\n\nThere are ___ penguins in the penguins data frame."
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap-A.html",
    "href": "ae/ae-18-duke-forest-bootstrap-A.html",
    "title": "AE 18: Houses in Duke Forest",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this application exercise, we will use bootstrapping to construct confidence intervals."
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap-A.html#packages",
    "href": "ae/ae-18-duke-forest-bootstrap-A.html#packages",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Packages",
    "text": "Packages\nWe will use tidyverse and tidymodels for data exploration and modeling, respectively, and the openintro package for the data, and the knitr package for formatting tables.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap-A.html#data",
    "href": "ae/ae-18-duke-forest-bootstrap-A.html#data",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…"
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap-A.html#model",
    "href": "ae/ae-18-duke-forest-bootstrap-A.html#model",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap-A.html#bootstrap-confidence-interval",
    "href": "ae/ae-18-duke-forest-bootstrap-A.html#bootstrap-confidence-interval",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Bootstrap confidence interval",
    "text": "Bootstrap confidence interval\n1. Calculate the observed fit (slope)\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159.\n\n\n2. Take n bootstrap samples and fit models to each one.\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(20241115)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = n, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept  149083.\n 2         1 area          143.\n 3         2 intercept  226037.\n 4         2 area          110.\n 5         3 intercept   37464.\n 6         3 area          188.\n 7         4 intercept    7631.\n 8         4 area          208.\n 9         5 intercept  245406.\n10         5 area          104.\n# ℹ 190 more rows\n\n\n\nWhy do we set a seed before taking the bootstrap samples?\nMake a histogram of the bootstrap samples to visualize the bootstrap distribution.\n\n\nboot_fits |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n3. Compute the 95% confidence interval as the middle 95% of the bootstrap distribution\nFill in the code, then set eval: true .\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          79.9     207.\n2 intercept  -3694.   316939."
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap-A.html#changing-confidence-level",
    "href": "ae/ae-18-duke-forest-bootstrap-A.html#changing-confidence-level",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Changing confidence level",
    "text": "Changing confidence level\nModify the code from Step 3 to create a 90% confidence interval.\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.90,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          94.7     203.\n2 intercept   8234.   284161.\n\n\nModify the code from Step 3 to create a 99% confidence interval.\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.99,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          64.2     211.\n2 intercept -19831.   370166.\n\n\n\nWhich confidence level produces the most accurate confidence interval (90%, 95%, 99%)? Explain\nWhich confidence level produces the most precise confidence interval (90%, 95%, 99%)? Explain\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "ae/ae-09-age-gaps-sales-import.html",
    "href": "ae/ae-09-age-gaps-sales-import.html",
    "title": "AE 09: Age gaps + sales + import",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\n\ntidyverse: For data import, wrangling, and visualization.\n\nreadxl: For importing data from Excel.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-09-age-gaps-sales-import.html#getting-started",
    "href": "ae/ae-09-age-gaps-sales-import.html#getting-started",
    "title": "AE 09: Age gaps + sales + import",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\n\ntidyverse: For data import, wrangling, and visualization.\n\nreadxl: For importing data from Excel.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-09-age-gaps-sales-import.html#part-1-hollywood-relationships",
    "href": "ae/ae-09-age-gaps-sales-import.html#part-1-hollywood-relationships",
    "title": "AE 09: Age gaps + sales + import",
    "section": "Part 1: Hollywood relationships",
    "text": "Part 1: Hollywood relationships\nLoad the data from age-gaps.csv in your data and assign it to age_gaps. Confirm that this new object appears in your Environment tab. Click on the name of the object in your Environment tab to pop open the data in the data viewer.\n\n# add code here\n\nCreate a subset of the data frame for heterosexual relationships on screen.\n\n# add code here\n\nSplit the data for heterosexual relationships into three – where woman is older, where man is older, where they are the same age. Save these subsets as two appropriately named data frames. Remember: Use concise and evocative names. Confirm that these new objects appear in your Environment tab and that the sum of the number of observations in the two new data frames add to the number of observations in the original data frame.\n\n# add code here\n\nWrite out the three new datasets you created into the data folder:\n\n# add code here"
  },
  {
    "objectID": "ae/ae-09-age-gaps-sales-import.html#part-2-sales",
    "href": "ae/ae-09-age-gaps-sales-import.html#part-2-sales",
    "title": "AE 09: Age gaps + sales + import",
    "section": "Part 2: Sales",
    "text": "Part 2: Sales\nSales data are stored in an Excel file that looks like the following:\n\nRead in the Excel file called sales.xlsx from the data folder such that it looks like the following.\n\n\n# add code here\n\nStretch goal: Manipulate the sales data such such that it looks like the following.\n\n\n# add code here\n\nWhy should we bother with writing code for reading the data in by skipping columns and assigning variable names as well as cleaning it up in multiple steps instead of opening the Excel file and editing the data in there to prepare it for a clean import?\nAdd response here."
  },
  {
    "objectID": "ae/ae-10-chronicle-scrape-A.html",
    "href": "ae/ae-10-chronicle-scrape-A.html",
    "title": "AE 10: Opinion articles in The Chronicle",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-10-chronicle-scrape-A.html#part-1---data-scraping",
    "href": "ae/ae-10-chronicle-scrape-A.html#part-1---data-scraping",
    "title": "AE 10: Opinion articles in The Chronicle",
    "section": "Part 1 - Data scraping",
    "text": "Part 1 - Data scraping\nSee chronicle-scrape.R for suggested scraping code."
  },
  {
    "objectID": "ae/ae-10-chronicle-scrape-A.html#part-2---data-analysis",
    "href": "ae/ae-10-chronicle-scrape-A.html#part-2---data-analysis",
    "title": "AE 10: Opinion articles in The Chronicle",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet’s start by loading the packages we will need:\n\nlibrary(tidyverse)\n\n\nLoad the data you saved into the data folder and name it chronicle.\n\n\nchronicle &lt;- read_csv(\"data/chronicle.csv\")\n\n\nWho are the most prolific authors of the 500 most recent opinion articles in The Chronicle?\n\n\nchronicle |&gt;\n  count(author, sort = TRUE)\n\n# A tibble: 191 × 2\n   author             n\n   &lt;chr&gt;          &lt;int&gt;\n 1 Luke A. Powery    32\n 2 Advikaa Anand     26\n 3 Heidi Smith       26\n 4 Nik Narain        23\n 5 Monday Monday     20\n 6 Aaron Siegle      15\n 7 Anna Garziera     15\n 8 Sonia Green       12\n 9 Linda Cao         10\n10 Angikar Ghosal     9\n# ℹ 181 more rows\n\n\n\nDraw a line plot of the number of opinion articles published per day in The Chronicle.\n\n\nchronicle |&gt;\n  count(date) |&gt;\n  ggplot(aes(x = date, y = n, group = 1)) +\n  geom_line()\n\n\n\n\n\n\n\n\nWhat percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title?\n\n\nchronicle |&gt;\n  mutate(\n    title = str_to_lower(title),\n    climate = if_else(str_detect(title, \"climate\"), \"mentioned\", \"not mentioned\")\n    ) |&gt;\n  count(climate) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  climate           n  prop\n  &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt;\n1 mentioned        11 0.022\n2 not mentioned   489 0.978\n\n\n\nWhat percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title or abstract?\n\n\nchronicle |&gt;\n  mutate(\n    title = str_to_lower(title),\n    abstract = str_to_lower(abstract),\n    climate = if_else(\n      str_detect(title, \"climate\") | str_detect(abstract, \"climate\"), \n      \"mentioned\", \n      \"not mentioned\"\n      )\n    ) |&gt;\n  count(climate) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  climate           n  prop\n  &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt;\n1 mentioned        16 0.032\n2 not mentioned   484 0.968\n\n\n\nCome up with another question and try to answer it using the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I-A.html",
    "href": "ae/ae-04-gerrymander-explore-I-A.html",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I-A.html#getting-started",
    "href": "ae/ae-04-gerrymander-explore-I-A.html#getting-started",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\n\nData\nThe data are availale in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I-A.html#districts-at-the-tails",
    "href": "ae/ae-04-gerrymander-explore-I-A.html#districts-at-the-tails",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "Districts at the tails",
    "text": "Districts at the tails\nMake side-by-side box plots of percent of vote received by Trump in 2016 Presidential Election by prevalence of gerrymandering. Identify any Congressional Districts that are potential outliers. Are they different from the rest of the Congressional Districts due to high support or low support for Trump in the 2016 Presidential Election? Which state are they in? Which city are they in?\n\nggplot(gerrymander, aes(x = trump16, y = gerry)) +\n  geom_boxplot()\n\n\n\n\n\n\ngerrymander |&gt;\n  filter(gerry == \"low\", trump16 &lt; 10)\n\n# A tibble: 2 × 12\n  district last_name first_name party16 clinton16 trump16 dem16 state party18\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n1 NY-13    Espaillat Adriano    D            92.3     5.4     1 NY    D      \n2 NY-15    Serrano   Jose       D            93.8     4.9     1 NY    D      \n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I-A.html#flips",
    "href": "ae/ae-04-gerrymander-explore-I-A.html#flips",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "Flips",
    "text": "Flips\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics. Hint: Calculate the conditional distribution of prevalance of gerrymandering based on whether a Democrat was able to flip the seat in the 2018 election.\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I-A.html#render-commit-and-push",
    "href": "ae/ae-04-gerrymander-explore-I-A.html#render-commit-and-push",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html",
    "href": "ae/ae-16-spam-filter-A.html",
    "title": "AE 16: Building a spam filter",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this application exercise, we will\nTo illustrate logistic regression, we will build a spam filter from email data.\nThe data come from incoming emails in David Diez’s (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nglimpse(email)\n\nRows: 3,921\nColumns: 21\n$ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         &lt;dttm&gt; 2012-01-01 01:16:41, 2012-01-01 02:03:59, 2012-01-01 11:…\n$ image        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       &lt;dbl&gt; 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ inherit      &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     &lt;dbl&gt; 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     &lt;dbl&gt; 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  &lt;int&gt; 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess &lt;dbl&gt; 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       &lt;fct&gt; big, small, small, small, none, none, big, small, small, …\nThe variables we’ll use in this analysis are\nGoal: Use the number of exclamation points in an email to predict whether or not it is spam."
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html#exercise-1",
    "href": "ae/ae-16-spam-filter-A.html#exercise-1",
    "title": "AE 16: Building a spam filter",
    "section": "Exercise 1",
    "text": "Exercise 1\n\n\nDemo: Fit the logistic regression model using the number of exclamation points to predict the probability an email is spam.\n\n\nlog_fit &lt;- logistic_reg() |&gt;\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(log_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n\n\n\n\nYour turn: How does the code above differ from previous code we’ve used to fit regression models? Compare your summary output to the estimated model below.\n\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2.27 - 0.000272 \\times exclaim\\_mess\\]\nWe use logistic instead of linear regression."
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html#exercise-2",
    "href": "ae/ae-16-spam-filter-A.html#exercise-2",
    "title": "AE 16: Building a spam filter",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhat is the probability the email is spam if it contains 10 exclamation points? Answer the question using the predict() function.\nWe can use the predict function in R to produce the probability as well.\n\nep_10 &lt;- tibble(exclaim_mess = 10)\npredict(log_fit, ep_10, type = \"prob\")\n\n# A tibble: 1 × 2\n  .pred_0 .pred_1\n    &lt;dbl&gt;   &lt;dbl&gt;\n1   0.906  0.0937"
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html#exercise-3",
    "href": "ae/ae-16-spam-filter-A.html#exercise-3",
    "title": "AE 16: Building a spam filter",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe have the probability an email is spam, but ultimately we want to use the probability to classify an email as spam or not spam. Therefore, we need to set a decision-making threshold, such that an email is classified as spam if the predicted probability is greater than the threshold and not spam otherwise.\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check).\nYour turn: What are some trade offs you would consider as you set the decision-making threshold? Discuss with your neighbor.\nAnswers will vary.\n\nlog_aug &lt;- augment(log_fit, email)\n\nggplot(log_aug, aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)"
  },
  {
    "objectID": "ae/ae-16-spam-filter-A.html#exercise-4",
    "href": "ae/ae-16-spam-filter-A.html#exercise-4",
    "title": "AE 16: Building a spam filter",
    "section": "Exercise 4",
    "text": "Exercise 4\nFit a model with all variables in the dataset as predictors and receate the visualization above for this model.\n\nlog_fit2 &lt;- logistic_reg() |&gt;\n  fit(spam ~ ., data = email)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nlog_aug2 &lt;- augment(log_fit2, email)\n\nggplot(log_aug2, aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)\n\n\n\n\n\n\nlog_aug2 |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n       p\n  &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;   &lt;dbl&gt;\n1 0     0            3521 0.991  \n2 0     1              33 0.00929\n3 1     0             299 0.815  \n4 1     1              68 0.185"
  },
  {
    "objectID": "ae/ae-15-modeling-loans.html",
    "href": "ae/ae-15-modeling-loans.html",
    "title": "AE 15: Modelling loan interest rates",
    "section": "",
    "text": "In this application exercise we will be studying loan interest rates. The dataset is one you’ve come across before in your reading – the dataset about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nBefore we use the dataset, we’ll make a few transformations to it.\nAdd response here.\nloans &lt;- loans_full_schema |&gt;\n  mutate(\n    credit_util = total_credit_utilized / total_credit_limit,\n    bankruptcy = as.factor(if_else(public_record_bankrupt == 0, 0, 1)),\n    verified_income = droplevels(verified_income),\n    homeownership = str_to_title(homeownership),\n    homeownership = fct_relevel(homeownership, \"Rent\", \"Mortgage\", \"Own\")\n  ) |&gt;\n  rename(credit_checks = inquiries_last_12m) |&gt;\n  select(\n    interest_rate, loan_amount, verified_income, \n    debt_to_income, credit_util, bankruptcy, term, \n    credit_checks, issue_month, homeownership\n  )\nHere is a glimpse at the data:\nglimpse(loans)\n\nRows: 10,000\nColumns: 10\n$ interest_rate   &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, …\n$ loan_amount     &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 2…\n$ verified_income &lt;fct&gt; Verified, Not Verified, Source Verified, Not Verified,…\n$ debt_to_income  &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, …\n$ credit_util     &lt;dbl&gt; 0.54759517, 0.15003472, 0.66134832, 0.19673228, 0.7549…\n$ bankruptcy      &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, …\n$ term            &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, 60, 60, 36, 60…\n$ credit_checks   &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8, 6, 0, 0, 4, 6, …\n$ issue_month     &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-2018, Mar-2018, Jan-…\n$ homeownership   &lt;fct&gt; Mortgage, Rent, Rent, Rent, Rent, Own, Mortgage, Mortg…"
  },
  {
    "objectID": "ae/ae-15-modeling-loans.html#main-effects-model",
    "href": "ae/ae-15-modeling-loans.html#main-effects-model",
    "title": "AE 15: Modelling loan interest rates",
    "section": "Main effects model",
    "text": "Main effects model\n\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, without an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\n# add code here\n\nAdd response here.\n\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: Add response here.\n\nMortgage: Add response here.\nOwn: Add response here.\n\n\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-15-modeling-loans.html#interaction-effects-model",
    "href": "ae/ae-15-modeling-loans.html#interaction-effects-model",
    "title": "AE 15: Modelling loan interest rates",
    "section": "Interaction effects model",
    "text": "Interaction effects model\n\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, with an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\n# add code here\n\nAdd response here.\n\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: Add response here.\n\nMortgage: Add response here.\nOwn: Add response here.\n\n\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-15-modeling-loans.html#choosing-a-model",
    "href": "ae/ae-15-modeling-loans.html#choosing-a-model",
    "title": "AE 15: Modelling loan interest rates",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\n# add code here\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nAdd response here.\n\n\nQuestion: Based on the adjusted \\(R^2\\)s of these two models, which one do we prefer?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II-A.html",
    "href": "ae/ae-05-gerrymander-explore-II-A.html",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II-A.html#getting-started",
    "href": "ae/ae-05-gerrymander-explore-II-A.html#getting-started",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\nlibrary(ggbeeswarm)\n\nData\nThe data are availale in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II-A.html#congressional-districts-per-state",
    "href": "ae/ae-05-gerrymander-explore-II-A.html#congressional-districts-per-state",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "Congressional districts per state",
    "text": "Congressional districts per state\nWhich state has the most congressional districts? How many congressional districts are there in this state?\n\ngerrymander |&gt;\n  count(state, sort = TRUE)\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 CA       53\n 2 TX       36\n 3 FL       27\n 4 NY       27\n 5 IL       18\n 6 PA       18\n 7 OH       16\n 8 GA       14\n 9 MI       14\n10 NC       13\n# ℹ 40 more rows"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II-A.html#gerrymandering-and-flipping",
    "href": "ae/ae-05-gerrymander-explore-II-A.html#gerrymandering-and-flipping",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "Gerrymandering and flipping",
    "text": "Gerrymandering and flipping\nIs a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering? Support your answer with a visualization and summary statistics.\n\ngerrymander |&gt;\n  mutate(flip18 = as.factor(flip18)) |&gt;\n  ggplot(aes(x = gerry, fill = flip18)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\ngerrymander |&gt;\n  count(gerry, dem18) |&gt;\n  group_by(gerry) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 6 × 4\n# Groups:   gerry [3]\n  gerry dem18     n     p\n  &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1 low       0    25 0.403\n2 low       1    37 0.597\n3 mid       0   131 0.485\n4 mid       1   139 0.515\n5 high      0    52 0.505\n6 high      1    51 0.495"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II-A.html#aesthetic-mappings",
    "href": "ae/ae-05-gerrymander-explore-II-A.html#aesthetic-mappings",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\nRecreate the following visualization, and then improve it.\n\n\nggplot(gerrymander, aes(x = gerry, y = clinton16)) +\n  geom_beeswarm(color = \"gray50\", alpha = 0.5) +\n  geom_boxplot(aes(color = gerry), alpha = 0.5) +\n  theme_minimal()"
  },
  {
    "objectID": "ae/ae-05-gerrymander-explore-II-A.html#render-commit-and-push",
    "href": "ae/ae-05-gerrymander-explore-II-A.html#render-commit-and-push",
    "title": "AE 05: Gerrymandering + data exploration II",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-11-unvotes-revisit-chatgpt.html",
    "href": "ae/ae-11-unvotes-revisit-chatgpt.html",
    "title": "AE 11: UN Votes - Revisit + Chat GPT adventures",
    "section": "",
    "text": "You’ve seen this analysis before. It’s time to revisit it and clean it up for code smell, style, and readability. Make the necessary updates to the code to improve the code. Then, review the diff before you render, commit (with an appropriate message), and push.\n\n\nHow do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(unvotes)\n\nIf you use data from the unvotes package, please cite the following:\n\nErik Voeten \"Data and Analyses of Voting in the UN General Assembly\" Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013)\n\nlibrary(ggthemes)\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;inner_join(un_roll_calls, by = join_by(rcid)) |&gt;\n  inner_join(un_roll_call_issues, \nby = join_by(rcid == rcid),relationship = \"many-to-many\")\n\nprint(unvotes)\n\n# A tibble: 857,878 × 14\n    rcid country country_code vote  session importantvote date       unres amend\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;fct&gt;   &lt;dbl&gt;         &lt;int&gt; &lt;date&gt;     &lt;chr&gt; &lt;int&gt;\n 1     6 United… US           no          1             0 1946-01-04 R/1/…     0\n 2     6 Canada  CA           no          1             0 1946-01-04 R/1/…     0\n 3     6 Cuba    CU           yes         1             0 1946-01-04 R/1/…     0\n 4     6 Domini… DO           abst…       1             0 1946-01-04 R/1/…     0\n 5     6 Mexico  MX           yes         1             0 1946-01-04 R/1/…     0\n 6     6 Guatem… GT           no          1             0 1946-01-04 R/1/…     0\n 7     6 Hondur… HN           yes         1             0 1946-01-04 R/1/…     0\n 8     6 El Sal… SV           abst…       1             0 1946-01-04 R/1/…     0\n 9     6 Nicara… NI           yes         1             0 1946-01-04 R/1/…     0\n10     6 Panama  PA           abst…       1             0 1946-01-04 R/1/…     0\n# ℹ 857,868 more rows\n# ℹ 5 more variables: para &lt;int&gt;, short &lt;chr&gt;, descr &lt;chr&gt;, short_name &lt;chr&gt;,\n#   issue &lt;fct&gt;\n\n\n\nLet’s create a data visualization that displays how the voting record of the United States, United Kingdom, and Turkey changed over time.\n\nlibrary(ggplot2)\nunvotes |&gt;\n  filter(country%in%c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n    mutate(year = year(date))|&gt;\n      group_by(country, year, issue) |&gt;\n    summarize(percent_yes = mean(vote==\"yes\"),.groups = \"drop\") |&gt;\n\n  \nggplot(aes(x = year, \n           y = percent_yes, \n           color = country)) +\n  geom_smooth(method = \"loess\", se = FALSE) + facet_wrap(~issue) +\n              scale_color_colorblind() +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\nsubtitle = \"1946 to 2019\",y = \"% Yes\",x = \"Year\",color = \"Country\"\n  )+\n   geom_point(alpha = 0.4)+scale_y_continuous(labels = percent)\n\n\n\n\n\n\n\n\n\nRobinson D (2021). unvotes: United Nations General Assembly Voting Data. R package version 0.3.0, https://github.com/dgrtwo/unvotes.\nErik Voeten “Data and Analyses of Voting in the UN General Assembly” Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "ae/ae-11-unvotes-revisit-chatgpt.html#introduction",
    "href": "ae/ae-11-unvotes-revisit-chatgpt.html#introduction",
    "title": "AE 11: UN Votes - Revisit + Chat GPT adventures",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(unvotes)\n\nIf you use data from the unvotes package, please cite the following:\n\nErik Voeten \"Data and Analyses of Voting in the UN General Assembly\" Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013)\n\nlibrary(ggthemes)\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;inner_join(un_roll_calls, by = join_by(rcid)) |&gt;\n  inner_join(un_roll_call_issues, \nby = join_by(rcid == rcid),relationship = \"many-to-many\")\n\nprint(unvotes)\n\n# A tibble: 857,878 × 14\n    rcid country country_code vote  session importantvote date       unres amend\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;fct&gt;   &lt;dbl&gt;         &lt;int&gt; &lt;date&gt;     &lt;chr&gt; &lt;int&gt;\n 1     6 United… US           no          1             0 1946-01-04 R/1/…     0\n 2     6 Canada  CA           no          1             0 1946-01-04 R/1/…     0\n 3     6 Cuba    CU           yes         1             0 1946-01-04 R/1/…     0\n 4     6 Domini… DO           abst…       1             0 1946-01-04 R/1/…     0\n 5     6 Mexico  MX           yes         1             0 1946-01-04 R/1/…     0\n 6     6 Guatem… GT           no          1             0 1946-01-04 R/1/…     0\n 7     6 Hondur… HN           yes         1             0 1946-01-04 R/1/…     0\n 8     6 El Sal… SV           abst…       1             0 1946-01-04 R/1/…     0\n 9     6 Nicara… NI           yes         1             0 1946-01-04 R/1/…     0\n10     6 Panama  PA           abst…       1             0 1946-01-04 R/1/…     0\n# ℹ 857,868 more rows\n# ℹ 5 more variables: para &lt;int&gt;, short &lt;chr&gt;, descr &lt;chr&gt;, short_name &lt;chr&gt;,\n#   issue &lt;fct&gt;"
  },
  {
    "objectID": "ae/ae-11-unvotes-revisit-chatgpt.html#un-voting-patterns",
    "href": "ae/ae-11-unvotes-revisit-chatgpt.html#un-voting-patterns",
    "title": "AE 11: UN Votes - Revisit + Chat GPT adventures",
    "section": "",
    "text": "Let’s create a data visualization that displays how the voting record of the United States, United Kingdom, and Turkey changed over time.\n\nlibrary(ggplot2)\nunvotes |&gt;\n  filter(country%in%c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n    mutate(year = year(date))|&gt;\n      group_by(country, year, issue) |&gt;\n    summarize(percent_yes = mean(vote==\"yes\"),.groups = \"drop\") |&gt;\n\n  \nggplot(aes(x = year, \n           y = percent_yes, \n           color = country)) +\n  geom_smooth(method = \"loess\", se = FALSE) + facet_wrap(~issue) +\n              scale_color_colorblind() +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\nsubtitle = \"1946 to 2019\",y = \"% Yes\",x = \"Year\",color = \"Country\"\n  )+\n   geom_point(alpha = 0.4)+scale_y_continuous(labels = percent)"
  },
  {
    "objectID": "ae/ae-11-unvotes-revisit-chatgpt.html#references",
    "href": "ae/ae-11-unvotes-revisit-chatgpt.html#references",
    "title": "AE 11: UN Votes - Revisit + Chat GPT adventures",
    "section": "",
    "text": "Robinson D (2021). unvotes: United Nations General Assembly Voting Data. R package version 0.3.0, https://github.com/dgrtwo/unvotes.\nErik Voeten “Data and Analyses of Voting in the UN General Assembly” Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "ae/ae-07-taxes-join-A.html",
    "href": "ae/ae-07-taxes-join-A.html",
    "title": "AE 07: Sales taxes + data joining",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-07-taxes-join-A.html#getting-started",
    "href": "ae/ae-07-taxes-join-A.html#getting-started",
    "title": "AE 07: Sales taxes + data joining",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are available in the data folder.\n\nsales_taxes &lt;- read_csv(\"data/sales-taxes.csv\")\n\nRows: 51 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): state\ndbl (4): state_tax_rate, avg_local_tax_rate, combined_rate, max_local_tax_rate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nus_regions &lt;- read_csv(\"data/us-regions.csv\")\n\nRows: 50 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): state_name, region\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAnd let’s take a look at the data.\n\nglimpse(sales_taxes)\n\nRows: 51\nColumns: 5\n$ state              &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"Califo…\n$ state_tax_rate     &lt;dbl&gt; 0.0400, 0.0000, 0.0560, 0.0650, 0.0725, 0.0290, 0.0…\n$ avg_local_tax_rate &lt;dbl&gt; 0.0529, 0.0182, 0.0278, 0.0295, 0.0160, 0.0491, 0.0…\n$ combined_rate      &lt;dbl&gt; 0.0929, 0.0182, 0.0838, 0.0945, 0.0885, 0.0781, 0.0…\n$ max_local_tax_rate &lt;dbl&gt; 0.0750, 0.0785, 0.0530, 0.0613, 0.0475, 0.0830, 0.0…\n\nglimpse(us_regions)\n\nRows: 50\nColumns: 2\n$ state_name &lt;chr&gt; \"Maine\", \"New Hampshire\", \"Vermont\", \"Massachusetts\", \"Rhod…\n$ region     &lt;chr&gt; \"Northeast\", \"Northeast\", \"Northeast\", \"Northeast\", \"Northe…"
  },
  {
    "objectID": "ae/ae-07-taxes-join-A.html#joining",
    "href": "ae/ae-07-taxes-join-A.html#joining",
    "title": "AE 07: Sales taxes + data joining",
    "section": "Joining",
    "text": "Joining\nJoin the sales tax data with region data and save the joined data frame as a new data frame, not overwriting either data frame that goes into the join.\n\nsales_taxes_regions &lt;- left_join(\n  sales_taxes, \n  us_regions, \n  by = join_by(state == state_name)\n)\n\nCalculate the average sales tax of states in each region. What is surprising in the output?\n\nsales_taxes_regions |&gt;\n  group_by(region) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 5 × 2\n  region    mean_state_tax\n  &lt;chr&gt;              &lt;dbl&gt;\n1 Midwest           0.0569\n2 Northeast         0.0530\n3 South             0.0523\n4 West              0.0416\n5 &lt;NA&gt;              0.06  \n\n\nIdentify the state with NA for region.\n\nsales_taxes_regions |&gt;\n  filter(is.na(region)) |&gt;\n  select(state, region)\n\n# A tibble: 1 × 2\n  state                region\n  &lt;chr&gt;                &lt;chr&gt; \n1 District of Columbia &lt;NA&gt;  \n\n\nApply a fix for the NA in region, and calculate the mean sales taxes for regions again. Display the results in ascending order of mean sales tax.\n\nsales_taxes_regions &lt;- sales_taxes_regions |&gt;\n  mutate(\n    region = if_else(state == \"District of Columbia\", \"Northeast\", region)\n  )\n\nsales_taxes_regions |&gt;\n  group_by(region) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate)) |&gt;\n  arrange(mean_state_tax)\n\n# A tibble: 4 × 2\n  region    mean_state_tax\n  &lt;chr&gt;              &lt;dbl&gt;\n1 West              0.0416\n2 South             0.0523\n3 Northeast         0.0537\n4 Midwest           0.0569"
  },
  {
    "objectID": "ae/ae-07-taxes-join-A.html#render-commit-and-push",
    "href": "ae/ae-07-taxes-join-A.html#render-commit-and-push",
    "title": "AE 07: Sales taxes + data joining",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-16-spam-filter.html",
    "href": "ae/ae-16-spam-filter.html",
    "title": "AE 16: Building a spam filter",
    "section": "",
    "text": "In this application exercise, we will\nTo illustrate logistic regression, we will build a spam filter from email data.\nThe data come from incoming emails in David Diez’s (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nglimpse(email)\n\nRows: 3,921\nColumns: 21\n$ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         &lt;dttm&gt; 2012-01-01 01:16:41, 2012-01-01 02:03:59, 2012-01-01 11:…\n$ image        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       &lt;dbl&gt; 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ inherit      &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     &lt;dbl&gt; 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     &lt;dbl&gt; 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  &lt;int&gt; 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess &lt;dbl&gt; 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       &lt;fct&gt; big, small, small, small, none, none, big, small, small, …\nThe variables we’ll use in this analysis are\nGoal: Use the number of exclamation points in an email to predict whether or not it is spam."
  },
  {
    "objectID": "ae/ae-16-spam-filter.html#exercise-1",
    "href": "ae/ae-16-spam-filter.html#exercise-1",
    "title": "AE 16: Building a spam filter",
    "section": "Exercise 1",
    "text": "Exercise 1\n\n\nDemo: Fit the logistic regression model using the number of exclamation points to predict the probability an email is spam.\n\n\nlog_fit &lt;- logistic_reg() |&gt;\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(log_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n\n\n\n\nYour turn: How does the code above differ from previous code we’ve used to fit regression models? Compare your summary output to the estimated model below.\n\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2.27 - 0.000272 \\times exclaim\\_mess\\]\nAdd response here."
  },
  {
    "objectID": "ae/ae-16-spam-filter.html#exercise-2",
    "href": "ae/ae-16-spam-filter.html#exercise-2",
    "title": "AE 16: Building a spam filter",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhat is the probability the email is spam if it contains 10 exclamation points? Answer the question using the predict() function.\nWe can use the predict function in R to produce the probability as well.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-16-spam-filter.html#exercise-3",
    "href": "ae/ae-16-spam-filter.html#exercise-3",
    "title": "AE 16: Building a spam filter",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe have the probability an email is spam, but ultimately we want to use the probability to classify an email as spam or not spam. Therefore, we need to set a decision-making threshold, such that an email is classified as spam if the predicted probability is greater than the threshold and not spam otherwise.\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check).\nYour turn: What are some trade offs you would consider as you set the decision-making threshold? Discuss with your neighbor.\nAdd response here.\n\nlog_aug &lt;- augment(log_fit, email)\n\nggplot(log_aug, aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)"
  },
  {
    "objectID": "ae/ae-16-spam-filter.html#exercise-4",
    "href": "ae/ae-16-spam-filter.html#exercise-4",
    "title": "AE 16: Building a spam filter",
    "section": "Exercise 4",
    "text": "Exercise 4\nFit a model with all variables in the dataset as predictors and receate the visualization above for this model.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-00-unvotes.html",
    "href": "ae/ae-00-unvotes.html",
    "title": "AE 00: UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\n\n\n\n\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis."
  },
  {
    "objectID": "ae/ae-00-unvotes.html#introduction",
    "href": "ae/ae-00-unvotes.html#introduction",
    "title": "AE 00: UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\n\n\n\n\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis."
  },
  {
    "objectID": "ae/ae-00-unvotes.html#un-voting-patterns",
    "href": "ae/ae-00-unvotes.html#un-voting-patterns",
    "title": "AE 00: UN Votes",
    "section": "UN voting patterns",
    "text": "UN voting patterns\nLet’s create a data visualisation that displays how the voting record of the United States, United Kingdom, and Turkey changed over time.\n\n\n\n\n\n\n\n\n\nTask: Write your first piece of (R) code!\n\nModify the code cell above to change the plot to include a different country in place of Turkey. Note that the country name should be spelled and capitalized exactly the same way as it appears in the data. See the Appendix for a list of the countries in the data."
  },
  {
    "objectID": "ae/ae-00-unvotes.html#references",
    "href": "ae/ae-00-unvotes.html#references",
    "title": "AE 00: UN Votes",
    "section": "References",
    "text": "References\n\nRobinson D (2021). unvotes: United Nations General Assembly Voting Data. R package version 0.3.0, https://github.com/dgrtwo/unvotes.\nErik Voeten “Data and Analyses of Voting in the UN General Assembly” Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "ae/ae-00-unvotes.html#appendix",
    "href": "ae/ae-00-unvotes.html#appendix",
    "title": "AE 00: UN Votes",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of countries in the dataset:"
  },
  {
    "objectID": "ae/ae-17-forest-classification-A.html",
    "href": "ae/ae-17-forest-classification-A.html",
    "title": "AE 17: Forest classification",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this application exercise, we will\nWe will use tidyverse and tidymodels for data exploration and modeling, respectively, and the forested package for the data.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)\nRemember from the lecture that the forested dataset contains information on whether a plot is forested (Yes) or not (No) as well as numerical and categorical features of that plot.\nglimpse(forested)\n\nRows: 7,107\nColumns: 19\n$ forested         &lt;fct&gt; Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005,…\n$ elevation        &lt;dbl&gt; 881, 113, 164, 299, 806, 736, 636, 224, 52, 2240, 104…\n$ eastness         &lt;dbl&gt; 90, -25, -84, 93, 47, -27, -48, -65, -62, -67, 96, -4…\n$ northness        &lt;dbl&gt; 43, 96, 53, 34, -88, -96, 87, -75, 78, -74, -26, 86, …\n$ roughness        &lt;dbl&gt; 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 190, 95, 212…\n$ tree_no_tree     &lt;fct&gt; Tree, Tree, Tree, No tree, Tree, Tree, No tree, Tree,…\n$ dew_temp         &lt;dbl&gt; 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6.39, 6.50,…\n$ precip_annual    &lt;dbl&gt; 466, 1710, 1297, 2545, 609, 539, 702, 1195, 1312, 103…\n$ temp_annual_mean &lt;dbl&gt; 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61, 10.45, 10…\n$ temp_annual_min  &lt;dbl&gt; -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.76, 1.11, …\n$ temp_annual_max  &lt;dbl&gt; 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 14.23, 15.3…\n$ temp_january_min &lt;dbl&gt; -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, 5.54, 6.20…\n$ vapor_min        &lt;dbl&gt; 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 172, 162, 70…\n$ vapor_max        &lt;dbl&gt; 1194, 938, 754, 1164, 1254, 1331, 1275, 944, 892, 549…\n$ canopy_cover     &lt;dbl&gt; 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74, 66, 83, 6…\n$ lon              &lt;dbl&gt; -118.6865, -123.0825, -122.3468, -121.9144, -117.8841…\n$ lat              &lt;dbl&gt; 48.69537, 47.07991, 48.77132, 45.80776, 48.07396, 48.…\n$ land_type        &lt;fct&gt; Tree, Tree, Tree, Tree, Tree, Tree, Non-tree vegetati…"
  },
  {
    "objectID": "ae/ae-17-forest-classification-A.html#fit",
    "href": "ae/ae-17-forest-classification-A.html#fit",
    "title": "AE 17: Forest classification",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on a subset of predictors of your choice. Name the model forested_custom_fit and display a tidy output of the model.\n\nforested_custom_fit &lt;- logistic_reg() |&gt;\n  fit(forested ~ elevation + tree_no_tree + lat + lon + temp_annual_mean, data = forested_train)\ntidy(forested_custom_fit)\n\n# A tibble: 6 × 5\n  term                 estimate std.error statistic   p.value\n  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)         48.2       6.06         7.96  1.71e- 15\n2 elevation           -0.000311  0.000384    -0.811 4.17e-  1\n3 tree_no_treeNo tree  3.35      0.0925      36.3   4.02e-288\n4 lat                 -0.313     0.0642      -4.87  1.09e-  6\n5 lon                  0.311     0.0288      10.8   3.81e- 27\n6 temp_annual_mean     0.270     0.0819       3.30  9.78e-  4"
  },
  {
    "objectID": "ae/ae-17-forest-classification-A.html#predict",
    "href": "ae/ae-17-forest-classification-A.html#predict",
    "title": "AE 17: Forest classification",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\nforested_custom_aug &lt;- augment(forested_custom_fit, new_data = forested_test)\nforested_custom_aug\n\n# A tibble: 1,777 × 22\n   .pred_class .pred_Yes .pred_No forested  year elevation eastness northness\n   &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes            0.877    0.123  Yes       2005       113      -25        96\n 2 Yes            0.829    0.171  Yes       2005       736      -27       -96\n 3 Yes            0.855    0.145  Yes       2005       224      -65       -75\n 4 Yes            0.957    0.0431 Yes       2003      1031      -49        86\n 5 Yes            0.728    0.272  No        2005      1713      -66        75\n 6 Yes            0.982    0.0175 Yes       2014      1612       30       -95\n 7 No             0.0765   0.924  No        2014       507       44       -89\n 8 Yes            0.889    0.111  Yes       2014       940      -93        35\n 9 Yes            0.659    0.341  No        2014       246       22       -97\n10 No             0.0877   0.912  No        2014       419       86       -49\n# ℹ 1,767 more rows\n# ℹ 14 more variables: roughness &lt;dbl&gt;, tree_no_tree &lt;fct&gt;, dew_temp &lt;dbl&gt;,\n#   precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, land_type &lt;fct&gt;"
  },
  {
    "objectID": "ae/ae-17-forest-classification-A.html#evaluate",
    "href": "ae/ae-17-forest-classification-A.html#evaluate",
    "title": "AE 17: Forest classification",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\nforested_custom_aug |&gt;\n  count(.pred_class, forested) |&gt;\n  arrange(forested) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = round(n / sum(n), 2),\n    decision = case_when(\n      .pred_class == \"Yes\" & forested == \"Yes\" ~ \"True positive\",\n      .pred_class == \"Yes\" & forested == \"No\" ~ \"False positive\",\n      .pred_class == \"No\" & forested == \"Yes\" ~ \"False negative\",\n      .pred_class == \"No\" & forested == \"No\" ~ \"True negative\"\n    )\n  )\n\n# A tibble: 4 × 5\n# Groups:   forested [2]\n  .pred_class forested     n     p decision      \n  &lt;fct&gt;       &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 Yes         Yes        864  0.9  True positive \n2 No          Yes         98  0.1  False negative\n3 Yes         No         124  0.15 False positive\n4 No          No         691  0.85 True negative \n\n\nAnother commonly used display of this information is a confusion matrix. Create this using the conf_mat() function. You will need to review the documentation for the function to determine how to use it.\n\nconf_mat(\n  forested_custom_aug, \n  truth = forested, \n  estimate = .pred_class\n)\n\n          Truth\nPrediction Yes  No\n       Yes 864 124\n       No   98 691"
  },
  {
    "objectID": "ae/ae-17-forest-classification-A.html#sensitivity-specificity-roc-curve",
    "href": "ae/ae-17-forest-classification-A.html#sensitivity-specificity-roc-curve",
    "title": "AE 17: Forest classification",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\nforested_custom_roc &lt;- roc_curve(forested_custom_aug, truth = forested, .pred_Yes)\nforested_custom_roc\n\n# A tibble: 1,779 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1  -Inf          0                 1\n 2     0.0186     0                 1\n 3     0.0202     0.00123           1\n 4     0.0204     0.00245           1\n 5     0.0207     0.00368           1\n 6     0.0227     0.00491           1\n 7     0.0286     0.00613           1\n 8     0.0298     0.00736           1\n 9     0.0299     0.00859           1\n10     0.0300     0.00982           1\n# ℹ 1,769 more rows\n\nggplot(forested_custom_roc, aes(x = 1 - specificity, y = sensitivity)) +\n  geom_path() +\n  geom_abline(lty = 3) +\n  coord_equal()"
  },
  {
    "objectID": "ae/ae-17-forest-classification-A.html#fit-1",
    "href": "ae/ae-17-forest-classification-A.html#fit-1",
    "title": "AE 17: Forest classification",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on all predictors available. Name the model forested_full_fit and display a tidy output of the model.\n\nforested_full_fit &lt;- logistic_reg() |&gt;\n  fit(forested ~ ., data = forested_train)\ntidy(forested_full_fit)\n\n# A tibble: 20 × 5\n   term                             estimate std.error statistic  p.value\n   &lt;chr&gt;                               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                  -12.1        32.6       -0.371   7.11e- 1\n 2 year                           0.00456     0.0152     0.299   7.65e- 1\n 3 elevation                     -0.00277     0.000639  -4.33    1.47e- 5\n 4 eastness                      -0.000910    0.000734  -1.24    2.15e- 1\n 5 northness                      0.00208     0.000745   2.79    5.26e- 3\n 6 roughness                     -0.00399     0.00146   -2.73    6.29e- 3\n 7 tree_no_treeNo tree            1.25        0.136      9.23    2.61e-20\n 8 dew_temp                      -0.125       0.176     -0.712   4.76e- 1\n 9 precip_annual                 -0.0000895   0.000100  -0.895   3.71e- 1\n10 temp_annual_mean              -7.30       12.4       -0.587   5.57e- 1\n11 temp_annual_min                0.819       0.103      7.93    2.20e-15\n12 temp_annual_max                2.59        6.22       0.417   6.77e- 1\n13 temp_january_min               3.34        6.21       0.538   5.91e- 1\n14 vapor_min                      0.00000990  0.00353    0.00280 9.98e- 1\n15 vapor_max                      0.00925     0.00132    7.00    2.62e-12\n16 canopy_cover                  -0.0446      0.00366  -12.2     4.18e-34\n17 lon                           -0.0953      0.0559    -1.71    8.80e- 2\n18 lat                            0.0748      0.109      0.683   4.94e- 1\n19 land_typeNon-tree vegetation  -0.735       0.282     -2.61    9.05e- 3\n20 land_typeTree                 -1.58        0.297     -5.33    9.93e- 8"
  },
  {
    "objectID": "ae/ae-17-forest-classification-A.html#predict-1",
    "href": "ae/ae-17-forest-classification-A.html#predict-1",
    "title": "AE 17: Forest classification",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\nforested_full_aug &lt;- augment(forested_full_fit, new_data = forested_test)\nforested_full_aug\n\n# A tibble: 1,777 × 22\n   .pred_class .pred_Yes .pred_No forested  year elevation eastness northness\n   &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes            0.930    0.0700 Yes       2005       113      -25        96\n 2 Yes            0.918    0.0822 Yes       2005       736      -27       -96\n 3 No             0.428    0.572  Yes       2005       224      -65       -75\n 4 Yes            0.972    0.0280 Yes       2003      1031      -49        86\n 5 Yes            0.633    0.367  No        2005      1713      -66        75\n 6 Yes            0.980    0.0201 Yes       2014      1612       30       -95\n 7 No             0.0436   0.956  No        2014       507       44       -89\n 8 Yes            0.845    0.155  Yes       2014       940      -93        35\n 9 No             0.0141   0.986  No        2014       246       22       -97\n10 No             0.0386   0.961  No        2014       419       86       -49\n# ℹ 1,767 more rows\n# ℹ 14 more variables: roughness &lt;dbl&gt;, tree_no_tree &lt;fct&gt;, dew_temp &lt;dbl&gt;,\n#   precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, land_type &lt;fct&gt;"
  },
  {
    "objectID": "ae/ae-17-forest-classification-A.html#evaluate-1",
    "href": "ae/ae-17-forest-classification-A.html#evaluate-1",
    "title": "AE 17: Forest classification",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\nforested_full_aug |&gt;\n  count(.pred_class, forested) |&gt;\n  arrange(forested) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = round(n / sum(n), 2),\n    decision = case_when(\n      .pred_class == \"Yes\" & forested == \"Yes\" ~ \"True positive\",\n      .pred_class == \"Yes\" & forested == \"No\" ~ \"False positive\",\n      .pred_class == \"No\" & forested == \"Yes\" ~ \"False negative\",\n      .pred_class == \"No\" & forested == \"No\" ~ \"True negative\"\n    )\n  )\n\n# A tibble: 4 × 5\n# Groups:   forested [2]\n  .pred_class forested     n     p decision      \n  &lt;fct&gt;       &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 Yes         Yes        876  0.91 True positive \n2 No          Yes         86  0.09 False negative\n3 Yes         No          85  0.1  False positive\n4 No          No         730  0.9  True negative"
  },
  {
    "objectID": "ae/ae-17-forest-classification-A.html#sensitivity-specificity-roc-curve-1",
    "href": "ae/ae-17-forest-classification-A.html#sensitivity-specificity-roc-curve-1",
    "title": "AE 17: Forest classification",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\nforested_full_roc &lt;- roc_curve(forested_full_aug, truth = forested, .pred_Yes)\nforested_full_roc\n\n# A tibble: 1,779 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 -Inf           0                 1\n 2    0.00106     0                 1\n 3    0.00107     0.00123           1\n 4    0.00217     0.00245           1\n 5    0.00287     0.00368           1\n 6    0.00290     0.00491           1\n 7    0.00290     0.00613           1\n 8    0.00309     0.00736           1\n 9    0.00321     0.00859           1\n10    0.00323     0.00982           1\n# ℹ 1,769 more rows\n\nggplot(forested_full_roc, aes(x = 1 - specificity, y = sensitivity)) +\n  geom_path() +\n  geom_abline(lty = 3) +\n  coord_equal()"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I.html",
    "href": "ae/ae-04-gerrymander-explore-I.html",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "",
    "text": "We’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\n\n\nThe data are availale in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I.html#getting-started",
    "href": "ae/ae-04-gerrymander-explore-I.html#getting-started",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "",
    "text": "We’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\n\n\nThe data are availale in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I.html#districts-at-the-tails",
    "href": "ae/ae-04-gerrymander-explore-I.html#districts-at-the-tails",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "Districts at the tails",
    "text": "Districts at the tails\nMake side-by-side box plots of percent of vote received by Trump in 2016 Presidential Election by prevalence of gerrymandering. Identify any Congressional Districts that are potential outliers. Are they different from the rest of the Congressional Districts due to high support or low support for Trump in the 2016 Presidential Election? Which state are they in? Which city are they in?\nAdd narrative here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I.html#flips",
    "href": "ae/ae-04-gerrymander-explore-I.html#flips",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "Flips",
    "text": "Flips\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics. Hint: Calculate the conditional distribution of prevalance of gerrymandering based on whether a Democrat was able to flip the seat in the 2018 election.\nAdd narrative here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-I.html#submit",
    "href": "ae/ae-04-gerrymander-explore-I.html#submit",
    "title": "AE 04: Gerrymandering + data exploration I",
    "section": "Submit",
    "text": "Submit\nRender, commit, and push:\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap.html",
    "href": "ae/ae-18-duke-forest-bootstrap.html",
    "title": "AE 18: Houses in Duke Forest",
    "section": "",
    "text": "In this application exercise, we will use bootstrapping to construct confidence intervals."
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap.html#packages",
    "href": "ae/ae-18-duke-forest-bootstrap.html#packages",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Packages",
    "text": "Packages\nWe will use tidyverse and tidymodels for data exploration and modeling, respectively, and the openintro package for the data, and the knitr package for formatting tables.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap.html#data",
    "href": "ae/ae-18-duke-forest-bootstrap.html#data",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…"
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap.html#model",
    "href": "ae/ae-18-duke-forest-bootstrap.html#model",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap.html#bootstrap-confidence-interval",
    "href": "ae/ae-18-duke-forest-bootstrap.html#bootstrap-confidence-interval",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Bootstrap confidence interval",
    "text": "Bootstrap confidence interval\n1. Calculate the observed fit (slope)\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159.\n\n\n2. Take n bootstrap samples and fit models to each one.\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(20241115)\n\nboot_fits &lt;- ______ |&gt;\n  specify(______) |&gt;\n  generate(reps = ____, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n\nWhy do we set a seed before taking the bootstrap samples?\nMake a histogram of the bootstrap samples to visualize the bootstrap distribution.\n\n\n# add code here\n\n3. Compute the 95% confidence interval as the middle 95% of the bootstrap distribution\nFill in the code, then set eval: true .\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = _____, \n  level = ____,\n  type = \"percentile\"\n)"
  },
  {
    "objectID": "ae/ae-18-duke-forest-bootstrap.html#changing-confidence-level",
    "href": "ae/ae-18-duke-forest-bootstrap.html#changing-confidence-level",
    "title": "AE 18: Houses in Duke Forest",
    "section": "Changing confidence level",
    "text": "Changing confidence level\nModify the code from Step 3 to create a 90% confidence interval.\n\n# add code here\n\nModify the code from Step 3 to create a 99% confidence interval.\n\n# add code here\n\n\nWhich confidence level produces the most accurate confidence interval (90%, 95%, 99%)? Explain\nWhich confidence level produces the most precise confidence interval (90%, 95%, 99%)? Explain\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "ae/ae-10-chronicle-scrape.html",
    "href": "ae/ae-10-chronicle-scrape.html",
    "title": "AE 10: Opinion articles in The Chronicle",
    "section": "",
    "text": "This will be done in the chronicle-scrape.R R script. Save the resulting data frame in the data folder."
  },
  {
    "objectID": "ae/ae-10-chronicle-scrape.html#part-1---data-scraping",
    "href": "ae/ae-10-chronicle-scrape.html#part-1---data-scraping",
    "title": "AE 10: Opinion articles in The Chronicle",
    "section": "",
    "text": "This will be done in the chronicle-scrape.R R script. Save the resulting data frame in the data folder."
  },
  {
    "objectID": "ae/ae-10-chronicle-scrape.html#part-2---data-analysis",
    "href": "ae/ae-10-chronicle-scrape.html#part-2---data-analysis",
    "title": "AE 10: Opinion articles in The Chronicle",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet’s start by loading the packages we will need:\n\nlibrary(tidyverse)\n\n\nLoad the data you saved into the data folder and name it chronicle.\n\n\n# add code here\n\n\nWho are the most prolific authors of the 500 most recent opinion articles in The Chronicle?\n\n\n# add code here\n\n\nDraw a line plot of the number of opinion articles published per day in The Chronicle.\n\n\n# add code here\n\n\nWhat percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title?\n\n\n# add code here\n\n\nWhat percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title or abstract?\n\n\n# add code here\n\n\nCome up with another question and try to answer it using the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-06-majors-tidy.html",
    "href": "ae/ae-06-majors-tidy.html",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "",
    "text": "We’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\n\nThe data are available in the data folder.\n\nstatsci &lt;- read_csv(\"data/statsci.csv\")\n\nRows: 4 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): degree\ndbl (14): 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAnd let’s take a look at the data.\n\nstatsci\n\n# A tibble: 4 × 15\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statist…     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist…      2      2      4      1      3      6      3      4      4      1\n3 Statist…      2      6      1     NA      5      6      6      8      8     17\n4 Statist…      5      9      4     13     10     17     24     21     26     27\n# ℹ 4 more variables: `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;, `2024` &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-06-majors-tidy.html#getting-started",
    "href": "ae/ae-06-majors-tidy.html#getting-started",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "",
    "text": "We’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\n\nThe data are available in the data folder.\n\nstatsci &lt;- read_csv(\"data/statsci.csv\")\n\nRows: 4 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): degree\ndbl (14): 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAnd let’s take a look at the data.\n\nstatsci\n\n# A tibble: 4 × 15\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statist…     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist…      2      2      4      1      3      6      3      4      4      1\n3 Statist…      2      6      1     NA      5      6      6      8      8     17\n4 Statist…      5      9      4     13     10     17     24     21     26     27\n# ℹ 4 more variables: `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;, `2024` &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-06-majors-tidy.html#pivoting",
    "href": "ae/ae-06-majors-tidy.html#pivoting",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "Pivoting",
    "text": "Pivoting\nPivot the statsci data frame longer such that\n\neach row represents a degree type / year combination,\n\nyear and number of graduates for that year are columns,\n\nyear is numerical,\n\nNAs in counts are replaced with 0s,\n\ndegree_type has levels BS, BS2, AB, and AB2 (in this order), and\nthe resulting data frame is saved as statsci_longer.\n\nReview the code below with your neighbor and come up with at least one question about the code.\n\nstatsci_longer &lt;- statsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n  )\n\nstatsci_longer\n\n# A tibble: 56 × 4\n   major               degree_type  year     n\n   &lt;chr&gt;               &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science AB2          2011     0\n 2 Statistical Science AB2          2012     1\n 3 Statistical Science AB2          2013     0\n 4 Statistical Science AB2          2014     0\n 5 Statistical Science AB2          2015     4\n 6 Statistical Science AB2          2016     4\n 7 Statistical Science AB2          2017     1\n 8 Statistical Science AB2          2018     0\n 9 Statistical Science AB2          2019     0\n10 Statistical Science AB2          2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "ae/ae-06-majors-tidy.html#plotting",
    "href": "ae/ae-06-majors-tidy.html#plotting",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "Plotting",
    "text": "Plotting\nStep 1: Basics\nLet’s start with a basic plot, nothing too fancy! Create a line plot of number of majors vs. year, where lines are colored by degree type, and the data are also represented as points on the lines.\n\n# add code here\n\nWhat aspects of the plot need to be updated to go from the draft you created above to the goal plot from the slides.\nAdd response here.\nStep 2: Scales\nUpdate x-axis scale such that the years displayed go from 2012 to 2024 in increments of 2 years. Do this by adding on to your ggplot call from earlier.\n\n# add code here\n\nStep 3: Colors\nUpdate line colors using the following level / color assignments. Once again, do this by adding on to your ggplot call from earlier.\n\n“BS” = “cadetblue4”\n“BS2” = “cadetblue3”\n“AB” = “lightgoldenrod4”\n“AB2” = “lightgoldenrod3”\n\nNote: A handy reference for named colors in R is http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf, though you can use HEX color codes as well.\n\n# add code here\n\nStep 4: Labels and themes\nUpdate the plot labels (title, subtitle, x, y, and caption) and use theme_minimal(). Once again, do this by adding on to your ggplot call from earlier. Note: The link in the caption is https://registrar.duke.edu/registration/enrollment-statistics.\n\n# add code here\n\nStep 5: Legends and figure sizing via cell options\nFinally, adding to your pipeline you’ve developed so far, move the legend into the plot, make its background white, and its border gray. Additionally, in the cell options, set\n\n\nout-width: 100% – Output should span 100% of the width\n\nfig-width: 8 – Figure output should have a width of 8 inches\n\nfig-asp: 0.5 – Figure output should have an aspect ratio of 0.5, resulting in a height of 8 * 0.5 = 4 inches\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-06-majors-tidy.html#render-commit-and-push",
    "href": "ae/ae-06-majors-tidy.html#render-commit-and-push",
    "title": "AE 06: StatSci majors + data tidying",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "project/5-writeup-presentation.html",
    "href": "project/5-writeup-presentation.html",
    "title": "Write-up and presentation",
    "section": "",
    "text": "Your written report must be completed in the index.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo: false in the YAML.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long (if it were to be printed). There is no minimum page requirement; however, you should comprehensively address all of the analysis in your report.\nTo check how many pages your report is, open it in your browser and go to File &gt; Print &gt; Save as PDF and review the number of pages.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\n\n\n\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The exploratory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you’ve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you’ve chosen to do modeling, describe the model(s) you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.\n\n\n\n\n\nThe write-up is worth 35 points, broken down as follows:\n\n\n\nTotal\n35 pts\n\n\n\n\nIntroduction/data\n4 pts\n\n\nMethodology\n10 pts\n\n\nResults\n15 pts\n\n\nDiscussion\n3 pts\n\n\nOrganization + formatting\n3 pts",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#expectations",
    "href": "project/5-writeup-presentation.html#expectations",
    "title": "Write-up and presentation",
    "section": "",
    "text": "Your written report must be completed in the index.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo: false in the YAML.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long (if it were to be printed). There is no minimum page requirement; however, you should comprehensively address all of the analysis in your report.\nTo check how many pages your report is, open it in your browser and go to File &gt; Print &gt; Save as PDF and review the number of pages.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#components",
    "href": "project/5-writeup-presentation.html#components",
    "title": "Write-up and presentation",
    "section": "",
    "text": "This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The exploratory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you’ve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you’ve chosen to do modeling, describe the model(s) you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#grading",
    "href": "project/5-writeup-presentation.html#grading",
    "title": "Write-up and presentation",
    "section": "",
    "text": "The write-up is worth 35 points, broken down as follows:\n\n\n\nTotal\n35 pts\n\n\n\n\nIntroduction/data\n4 pts\n\n\nMethodology\n10 pts\n\n\nResults\n15 pts\n\n\nDiscussion\n3 pts\n\n\nOrganization + formatting\n3 pts",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#slides",
    "href": "project/5-writeup-presentation.html#slides",
    "title": "Write-up and presentation",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and record a presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides. If you choose this option, save the slides as PDF and upload it to your repo as presentation.pdf.\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe slide deck should be roughly 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#presentation",
    "href": "project/5-writeup-presentation.html#presentation",
    "title": "Write-up and presentation",
    "section": "Presentation",
    "text": "Presentation\nPresentations will be recorded and uploaded to Warpwire or YouTube. The presentation must be no longer than 5 minutes. During grading, we will stop watching your video at the 5-minute mark.\nFor recording your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire or another video platform (e.g., YouTube), then add a link to your video in your repo README.\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Canvas site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\n\nThe instructions should be a lot more straightforward for YouTube. See https://support.google.com/youtube/answer/57407?hl=en&co=GENIE.Platform%3DDesktop for step-by-step instructions.\nOnce you’ve uploaded your video to some platform, grab its sharing link and post it on Ed Discussion. More information on this will be posted closer to the project deadline.",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#grading-1",
    "href": "project/5-writeup-presentation.html#grading-1",
    "title": "Write-up and presentation",
    "section": "Grading",
    "text": "Grading\nThe presentation is worth 25 points, broken down as follows:\n\n\n\nTotal\n25 pts\n\n\n\n\nSlides\n10 pts\n\n\nPresentation\n15 pts\n\n\n\n\nSlides\nAre the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n\n\nPresentation\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\nCreativity and critical thought: Is the project carefully thought out? Does it appear that time and effort went into the planning and implementation of the project?\nContent: Including, but not limited to the following:\n\nIs the question well articulated in the presentation?\nCan the question be answered with the data?\nDoes the analysis answer the question?\nAre the conclusion(s) made based on the analysis justifiable?\nAre the limitations carefully considered and articulated?",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/description.html",
    "href": "project/description.html",
    "title": "Project description",
    "section": "",
    "text": "TL;DR: Ask a question you’re curious about and answer it with a dataset of your choice. This is your project in a nutshell.\nMay be too long, but please do read\nThe project for this course will consist of analysis on a dataset of your own choosing. The dataset may already exist, or you may collect your own data using a survey or by conducting an experiment. You can choose the data based on your teams’ interests or based on work in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this course (and beyond, if you like) and apply them to a novel dataset in a meaningful way.\nThe goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results. Focus on methods that help you begin to answer your research questions. You do not have to apply every statistical procedure we learned. Also, critique your own methods and provide suggestions for improving your analysis. Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here.\nThe project is very open ended. You should create some kind of compelling visualization(s) of this data in R. There is no limit on what tools or packages you may use but sticking to packages we learned in the course is required. You do not need to visualize all of the data at once. A single high-quality visualization will receive a much higher grade than a large number of poor-quality visualizations. Also pay attention to your presentation. Neatness, coherency, and clarity will count. All analyses must be done in RStudio, using R, and all components of the project must be reproducible (with the exception of the slide deck).\nYou will work on the project with your lab teams.\nThe four milestones for the final project are\n\nMilestone 1 - Working collaboratively\nMilestone 2 - Proposals, with three dataset ideas\nMilestone 3 - Improvement and progress\nMilestone 4 - Peer review, on another team’s project\nMilestone 5 - Presentation with slides and a reproducible project write-up of your analysis, with a draft along the way.\n\nYou will not be submitting anything on Gradescope for the project. Submission of these deliverables will happen on GitHub and feedback will be provided as GitHub issues that you need to engage with and close. The collection of the documents in your GitHub repo will create a webpage for your project. To create the webpage go to the Build tab in RStudio, and click on Render Website.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#reproducibility-organization",
    "href": "project/description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the write-up and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#teamwork",
    "href": "project/description.html#teamwork",
    "title": "Project description",
    "section": "Teamwork",
    "text": "Teamwork\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly and penalties may apply beyond the teamwork component of the grade.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project presentation deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#grading-summary",
    "href": "project/description.html#grading-summary",
    "title": "Project description",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#late-work-policy",
    "href": "project/description.html#late-work-policy",
    "title": "Project description",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/tips-resources.html",
    "href": "project/tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "The project is very open ended. For instance, in creating a compelling visualization(s) of your data in R, there is no limit on what tools or packages you may use. You do not need to visualize all of the data at once. A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.\nBefore you finalize your write up, make sure the printing of code chunks is turned off with the option echo: false. In addition to code chunks, ensure all messages are turned off with the options warning: false and message: false.\nFinally, pay attention to details in your write-up and presentation. Neatness, coherency, and clarity will count.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#suppress-code-and-warnings",
    "href": "project/tips-resources.html#suppress-code-and-warnings",
    "title": "Project tips + resources",
    "section": "Suppress code and warnings",
    "text": "Suppress code and warnings\n\nInclude the following in the YAML of your report.qmd to suppress all code, warnings, and other messages.\n\nexecute:\n  echo: false\n  warning: false",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#headers",
    "href": "project/tips-resources.html#headers",
    "title": "Project tips + resources",
    "section": "Headers",
    "text": "Headers\nUse headers to clearly label each section. Make sure there is a space between the previous line and the header. Use appropriate header levels.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#references",
    "href": "project/tips-resources.html#references",
    "title": "Project tips + resources",
    "section": "References",
    "text": "References\nInclude all references in a section called “References” at the end of the report. This course does not have specific requirements for formatting citations and references. Optional: Use Quarto’s citation support for generating your reference. See Citations & Footnotes on the Quarto documentation for more on that.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#appendix",
    "href": "project/tips-resources.html#appendix",
    "title": "Project tips + resources",
    "section": "Appendix",
    "text": "Appendix\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”. The items in the appendix should be properly labeled. The appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix. We will not grade your appendix.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#resize-figures",
    "href": "project/tips-resources.html#resize-figures",
    "title": "Project tips + resources",
    "section": "Resize figures",
    "text": "Resize figures\nResize plots and figures, so you have more space for the narrative. Resize individual figures: Set fig-width and fig-height in chunk options, e.g.,\n#| echo: fenced\n#| label: code-cell-label\n#| fig-width: 5\n#| fig-asp: 0.628\nreplacing code-cell-label with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig-width and fig-asp options in the YAML header as shown below:\nexecute:\n  fig-width: 5\n  fig-asp: 0.628\nReplace the height and width values with values appropriate for your write up.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#arranging-plots",
    "href": "project/tips-resources.html#arranging-plots",
    "title": "Project tips + resources",
    "section": "Arranging plots",
    "text": "Arranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nThe patchwork package makes it easy to arrange plots in a grid.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html",
    "href": "project/1-working-collaboratively.html",
    "title": "Working collaboratively",
    "section": "",
    "text": "Important\n\n\n\nYou must attend this lab in person and participate in the merge conflict activity to be eligible for the points for this milestone. Team members who are not in lab in person for this activity will not be eligible for these points, regardless of their contribution throughout the rest of the project.\nData science is a collaborative discipline. Pretty much no data scientist works alone, so neither should you! In this course you’ll collaborate with teammates on the project.\nThe first milestone of the project, today’s activity, will introduce you to the technical aspects of collaborating on a reproducible data science project that is version controlled by Git and hosted on GitHub in a repository shared by all teammates.\nYes, this means you and all of your teammates will be pushing to the same repository! Sometimes things will go swimmingly, and sometimes you’ll run into merge conflicts.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html#activity",
    "href": "project/1-working-collaboratively.html#activity",
    "title": "Working collaboratively",
    "section": "Activity",
    "text": "Activity\n\nSetup\n\nClone the project repo and open the about.qmd file.\nAssign the numbers 1, 2, 3, 4, and 5 to each of the team members. If your team has fewer than 5 people, some people will need to have multiple numbers.\n\n\n\nLet’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\n\nBefore starting\nEveryone should have the repo cloned and know which role number(s) they are.\n\n\nRole 1\n\nGo to about.qmd in your project repo. Change the [team name] to your actual team name.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 2\n\nChange the team name to some other word.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push. You should get an error.\nPull. Take a look at the document (about.qmd) with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nRender the project by clicking on Render in the Build tab.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 3\n\nChange the name of the first team member.\nRender the project by clicking on Render in the Build tab, commit, and push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 4\n\nChange the name of the first team member to something other than what the previous team member did.\nRender the project by clicking on Render in the Build tab, commit, and push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Render the project by clicking on Render in the Build tab, commit, and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 5\n\nChange the name of the rest of the team members and add descriptions for each person with the help of your team members. Role 5 should be the only one typing; the others should help verbally.\nRender the project by clicking on Render in the Build tab and commit. Discuss as a team what you expect to happen when you hit push. Should there be a merge conflict error or not?\nIf there is a merge conflict, fix it. If not, push your changes.\n\n\n\nEveryone\nPull, and observe the changes in your project.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "href": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "title": "Working collaboratively",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (render and push) before continuing your work. Never do new work while resolving a merge conflict.\nRender, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "computing-code-alongs.html",
    "href": "computing-code-alongs.html",
    "title": "Code alongs",
    "section": "",
    "text": "The following videos feature “code alongs” as an additional resource for getting coding practice.",
    "crumbs": [
      "Computing",
      "Code alongs"
    ]
  },
  {
    "objectID": "computing-code-alongs.html#data-visualization-and-transformation",
    "href": "computing-code-alongs.html#data-visualization-and-transformation",
    "title": "Code alongs",
    "section": "Data visualization and transformation",
    "text": "Data visualization and transformation\n\nUN Votes\nFirst look at R amd RStudio.\n\n\n\nFirst look at Palmer Penguins\nFirst look at data science with the tidyverse.\n\n\n\nFlights and pipes\nData transformation\n\n\n\nStarwars characters\nData visualization\n\n\n\nDiving deeper with Palmer Penguins\nData visualization and transformation",
    "crumbs": [
      "Computing",
      "Code alongs"
    ]
  },
  {
    "objectID": "slides/20-evaluating-models.html#while-you-wait",
    "href": "slides/20-evaluating-models.html#while-you-wait",
    "title": "Evaluating models",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-17-forest-classification.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/20-evaluating-models.html#announcements",
    "href": "slides/20-evaluating-models.html#announcements",
    "title": "Evaluating models",
    "section": "Announcements",
    "text": "Announcements\n\nProject milestone 3 - Improvement and progress due at 5 pm on Friday"
  },
  {
    "objectID": "slides/20-evaluating-models.html#packages",
    "href": "slides/20-evaluating-models.html#packages",
    "title": "Evaluating models",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)"
  },
  {
    "objectID": "slides/20-evaluating-models.html#data",
    "href": "slides/20-evaluating-models.html#data",
    "title": "Evaluating models",
    "section": "Data",
    "text": "Data\n\nThe U.S. Forest Service maintains machine learning models to predict whether a plot of land is “forested.”\nThis classification is important for research, legislation, land management, etc. purposes.\nPlots are typically remeasured every 10 years.\nThe forested dataset contains the most recent measurement per plot."
  },
  {
    "objectID": "slides/20-evaluating-models.html#data-forested",
    "href": "slides/20-evaluating-models.html#data-forested",
    "title": "Evaluating models",
    "section": "Data: forested\n",
    "text": "Data: forested\n\n\nforested\n\n# A tibble: 7,107 × 19\n   forested  year elevation eastness northness roughness tree_no_tree\n   &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;       \n 1 Yes       2005       881       90        43        63 Tree        \n 2 Yes       2005       113      -25        96        30 Tree        \n 3 No        2005       164      -84        53        13 Tree        \n 4 Yes       2005       299       93        34         6 No tree     \n 5 Yes       2005       806       47       -88        35 Tree        \n 6 Yes       2005       736      -27       -96        53 Tree        \n 7 Yes       2005       636      -48        87         3 No tree     \n 8 Yes       2005       224      -65       -75         9 Tree        \n 9 Yes       2005        52      -62        78        42 Tree        \n10 Yes       2005      2240      -67       -74        99 No tree     \n# ℹ 7,097 more rows\n# ℹ 12 more variables: dew_temp &lt;dbl&gt;, precip_annual &lt;dbl&gt;,\n#   temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;,\n#   land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/20-evaluating-models.html#data-forested-1",
    "href": "slides/20-evaluating-models.html#data-forested-1",
    "title": "Evaluating models",
    "section": "Data: forested\n",
    "text": "Data: forested\n\n\nglimpse(forested)\n\nRows: 7,107\nColumns: 19\n$ forested         &lt;fct&gt; Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2…\n$ elevation        &lt;dbl&gt; 881, 113, 164, 299, 806, 736, 636, 224, 52,…\n$ eastness         &lt;dbl&gt; 90, -25, -84, 93, 47, -27, -48, -65, -62, -…\n$ northness        &lt;dbl&gt; 43, 96, 53, 34, -88, -96, 87, -75, 78, -74,…\n$ roughness        &lt;dbl&gt; 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 19…\n$ tree_no_tree     &lt;fct&gt; Tree, Tree, Tree, No tree, Tree, Tree, No t…\n$ dew_temp         &lt;dbl&gt; 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6…\n$ precip_annual    &lt;dbl&gt; 466, 1710, 1297, 2545, 609, 539, 702, 1195,…\n$ temp_annual_mean &lt;dbl&gt; 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61,…\n$ temp_annual_min  &lt;dbl&gt; -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.…\n$ temp_annual_max  &lt;dbl&gt; 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 1…\n$ temp_january_min &lt;dbl&gt; -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, …\n$ vapor_min        &lt;dbl&gt; 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 17…\n$ vapor_max        &lt;dbl&gt; 1194, 938, 754, 1164, 1254, 1331, 1275, 944…\n$ canopy_cover     &lt;dbl&gt; 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74,…\n$ lon              &lt;dbl&gt; -118.6865, -123.0825, -122.3468, -121.9144,…\n$ lat              &lt;dbl&gt; 48.69537, 47.07991, 48.77132, 45.80776, 48.…\n$ land_type        &lt;fct&gt; Tree, Tree, Tree, Tree, Tree, Tree, Non-tre…"
  },
  {
    "objectID": "slides/20-evaluating-models.html#outcome-and-predictors",
    "href": "slides/20-evaluating-models.html#outcome-and-predictors",
    "title": "Evaluating models",
    "section": "Outcome and predictors",
    "text": "Outcome and predictors\n\nOutcome: forested - Factor, Yes or No\n\n\n\nlevels(forested$forested)\n\n[1] \"Yes\" \"No\" \n\n\n\n\nPredictors: 18 remotely-sensed and easily-accessible predictors:\n\nnumeric variables based on weather and topography\ncategorical variables based on classifications from other governmental organizations"
  },
  {
    "objectID": "slides/20-evaluating-models.html#forested",
    "href": "slides/20-evaluating-models.html#forested",
    "title": "Evaluating models",
    "section": "?forested",
    "text": "?forested"
  },
  {
    "objectID": "slides/20-evaluating-models.html#should-we-include-a-predictor",
    "href": "slides/20-evaluating-models.html#should-we-include-a-predictor",
    "title": "Evaluating models",
    "section": "Should we include a predictor?",
    "text": "Should we include a predictor?\nTo determine whether we should include a predictor in a model, we should start by asking:\n\n\nIs it ethical to use this variable? (Or even legal?)\nWill this variable be available at prediction time?\nDoes this variable contribute to explainability?"
  },
  {
    "objectID": "slides/20-evaluating-models.html#weve-been-cheating",
    "href": "slides/20-evaluating-models.html#weve-been-cheating",
    "title": "Evaluating models",
    "section": "We’ve been cheating!",
    "text": "We’ve been cheating!\n\n\nSo far, we’ve been using all the data we have for building models. In predictive contexts, this would be considered cheating.\nEvaluating model performance for predicting outcomes that were used when building the models is like evaluating your learning with questions whose answers you’ve already seen."
  },
  {
    "objectID": "slides/20-evaluating-models.html#spending-your-data",
    "href": "slides/20-evaluating-models.html#spending-your-data",
    "title": "Evaluating models",
    "section": "Spending your data",
    "text": "Spending your data\nFor predictive models (used primarily in machine learning), we typically split data into training and test sets:\n\n\n\n\n\nThe training set is used to estimate model parameters.\nThe test set is used to find an independent assessment of model performance.\n\n. . .\n\n\n\n\n\n\nWarning\n\n\n\nDo not use, or even peek at, the test set during training."
  },
  {
    "objectID": "slides/20-evaluating-models.html#how-much-to-spend",
    "href": "slides/20-evaluating-models.html#how-much-to-spend",
    "title": "Evaluating models",
    "section": "How much to spend?",
    "text": "How much to spend?\n\n\nThe more data we spend (use in training), the better estimates we’ll get.\nSpending too much data in training prevents us from computing a good assessment of predictive performance.\nSpending too much data in testing prevents us from computing a good estimate of model parameters."
  },
  {
    "objectID": "slides/20-evaluating-models.html#the-initial-split",
    "href": "slides/20-evaluating-models.html#the-initial-split",
    "title": "Evaluating models",
    "section": "The initial split",
    "text": "The initial split\n\nset.seed(20241112)\nforested_split &lt;- initial_split(forested)\nforested_split\n\n&lt;Training/Testing/Total&gt;\n&lt;5330/1777/7107&gt;"
  },
  {
    "objectID": "slides/20-evaluating-models.html#setting-a-seed",
    "href": "slides/20-evaluating-models.html#setting-a-seed",
    "title": "Evaluating models",
    "section": "Setting a seed",
    "text": "Setting a seed\n\nWhat does set.seed() do?\n\n\n\nTo create that split of the data, R generates “pseudo-random” numbers: while they are made to behave like random numbers, their generation is deterministic given a “seed”.\nThis allows us to reproduce results by setting that seed.\nWhich seed you pick doesn’t matter, as long as you don’t try a bunch of seeds and pick the one that gives you the best performance."
  },
  {
    "objectID": "slides/20-evaluating-models.html#accessing-the-data",
    "href": "slides/20-evaluating-models.html#accessing-the-data",
    "title": "Evaluating models",
    "section": "Accessing the data",
    "text": "Accessing the data\n\nforested_train &lt;- training(forested_split)\nforested_test &lt;- testing(forested_split)"
  },
  {
    "objectID": "slides/20-evaluating-models.html#the-training-set",
    "href": "slides/20-evaluating-models.html#the-training-set",
    "title": "Evaluating models",
    "section": "The training set",
    "text": "The training set\n\nforested_train\n\n# A tibble: 5,330 × 19\n   forested  year elevation eastness northness roughness tree_no_tree\n   &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;       \n 1 Yes       2013       315      -17        98        92 Tree        \n 2 No        2018       374       93       -34        23 No tree     \n 3 No        2017       377       44       -89         1 Tree        \n 4 Yes       2013       541       31       -94       139 Tree        \n 5 Yes       2017       680       14       -98        20 Tree        \n 6 Yes       2017      1482       76       -64        43 Tree        \n 7 No        2020        84       42       -90        12 No tree     \n 8 Yes       2011       210       34        93        16 Tree        \n 9 No        2020       766       14        98        20 No tree     \n10 Yes       2013      1559       98        16        79 Tree        \n# ℹ 5,320 more rows\n# ℹ 12 more variables: dew_temp &lt;dbl&gt;, precip_annual &lt;dbl&gt;,\n#   temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;,\n#   land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/20-evaluating-models.html#the-testing-data",
    "href": "slides/20-evaluating-models.html#the-testing-data",
    "title": "Evaluating models",
    "section": "The testing data",
    "text": "The testing data\n. . .\n🙈"
  },
  {
    "objectID": "slides/20-evaluating-models.html#initial-questions",
    "href": "slides/20-evaluating-models.html#initial-questions",
    "title": "Evaluating models",
    "section": "Initial questions",
    "text": "Initial questions\n\nWhat’s the distribution of the outcome, forested?\nWhat’s the distribution of numeric variables like precip_annual?\nHow does the distribution of forested differ across the categorical and numerical variables?\n\n. . .\n\nWhich dataset should we use for the exploration? The entire data forested, the training data forested_train, or the testing data forested_test?"
  },
  {
    "objectID": "slides/20-evaluating-models.html#forested-1",
    "href": "slides/20-evaluating-models.html#forested-1",
    "title": "Evaluating models",
    "section": "forested",
    "text": "forested\nWhat’s the distribution of the outcome, forested?"
  },
  {
    "objectID": "slides/20-evaluating-models.html#precip_annual",
    "href": "slides/20-evaluating-models.html#precip_annual",
    "title": "Evaluating models",
    "section": "precip_annual",
    "text": "precip_annual\nWhat’s the distribution of precip_annual?"
  },
  {
    "objectID": "slides/20-evaluating-models.html#forested-and-precip_annual",
    "href": "slides/20-evaluating-models.html#forested-and-precip_annual",
    "title": "Evaluating models",
    "section": "\nforested and precip_annual\n",
    "text": "forested and precip_annual\n\n\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"identity\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/20-evaluating-models.html#forested-and-precip_annual-1",
    "href": "slides/20-evaluating-models.html#forested-and-precip_annual-1",
    "title": "Evaluating models",
    "section": "\nforested and precip_annual\n",
    "text": "forested and precip_annual\n\n\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"fill\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/20-evaluating-models.html#forested-and-tree_no_tree",
    "href": "slides/20-evaluating-models.html#forested-and-tree_no_tree",
    "title": "Evaluating models",
    "section": "\nforested and tree_no_tree\n",
    "text": "forested and tree_no_tree\n\n\nggplot(forested_train, aes(x = tree_no_tree, fill = forested)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/20-evaluating-models.html#forested-and-lat-lon",
    "href": "slides/20-evaluating-models.html#forested-and-lat-lon",
    "title": "Evaluating models",
    "section": "\nforested and lat / lon\n",
    "text": "forested and lat / lon\n\n\nggplot(forested_train, aes(x = lon, y = lat, color = forested)) +\n  geom_point(alpha = 0.7) +\n  scale_color_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/20-evaluating-models.html#false-negative-and-positive",
    "href": "slides/20-evaluating-models.html#false-negative-and-positive",
    "title": "Evaluating models",
    "section": "False negative and positive",
    "text": "False negative and positive\n\nFalse negative rate is the proportion of actual positives that were classified as negatives.\nFalse positive rate is the proportion of actual negatives that were classified as positives."
  },
  {
    "objectID": "slides/20-evaluating-models.html#sensitivity",
    "href": "slides/20-evaluating-models.html#sensitivity",
    "title": "Evaluating models",
    "section": "Sensitivity",
    "text": "Sensitivity\nSensitivity is the proportion of actual positives that were correctly classified as positive.\n\nAlso known as true positive rate and recall\nSensitivity = 1 − False negative rate\nUseful when false negatives are more “expensive” than false positives"
  },
  {
    "objectID": "slides/20-evaluating-models.html#specificity",
    "href": "slides/20-evaluating-models.html#specificity",
    "title": "Evaluating models",
    "section": "Specificity",
    "text": "Specificity\nSpecificity is the proportion of actual negatives that were correctly classified as negative\n\nAlso known as true negative rate\nSpecificity = 1 − False positive rate"
  },
  {
    "objectID": "slides/20-evaluating-models.html#roc-curve",
    "href": "slides/20-evaluating-models.html#roc-curve",
    "title": "Evaluating models",
    "section": "ROC curve",
    "text": "ROC curve\nThe receiver operating characteristic (ROC) curve allows to assess the model performance across a range of thresholds."
  },
  {
    "objectID": "slides/20-evaluating-models.html#roc-curve-1",
    "href": "slides/20-evaluating-models.html#roc-curve-1",
    "title": "Evaluating models",
    "section": "ROC curve",
    "text": "ROC curve\n\nWhich corner of the plot indicates the best model performance?"
  },
  {
    "objectID": "slides/20-evaluating-models.html#next-steps-1",
    "href": "slides/20-evaluating-models.html#next-steps-1",
    "title": "Evaluating models",
    "section": "Next steps",
    "text": "Next steps\n\n\nFit models on training data\nMake predictions on testing data\n\nEvaluate predictions on testing data:\n\nLinear models: R-squared, adjusted R-squared, RMSE (root mean squared error), etc.\nLogistic models: False negative and positive rates, AUC (area under the curve), etc.\n\n\nMake decisions based on model predictive performance, validity across various testing/training splits (aka “cross validation”), explainability\n\n\n. . .\n\n\n\n\n\n\nNote\n\n\n\nWe will only learn about a subset of these in this course, but you can go further into these ideas in STA 210 or STA 221 as well as in various machine learning courses."
  },
  {
    "objectID": "slides/20-evaluating-models.html#ae-17-forest-classification",
    "href": "slides/20-evaluating-models.html#ae-17-forest-classification",
    "title": "Evaluating models",
    "section": "ae-17-forest-classification",
    "text": "ae-17-forest-classification\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-17-forest-classification.qmd. You might be prompted to install forested, say yes.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#while-you-wait",
    "href": "slides/20-evaluating-models-slides.html#while-you-wait",
    "title": "Evaluating models",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-17-forest-classification.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#announcements",
    "href": "slides/20-evaluating-models-slides.html#announcements",
    "title": "Evaluating models",
    "section": "Announcements",
    "text": "Announcements\n\nProject milestone 3 - Improvement and progress due at 5 pm on Friday"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#packages",
    "href": "slides/20-evaluating-models-slides.html#packages",
    "title": "Evaluating models",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#data",
    "href": "slides/20-evaluating-models-slides.html#data",
    "title": "Evaluating models",
    "section": "Data",
    "text": "Data\n\nThe U.S. Forest Service maintains machine learning models to predict whether a plot of land is “forested.”\nThis classification is important for research, legislation, land management, etc. purposes.\nPlots are typically remeasured every 10 years.\nThe forested dataset contains the most recent measurement per plot."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#data-forested",
    "href": "slides/20-evaluating-models-slides.html#data-forested",
    "title": "Evaluating models",
    "section": "Data: forested\n",
    "text": "Data: forested\n\n\nforested\n\n# A tibble: 7,107 × 19\n   forested  year elevation eastness northness roughness tree_no_tree\n   &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;       \n 1 Yes       2005       881       90        43        63 Tree        \n 2 Yes       2005       113      -25        96        30 Tree        \n 3 No        2005       164      -84        53        13 Tree        \n 4 Yes       2005       299       93        34         6 No tree     \n 5 Yes       2005       806       47       -88        35 Tree        \n 6 Yes       2005       736      -27       -96        53 Tree        \n 7 Yes       2005       636      -48        87         3 No tree     \n 8 Yes       2005       224      -65       -75         9 Tree        \n 9 Yes       2005        52      -62        78        42 Tree        \n10 Yes       2005      2240      -67       -74        99 No tree     \n# ℹ 7,097 more rows\n# ℹ 12 more variables: dew_temp &lt;dbl&gt;, precip_annual &lt;dbl&gt;,\n#   temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;,\n#   land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#data-forested-1",
    "href": "slides/20-evaluating-models-slides.html#data-forested-1",
    "title": "Evaluating models",
    "section": "Data: forested\n",
    "text": "Data: forested\n\n\nglimpse(forested)\n\nRows: 7,107\nColumns: 19\n$ forested         &lt;fct&gt; Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2…\n$ elevation        &lt;dbl&gt; 881, 113, 164, 299, 806, 736, 636, 224, 52,…\n$ eastness         &lt;dbl&gt; 90, -25, -84, 93, 47, -27, -48, -65, -62, -…\n$ northness        &lt;dbl&gt; 43, 96, 53, 34, -88, -96, 87, -75, 78, -74,…\n$ roughness        &lt;dbl&gt; 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 19…\n$ tree_no_tree     &lt;fct&gt; Tree, Tree, Tree, No tree, Tree, Tree, No t…\n$ dew_temp         &lt;dbl&gt; 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6…\n$ precip_annual    &lt;dbl&gt; 466, 1710, 1297, 2545, 609, 539, 702, 1195,…\n$ temp_annual_mean &lt;dbl&gt; 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61,…\n$ temp_annual_min  &lt;dbl&gt; -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.…\n$ temp_annual_max  &lt;dbl&gt; 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 1…\n$ temp_january_min &lt;dbl&gt; -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, …\n$ vapor_min        &lt;dbl&gt; 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 17…\n$ vapor_max        &lt;dbl&gt; 1194, 938, 754, 1164, 1254, 1331, 1275, 944…\n$ canopy_cover     &lt;dbl&gt; 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74,…\n$ lon              &lt;dbl&gt; -118.6865, -123.0825, -122.3468, -121.9144,…\n$ lat              &lt;dbl&gt; 48.69537, 47.07991, 48.77132, 45.80776, 48.…\n$ land_type        &lt;fct&gt; Tree, Tree, Tree, Tree, Tree, Tree, Non-tre…"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#outcome-and-predictors",
    "href": "slides/20-evaluating-models-slides.html#outcome-and-predictors",
    "title": "Evaluating models",
    "section": "Outcome and predictors",
    "text": "Outcome and predictors\n\nOutcome: forested - Factor, Yes or No\n\n\n\nlevels(forested$forested)\n\n[1] \"Yes\" \"No\" \n\n\n\n\nPredictors: 18 remotely-sensed and easily-accessible predictors:\n\nnumeric variables based on weather and topography\ncategorical variables based on classifications from other governmental organizations"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#forested",
    "href": "slides/20-evaluating-models-slides.html#forested",
    "title": "Evaluating models",
    "section": "?forested",
    "text": "?forested"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#should-we-include-a-predictor",
    "href": "slides/20-evaluating-models-slides.html#should-we-include-a-predictor",
    "title": "Evaluating models",
    "section": "Should we include a predictor?",
    "text": "Should we include a predictor?\nTo determine whether we should include a predictor in a model, we should start by asking:\n\n\nIs it ethical to use this variable? (Or even legal?)\nWill this variable be available at prediction time?\nDoes this variable contribute to explainability?"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#weve-been-cheating",
    "href": "slides/20-evaluating-models-slides.html#weve-been-cheating",
    "title": "Evaluating models",
    "section": "We’ve been cheating!",
    "text": "We’ve been cheating!\n\n\nSo far, we’ve been using all the data we have for building models. In predictive contexts, this would be considered cheating.\nEvaluating model performance for predicting outcomes that were used when building the models is like evaluating your learning with questions whose answers you’ve already seen."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#spending-your-data",
    "href": "slides/20-evaluating-models-slides.html#spending-your-data",
    "title": "Evaluating models",
    "section": "Spending your data",
    "text": "Spending your data\nFor predictive models (used primarily in machine learning), we typically split data into training and test sets:\n\n\nThe training set is used to estimate model parameters.\nThe test set is used to find an independent assessment of model performance.\n\n\n\n\n\n\n\n\nWarning\n\n\nDo not use, or even peek at, the test set during training."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#how-much-to-spend",
    "href": "slides/20-evaluating-models-slides.html#how-much-to-spend",
    "title": "Evaluating models",
    "section": "How much to spend?",
    "text": "How much to spend?\n\n\nThe more data we spend (use in training), the better estimates we’ll get.\nSpending too much data in training prevents us from computing a good assessment of predictive performance.\nSpending too much data in testing prevents us from computing a good estimate of model parameters."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#the-initial-split",
    "href": "slides/20-evaluating-models-slides.html#the-initial-split",
    "title": "Evaluating models",
    "section": "The initial split",
    "text": "The initial split\n\nset.seed(20241112)\nforested_split &lt;- initial_split(forested)\nforested_split\n\n&lt;Training/Testing/Total&gt;\n&lt;5330/1777/7107&gt;"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#setting-a-seed",
    "href": "slides/20-evaluating-models-slides.html#setting-a-seed",
    "title": "Evaluating models",
    "section": "Setting a seed",
    "text": "Setting a seed\n\nWhat does set.seed() do?\n\n\n\nTo create that split of the data, R generates “pseudo-random” numbers: while they are made to behave like random numbers, their generation is deterministic given a “seed”.\nThis allows us to reproduce results by setting that seed.\nWhich seed you pick doesn’t matter, as long as you don’t try a bunch of seeds and pick the one that gives you the best performance."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#accessing-the-data",
    "href": "slides/20-evaluating-models-slides.html#accessing-the-data",
    "title": "Evaluating models",
    "section": "Accessing the data",
    "text": "Accessing the data\n\nforested_train &lt;- training(forested_split)\nforested_test &lt;- testing(forested_split)"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#the-training-set",
    "href": "slides/20-evaluating-models-slides.html#the-training-set",
    "title": "Evaluating models",
    "section": "The training set",
    "text": "The training set\n\nforested_train\n\n# A tibble: 5,330 × 19\n   forested  year elevation eastness northness roughness tree_no_tree\n   &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;       \n 1 Yes       2013       315      -17        98        92 Tree        \n 2 No        2018       374       93       -34        23 No tree     \n 3 No        2017       377       44       -89         1 Tree        \n 4 Yes       2013       541       31       -94       139 Tree        \n 5 Yes       2017       680       14       -98        20 Tree        \n 6 Yes       2017      1482       76       -64        43 Tree        \n 7 No        2020        84       42       -90        12 No tree     \n 8 Yes       2011       210       34        93        16 Tree        \n 9 No        2020       766       14        98        20 No tree     \n10 Yes       2013      1559       98        16        79 Tree        \n# ℹ 5,320 more rows\n# ℹ 12 more variables: dew_temp &lt;dbl&gt;, precip_annual &lt;dbl&gt;,\n#   temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;,\n#   land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#the-testing-data",
    "href": "slides/20-evaluating-models-slides.html#the-testing-data",
    "title": "Evaluating models",
    "section": "The testing data",
    "text": "The testing data\n\n🙈"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#initial-questions",
    "href": "slides/20-evaluating-models-slides.html#initial-questions",
    "title": "Evaluating models",
    "section": "Initial questions",
    "text": "Initial questions\n\nWhat’s the distribution of the outcome, forested?\nWhat’s the distribution of numeric variables like precip_annual?\nHow does the distribution of forested differ across the categorical and numerical variables?\n\n\n\nWhich dataset should we use for the exploration? The entire data forested, the training data forested_train, or the testing data forested_test?"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#forested-1",
    "href": "slides/20-evaluating-models-slides.html#forested-1",
    "title": "Evaluating models",
    "section": "forested",
    "text": "forested\nWhat’s the distribution of the outcome, forested?"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#precip_annual",
    "href": "slides/20-evaluating-models-slides.html#precip_annual",
    "title": "Evaluating models",
    "section": "precip_annual",
    "text": "precip_annual\nWhat’s the distribution of precip_annual?"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#forested-and-precip_annual",
    "href": "slides/20-evaluating-models-slides.html#forested-and-precip_annual",
    "title": "Evaluating models",
    "section": "\nforested and precip_annual\n",
    "text": "forested and precip_annual\n\n\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"identity\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#forested-and-precip_annual-1",
    "href": "slides/20-evaluating-models-slides.html#forested-and-precip_annual-1",
    "title": "Evaluating models",
    "section": "\nforested and precip_annual\n",
    "text": "forested and precip_annual\n\n\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"fill\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#forested-and-tree_no_tree",
    "href": "slides/20-evaluating-models-slides.html#forested-and-tree_no_tree",
    "title": "Evaluating models",
    "section": "\nforested and tree_no_tree\n",
    "text": "forested and tree_no_tree\n\n\nggplot(forested_train, aes(x = tree_no_tree, fill = forested)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#forested-and-lat-lon",
    "href": "slides/20-evaluating-models-slides.html#forested-and-lat-lon",
    "title": "Evaluating models",
    "section": "\nforested and lat / lon\n",
    "text": "forested and lat / lon\n\n\nggplot(forested_train, aes(x = lon, y = lat, color = forested)) +\n  geom_point(alpha = 0.7) +\n  scale_color_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#false-negative-and-positive",
    "href": "slides/20-evaluating-models-slides.html#false-negative-and-positive",
    "title": "Evaluating models",
    "section": "False negative and positive",
    "text": "False negative and positive\n\nFalse negative rate is the proportion of actual positives that were classified as negatives.\nFalse positive rate is the proportion of actual negatives that were classified as positives."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#sensitivity",
    "href": "slides/20-evaluating-models-slides.html#sensitivity",
    "title": "Evaluating models",
    "section": "Sensitivity",
    "text": "Sensitivity\nSensitivity is the proportion of actual positives that were correctly classified as positive.\n\nAlso known as true positive rate and recall\nSensitivity = 1 − False negative rate\nUseful when false negatives are more “expensive” than false positives"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#specificity",
    "href": "slides/20-evaluating-models-slides.html#specificity",
    "title": "Evaluating models",
    "section": "Specificity",
    "text": "Specificity\nSpecificity is the proportion of actual negatives that were correctly classified as negative\n\nAlso known as true negative rate\nSpecificity = 1 − False positive rate"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#roc-curve",
    "href": "slides/20-evaluating-models-slides.html#roc-curve",
    "title": "Evaluating models",
    "section": "ROC curve",
    "text": "ROC curve\nThe receiver operating characteristic (ROC) curve allows to assess the model performance across a range of thresholds."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#roc-curve-1",
    "href": "slides/20-evaluating-models-slides.html#roc-curve-1",
    "title": "Evaluating models",
    "section": "ROC curve",
    "text": "ROC curve\n\nWhich corner of the plot indicates the best model performance?"
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#next-steps-1",
    "href": "slides/20-evaluating-models-slides.html#next-steps-1",
    "title": "Evaluating models",
    "section": "Next steps",
    "text": "Next steps\n\n\nFit models on training data\nMake predictions on testing data\n\nEvaluate predictions on testing data:\n\nLinear models: R-squared, adjusted R-squared, RMSE (root mean squared error), etc.\nLogistic models: False negative and positive rates, AUC (area under the curve), etc.\n\n\nMake decisions based on model predictive performance, validity across various testing/training splits (aka “cross validation”), explainability\n\n\n\n\n\n\n\n\n\nNote\n\n\nWe will only learn about a subset of these in this course, but you can go further into these ideas in STA 210 or STA 221 as well as in various machine learning courses."
  },
  {
    "objectID": "slides/20-evaluating-models-slides.html#ae-17-forest-classification",
    "href": "slides/20-evaluating-models-slides.html#ae-17-forest-classification",
    "title": "Evaluating models",
    "section": "ae-17-forest-classification",
    "text": "ae-17-forest-classification\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-17-forest-classification.qmd. You might be prompted to install forested, say yes.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/21-bootstrap.html#while-you-wait",
    "href": "slides/21-bootstrap.html#while-you-wait",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-18-duke-forest-bootstrap.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/21-bootstrap.html#announcements",
    "href": "slides/21-bootstrap.html#announcements",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Announcements",
    "text": "Announcements\nProject timeline and progress:\n\n\n\nDue this Friday, Nov 15 - Milestone 3\n\nBare minimum: Address and close issues\nIdeal: Start working on your project write-up in index.qmd\n\n\n\n\nBefore Monday, Nov 25 - Between Milestones 3 and 4\n\nBare minimum: Make substantial progress on your project write-up: Finish your introduction and exploratory data analysis (plots/summary statistics + their interpretations) + Write up methods you plan to use\nIdeal: Start implementing the methods and get closer to answering your research question\n\n\n\nOn Monday, Nov 25 - Milestone 4\n\nPeer review of others’ projects in lab\nYou must be in lab to participate in the peer review\nIf you cannot be there physically due to Thanksgiving travel, make arrangements to Zoom in with the rest of your team who are in lab\n\n\n\nAfter Monday, Nov 26: Work on write-up and presentation incorporating feedback from peers and meeting with TAs/instructor as needed during office hours for further feedback"
  },
  {
    "objectID": "slides/21-bootstrap.html#from-last-time",
    "href": "slides/21-bootstrap.html#from-last-time",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "From last time",
    "text": "From last time\n\n\nGo to your ae project in RStudio.\nContinue working on ae-17-forest-classification.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/21-bootstrap.html#goal",
    "href": "slides/21-bootstrap.html#goal",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Goal",
    "text": "Goal\nFind range of plausible values for the slope using bootstrap confidence intervals."
  },
  {
    "objectID": "slides/21-bootstrap.html#packages",
    "href": "slides/21-bootstrap.html#packages",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Packages",
    "text": "Packages\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables"
  },
  {
    "objectID": "slides/21-bootstrap.html#data-houses-in-duke-forest",
    "href": "slides/21-bootstrap.html#data-houses-in-duke-forest",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/21-bootstrap.html#exploratory-data-analysis",
    "href": "slides/21-bootstrap.html#exploratory-data-analysis",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nCodeggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/21-bootstrap.html#modeling",
    "href": "slides/21-bootstrap.html#modeling",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- linear_reg() |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) # neatly format table to 2 digits\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n. . .\n\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, for $116,652, on average.\n\nIs this interpretation useful?\n\n\n\nSlope: For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/21-bootstrap.html#from-sample-to-population",
    "href": "slides/21-bootstrap.html#from-sample-to-population",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average.\n\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if we’re not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/21-bootstrap.html#statistical-inference",
    "href": "slides/21-bootstrap.html#statistical-inference",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nStatistical inference provide methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be random and representative of the population we’re interested in"
  },
  {
    "objectID": "slides/21-bootstrap.html#inference-for-simple-linear-regression",
    "href": "slides/21-bootstrap.html#inference-for-simple-linear-regression",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\) (today)\nConduct a hypothesis test for the slope,\\(\\beta_1\\) (next week)"
  },
  {
    "objectID": "slides/21-bootstrap.html#confidence-interval",
    "href": "slides/21-bootstrap.html#confidence-interval",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Confidence interval",
    "text": "Confidence interval\n\n\nA plausible range of values for a population parameter is called a confidence interval\n\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/21-bootstrap.html#confidence-interval-for-the-slope-1",
    "href": "slides/21-bootstrap.html#confidence-interval-for-the-slope-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”\n. . .\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/21-bootstrap.html#quantify-the-variability-of-the-slope",
    "href": "slides/21-bootstrap.html#quantify-the-variability-of-the-slope",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\n\nTwo approaches:\n\nVia simulation (what we’ll do in this course)\nVia mathematical models (what you can learn about in future courses)\n\n\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/21-bootstrap.html#bootstrap-sample-1",
    "href": "slides/21-bootstrap.html#bootstrap-sample-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/21-bootstrap.html#bootstrap-sample-2",
    "href": "slides/21-bootstrap.html#bootstrap-sample-2",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/21-bootstrap.html#bootstrap-sample-3",
    "href": "slides/21-bootstrap.html#bootstrap-sample-3",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/21-bootstrap.html#bootstrap-sample-4",
    "href": "slides/21-bootstrap.html#bootstrap-sample-4",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/21-bootstrap.html#bootstrap-sample-5",
    "href": "slides/21-bootstrap.html#bootstrap-sample-5",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n. . .\nso on and so forth…"
  },
  {
    "objectID": "slides/21-bootstrap.html#bootstrap-samples-1---5",
    "href": "slides/21-bootstrap.html#bootstrap-samples-1---5",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/21-bootstrap.html#bootstrap-samples-1---100",
    "href": "slides/21-bootstrap.html#bootstrap-samples-1---100",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/21-bootstrap.html#slopes-of-bootstrap-samples",
    "href": "slides/21-bootstrap.html#slopes-of-bootstrap-samples",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/21-bootstrap.html#slopes-of-bootstrap-samples-1",
    "href": "slides/21-bootstrap.html#slopes-of-bootstrap-samples-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/21-bootstrap.html#confidence-level",
    "href": "slides/21-bootstrap.html#confidence-level",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/21-bootstrap.html#confidence-interval-1",
    "href": "slides/21-bootstrap.html#confidence-interval-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/21-bootstrap.html#ae-18-duke-forest-bootstrap",
    "href": "slides/21-bootstrap.html#ae-18-duke-forest-bootstrap",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "ae-18-duke-forest-bootstrap",
    "text": "ae-18-duke-forest-bootstrap\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-18-duke-forest-bootstrap.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/21-bootstrap.html#computing-the-ci-for-the-slope-i",
    "href": "slides/21-bootstrap.html#computing-the-ci-for-the-slope-i",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/21-bootstrap.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/21-bootstrap.html#computing-the-ci-for-the-slope-ii",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/21-bootstrap.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/21-bootstrap.html#computing-the-ci-for-the-slope-iii",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" # default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/21-bootstrap.html#precision-vs.-accuracy",
    "href": "slides/21-bootstrap.html#precision-vs.-accuracy",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n. . ."
  },
  {
    "objectID": "slides/21-bootstrap.html#precision-vs.-accuracy-1",
    "href": "slides/21-bootstrap.html#precision-vs.-accuracy-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?"
  },
  {
    "objectID": "slides/21-bootstrap.html#changing-confidence-level",
    "href": "slides/21-bootstrap.html#changing-confidence-level",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/21-bootstrap.html#changing-confidence-level-1",
    "href": "slides/21-bootstrap.html#changing-confidence-level-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/21-bootstrap.html#recap",
    "href": "slides/21-bootstrap.html#recap",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#while-you-wait",
    "href": "slides/21-bootstrap-slides.html#while-you-wait",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-18-duke-forest-bootstrap.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#announcements",
    "href": "slides/21-bootstrap-slides.html#announcements",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Announcements",
    "text": "Announcements\nProject timeline and progress:\n\n\n\nDue this Friday, Nov 15 - Milestone 3\n\nBare minimum: Address and close issues\nIdeal: Start working on your project write-up in index.qmd\n\n\n\n\nBefore Monday, Nov 25 - Between Milestones 3 and 4\n\nBare minimum: Make substantial progress on your project write-up: Finish your introduction and exploratory data analysis (plots/summary statistics + their interpretations) + Write up methods you plan to use\nIdeal: Start implementing the methods and get closer to answering your research question\n\n\n\nOn Monday, Nov 25 - Milestone 4\n\nPeer review of others’ projects in lab\nYou must be in lab to participate in the peer review\nIf you cannot be there physically due to Thanksgiving travel, make arrangements to Zoom in with the rest of your team who are in lab\n\n\n\nAfter Monday, Nov 26: Work on write-up and presentation incorporating feedback from peers and meeting with TAs/instructor as needed during office hours for further feedback"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#from-last-time",
    "href": "slides/21-bootstrap-slides.html#from-last-time",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "From last time",
    "text": "From last time\n\n\nGo to your ae project in RStudio.\nContinue working on ae-17-forest-classification.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#goal",
    "href": "slides/21-bootstrap-slides.html#goal",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Goal",
    "text": "Goal\nFind range of plausible values for the slope using bootstrap confidence intervals."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#packages",
    "href": "slides/21-bootstrap-slides.html#packages",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Packages",
    "text": "Packages\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#data-houses-in-duke-forest",
    "href": "slides/21-bootstrap-slides.html#data-houses-in-duke-forest",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#exploratory-data-analysis",
    "href": "slides/21-bootstrap-slides.html#exploratory-data-analysis",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nCodeggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#modeling",
    "href": "slides/21-bootstrap-slides.html#modeling",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- linear_reg() |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) # neatly format table to 2 digits\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, for $116,652, on average.\n\nIs this interpretation useful?\n\n\n\nSlope: For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#from-sample-to-population",
    "href": "slides/21-bootstrap-slides.html#from-sample-to-population",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average.\n\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if we’re not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#statistical-inference",
    "href": "slides/21-bootstrap-slides.html#statistical-inference",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nStatistical inference provide methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be random and representative of the population we’re interested in"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#inference-for-simple-linear-regression",
    "href": "slides/21-bootstrap-slides.html#inference-for-simple-linear-regression",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\) (today)\nConduct a hypothesis test for the slope,\\(\\beta_1\\) (next week)"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#confidence-interval",
    "href": "slides/21-bootstrap-slides.html#confidence-interval",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Confidence interval",
    "text": "Confidence interval\n\n\nA plausible range of values for a population parameter is called a confidence interval\n\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#confidence-interval-for-the-slope-1",
    "href": "slides/21-bootstrap-slides.html#confidence-interval-for-the-slope-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”\n\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#quantify-the-variability-of-the-slope",
    "href": "slides/21-bootstrap-slides.html#quantify-the-variability-of-the-slope",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\n\nTwo approaches:\n\nVia simulation (what we’ll do in this course)\nVia mathematical models (what you can learn about in future courses)\n\n\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#bootstrap-sample-1",
    "href": "slides/21-bootstrap-slides.html#bootstrap-sample-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#bootstrap-sample-2",
    "href": "slides/21-bootstrap-slides.html#bootstrap-sample-2",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#bootstrap-sample-3",
    "href": "slides/21-bootstrap-slides.html#bootstrap-sample-3",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#bootstrap-sample-4",
    "href": "slides/21-bootstrap-slides.html#bootstrap-sample-4",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#bootstrap-sample-5",
    "href": "slides/21-bootstrap-slides.html#bootstrap-sample-5",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nso on and so forth…"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#bootstrap-samples-1---5",
    "href": "slides/21-bootstrap-slides.html#bootstrap-samples-1---5",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#bootstrap-samples-1---100",
    "href": "slides/21-bootstrap-slides.html#bootstrap-samples-1---100",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#slopes-of-bootstrap-samples",
    "href": "slides/21-bootstrap-slides.html#slopes-of-bootstrap-samples",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#slopes-of-bootstrap-samples-1",
    "href": "slides/21-bootstrap-slides.html#slopes-of-bootstrap-samples-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#confidence-level",
    "href": "slides/21-bootstrap-slides.html#confidence-level",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#confidence-interval-1",
    "href": "slides/21-bootstrap-slides.html#confidence-interval-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#ae-18-duke-forest-bootstrap",
    "href": "slides/21-bootstrap-slides.html#ae-18-duke-forest-bootstrap",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "ae-18-duke-forest-bootstrap",
    "text": "ae-18-duke-forest-bootstrap\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-18-duke-forest-bootstrap.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#computing-the-ci-for-the-slope-i",
    "href": "slides/21-bootstrap-slides.html#computing-the-ci-for-the-slope-i",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/21-bootstrap-slides.html#computing-the-ci-for-the-slope-ii",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/21-bootstrap-slides.html#computing-the-ci-for-the-slope-iii",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" # default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#precision-vs.-accuracy",
    "href": "slides/21-bootstrap-slides.html#precision-vs.-accuracy",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#precision-vs.-accuracy-1",
    "href": "slides/21-bootstrap-slides.html#precision-vs.-accuracy-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?"
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#changing-confidence-level",
    "href": "slides/21-bootstrap-slides.html#changing-confidence-level",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#changing-confidence-level-1",
    "href": "slides/21-bootstrap-slides.html#changing-confidence-level-1",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/21-bootstrap-slides.html#recap",
    "href": "slides/21-bootstrap-slides.html#recap",
    "title": "Quantifying uncertainty with bootstrap intervals",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#while-you-wait",
    "href": "slides/09-importing-recoding-data.html#while-you-wait",
    "title": "Importing and recoding data",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-09-age-gaps-sales-import.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#announcements",
    "href": "slides/09-importing-recoding-data.html#announcements",
    "title": "Importing and recoding data",
    "section": "Announcements",
    "text": "Announcements\nMidterm things\n\nFocus\nFormat\nPrep\nReview\nAccommodations"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#finish-up-ae-08-durham-climate-factors",
    "href": "slides/09-importing-recoding-data.html#finish-up-ae-08-durham-climate-factors",
    "title": "Importing and recoding data",
    "section": "Finish up: ae-08-durham-climate-factors\n",
    "text": "Finish up: ae-08-durham-climate-factors\n\n\n\nGo to your ae project in RStudio.\nOpen ae-08-durham-climate-factors.qmd and pick up at “Recode and reorder”."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#reading-rectangular-data",
    "href": "slides/09-importing-recoding-data.html#reading-rectangular-data",
    "title": "Importing and recoding data",
    "section": "Reading rectangular data",
    "text": "Reading rectangular data\n\nUsing readr:\n\nMost commonly: read_csv()\n\nMaybe also: read_tsv(), read_delim(), etc.\n\n\n\n. . .\n\nUsing readxl: read_excel()\n\n\n. . .\n\nUsing googlesheets4: read_sheet() – We haven’t covered this in the videos, but might be useful for your projects"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#goal-1-reading-and-writing-csv-files",
    "href": "slides/09-importing-recoding-data.html#goal-1-reading-and-writing-csv-files",
    "title": "Importing and recoding data",
    "section": "Goal 1: Reading and writing CSV files",
    "text": "Goal 1: Reading and writing CSV files\n\nRead a CSV file\nSplit it into subsets based on features of the data\nWrite out subsets as CSV files"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#age-gap-in-hollywood-relationships",
    "href": "slides/09-importing-recoding-data.html#age-gap-in-hollywood-relationships",
    "title": "Importing and recoding data",
    "section": "Age gap in Hollywood relationships",
    "text": "Age gap in Hollywood relationships\n\n\n\nWhat is the story in this visualization?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#ae-09-age-gaps-sales-import---part-1",
    "href": "slides/09-importing-recoding-data.html#ae-09-age-gaps-sales-import---part-1",
    "title": "Importing and recoding data",
    "section": "ae-09-age-gaps-sales-import - Part 1",
    "text": "ae-09-age-gaps-sales-import - Part 1\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-09-age-gaps-sales-import.qmd.\nWork through Part 1 of the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#goal-2-reading-excel-files",
    "href": "slides/09-importing-recoding-data.html#goal-2-reading-excel-files",
    "title": "Importing and recoding data",
    "section": "Goal 2: Reading Excel files",
    "text": "Goal 2: Reading Excel files\n\nRead an Excel file with non-tidy data\nTidy it up!"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#sales-data",
    "href": "slides/09-importing-recoding-data.html#sales-data",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\n. . .\n\nAre these data tidy? Why or why not?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#sales-data-1",
    "href": "slides/09-importing-recoding-data.html#sales-data-1",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\nWhat “data moves” do we need to go from the original, non-tidy data to this, tidy one?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#ae-09-age-gaps-sales-import---part-2",
    "href": "slides/09-importing-recoding-data.html#ae-09-age-gaps-sales-import---part-2",
    "title": "Importing and recoding data",
    "section": "ae-09-age-gaps-sales-import - Part 2",
    "text": "ae-09-age-gaps-sales-import - Part 2\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-09-age-gaps-sales-import.qmd.\nWork through Part 2 of the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#while-you-wait",
    "href": "slides/09-importing-recoding-data-slides.html#while-you-wait",
    "title": "Importing and recoding data",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-09-age-gaps-sales-import.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#announcements",
    "href": "slides/09-importing-recoding-data-slides.html#announcements",
    "title": "Importing and recoding data",
    "section": "Announcements",
    "text": "Announcements\nMidterm things\n\nFocus\nFormat\nPrep\nReview\nAccommodations"
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#finish-up-ae-08-durham-climate-factors",
    "href": "slides/09-importing-recoding-data-slides.html#finish-up-ae-08-durham-climate-factors",
    "title": "Importing and recoding data",
    "section": "Finish up: ae-08-durham-climate-factors\n",
    "text": "Finish up: ae-08-durham-climate-factors\n\n\n\nGo to your ae project in RStudio.\nOpen ae-08-durham-climate-factors.qmd and pick up at “Recode and reorder”."
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#reading-rectangular-data",
    "href": "slides/09-importing-recoding-data-slides.html#reading-rectangular-data",
    "title": "Importing and recoding data",
    "section": "Reading rectangular data",
    "text": "Reading rectangular data\n\nUsing readr:\n\nMost commonly: read_csv()\n\nMaybe also: read_tsv(), read_delim(), etc.\n\n\n\n\n\nUsing readxl: read_excel()\n\n\n\n\n\nUsing googlesheets4: read_sheet() – We haven’t covered this in the videos, but might be useful for your projects"
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#goal-1-reading-and-writing-csv-files",
    "href": "slides/09-importing-recoding-data-slides.html#goal-1-reading-and-writing-csv-files",
    "title": "Importing and recoding data",
    "section": "Goal 1: Reading and writing CSV files",
    "text": "Goal 1: Reading and writing CSV files\n\nRead a CSV file\nSplit it into subsets based on features of the data\nWrite out subsets as CSV files"
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#age-gap-in-hollywood-relationships",
    "href": "slides/09-importing-recoding-data-slides.html#age-gap-in-hollywood-relationships",
    "title": "Importing and recoding data",
    "section": "Age gap in Hollywood relationships",
    "text": "Age gap in Hollywood relationships\n\n\n\nWhat is the story in this visualization?"
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#ae-09-age-gaps-sales-import---part-1",
    "href": "slides/09-importing-recoding-data-slides.html#ae-09-age-gaps-sales-import---part-1",
    "title": "Importing and recoding data",
    "section": "ae-09-age-gaps-sales-import - Part 1",
    "text": "ae-09-age-gaps-sales-import - Part 1\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-09-age-gaps-sales-import.qmd.\nWork through Part 1 of the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#goal-2-reading-excel-files",
    "href": "slides/09-importing-recoding-data-slides.html#goal-2-reading-excel-files",
    "title": "Importing and recoding data",
    "section": "Goal 2: Reading Excel files",
    "text": "Goal 2: Reading Excel files\n\nRead an Excel file with non-tidy data\nTidy it up!"
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#sales-data",
    "href": "slides/09-importing-recoding-data-slides.html#sales-data",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\n\n\nAre these data tidy? Why or why not?"
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#sales-data-1",
    "href": "slides/09-importing-recoding-data-slides.html#sales-data-1",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\nWhat “data moves” do we need to go from the original, non-tidy data to this, tidy one?"
  },
  {
    "objectID": "slides/09-importing-recoding-data-slides.html#ae-09-age-gaps-sales-import---part-2",
    "href": "slides/09-importing-recoding-data-slides.html#ae-09-age-gaps-sales-import---part-2",
    "title": "Importing and recoding data",
    "section": "ae-09-age-gaps-sales-import - Part 2",
    "text": "ae-09-age-gaps-sales-import - Part 2\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-09-age-gaps-sales-import.qmd.\nWork through Part 2 of the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/11-midterm-review.html#while-you-wait",
    "href": "slides/11-midterm-review.html#while-you-wait",
    "title": "Midterm review",
    "section": "While you wait…",
    "text": "While you wait…\n\nGo to your ae project in RStudio\nMake sure you have each piece of information we need extracted from The Chronicle opinion page – up to create a data frame in chronicle-scrape.R."
  },
  {
    "objectID": "slides/11-midterm-review.html#announcements",
    "href": "slides/11-midterm-review.html#announcements",
    "title": "Midterm review",
    "section": "Announcements",
    "text": "Announcements\nMidterm things:\n\nExam room: Bio Sci 111 or Gross Hall 107\nCheat sheet: 8.5x11, both sides, hand written or typed, any content you want, must be prepared by you\nAlso bring a pencil and eraser (you’re allowed to use a pen, but you might not want to)\nReminder: Academic dishonesty / Duke Community Standard"
  },
  {
    "objectID": "slides/11-midterm-review.html#opinion-articles-in-the-chronicle",
    "href": "slides/11-midterm-review.html#opinion-articles-in-the-chronicle",
    "title": "Midterm review",
    "section": "Opinion articles in The Chronicle",
    "text": "Opinion articles in The Chronicle\n\n\n\nScrape data and organize it in a tidy format in R\nPerform light text parsing to clean data\nSummarize and visualize the data"
  },
  {
    "objectID": "slides/11-midterm-review.html#ae-10-chronicle-scrape",
    "href": "slides/11-midterm-review.html#ae-10-chronicle-scrape",
    "title": "Midterm review",
    "section": "ae-10-chronicle-scrape",
    "text": "ae-10-chronicle-scrape\n\n\nGo to your ae project in RStudio.\nOpen chronicle-scrape.R and ae-10-chronicle-scrape.qmd."
  },
  {
    "objectID": "slides/11-midterm-review.html#recap",
    "href": "slides/11-midterm-review.html#recap",
    "title": "Midterm review",
    "section": "Recap",
    "text": "Recap\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse rvest to first read the whole page (into R) and then parse the object you’ve read in to the elements you’re interested in\nPut the components together in a data frame (a tibble) and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/11-midterm-review.html#a-new-r-workflow",
    "href": "slides/11-midterm-review.html#a-new-r-workflow",
    "title": "Midterm review",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in a Quarto document, your analysis is re-run each time you knit\nIf web scraping in a Quarto document, you’d be re-scraping the data each time you knit, which is undesirable (and not nice)!\n\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your Quarto document"
  },
  {
    "objectID": "slides/11-midterm-review.html#ae-09-age-gaps-sales-import",
    "href": "slides/11-midterm-review.html#ae-09-age-gaps-sales-import",
    "title": "Midterm review",
    "section": "ae-09-age-gaps-sales-import",
    "text": "ae-09-age-gaps-sales-import\n\n\nGo to your ae project in RStudio.\nOpen ae-09-age-gaps-sales-import.qmd - Part 2."
  },
  {
    "objectID": "slides/11-midterm-review.html#your-document-environment-vs.-your-global-environment",
    "href": "slides/11-midterm-review.html#your-document-environment-vs.-your-global-environment",
    "title": "Midterm review",
    "section": "Your document environment vs. your global environment",
    "text": "Your document environment vs. your global environment\n\nObjects you define in your Quarto document are available in your Quarto document, and if you ran that code cell individually, they will also be available in your global environment\nObjects you define in your global environment are not, by default, available in your Quarto document"
  },
  {
    "objectID": "slides/11-midterm-review.html#recipe-for-success-for-reproducible-documents",
    "href": "slides/11-midterm-review.html#recipe-for-success-for-reproducible-documents",
    "title": "Midterm review",
    "section": "Recipe for success for reproducible documents",
    "text": "Recipe for success for reproducible documents\n\nRender – after each “win” or at each stopping point\nCommit – all files, with a commit message that describes the substance of what you did\nPush – to make sure files are updated on GitHub as well"
  },
  {
    "objectID": "slides/11-midterm-review.html#explicit-vs.-implicit-type-coercion",
    "href": "slides/11-midterm-review.html#explicit-vs.-implicit-type-coercion",
    "title": "Midterm review",
    "section": "Explicit vs. implicit type coercion",
    "text": "Explicit vs. implicit type coercion\n\nExplicit type coercion: You ask R to change the type of a variable\n\nImplicit type coercion: R changes / makes assumptions for you about the type of a variable without you asking for it\n\nThis happens because in a vector, you can’t have multiple types of values"
  },
  {
    "objectID": "slides/11-midterm-review.html#vectors",
    "href": "slides/11-midterm-review.html#vectors",
    "title": "Midterm review",
    "section": "Vectors",
    "text": "Vectors\n\n\n\nA vector is a collection of values\n\nAtomic vectors can only contain values of the same type\nLists can contain values of different types\n\n\nWhy do we care? Because each column of a data frame is a vector.\n\n\n. . .\n\nlibrary(tidyverse)\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3),          # numeric (double)\n  y = c(\"a\", \"b\", \"c\"),    # character\n  z = c(TRUE, FALSE, TRUE) # logical\n)\ndf\n\n# A tibble: 3 × 3\n      x y     z    \n  &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt;\n1     1 a     TRUE \n2     2 b     FALSE\n3     3 c     TRUE"
  },
  {
    "objectID": "slides/11-midterm-review.html#explicit-coercion",
    "href": "slides/11-midterm-review.html#explicit-coercion",
    "title": "Midterm review",
    "section": "Explicit coercion",
    "text": "Explicit coercion\n✅ From numeric to character\n\ndf |&gt;\n  mutate(x_new = as.character(x))\n\n# A tibble: 3 × 4\n      x y     z     x_new\n  &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt;\n1     1 a     TRUE  1    \n2     2 b     FALSE 2    \n3     3 c     TRUE  3"
  },
  {
    "objectID": "slides/11-midterm-review.html#explicit-coercion-1",
    "href": "slides/11-midterm-review.html#explicit-coercion-1",
    "title": "Midterm review",
    "section": "Explicit coercion",
    "text": "Explicit coercion\n❌ From character to numeric\n\ndf |&gt;\n  mutate(y_new = as.numeric(y))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `y_new = as.numeric(y)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n# A tibble: 3 × 4\n      x y     z     y_new\n  &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;dbl&gt;\n1     1 a     TRUE     NA\n2     2 b     FALSE    NA\n3     3 c     TRUE     NA"
  },
  {
    "objectID": "slides/11-midterm-review.html#implicit-coercion",
    "href": "slides/11-midterm-review.html#implicit-coercion",
    "title": "Midterm review",
    "section": "Implicit coercion",
    "text": "Implicit coercion\n\nWhich of the column types were implicitly coerced?\n\n\ndf &lt;- tibble(\n  w = c(1, 2, 3),\n  x = c(\"a\", \"b\", 4),\n  y = c(\"c\", \"d\", NA),\n  z = c(5, 6, NA),\n)\ndf\n\n# A tibble: 3 × 4\n      w x     y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a     c         5\n2     2 b     d         6\n3     3 4     &lt;NA&gt;     NA"
  },
  {
    "objectID": "slides/11-midterm-review.html#collecting-data",
    "href": "slides/11-midterm-review.html#collecting-data",
    "title": "Midterm review",
    "section": "Collecting data",
    "text": "Collecting data\n\nSuppose you conduct a survey and ask students their student ID number and number of credits they’re taking this semester. What is the type of each variable?\n\n. . .\n\nsurvey_raw &lt;- tibble(\n  student_id = c(273674, 298765, 287129, \"I don't remember\"),\n  n_credits = c(4, 4.5, \"I'm not sure yet\", \"2 - underloading\")\n)\nsurvey_raw\n\n# A tibble: 4 × 2\n  student_id       n_credits       \n  &lt;chr&gt;            &lt;chr&gt;           \n1 273674           4               \n2 298765           4.5             \n3 287129           I'm not sure yet\n4 I don't remember 2 - underloading"
  },
  {
    "objectID": "slides/11-midterm-review.html#cleaning-data",
    "href": "slides/11-midterm-review.html#cleaning-data",
    "title": "Midterm review",
    "section": "Cleaning data",
    "text": "Cleaning data\n\nsurvey &lt;- survey_raw |&gt;\n  mutate(\n    student_id = if_else(student_id == \"I don't remember\", NA, student_id),\n    n_credits = case_when(\n      n_credits == \"I'm not sure yet\" ~ NA,\n      n_credits == \"2 - underloading\" ~ \"2\",\n      .default = n_credits\n    ),\n    n_credits = as.numeric(n_credits)\n  )\nsurvey\n\n# A tibble: 4 × 2\n  student_id n_credits\n  &lt;chr&gt;          &lt;dbl&gt;\n1 273674           4  \n2 298765           4.5\n3 287129          NA  \n4 &lt;NA&gt;             2"
  },
  {
    "objectID": "slides/11-midterm-review.html#cleaning-data-alternative",
    "href": "slides/11-midterm-review.html#cleaning-data-alternative",
    "title": "Midterm review",
    "section": "Cleaning data – alternative",
    "text": "Cleaning data – alternative\n\nsurvey &lt;- survey_raw |&gt;\n  mutate(\n    student_id = parse_number(student_id),\n    n_credits = parse_number(n_credits)\n  )\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `student_id = parse_number(student_id)`.\nCaused by warning:\n! 1 parsing failure.\nrow col expected           actual\n  4  -- a number I don't remember\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\nsurvey\n\n# A tibble: 4 × 2\n  student_id n_credits\n       &lt;dbl&gt;     &lt;dbl&gt;\n1     273674       4  \n2     298765       4.5\n3     287129      NA  \n4         NA       2"
  },
  {
    "objectID": "slides/11-midterm-review.html#recap-type-coercion",
    "href": "slides/11-midterm-review.html#recap-type-coercion",
    "title": "Midterm review",
    "section": "Recap: Type coercion",
    "text": "Recap: Type coercion\n\n\nIf variables in a data frame have multiple types of values, R will coerce them into a single type, which may or may not be what you want.\nIf what R does by default is not what you want, you can use explicit coercion functions like as.numeric(), as.character(), etc. to turn them into the types you want them to be, which will generally also involve cleaning up the features of the data that caused the unwanted implicit coercion in the first place."
  },
  {
    "objectID": "slides/11-midterm-review.html#openintroloan50",
    "href": "slides/11-midterm-review.html#openintroloan50",
    "title": "Midterm review",
    "section": "openintro::loan50",
    "text": "openintro::loan50"
  },
  {
    "objectID": "slides/11-midterm-review.html#aesthetic-mappings",
    "href": "slides/11-midterm-review.html#aesthetic-mappings",
    "title": "Midterm review",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\n\nWhat will the following code result in?"
  },
  {
    "objectID": "slides/11-midterm-review.html#global-mappings",
    "href": "slides/11-midterm-review.html#global-mappings",
    "title": "Midterm review",
    "section": "Global mappings",
    "text": "Global mappings\n\nWhat will the following code result in?"
  },
  {
    "objectID": "slides/11-midterm-review.html#local-mappings",
    "href": "slides/11-midterm-review.html#local-mappings",
    "title": "Midterm review",
    "section": "Local mappings",
    "text": "Local mappings\n\nWhat will the following code result in?"
  },
  {
    "objectID": "slides/11-midterm-review.html#mapping-vs.-setting",
    "href": "slides/11-midterm-review.html#mapping-vs.-setting",
    "title": "Midterm review",
    "section": "Mapping vs. setting",
    "text": "Mapping vs. setting\n\nWhat will the following code result in?"
  },
  {
    "objectID": "slides/11-midterm-review.html#recap-aesthetic-mappings",
    "href": "slides/11-midterm-review.html#recap-aesthetic-mappings",
    "title": "Midterm review",
    "section": "Recap: Aesthetic mappings",
    "text": "Recap: Aesthetic mappings\n\n\nAesthetic mapping defined at the global level will be used by all geoms for which the aesthetic is defined.\nAesthetic mapping defined at the local level will be used only by the geoms they’re defined for."
  },
  {
    "objectID": "slides/11-midterm-review.html#aside-legends",
    "href": "slides/11-midterm-review.html#aside-legends",
    "title": "Midterm review",
    "section": "Aside: Legends",
    "text": "Aside: Legends"
  },
  {
    "objectID": "slides/11-midterm-review.html#aside-legends-1",
    "href": "slides/11-midterm-review.html#aside-legends-1",
    "title": "Midterm review",
    "section": "Aside: Legends",
    "text": "Aside: Legends\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  scale_color_colorblind() +\n  labs(color = \"Home ownership\")"
  },
  {
    "objectID": "slides/11-midterm-review.html#aside-legends-2",
    "href": "slides/11-midterm-review.html#aside-legends-2",
    "title": "Midterm review",
    "section": "Aside: Legends",
    "text": "Aside: Legends\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  scale_color_colorblind() +\n  labs(\n    color = \"Home ownership\",\n    shape = \"Home ownership\"\n  )"
  },
  {
    "objectID": "slides/11-midterm-review.html#factors",
    "href": "slides/11-midterm-review.html#factors",
    "title": "Midterm review",
    "section": "Factors",
    "text": "Factors\n\nFactors are used for categorical variables – variables that have a fixed and known set of possible values.\nThey are also useful when you want to display character vectors in a non-alphabetical order.\n\n\n\nR4DS: https://r4ds.hadley.nz/factors."
  },
  {
    "objectID": "slides/11-midterm-review.html#bar-plot",
    "href": "slides/11-midterm-review.html#bar-plot",
    "title": "Midterm review",
    "section": "Bar plot",
    "text": "Bar plot"
  },
  {
    "objectID": "slides/11-midterm-review.html#bar-plot---reordered",
    "href": "slides/11-midterm-review.html#bar-plot---reordered",
    "title": "Midterm review",
    "section": "Bar plot - reordered",
    "text": "Bar plot - reordered"
  },
  {
    "objectID": "slides/11-midterm-review.html#frequency-table",
    "href": "slides/11-midterm-review.html#frequency-table",
    "title": "Midterm review",
    "section": "Frequency table",
    "text": "Frequency table"
  },
  {
    "objectID": "slides/11-midterm-review.html#bar-plot---reordered-1",
    "href": "slides/11-midterm-review.html#bar-plot---reordered-1",
    "title": "Midterm review",
    "section": "Bar plot - reordered",
    "text": "Bar plot - reordered"
  },
  {
    "objectID": "slides/11-midterm-review.html#under-the-hood",
    "href": "slides/11-midterm-review.html#under-the-hood",
    "title": "Midterm review",
    "section": "Under the hood",
    "text": "Under the hood\n\n\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n\n\n. . ."
  },
  {
    "objectID": "slides/11-midterm-review.html#recap-factors",
    "href": "slides/11-midterm-review.html#recap-factors",
    "title": "Midterm review",
    "section": "Recap: Factors",
    "text": "Recap: Factors\n\n\nThe forcats package has a bunch of functions (that start with fct_*()) for dealing with factors and their levels: https://forcats.tidyverse.org/reference/index.html\nFactors and the order of their levels are relevant for displays (tables, plots) and they’ll be relevant for modeling (later in the course)\nfactor is a data class"
  },
  {
    "objectID": "slides/11-midterm-review.html#aside",
    "href": "slides/11-midterm-review.html#aside",
    "title": "Midterm review",
    "section": "Aside: ==\n",
    "text": "Aside: =="
  },
  {
    "objectID": "slides/11-midterm-review.html#aside-1",
    "href": "slides/11-midterm-review.html#aside-1",
    "title": "Midterm review",
    "section": "Aside: |\n",
    "text": "Aside: |"
  },
  {
    "objectID": "slides/11-midterm-review.html#aside-2",
    "href": "slides/11-midterm-review.html#aside-2",
    "title": "Midterm review",
    "section": "Aside: |\n",
    "text": "Aside: |"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#while-you-wait",
    "href": "slides/11-midterm-review-slides.html#while-you-wait",
    "title": "Midterm review",
    "section": "While you wait…",
    "text": "While you wait…\n\nGo to your ae project in RStudio\nMake sure you have each piece of information we need extracted from The Chronicle opinion page – up to create a data frame in chronicle-scrape.R."
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#announcements",
    "href": "slides/11-midterm-review-slides.html#announcements",
    "title": "Midterm review",
    "section": "Announcements",
    "text": "Announcements\nMidterm things:\n\nExam room: Bio Sci 111 or Gross Hall 107\nCheat sheet: 8.5x11, both sides, hand written or typed, any content you want, must be prepared by you\nAlso bring a pencil and eraser (you’re allowed to use a pen, but you might not want to)\nReminder: Academic dishonesty / Duke Community Standard"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#opinion-articles-in-the-chronicle",
    "href": "slides/11-midterm-review-slides.html#opinion-articles-in-the-chronicle",
    "title": "Midterm review",
    "section": "Opinion articles in The Chronicle",
    "text": "Opinion articles in The Chronicle\n\n\n\nScrape data and organize it in a tidy format in R\nPerform light text parsing to clean data\nSummarize and visualize the data"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#ae-10-chronicle-scrape",
    "href": "slides/11-midterm-review-slides.html#ae-10-chronicle-scrape",
    "title": "Midterm review",
    "section": "ae-10-chronicle-scrape",
    "text": "ae-10-chronicle-scrape\n\n\nGo to your ae project in RStudio.\nOpen chronicle-scrape.R and ae-10-chronicle-scrape.qmd."
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#recap",
    "href": "slides/11-midterm-review-slides.html#recap",
    "title": "Midterm review",
    "section": "Recap",
    "text": "Recap\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse rvest to first read the whole page (into R) and then parse the object you’ve read in to the elements you’re interested in\nPut the components together in a data frame (a tibble) and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#a-new-r-workflow",
    "href": "slides/11-midterm-review-slides.html#a-new-r-workflow",
    "title": "Midterm review",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in a Quarto document, your analysis is re-run each time you knit\nIf web scraping in a Quarto document, you’d be re-scraping the data each time you knit, which is undesirable (and not nice)!\n\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your Quarto document"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#ae-09-age-gaps-sales-import",
    "href": "slides/11-midterm-review-slides.html#ae-09-age-gaps-sales-import",
    "title": "Midterm review",
    "section": "ae-09-age-gaps-sales-import",
    "text": "ae-09-age-gaps-sales-import\n\n\nGo to your ae project in RStudio.\nOpen ae-09-age-gaps-sales-import.qmd - Part 2."
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#your-document-environment-vs.-your-global-environment",
    "href": "slides/11-midterm-review-slides.html#your-document-environment-vs.-your-global-environment",
    "title": "Midterm review",
    "section": "Your document environment vs. your global environment",
    "text": "Your document environment vs. your global environment\n\nObjects you define in your Quarto document are available in your Quarto document, and if you ran that code cell individually, they will also be available in your global environment\nObjects you define in your global environment are not, by default, available in your Quarto document"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#recipe-for-success-for-reproducible-documents",
    "href": "slides/11-midterm-review-slides.html#recipe-for-success-for-reproducible-documents",
    "title": "Midterm review",
    "section": "Recipe for success for reproducible documents",
    "text": "Recipe for success for reproducible documents\n\nRender – after each “win” or at each stopping point\nCommit – all files, with a commit message that describes the substance of what you did\nPush – to make sure files are updated on GitHub as well"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#explicit-vs.-implicit-type-coercion",
    "href": "slides/11-midterm-review-slides.html#explicit-vs.-implicit-type-coercion",
    "title": "Midterm review",
    "section": "Explicit vs. implicit type coercion",
    "text": "Explicit vs. implicit type coercion\n\nExplicit type coercion: You ask R to change the type of a variable\n\nImplicit type coercion: R changes / makes assumptions for you about the type of a variable without you asking for it\n\nThis happens because in a vector, you can’t have multiple types of values"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#vectors",
    "href": "slides/11-midterm-review-slides.html#vectors",
    "title": "Midterm review",
    "section": "Vectors",
    "text": "Vectors\n\n\n\nA vector is a collection of values\n\nAtomic vectors can only contain values of the same type\nLists can contain values of different types\n\n\nWhy do we care? Because each column of a data frame is a vector.\n\n\n\n\nlibrary(tidyverse)\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3),          # numeric (double)\n  y = c(\"a\", \"b\", \"c\"),    # character\n  z = c(TRUE, FALSE, TRUE) # logical\n)\ndf\n\n# A tibble: 3 × 3\n      x y     z    \n  &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt;\n1     1 a     TRUE \n2     2 b     FALSE\n3     3 c     TRUE"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#explicit-coercion",
    "href": "slides/11-midterm-review-slides.html#explicit-coercion",
    "title": "Midterm review",
    "section": "Explicit coercion",
    "text": "Explicit coercion\n✅ From numeric to character\n\ndf |&gt;\n  mutate(x_new = as.character(x))\n\n# A tibble: 3 × 4\n      x y     z     x_new\n  &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt;\n1     1 a     TRUE  1    \n2     2 b     FALSE 2    \n3     3 c     TRUE  3"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#explicit-coercion-1",
    "href": "slides/11-midterm-review-slides.html#explicit-coercion-1",
    "title": "Midterm review",
    "section": "Explicit coercion",
    "text": "Explicit coercion\n❌ From character to numeric\n\ndf |&gt;\n  mutate(y_new = as.numeric(y))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `y_new = as.numeric(y)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n# A tibble: 3 × 4\n      x y     z     y_new\n  &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;dbl&gt;\n1     1 a     TRUE     NA\n2     2 b     FALSE    NA\n3     3 c     TRUE     NA"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#implicit-coercion",
    "href": "slides/11-midterm-review-slides.html#implicit-coercion",
    "title": "Midterm review",
    "section": "Implicit coercion",
    "text": "Implicit coercion\n\nWhich of the column types were implicitly coerced?\n\n\ndf &lt;- tibble(\n  w = c(1, 2, 3),\n  x = c(\"a\", \"b\", 4),\n  y = c(\"c\", \"d\", NA),\n  z = c(5, 6, NA),\n)\ndf\n\n# A tibble: 3 × 4\n      w x     y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a     c         5\n2     2 b     d         6\n3     3 4     &lt;NA&gt;     NA"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#collecting-data",
    "href": "slides/11-midterm-review-slides.html#collecting-data",
    "title": "Midterm review",
    "section": "Collecting data",
    "text": "Collecting data\n\nSuppose you conduct a survey and ask students their student ID number and number of credits they’re taking this semester. What is the type of each variable?\n\n\n\nsurvey_raw &lt;- tibble(\n  student_id = c(273674, 298765, 287129, \"I don't remember\"),\n  n_credits = c(4, 4.5, \"I'm not sure yet\", \"2 - underloading\")\n)\nsurvey_raw\n\n# A tibble: 4 × 2\n  student_id       n_credits       \n  &lt;chr&gt;            &lt;chr&gt;           \n1 273674           4               \n2 298765           4.5             \n3 287129           I'm not sure yet\n4 I don't remember 2 - underloading"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#cleaning-data",
    "href": "slides/11-midterm-review-slides.html#cleaning-data",
    "title": "Midterm review",
    "section": "Cleaning data",
    "text": "Cleaning data\n\nsurvey &lt;- survey_raw |&gt;\n  mutate(\n    student_id = if_else(student_id == \"I don't remember\", NA, student_id),\n    n_credits = case_when(\n      n_credits == \"I'm not sure yet\" ~ NA,\n      n_credits == \"2 - underloading\" ~ \"2\",\n      .default = n_credits\n    ),\n    n_credits = as.numeric(n_credits)\n  )\nsurvey\n\n# A tibble: 4 × 2\n  student_id n_credits\n  &lt;chr&gt;          &lt;dbl&gt;\n1 273674           4  \n2 298765           4.5\n3 287129          NA  \n4 &lt;NA&gt;             2"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#cleaning-data-alternative",
    "href": "slides/11-midterm-review-slides.html#cleaning-data-alternative",
    "title": "Midterm review",
    "section": "Cleaning data – alternative",
    "text": "Cleaning data – alternative\n\nsurvey &lt;- survey_raw |&gt;\n  mutate(\n    student_id = parse_number(student_id),\n    n_credits = parse_number(n_credits)\n  )\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `student_id = parse_number(student_id)`.\nCaused by warning:\n! 1 parsing failure.\nrow col expected           actual\n  4  -- a number I don't remember\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\nsurvey\n\n# A tibble: 4 × 2\n  student_id n_credits\n       &lt;dbl&gt;     &lt;dbl&gt;\n1     273674       4  \n2     298765       4.5\n3     287129      NA  \n4         NA       2"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#recap-type-coercion",
    "href": "slides/11-midterm-review-slides.html#recap-type-coercion",
    "title": "Midterm review",
    "section": "Recap: Type coercion",
    "text": "Recap: Type coercion\n\n\nIf variables in a data frame have multiple types of values, R will coerce them into a single type, which may or may not be what you want.\nIf what R does by default is not what you want, you can use explicit coercion functions like as.numeric(), as.character(), etc. to turn them into the types you want them to be, which will generally also involve cleaning up the features of the data that caused the unwanted implicit coercion in the first place."
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#openintroloan50",
    "href": "slides/11-midterm-review-slides.html#openintroloan50",
    "title": "Midterm review",
    "section": "openintro::loan50",
    "text": "openintro::loan50"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#aesthetic-mappings",
    "href": "slides/11-midterm-review-slides.html#aesthetic-mappings",
    "title": "Midterm review",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\n\nWhat will the following code result in?"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#global-mappings",
    "href": "slides/11-midterm-review-slides.html#global-mappings",
    "title": "Midterm review",
    "section": "Global mappings",
    "text": "Global mappings\n\nWhat will the following code result in?"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#local-mappings",
    "href": "slides/11-midterm-review-slides.html#local-mappings",
    "title": "Midterm review",
    "section": "Local mappings",
    "text": "Local mappings\n\nWhat will the following code result in?"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#mapping-vs.-setting",
    "href": "slides/11-midterm-review-slides.html#mapping-vs.-setting",
    "title": "Midterm review",
    "section": "Mapping vs. setting",
    "text": "Mapping vs. setting\n\nWhat will the following code result in?"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#recap-aesthetic-mappings",
    "href": "slides/11-midterm-review-slides.html#recap-aesthetic-mappings",
    "title": "Midterm review",
    "section": "Recap: Aesthetic mappings",
    "text": "Recap: Aesthetic mappings\n\n\nAesthetic mapping defined at the global level will be used by all geoms for which the aesthetic is defined.\nAesthetic mapping defined at the local level will be used only by the geoms they’re defined for."
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#aside-legends",
    "href": "slides/11-midterm-review-slides.html#aside-legends",
    "title": "Midterm review",
    "section": "Aside: Legends",
    "text": "Aside: Legends"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#aside-legends-1",
    "href": "slides/11-midterm-review-slides.html#aside-legends-1",
    "title": "Midterm review",
    "section": "Aside: Legends",
    "text": "Aside: Legends\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  scale_color_colorblind() +\n  labs(color = \"Home ownership\")"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#aside-legends-2",
    "href": "slides/11-midterm-review-slides.html#aside-legends-2",
    "title": "Midterm review",
    "section": "Aside: Legends",
    "text": "Aside: Legends\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  scale_color_colorblind() +\n  labs(\n    color = \"Home ownership\",\n    shape = \"Home ownership\"\n  )"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#factors",
    "href": "slides/11-midterm-review-slides.html#factors",
    "title": "Midterm review",
    "section": "Factors",
    "text": "Factors\n\nFactors are used for categorical variables – variables that have a fixed and known set of possible values.\nThey are also useful when you want to display character vectors in a non-alphabetical order.\n\n\n\nR4DS: https://r4ds.hadley.nz/factors."
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#bar-plot",
    "href": "slides/11-midterm-review-slides.html#bar-plot",
    "title": "Midterm review",
    "section": "Bar plot",
    "text": "Bar plot"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#bar-plot---reordered",
    "href": "slides/11-midterm-review-slides.html#bar-plot---reordered",
    "title": "Midterm review",
    "section": "Bar plot - reordered",
    "text": "Bar plot - reordered"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#frequency-table",
    "href": "slides/11-midterm-review-slides.html#frequency-table",
    "title": "Midterm review",
    "section": "Frequency table",
    "text": "Frequency table"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#bar-plot---reordered-1",
    "href": "slides/11-midterm-review-slides.html#bar-plot---reordered-1",
    "title": "Midterm review",
    "section": "Bar plot - reordered",
    "text": "Bar plot - reordered"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#under-the-hood",
    "href": "slides/11-midterm-review-slides.html#under-the-hood",
    "title": "Midterm review",
    "section": "Under the hood",
    "text": "Under the hood"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#recap-factors",
    "href": "slides/11-midterm-review-slides.html#recap-factors",
    "title": "Midterm review",
    "section": "Recap: Factors",
    "text": "Recap: Factors\n\n\nThe forcats package has a bunch of functions (that start with fct_*()) for dealing with factors and their levels: https://forcats.tidyverse.org/reference/index.html\nFactors and the order of their levels are relevant for displays (tables, plots) and they’ll be relevant for modeling (later in the course)\nfactor is a data class"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#aside",
    "href": "slides/11-midterm-review-slides.html#aside",
    "title": "Midterm review",
    "section": "Aside: ==\n",
    "text": "Aside: =="
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#aside-1",
    "href": "slides/11-midterm-review-slides.html#aside-1",
    "title": "Midterm review",
    "section": "Aside: |\n",
    "text": "Aside: |"
  },
  {
    "objectID": "slides/11-midterm-review-slides.html#aside-2",
    "href": "slides/11-midterm-review-slides.html#aside-2",
    "title": "Midterm review",
    "section": "Aside: |\n",
    "text": "Aside: |"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#while-you-wait",
    "href": "slides/15-linear-model-single-predictor.html#while-you-wait",
    "title": "Linear models with a single predictor",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-13-modeling-penguins.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#announcements",
    "href": "slides/15-linear-model-single-predictor.html#announcements",
    "title": "Linear models with a single predictor",
    "section": "Announcements",
    "text": "Announcements\n\nAE 12 (Tuesday’s AE) solutions posted for extra practice, AE 13 (today’s AE) incorporates bits of AE 12 we didn’t get to on Tuesday\nAcademic misconduct issues so far:\n\nUncited use of outside materials, including (and especially) AI tools\nSame work turned in by multiple students"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#spurious-correlations",
    "href": "slides/15-linear-model-single-predictor.html#spurious-correlations",
    "title": "Linear models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#spurious-correlations-1",
    "href": "slides/15-linear-model-single-predictor.html#spurious-correlations-1",
    "title": "Linear models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#data-prep",
    "href": "slides/15-linear-model-single-predictor.html#data-prep",
    "title": "Linear models with a single predictor",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\n\nRename the dataset as movie_scores\n\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#data-overview",
    "href": "slides/15-linear-model-single-predictor.html#data-overview",
    "title": "Linear models with a single predictor",
    "section": "Data overview",
    "text": "Data overview\n\nmovie_scores |&gt;\n  select(critics, audience)\n\n# A tibble: 146 × 2\n   critics audience\n     &lt;int&gt;    &lt;int&gt;\n 1      74       86\n 2      85       80\n 3      80       90\n 4      18       84\n 5      14       28\n 6      63       62\n 7      42       53\n 8      86       64\n 9      99       82\n10      89       87\n# ℹ 136 more rows"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#data-visualization",
    "href": "slides/15-linear-model-single-predictor.html#data-visualization",
    "title": "Linear models with a single predictor",
    "section": "Data visualization",
    "text": "Data visualization"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#regression-model-1",
    "href": "slides/15-linear-model-single-predictor.html#regression-model-1",
    "title": "Linear models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the outcome, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#regression-model",
    "href": "slides/15-linear-model-single-predictor.html#regression-model",
    "title": "Linear models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{#325b74}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{#325b74}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{#325b74}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#simple-linear-regression",
    "href": "slides/15-linear-model-single-predictor.html#simple-linear-regression",
    "title": "Linear models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nUse simple linear regression to model the relationship between a quantitative outcome (\\(Y\\)) and a single quantitative predictor (\\(X\\)): \\[\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}\\]\n\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\epsilon\\): Error (residual)"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#simple-linear-regression-1",
    "href": "slides/15-linear-model-single-predictor.html#simple-linear-regression-1",
    "title": "Linear models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\\[\\Large{\\hat{Y} = b_0 + b_1 X}\\]\n\n\n\\(b_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(b_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\n\nNo error term!"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "href": "slides/15-linear-model-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "title": "Linear models with a single predictor",
    "section": "Choosing values for \\(b_1\\) and \\(b_0\\)\n",
    "text": "Choosing values for \\(b_1\\) and \\(b_0\\)"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#residuals",
    "href": "slides/15-linear-model-single-predictor.html#residuals",
    "title": "Linear models with a single predictor",
    "section": "Residuals",
    "text": "Residuals\n\n\n\n\n\n\n\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}\\]"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#least-squares-line",
    "href": "slides/15-linear-model-single-predictor.html#least-squares-line",
    "title": "Linear models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#least-squares-line-1",
    "href": "slides/15-linear-model-single-predictor.html#least-squares-line-1",
    "title": "Linear models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#properties-of-least-squares-regression",
    "href": "slides/15-linear-model-single-predictor.html#properties-of-least-squares-regression",
    "title": "Linear models with a single predictor",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point (the coordinates corresponding to average \\(X\\) and average \\(Y\\)): \\(b_0 = \\bar{Y} - b_1~\\bar{X}\\)\nSlope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_Y}{s_X}\\)\nSum of the residuals is zero: \\(\\sum_{i = 1}^n \\epsilon_i = 0\\)\nResiduals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#interpreting-the-slope",
    "href": "slides/15-linear-model-single-predictor.html#interpreting-the-slope",
    "title": "Linear models with a single predictor",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\n\n\nQuestion\nSubmit\n\n\n\n\nThe slope of the model for predicting audience score from critics score is 0.519. Which of the following is the best interpretation of this value?\n\n\n\n\nFor every one point increase in the critics score, the audience score goes up by 0.519 points, on average.\nFor every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\nFor every one point increase in the critics score, the audience score goes up by 0.519 points.\nFor every one point increase in the audience score, the critics score goes up by 0.519 points, on average."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#interpreting-slope-intercept",
    "href": "slides/15-linear-model-single-predictor.html#interpreting-slope-intercept",
    "title": "Linear models with a single predictor",
    "section": "Interpreting slope & intercept",
    "text": "Interpreting slope & intercept\n\\[\\widehat{\\text{audience}} = 32.3 + 0.519 \\times \\text{critics}\\]\n\n\n\nSlope: For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\n\nIntercept: If the critics score is 0 points, we expect the audience score to be 32.3 points."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#is-the-intercept-meaningful",
    "href": "slides/15-linear-model-single-predictor.html#is-the-intercept-meaningful",
    "title": "Linear models with a single predictor",
    "section": "Is the intercept meaningful?",
    "text": "Is the intercept meaningful?\n✅ The intercept is meaningful in context of the data if\n\nthe predictor can feasibly take values equal to or near zero or\nthe predictor has values near zero in the observed data\n\n. . .\n🛑 Otherwise, it might not be meaningful!"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#ae-13-modeling-penguins",
    "href": "slides/15-linear-model-single-predictor.html#ae-13-modeling-penguins",
    "title": "Linear models with a single predictor",
    "section": "ae-13-modeling-penguins",
    "text": "ae-13-modeling-penguins\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-13-modeling-penguins.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#while-you-wait",
    "href": "slides/15-linear-model-single-predictor-slides.html#while-you-wait",
    "title": "Linear models with a single predictor",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-13-modeling-penguins.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#announcements",
    "href": "slides/15-linear-model-single-predictor-slides.html#announcements",
    "title": "Linear models with a single predictor",
    "section": "Announcements",
    "text": "Announcements\n\nAE 12 (Tuesday’s AE) solutions posted for extra practice, AE 13 (today’s AE) incorporates bits of AE 12 we didn’t get to on Tuesday\nAcademic misconduct issues so far:\n\nUncited use of outside materials, including (and especially) AI tools\nSame work turned in by multiple students"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#spurious-correlations",
    "href": "slides/15-linear-model-single-predictor-slides.html#spurious-correlations",
    "title": "Linear models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#spurious-correlations-1",
    "href": "slides/15-linear-model-single-predictor-slides.html#spurious-correlations-1",
    "title": "Linear models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#data-prep",
    "href": "slides/15-linear-model-single-predictor-slides.html#data-prep",
    "title": "Linear models with a single predictor",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\n\nRename the dataset as movie_scores\n\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#data-overview",
    "href": "slides/15-linear-model-single-predictor-slides.html#data-overview",
    "title": "Linear models with a single predictor",
    "section": "Data overview",
    "text": "Data overview\n\nmovie_scores |&gt;\n  select(critics, audience)\n\n# A tibble: 146 × 2\n   critics audience\n     &lt;int&gt;    &lt;int&gt;\n 1      74       86\n 2      85       80\n 3      80       90\n 4      18       84\n 5      14       28\n 6      63       62\n 7      42       53\n 8      86       64\n 9      99       82\n10      89       87\n# ℹ 136 more rows"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#data-visualization",
    "href": "slides/15-linear-model-single-predictor-slides.html#data-visualization",
    "title": "Linear models with a single predictor",
    "section": "Data visualization",
    "text": "Data visualization"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#regression-model-1",
    "href": "slides/15-linear-model-single-predictor-slides.html#regression-model-1",
    "title": "Linear models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the outcome, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#regression-model",
    "href": "slides/15-linear-model-single-predictor-slides.html#regression-model",
    "title": "Linear models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{#325b74}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{#325b74}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{#325b74}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#simple-linear-regression",
    "href": "slides/15-linear-model-single-predictor-slides.html#simple-linear-regression",
    "title": "Linear models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nUse simple linear regression to model the relationship between a quantitative outcome (\\(Y\\)) and a single quantitative predictor (\\(X\\)): \\[\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}\\]\n\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\epsilon\\): Error (residual)"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#simple-linear-regression-1",
    "href": "slides/15-linear-model-single-predictor-slides.html#simple-linear-regression-1",
    "title": "Linear models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\\[\\Large{\\hat{Y} = b_0 + b_1 X}\\]\n\n\n\\(b_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(b_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\n\nNo error term!"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#choosing-values-for-b_1-and-b_0",
    "href": "slides/15-linear-model-single-predictor-slides.html#choosing-values-for-b_1-and-b_0",
    "title": "Linear models with a single predictor",
    "section": "Choosing values for \\(b_1\\) and \\(b_0\\)\n",
    "text": "Choosing values for \\(b_1\\) and \\(b_0\\)"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#residuals",
    "href": "slides/15-linear-model-single-predictor-slides.html#residuals",
    "title": "Linear models with a single predictor",
    "section": "Residuals",
    "text": "Residuals\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}\\]"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#least-squares-line",
    "href": "slides/15-linear-model-single-predictor-slides.html#least-squares-line",
    "title": "Linear models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#least-squares-line-1",
    "href": "slides/15-linear-model-single-predictor-slides.html#least-squares-line-1",
    "title": "Linear models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#properties-of-least-squares-regression",
    "href": "slides/15-linear-model-single-predictor-slides.html#properties-of-least-squares-regression",
    "title": "Linear models with a single predictor",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point (the coordinates corresponding to average \\(X\\) and average \\(Y\\)): \\(b_0 = \\bar{Y} - b_1~\\bar{X}\\)\nSlope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_Y}{s_X}\\)\nSum of the residuals is zero: \\(\\sum_{i = 1}^n \\epsilon_i = 0\\)\nResiduals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#interpreting-the-slope",
    "href": "slides/15-linear-model-single-predictor-slides.html#interpreting-the-slope",
    "title": "Linear models with a single predictor",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\n\n\nQuestion\nSubmit\n\n\n\n\nThe slope of the model for predicting audience score from critics score is 0.519. Which of the following is the best interpretation of this value?\n\n\n\n\nFor every one point increase in the critics score, the audience score goes up by 0.519 points, on average.\nFor every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\nFor every one point increase in the critics score, the audience score goes up by 0.519 points.\nFor every one point increase in the audience score, the critics score goes up by 0.519 points, on average."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#interpreting-slope-intercept",
    "href": "slides/15-linear-model-single-predictor-slides.html#interpreting-slope-intercept",
    "title": "Linear models with a single predictor",
    "section": "Interpreting slope & intercept",
    "text": "Interpreting slope & intercept\n\\[\\widehat{\\text{audience}} = 32.3 + 0.519 \\times \\text{critics}\\]\n\n\n\nSlope: For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\n\nIntercept: If the critics score is 0 points, we expect the audience score to be 32.3 points."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#is-the-intercept-meaningful",
    "href": "slides/15-linear-model-single-predictor-slides.html#is-the-intercept-meaningful",
    "title": "Linear models with a single predictor",
    "section": "Is the intercept meaningful?",
    "text": "Is the intercept meaningful?\n✅ The intercept is meaningful in context of the data if\n\nthe predictor can feasibly take values equal to or near zero or\nthe predictor has values near zero in the observed data\n\n\n🛑 Otherwise, it might not be meaningful!"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor-slides.html#ae-13-modeling-penguins",
    "href": "slides/15-linear-model-single-predictor-slides.html#ae-13-modeling-penguins",
    "title": "Linear models with a single predictor",
    "section": "ae-13-modeling-penguins",
    "text": "ae-13-modeling-penguins\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-13-modeling-penguins.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/22-randomization.html#while-you-wait",
    "href": "slides/22-randomization.html#while-you-wait",
    "title": "Making decisions with randomization tests",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-18-duke-forest-bootstrap.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/22-randomization.html#announcements",
    "href": "slides/22-randomization.html#announcements",
    "title": "Making decisions with randomization tests",
    "section": "Announcements",
    "text": "Announcements\nBefore Monday, Nov 25\n\nBare minimum: Make substantial progress on your project write-up: Finish your introduction and exploratory data analysis (plots/summary statistics + their interpretations) + Write up methods you plan to use.\nIdeal: Start implementing the methods and get closer to answering your research question.\nYour work goes in index.qmd – as of yesterday 50% of teams had not yet touched this file!\nView (and review) your rendered project on your project website linked from the “About” section of your project repo."
  },
  {
    "objectID": "slides/22-randomization.html#packages",
    "href": "slides/22-randomization.html#packages",
    "title": "Making decisions with randomization tests",
    "section": "Packages",
    "text": "Packages\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables"
  },
  {
    "objectID": "slides/22-randomization.html#data-houses-in-duke-forest",
    "href": "slides/22-randomization.html#data-houses-in-duke-forest",
    "title": "Making decisions with randomization tests",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/22-randomization.html#modeling",
    "href": "slides/22-randomization.html#modeling",
    "title": "Making decisions with randomization tests",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- linear_reg() |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) # neatly format table to 2 digits\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/22-randomization.html#confidence-interval-for-the-slope",
    "href": "slides/22-randomization.html#confidence-interval-for-the-slope",
    "title": "Making decisions with randomization tests",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”"
  },
  {
    "objectID": "slides/22-randomization.html#slopes-of-bootstrap-samples",
    "href": "slides/22-randomization.html#slopes-of-bootstrap-samples",
    "title": "Making decisions with randomization tests",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/22-randomization.html#slopes-of-bootstrap-samples-1",
    "href": "slides/22-randomization.html#slopes-of-bootstrap-samples-1",
    "title": "Making decisions with randomization tests",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/22-randomization.html#confidence-level",
    "href": "slides/22-randomization.html#confidence-level",
    "title": "Making decisions with randomization tests",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/22-randomization.html#confidence-interval",
    "href": "slides/22-randomization.html#confidence-interval",
    "title": "Making decisions with randomization tests",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\n\n\n\n\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/22-randomization.html#ae-18-duke-forest-bootstrap",
    "href": "slides/22-randomization.html#ae-18-duke-forest-bootstrap",
    "title": "Making decisions with randomization tests",
    "section": "ae-18-duke-forest-bootstrap",
    "text": "ae-18-duke-forest-bootstrap\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-18-duke-forest-bootstrap.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/22-randomization.html#computing-the-ci-for-the-slope-i",
    "href": "slides/22-randomization.html#computing-the-ci-for-the-slope-i",
    "title": "Making decisions with randomization tests",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/22-randomization.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/22-randomization.html#computing-the-ci-for-the-slope-ii",
    "title": "Making decisions with randomization tests",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/22-randomization.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/22-randomization.html#computing-the-ci-for-the-slope-iii",
    "title": "Making decisions with randomization tests",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" # default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/22-randomization.html#precision-vs.-accuracy",
    "href": "slides/22-randomization.html#precision-vs.-accuracy",
    "title": "Making decisions with randomization tests",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n. . ."
  },
  {
    "objectID": "slides/22-randomization.html#precision-vs.-accuracy-1",
    "href": "slides/22-randomization.html#precision-vs.-accuracy-1",
    "title": "Making decisions with randomization tests",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?"
  },
  {
    "objectID": "slides/22-randomization.html#changing-confidence-level",
    "href": "slides/22-randomization.html#changing-confidence-level",
    "title": "Making decisions with randomization tests",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/22-randomization.html#changing-confidence-level-1",
    "href": "slides/22-randomization.html#changing-confidence-level-1",
    "title": "Making decisions with randomization tests",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/22-randomization.html#recap",
    "href": "slides/22-randomization.html#recap",
    "title": "Making decisions with randomization tests",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/22-randomization.html#why-do-we-construct-confidence-intervals",
    "href": "slides/22-randomization.html#why-do-we-construct-confidence-intervals",
    "title": "Making decisions with randomization tests",
    "section": "Why do we construct confidence intervals?",
    "text": "Why do we construct confidence intervals?\nTo estimate plausible values of a parameter of interest, e.g., a slope (\\(\\beta_1\\)), a mean (\\(\\mu\\)), a proportion (\\(p\\))."
  },
  {
    "objectID": "slides/22-randomization.html#what-is-bootstrapping",
    "href": "slides/22-randomization.html#what-is-bootstrapping",
    "title": "Making decisions with randomization tests",
    "section": "What is bootstrapping?",
    "text": "What is bootstrapping?\n\nBootstrapping is a statistical procedure that resamples(with replacement) a single data set to create many simulated samples.\nWe then use these simulated samples to quantify the uncertainty around the sample statistic we’re interested in, e.g., a slope (\\(b_1\\)), a mean (\\(\\bar{x}\\)), a proportion (\\(\\hat{p}\\))."
  },
  {
    "objectID": "slides/22-randomization.html#what-does-each-dot-on-the-plot-represent",
    "href": "slides/22-randomization.html#what-does-each-dot-on-the-plot-represent",
    "title": "Making decisions with randomization tests",
    "section": "What does each dot on the plot represent?",
    "text": "What does each dot on the plot represent?\nNote: The plot is of a bootstrap distribution of a sample mean.\n\nResample, with replacement, from the original data\nDo this 20 times (since there are 20 dots on the plot)\nCalculate the summary statistic of interest in each of these samples"
  },
  {
    "objectID": "slides/22-randomization.html#bootstrapping-for-categorical-data",
    "href": "slides/22-randomization.html#bootstrapping-for-categorical-data",
    "title": "Making decisions with randomization tests",
    "section": "Bootstrapping for categorical data",
    "text": "Bootstrapping for categorical data\n\nspecify(response = x, success = \"success level\")\ncalculate(stat = \"prop\")"
  },
  {
    "objectID": "slides/22-randomization.html#bootstrapping-for-other-stats",
    "href": "slides/22-randomization.html#bootstrapping-for-other-stats",
    "title": "Making decisions with randomization tests",
    "section": "Bootstrapping for other stats",
    "text": "Bootstrapping for other stats\n\ncalculate() documentation: infer.tidymodels.org/reference/calculate.html\ninfer pipelines: infer.tidymodels.org/articles/observed_stat_examples.html"
  },
  {
    "objectID": "slides/22-randomization.html#hypothesis-testing-1",
    "href": "slides/22-randomization.html#hypothesis-testing-1",
    "title": "Making decisions with randomization tests",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nA hypothesis test is a statistical technique used to evaluate competing claims using data\n\n\nNull hypothesis, \\(H_0\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n. . .\nNote: Hypotheses are always at the population level!"
  },
  {
    "objectID": "slides/22-randomization.html#setting-hypotheses",
    "href": "slides/22-randomization.html#setting-hypotheses",
    "title": "Making decisions with randomization tests",
    "section": "Setting hypotheses",
    "text": "Setting hypotheses\n\nNull hypothesis, \\(H_0\\): “There is nothing going on.” The slope of the model for predicting the prices of houses in Duke Forest from their areas is 0, \\(\\beta_1 = 0\\).\nAlternative hypothesis, \\(H_A\\): “There is something going on”. The slope of the model for predicting the prices of houses in Duke Forest from their areas is different than, \\(\\beta_1 \\ne 0\\)."
  },
  {
    "objectID": "slides/22-randomization.html#hypothesis-testing-mindset",
    "href": "slides/22-randomization.html#hypothesis-testing-mindset",
    "title": "Making decisions with randomization tests",
    "section": "Hypothesis testing “mindset”",
    "text": "Hypothesis testing “mindset”\n\nAssume you live in a world where null hypothesis is true: \\(\\beta_1 = 0\\).\nAsk yourself how likely you are to observe the sample statistic, or something even more extreme, in this world: \\(P(b_1 \\leq 159.48~or~b_1 \\geq 159.48 | \\beta_1 = 0)\\) = ?"
  },
  {
    "objectID": "slides/22-randomization.html#hypothesis-testing-as-a-court-trial",
    "href": "slides/22-randomization.html#hypothesis-testing-as-a-court-trial",
    "title": "Making decisions with randomization tests",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\n\n. . .\n\n\nPresent the evidence: Collect data\n\n. . .\n\n\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\n\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/22-randomization.html#hypothesis-testing-framework",
    "href": "slides/22-randomization.html#hypothesis-testing-framework",
    "title": "Making decisions with randomization tests",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\), that represents the status quo\nSet an alternative hypothesis, \\(H_A\\), that represents the research question, i.e. what we’re testing for\n\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/22-randomization.html#calculate-observed-slope",
    "href": "slides/22-randomization.html#calculate-observed-slope",
    "title": "Making decisions with randomization tests",
    "section": "Calculate observed slope",
    "text": "Calculate observed slope\n… which we have already done:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/22-randomization.html#simulate-null-distribution",
    "href": "slides/22-randomization.html#simulate-null-distribution",
    "title": "Making decisions with randomization tests",
    "section": "Simulate null distribution",
    "text": "Simulate null distribution\n\nset.seed(20241118)\nnull_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 100, type = \"permute\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/22-randomization.html#view-null-distribution",
    "href": "slides/22-randomization.html#view-null-distribution",
    "title": "Making decisions with randomization tests",
    "section": "View null distribution",
    "text": "View null distribution\n\nnull_dist\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term        estimate\n       &lt;int&gt; &lt;chr&gt;          &lt;dbl&gt;\n 1         1 intercept 547294.   \n 2         1 area           4.54 \n 3         2 intercept 568599.   \n 4         2 area          -3.13 \n 5         3 intercept 561547.   \n 6         3 area          -0.593\n 7         4 intercept 526286.   \n 8         4 area          12.1  \n 9         5 intercept 651476.   \n10         5 area         -33.0  \n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/22-randomization.html#visualize-null-distribution",
    "href": "slides/22-randomization.html#visualize-null-distribution",
    "title": "Making decisions with randomization tests",
    "section": "Visualize null distribution",
    "text": "Visualize null distribution\n\nnull_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 15)"
  },
  {
    "objectID": "slides/22-randomization.html#visualize-null-distribution-alternative",
    "href": "slides/22-randomization.html#visualize-null-distribution-alternative",
    "title": "Making decisions with randomization tests",
    "section": "Visualize null distribution (alternative)",
    "text": "Visualize null distribution (alternative)\n\nvisualize(null_dist) +\n  shade_p_value(obs_stat = observed_fit, direction = \"two-sided\")"
  },
  {
    "objectID": "slides/22-randomization.html#get-p-value",
    "href": "slides/22-randomization.html#get-p-value",
    "title": "Making decisions with randomization tests",
    "section": "Get p-value",
    "text": "Get p-value\n\nnull_dist |&gt;\n  get_p_value(obs_stat = observed_fit, direction = \"two-sided\")\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the\n`generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\nPlease be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the\n`generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n\n\n# A tibble: 2 × 2\n  term      p_value\n  &lt;chr&gt;       &lt;dbl&gt;\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/22-randomization.html#make-a-decision",
    "href": "slides/22-randomization.html#make-a-decision",
    "title": "Making decisions with randomization tests",
    "section": "Make a decision",
    "text": "Make a decision\n\nBased on the p-value calculated, what is the conclusion of the hypothesis test?"
  },
  {
    "objectID": "slides/22-randomization-slides.html#while-you-wait",
    "href": "slides/22-randomization-slides.html#while-you-wait",
    "title": "Making decisions with randomization tests",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-18-duke-forest-bootstrap.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/22-randomization-slides.html#announcements",
    "href": "slides/22-randomization-slides.html#announcements",
    "title": "Making decisions with randomization tests",
    "section": "Announcements",
    "text": "Announcements\nBefore Monday, Nov 25\n\nBare minimum: Make substantial progress on your project write-up: Finish your introduction and exploratory data analysis (plots/summary statistics + their interpretations) + Write up methods you plan to use.\nIdeal: Start implementing the methods and get closer to answering your research question.\nYour work goes in index.qmd – as of yesterday 50% of teams had not yet touched this file!\nView (and review) your rendered project on your project website linked from the “About” section of your project repo."
  },
  {
    "objectID": "slides/22-randomization-slides.html#packages",
    "href": "slides/22-randomization-slides.html#packages",
    "title": "Making decisions with randomization tests",
    "section": "Packages",
    "text": "Packages\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables"
  },
  {
    "objectID": "slides/22-randomization-slides.html#data-houses-in-duke-forest",
    "href": "slides/22-randomization-slides.html#data-houses-in-duke-forest",
    "title": "Making decisions with randomization tests",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/22-randomization-slides.html#modeling",
    "href": "slides/22-randomization-slides.html#modeling",
    "title": "Making decisions with randomization tests",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- linear_reg() |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) # neatly format table to 2 digits\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/22-randomization-slides.html#confidence-interval-for-the-slope",
    "href": "slides/22-randomization-slides.html#confidence-interval-for-the-slope",
    "title": "Making decisions with randomization tests",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”"
  },
  {
    "objectID": "slides/22-randomization-slides.html#slopes-of-bootstrap-samples",
    "href": "slides/22-randomization-slides.html#slopes-of-bootstrap-samples",
    "title": "Making decisions with randomization tests",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/22-randomization-slides.html#slopes-of-bootstrap-samples-1",
    "href": "slides/22-randomization-slides.html#slopes-of-bootstrap-samples-1",
    "title": "Making decisions with randomization tests",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/22-randomization-slides.html#confidence-level",
    "href": "slides/22-randomization-slides.html#confidence-level",
    "title": "Making decisions with randomization tests",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/22-randomization-slides.html#confidence-interval",
    "href": "slides/22-randomization-slides.html#confidence-interval",
    "title": "Making decisions with randomization tests",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/22-randomization-slides.html#ae-18-duke-forest-bootstrap",
    "href": "slides/22-randomization-slides.html#ae-18-duke-forest-bootstrap",
    "title": "Making decisions with randomization tests",
    "section": "ae-18-duke-forest-bootstrap",
    "text": "ae-18-duke-forest-bootstrap\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-18-duke-forest-bootstrap.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/22-randomization-slides.html#computing-the-ci-for-the-slope-i",
    "href": "slides/22-randomization-slides.html#computing-the-ci-for-the-slope-i",
    "title": "Making decisions with randomization tests",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/22-randomization-slides.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/22-randomization-slides.html#computing-the-ci-for-the-slope-ii",
    "title": "Making decisions with randomization tests",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/22-randomization-slides.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/22-randomization-slides.html#computing-the-ci-for-the-slope-iii",
    "title": "Making decisions with randomization tests",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" # default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/22-randomization-slides.html#precision-vs.-accuracy",
    "href": "slides/22-randomization-slides.html#precision-vs.-accuracy",
    "title": "Making decisions with randomization tests",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "slides/22-randomization-slides.html#precision-vs.-accuracy-1",
    "href": "slides/22-randomization-slides.html#precision-vs.-accuracy-1",
    "title": "Making decisions with randomization tests",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?"
  },
  {
    "objectID": "slides/22-randomization-slides.html#changing-confidence-level",
    "href": "slides/22-randomization-slides.html#changing-confidence-level",
    "title": "Making decisions with randomization tests",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/22-randomization-slides.html#changing-confidence-level-1",
    "href": "slides/22-randomization-slides.html#changing-confidence-level-1",
    "title": "Making decisions with randomization tests",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/22-randomization-slides.html#recap",
    "href": "slides/22-randomization-slides.html#recap",
    "title": "Making decisions with randomization tests",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/22-randomization-slides.html#why-do-we-construct-confidence-intervals",
    "href": "slides/22-randomization-slides.html#why-do-we-construct-confidence-intervals",
    "title": "Making decisions with randomization tests",
    "section": "Why do we construct confidence intervals?",
    "text": "Why do we construct confidence intervals?\nTo estimate plausible values of a parameter of interest, e.g., a slope (\\(\\beta_1\\)), a mean (\\(\\mu\\)), a proportion (\\(p\\))."
  },
  {
    "objectID": "slides/22-randomization-slides.html#what-is-bootstrapping",
    "href": "slides/22-randomization-slides.html#what-is-bootstrapping",
    "title": "Making decisions with randomization tests",
    "section": "What is bootstrapping?",
    "text": "What is bootstrapping?\n\nBootstrapping is a statistical procedure that resamples(with replacement) a single data set to create many simulated samples.\nWe then use these simulated samples to quantify the uncertainty around the sample statistic we’re interested in, e.g., a slope (\\(b_1\\)), a mean (\\(\\bar{x}\\)), a proportion (\\(\\hat{p}\\))."
  },
  {
    "objectID": "slides/22-randomization-slides.html#what-does-each-dot-on-the-plot-represent",
    "href": "slides/22-randomization-slides.html#what-does-each-dot-on-the-plot-represent",
    "title": "Making decisions with randomization tests",
    "section": "What does each dot on the plot represent?",
    "text": "What does each dot on the plot represent?\nNote: The plot is of a bootstrap distribution of a sample mean.\n\nResample, with replacement, from the original data\nDo this 20 times (since there are 20 dots on the plot)\nCalculate the summary statistic of interest in each of these samples"
  },
  {
    "objectID": "slides/22-randomization-slides.html#bootstrapping-for-categorical-data",
    "href": "slides/22-randomization-slides.html#bootstrapping-for-categorical-data",
    "title": "Making decisions with randomization tests",
    "section": "Bootstrapping for categorical data",
    "text": "Bootstrapping for categorical data\n\nspecify(response = x, success = \"success level\")\ncalculate(stat = \"prop\")"
  },
  {
    "objectID": "slides/22-randomization-slides.html#bootstrapping-for-other-stats",
    "href": "slides/22-randomization-slides.html#bootstrapping-for-other-stats",
    "title": "Making decisions with randomization tests",
    "section": "Bootstrapping for other stats",
    "text": "Bootstrapping for other stats\n\ncalculate() documentation: infer.tidymodels.org/reference/calculate.html\ninfer pipelines: infer.tidymodels.org/articles/observed_stat_examples.html"
  },
  {
    "objectID": "slides/22-randomization-slides.html#hypothesis-testing-1",
    "href": "slides/22-randomization-slides.html#hypothesis-testing-1",
    "title": "Making decisions with randomization tests",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nA hypothesis test is a statistical technique used to evaluate competing claims using data\n\n\nNull hypothesis, \\(H_0\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n\nNote: Hypotheses are always at the population level!"
  },
  {
    "objectID": "slides/22-randomization-slides.html#setting-hypotheses",
    "href": "slides/22-randomization-slides.html#setting-hypotheses",
    "title": "Making decisions with randomization tests",
    "section": "Setting hypotheses",
    "text": "Setting hypotheses\n\nNull hypothesis, \\(H_0\\): “There is nothing going on.” The slope of the model for predicting the prices of houses in Duke Forest from their areas is 0, \\(\\beta_1 = 0\\).\nAlternative hypothesis, \\(H_A\\): “There is something going on”. The slope of the model for predicting the prices of houses in Duke Forest from their areas is different than, \\(\\beta_1 \\ne 0\\)."
  },
  {
    "objectID": "slides/22-randomization-slides.html#hypothesis-testing-mindset",
    "href": "slides/22-randomization-slides.html#hypothesis-testing-mindset",
    "title": "Making decisions with randomization tests",
    "section": "Hypothesis testing “mindset”",
    "text": "Hypothesis testing “mindset”\n\nAssume you live in a world where null hypothesis is true: \\(\\beta_1 = 0\\).\nAsk yourself how likely you are to observe the sample statistic, or something even more extreme, in this world: \\(P(b_1 \\leq 159.48~or~b_1 \\geq 159.48 | \\beta_1 = 0)\\) = ?"
  },
  {
    "objectID": "slides/22-randomization-slides.html#hypothesis-testing-as-a-court-trial",
    "href": "slides/22-randomization-slides.html#hypothesis-testing-as-a-court-trial",
    "title": "Making decisions with randomization tests",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\n\n\n\n\nPresent the evidence: Collect data\n\n\n\n\n\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\n\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/22-randomization-slides.html#hypothesis-testing-framework",
    "href": "slides/22-randomization-slides.html#hypothesis-testing-framework",
    "title": "Making decisions with randomization tests",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\), that represents the status quo\nSet an alternative hypothesis, \\(H_A\\), that represents the research question, i.e. what we’re testing for\n\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/22-randomization-slides.html#calculate-observed-slope",
    "href": "slides/22-randomization-slides.html#calculate-observed-slope",
    "title": "Making decisions with randomization tests",
    "section": "Calculate observed slope",
    "text": "Calculate observed slope\n… which we have already done:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/22-randomization-slides.html#simulate-null-distribution",
    "href": "slides/22-randomization-slides.html#simulate-null-distribution",
    "title": "Making decisions with randomization tests",
    "section": "Simulate null distribution",
    "text": "Simulate null distribution\n\nset.seed(20241118)\nnull_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 100, type = \"permute\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/22-randomization-slides.html#view-null-distribution",
    "href": "slides/22-randomization-slides.html#view-null-distribution",
    "title": "Making decisions with randomization tests",
    "section": "View null distribution",
    "text": "View null distribution\n\nnull_dist\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term        estimate\n       &lt;int&gt; &lt;chr&gt;          &lt;dbl&gt;\n 1         1 intercept 547294.   \n 2         1 area           4.54 \n 3         2 intercept 568599.   \n 4         2 area          -3.13 \n 5         3 intercept 561547.   \n 6         3 area          -0.593\n 7         4 intercept 526286.   \n 8         4 area          12.1  \n 9         5 intercept 651476.   \n10         5 area         -33.0  \n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/22-randomization-slides.html#visualize-null-distribution",
    "href": "slides/22-randomization-slides.html#visualize-null-distribution",
    "title": "Making decisions with randomization tests",
    "section": "Visualize null distribution",
    "text": "Visualize null distribution\n\nnull_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 15)"
  },
  {
    "objectID": "slides/22-randomization-slides.html#visualize-null-distribution-alternative",
    "href": "slides/22-randomization-slides.html#visualize-null-distribution-alternative",
    "title": "Making decisions with randomization tests",
    "section": "Visualize null distribution (alternative)",
    "text": "Visualize null distribution (alternative)\n\nvisualize(null_dist) +\n  shade_p_value(obs_stat = observed_fit, direction = \"two-sided\")"
  },
  {
    "objectID": "slides/22-randomization-slides.html#get-p-value",
    "href": "slides/22-randomization-slides.html#get-p-value",
    "title": "Making decisions with randomization tests",
    "section": "Get p-value",
    "text": "Get p-value\n\nnull_dist |&gt;\n  get_p_value(obs_stat = observed_fit, direction = \"two-sided\")\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the\n`generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\nPlease be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the\n`generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n\n\n# A tibble: 2 × 2\n  term      p_value\n  &lt;chr&gt;       &lt;dbl&gt;\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/22-randomization-slides.html#make-a-decision",
    "href": "slides/22-randomization-slides.html#make-a-decision",
    "title": "Making decisions with randomization tests",
    "section": "Make a decision",
    "text": "Make a decision\n\nBased on the p-value calculated, what is the conclusion of the hypothesis test?"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#while-you-wait",
    "href": "slides/04-exploring-data-I.html#while-you-wait",
    "title": "Exploring data I",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-04-gerrymander-explore-I\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-04-gerrymander-explore-I.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/04-exploring-data-I.html#announcements",
    "href": "slides/04-exploring-data-I.html#announcements",
    "title": "Exploring data I",
    "section": "Announcements",
    "text": "Announcements\n\n\nWeekend office hours in Old Chem – bring your Duke Card, you’ll need to swipe/tap in to get in\nAEs are due by the end of class (precisely, by 2 pm) – done = at least one commit + push\nCoding principles bonus office hour, RSVP at https://forms.gle/mufcsHnPXejZbkdT8 – Thursday, 9/12 at 7:30 pm at Old Chem 116\n\nRStudio visual editor acting up?\n\nUsing Chrome – make sure to update!\nUsing another browser or update doesn’t solve the problem, come by my office hours to diagnose\n\n\nNew resource: Code along videos\nAny questions about lab before we get started?"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#packages",
    "href": "slides/04-exploring-data-I.html#packages",
    "title": "Exploring data I",
    "section": "Packages",
    "text": "Packages\n\nFor the data: usdata\n\n\n\nlibrary(usdata)\n\n\nFor the analysis: tidyverse and ggthemes\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ──────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#data-gerrymander",
    "href": "slides/04-exploring-data-I.html#data-gerrymander",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\ngerrymander\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK   \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL   \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL   \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL   \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL   \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL   \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL   \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL   \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR   \n10 AR-02    Hill      French     R            41.7    52.4     0 AR   \n# ℹ 425 more rows\n# ℹ 4 more variables: party18 &lt;chr&gt;, dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;,\n#   gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#what-is-gerrymandering",
    "href": "slides/04-exploring-data-I.html#what-is-gerrymandering",
    "title": "Exploring data I",
    "section": "What is gerrymandering?",
    "text": "What is gerrymandering?"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#data-gerrymander-1",
    "href": "slides/04-exploring-data-I.html#data-gerrymander-1",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\nWhat is a good first function to use to get to know a dataset?"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#data-gerrymander-2",
    "href": "slides/04-exploring-data-I.html#data-gerrymander-2",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\nRows: Congressional districts\n\nColumns:\n\nCongressional district and state\n2016 election: winning party, % for Clinton, % for Trump, whether a Democrat won the House election, name of election winner\n2018 election: winning party, whether a Democrat won the 2018 House election\nWhether a Democrat flipped the seat in the 2018 election\nPrevalence of gerrymandering: low, mid, and high"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#variable-types",
    "href": "slides/04-exploring-data-I.html#variable-types",
    "title": "Exploring data I",
    "section": "Variable types",
    "text": "Variable types\n\n\n\n\n\nVariable\nType\n\n\n\ndistrict\ncategorical, ID\n\n\nlast_name\ncategorical, ID\n\n\nfirst_name\ncategorical, ID\n\n\nparty16\ncategorical\n\n\nclinton16\nnumerical, continuous\n\n\ntrump16\nnumerical, continuous\n\n\ndem16\ncategorical\n\n\nstate\ncategorical\n\n\nparty18\ncategorical\n\n\ndem18\ncategorical\n\n\nflip18\ncategorical\n\n\ngerry\ncategorical, ordinal"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#univariate-analysis-1",
    "href": "slides/04-exploring-data-I.html#univariate-analysis-1",
    "title": "Exploring data I",
    "section": "Univariate analysis",
    "text": "Univariate analysis\nAnalyzing a single variable:\n\n\nNumerical: histogram, box plot, density plot, etc.\nCategorical: bar plot, pie chart, etc."
  },
  {
    "objectID": "slides/04-exploring-data-I.html#histogram---step-1",
    "href": "slides/04-exploring-data-I.html#histogram---step-1",
    "title": "Exploring data I",
    "section": "Histogram - Step 1",
    "text": "Histogram - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#histogram---step-2",
    "href": "slides/04-exploring-data-I.html#histogram---step-2",
    "title": "Exploring data I",
    "section": "Histogram - Step 2",
    "text": "Histogram - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#histogram---step-3",
    "href": "slides/04-exploring-data-I.html#histogram---step-3",
    "title": "Exploring data I",
    "section": "Histogram - Step 3",
    "text": "Histogram - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "slides/04-exploring-data-I.html#histogram---step-4",
    "href": "slides/04-exploring-data-I.html#histogram---step-4",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#histogram---step-5",
    "href": "slides/04-exploring-data-I.html#histogram---step-5",
    "title": "Exploring data I",
    "section": "Histogram - Step 5",
    "text": "Histogram - Step 5\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 5) +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = \"Count\"\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#box-plot---step-1",
    "href": "slides/04-exploring-data-I.html#box-plot---step-1",
    "title": "Exploring data I",
    "section": "Box plot - Step 1",
    "text": "Box plot - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#box-plot---step-2",
    "href": "slides/04-exploring-data-I.html#box-plot---step-2",
    "title": "Exploring data I",
    "section": "Box plot - Step 2",
    "text": "Box plot - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#box-plot---step-3",
    "href": "slides/04-exploring-data-I.html#box-plot---step-3",
    "title": "Exploring data I",
    "section": "Box plot - Step 3",
    "text": "Box plot - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#box-plot---alternative-step-2-3",
    "href": "slides/04-exploring-data-I.html#box-plot---alternative-step-2-3",
    "title": "Exploring data I",
    "section": "Box plot - Alternative Step 2 + 3",
    "text": "Box plot - Alternative Step 2 + 3"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#box-plot---step-4",
    "href": "slides/04-exploring-data-I.html#box-plot---step-4",
    "title": "Exploring data I",
    "section": "Box plot - Step 4",
    "text": "Box plot - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_boxplot() +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = NULL\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#density-plot---step-1",
    "href": "slides/04-exploring-data-I.html#density-plot---step-1",
    "title": "Exploring data I",
    "section": "Density plot - Step 1",
    "text": "Density plot - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#density-plot---step-2",
    "href": "slides/04-exploring-data-I.html#density-plot---step-2",
    "title": "Exploring data I",
    "section": "Density plot - Step 2",
    "text": "Density plot - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#density-plot---step-3",
    "href": "slides/04-exploring-data-I.html#density-plot---step-3",
    "title": "Exploring data I",
    "section": "Density plot - Step 3",
    "text": "Density plot - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#density-plot---step-4",
    "href": "slides/04-exploring-data-I.html#density-plot---step-4",
    "title": "Exploring data I",
    "section": "Density plot - Step 4",
    "text": "Density plot - Step 4"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#density-plot---step-5",
    "href": "slides/04-exploring-data-I.html#density-plot---step-5",
    "title": "Exploring data I",
    "section": "Density plot - Step 5",
    "text": "Density plot - Step 5"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#density-plot---step-6",
    "href": "slides/04-exploring-data-I.html#density-plot---step-6",
    "title": "Exploring data I",
    "section": "Density plot - Step 6",
    "text": "Density plot - Step 6"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#density-plot---step-7",
    "href": "slides/04-exploring-data-I.html#density-plot---step-7",
    "title": "Exploring data I",
    "section": "Density plot - Step 7",
    "text": "Density plot - Step 7"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#density-plot---step-8",
    "href": "slides/04-exploring-data-I.html#density-plot---step-8",
    "title": "Exploring data I",
    "section": "Density plot - Step 8",
    "text": "Density plot - Step 8\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0.5, linewidth = 2) +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = \"Density\"\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#summary-statistics",
    "href": "slides/04-exploring-data-I.html#summary-statistics",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#distribution-of-votes-for-trump-in-the-2016-election",
    "href": "slides/04-exploring-data-I.html#distribution-of-votes-for-trump-in-the-2016-election",
    "title": "Exploring data I",
    "section": "Distribution of votes for Trump in the 2016 election",
    "text": "Distribution of votes for Trump in the 2016 election\n\nDescribe the distribution of percent of vote received by Trump in 2016 Presidential Election from Congressional Districts.\n\n\nShape: The distribution of votes for Trump in the 2016 election from Congressional Districts is unimodal and left-skewed.\nCenter: The percent of vote received by Trump in the 2016 Presidential Election from a typical Congressional Districts is 48.7%.\nSpread: In the middle 50% of Congressional Districts, 34.8% to 58.1% of voters voted for Trump in the 2016 Presidential Election.\nUnusual observations: -"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#bivariate-analysis-1",
    "href": "slides/04-exploring-data-I.html#bivariate-analysis-1",
    "title": "Exploring data I",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\nAnalyzing the relationship between two variables:\n\n\nNumerical + numerical: scatterplot\nNumerical + categorical: side-by-side box plots, violin plots, etc.\nCategorical + categorical: stacked bar plots\nUsing an aesthetic (e.g., fill, color, shape, etc.) or facets to represent the second variable in any plot"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#side-by-side-box-plots",
    "href": "slides/04-exploring-data-I.html#side-by-side-box-plots",
    "title": "Exploring data I",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    y = gerry\n    )\n  ) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#summary-statistics-1",
    "href": "slides/04-exploring-data-I.html#summary-statistics-1",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#density-plots",
    "href": "slides/04-exploring-data-I.html#density-plots",
    "title": "Exploring data I",
    "section": "Density plots",
    "text": "Density plots\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    color = gerry\n    )\n  ) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#filled-density-plots",
    "href": "slides/04-exploring-data-I.html#filled-density-plots",
    "title": "Exploring data I",
    "section": "Filled density plots",
    "text": "Filled density plots\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    color = gerry,\n    fill = gerry\n    )\n  ) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#better-filled-density-plots",
    "href": "slides/04-exploring-data-I.html#better-filled-density-plots",
    "title": "Exploring data I",
    "section": "Better filled density plots",
    "text": "Better filled density plots\n\nggplot(\n  gerrymander, \n  aes(x = trump16, color = gerry, fill = gerry)\n  ) +\n  geom_density(alpha = 0.5)"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#better-colors",
    "href": "slides/04-exploring-data-I.html#better-colors",
    "title": "Exploring data I",
    "section": "Better colors",
    "text": "Better colors\n\nggplot(\n  gerrymander, \n  aes(x = trump16, color = gerry, fill = gerry)\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#violin-plots",
    "href": "slides/04-exploring-data-I.html#violin-plots",
    "title": "Exploring data I",
    "section": "Violin plots",
    "text": "Violin plots\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#multiple-geoms",
    "href": "slides/04-exploring-data-I.html#multiple-geoms",
    "title": "Exploring data I",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_point() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#multiple-geoms-1",
    "href": "slides/04-exploring-data-I.html#multiple-geoms-1",
    "title": "Exploring data I",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#remove-legend",
    "href": "slides/04-exploring-data-I.html#remove-legend",
    "title": "Exploring data I",
    "section": "Remove legend",
    "text": "Remove legend\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  scale_color_colorblind() +\n  scale_fill_colorblind() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#multivariate-analysis-1",
    "href": "slides/04-exploring-data-I.html#multivariate-analysis-1",
    "title": "Exploring data I",
    "section": "Multivariate analysis",
    "text": "Multivariate analysis\nAnalyzing the relationship between multiple variables:\n\n\nIn general, one variable is identified as the outcome of interest\nThe remaining variables are predictors or explanatory variables\n\nPlots for exploring multivariate relationships are the same as those for bivariate relationships, but conditional on one or more variables\n\nConditioning can be done via faceting or aesthetic mappings (e.g., scatterplot of y vs. x1, colored by x2, faceted by x3)\n\n\n\nSummary statistics for exploring multivariate relationships are the same as those for bivariate relationships, but conditional on one or more variables\n\nConditioning can be done via grouping (e.g., correlation between y and x1, grouped by levels of x2 and x3)"
  },
  {
    "objectID": "slides/04-exploring-data-I.html#ae-04-gerrymander-explore-i",
    "href": "slides/04-exploring-data-I.html#ae-04-gerrymander-explore-i",
    "title": "Exploring data I",
    "section": "ae-04-gerrymander-explore-I",
    "text": "ae-04-gerrymander-explore-I\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-04-gerrymander-explore-I.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#while-you-wait",
    "href": "slides/04-exploring-data-I-slides.html#while-you-wait",
    "title": "Exploring data I",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-04-gerrymander-explore-I\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-04-gerrymander-explore-I.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#announcements",
    "href": "slides/04-exploring-data-I-slides.html#announcements",
    "title": "Exploring data I",
    "section": "Announcements",
    "text": "Announcements\n\n\nWeekend office hours in Old Chem – bring your Duke Card, you’ll need to swipe/tap in to get in\nAEs are due by the end of class (precisely, by 2 pm) – done = at least one commit + push\nCoding principles bonus office hour, RSVP at https://forms.gle/mufcsHnPXejZbkdT8 – Thursday, 9/12 at 7:30 pm at Old Chem 116\n\nRStudio visual editor acting up?\n\nUsing Chrome – make sure to update!\nUsing another browser or update doesn’t solve the problem, come by my office hours to diagnose\n\n\nNew resource: Code along videos\nAny questions about lab before we get started?"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#packages",
    "href": "slides/04-exploring-data-I-slides.html#packages",
    "title": "Exploring data I",
    "section": "Packages",
    "text": "Packages\n\nFor the data: usdata\n\n\n\nlibrary(usdata)\n\n\nFor the analysis: tidyverse and ggthemes\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ──────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#data-gerrymander",
    "href": "slides/04-exploring-data-I-slides.html#data-gerrymander",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\ngerrymander\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK   \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL   \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL   \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL   \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL   \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL   \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL   \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL   \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR   \n10 AR-02    Hill      French     R            41.7    52.4     0 AR   \n# ℹ 425 more rows\n# ℹ 4 more variables: party18 &lt;chr&gt;, dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;,\n#   gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#what-is-gerrymandering",
    "href": "slides/04-exploring-data-I-slides.html#what-is-gerrymandering",
    "title": "Exploring data I",
    "section": "What is gerrymandering?",
    "text": "What is gerrymandering?"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#data-gerrymander-1",
    "href": "slides/04-exploring-data-I-slides.html#data-gerrymander-1",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\nWhat is a good first function to use to get to know a dataset?"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#data-gerrymander-2",
    "href": "slides/04-exploring-data-I-slides.html#data-gerrymander-2",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\nRows: Congressional districts\n\nColumns:\n\nCongressional district and state\n2016 election: winning party, % for Clinton, % for Trump, whether a Democrat won the House election, name of election winner\n2018 election: winning party, whether a Democrat won the 2018 House election\nWhether a Democrat flipped the seat in the 2018 election\nPrevalence of gerrymandering: low, mid, and high"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#variable-types",
    "href": "slides/04-exploring-data-I-slides.html#variable-types",
    "title": "Exploring data I",
    "section": "Variable types",
    "text": "Variable types\n\n\n\n\n\nVariable\nType\n\n\n\ndistrict\ncategorical, ID\n\n\nlast_name\ncategorical, ID\n\n\nfirst_name\ncategorical, ID\n\n\nparty16\ncategorical\n\n\nclinton16\nnumerical, continuous\n\n\ntrump16\nnumerical, continuous\n\n\ndem16\ncategorical\n\n\nstate\ncategorical\n\n\nparty18\ncategorical\n\n\ndem18\ncategorical\n\n\nflip18\ncategorical\n\n\ngerry\ncategorical, ordinal"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#univariate-analysis-1",
    "href": "slides/04-exploring-data-I-slides.html#univariate-analysis-1",
    "title": "Exploring data I",
    "section": "Univariate analysis",
    "text": "Univariate analysis\nAnalyzing a single variable:\n\n\nNumerical: histogram, box plot, density plot, etc.\nCategorical: bar plot, pie chart, etc."
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#histogram---step-1",
    "href": "slides/04-exploring-data-I-slides.html#histogram---step-1",
    "title": "Exploring data I",
    "section": "Histogram - Step 1",
    "text": "Histogram - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#histogram---step-2",
    "href": "slides/04-exploring-data-I-slides.html#histogram---step-2",
    "title": "Exploring data I",
    "section": "Histogram - Step 2",
    "text": "Histogram - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#histogram---step-3",
    "href": "slides/04-exploring-data-I-slides.html#histogram---step-3",
    "title": "Exploring data I",
    "section": "Histogram - Step 3",
    "text": "Histogram - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#histogram---step-4",
    "href": "slides/04-exploring-data-I-slides.html#histogram---step-4",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#histogram---step-5",
    "href": "slides/04-exploring-data-I-slides.html#histogram---step-5",
    "title": "Exploring data I",
    "section": "Histogram - Step 5",
    "text": "Histogram - Step 5\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 5) +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = \"Count\"\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#box-plot---step-1",
    "href": "slides/04-exploring-data-I-slides.html#box-plot---step-1",
    "title": "Exploring data I",
    "section": "Box plot - Step 1",
    "text": "Box plot - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#box-plot---step-2",
    "href": "slides/04-exploring-data-I-slides.html#box-plot---step-2",
    "title": "Exploring data I",
    "section": "Box plot - Step 2",
    "text": "Box plot - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#box-plot---step-3",
    "href": "slides/04-exploring-data-I-slides.html#box-plot---step-3",
    "title": "Exploring data I",
    "section": "Box plot - Step 3",
    "text": "Box plot - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#box-plot---alternative-step-2-3",
    "href": "slides/04-exploring-data-I-slides.html#box-plot---alternative-step-2-3",
    "title": "Exploring data I",
    "section": "Box plot - Alternative Step 2 + 3",
    "text": "Box plot - Alternative Step 2 + 3"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#box-plot---step-4",
    "href": "slides/04-exploring-data-I-slides.html#box-plot---step-4",
    "title": "Exploring data I",
    "section": "Box plot - Step 4",
    "text": "Box plot - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_boxplot() +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = NULL\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#density-plot---step-1",
    "href": "slides/04-exploring-data-I-slides.html#density-plot---step-1",
    "title": "Exploring data I",
    "section": "Density plot - Step 1",
    "text": "Density plot - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#density-plot---step-2",
    "href": "slides/04-exploring-data-I-slides.html#density-plot---step-2",
    "title": "Exploring data I",
    "section": "Density plot - Step 2",
    "text": "Density plot - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#density-plot---step-3",
    "href": "slides/04-exploring-data-I-slides.html#density-plot---step-3",
    "title": "Exploring data I",
    "section": "Density plot - Step 3",
    "text": "Density plot - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#density-plot---step-4",
    "href": "slides/04-exploring-data-I-slides.html#density-plot---step-4",
    "title": "Exploring data I",
    "section": "Density plot - Step 4",
    "text": "Density plot - Step 4"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#density-plot---step-5",
    "href": "slides/04-exploring-data-I-slides.html#density-plot---step-5",
    "title": "Exploring data I",
    "section": "Density plot - Step 5",
    "text": "Density plot - Step 5"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#density-plot---step-6",
    "href": "slides/04-exploring-data-I-slides.html#density-plot---step-6",
    "title": "Exploring data I",
    "section": "Density plot - Step 6",
    "text": "Density plot - Step 6"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#density-plot---step-7",
    "href": "slides/04-exploring-data-I-slides.html#density-plot---step-7",
    "title": "Exploring data I",
    "section": "Density plot - Step 7",
    "text": "Density plot - Step 7"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#density-plot---step-8",
    "href": "slides/04-exploring-data-I-slides.html#density-plot---step-8",
    "title": "Exploring data I",
    "section": "Density plot - Step 8",
    "text": "Density plot - Step 8\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0.5, linewidth = 2) +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = \"Density\"\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#summary-statistics",
    "href": "slides/04-exploring-data-I-slides.html#summary-statistics",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#distribution-of-votes-for-trump-in-the-2016-election",
    "href": "slides/04-exploring-data-I-slides.html#distribution-of-votes-for-trump-in-the-2016-election",
    "title": "Exploring data I",
    "section": "Distribution of votes for Trump in the 2016 election",
    "text": "Distribution of votes for Trump in the 2016 election\n\nDescribe the distribution of percent of vote received by Trump in 2016 Presidential Election from Congressional Districts.\n\n\nShape: The distribution of votes for Trump in the 2016 election from Congressional Districts is unimodal and left-skewed.\nCenter: The percent of vote received by Trump in the 2016 Presidential Election from a typical Congressional Districts is 48.7%.\nSpread: In the middle 50% of Congressional Districts, 34.8% to 58.1% of voters voted for Trump in the 2016 Presidential Election.\nUnusual observations: -"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#bivariate-analysis-1",
    "href": "slides/04-exploring-data-I-slides.html#bivariate-analysis-1",
    "title": "Exploring data I",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\nAnalyzing the relationship between two variables:\n\n\nNumerical + numerical: scatterplot\nNumerical + categorical: side-by-side box plots, violin plots, etc.\nCategorical + categorical: stacked bar plots\nUsing an aesthetic (e.g., fill, color, shape, etc.) or facets to represent the second variable in any plot"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#side-by-side-box-plots",
    "href": "slides/04-exploring-data-I-slides.html#side-by-side-box-plots",
    "title": "Exploring data I",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    y = gerry\n    )\n  ) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#summary-statistics-1",
    "href": "slides/04-exploring-data-I-slides.html#summary-statistics-1",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#density-plots",
    "href": "slides/04-exploring-data-I-slides.html#density-plots",
    "title": "Exploring data I",
    "section": "Density plots",
    "text": "Density plots\n\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    color = gerry\n    )\n  ) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#filled-density-plots",
    "href": "slides/04-exploring-data-I-slides.html#filled-density-plots",
    "title": "Exploring data I",
    "section": "Filled density plots",
    "text": "Filled density plots\n\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    color = gerry,\n    fill = gerry\n    )\n  ) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#better-filled-density-plots",
    "href": "slides/04-exploring-data-I-slides.html#better-filled-density-plots",
    "title": "Exploring data I",
    "section": "Better filled density plots",
    "text": "Better filled density plots\n\nggplot(\n  gerrymander, \n  aes(x = trump16, color = gerry, fill = gerry)\n  ) +\n  geom_density(alpha = 0.5)"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#better-colors",
    "href": "slides/04-exploring-data-I-slides.html#better-colors",
    "title": "Exploring data I",
    "section": "Better colors",
    "text": "Better colors\n\n\nggplot(\n  gerrymander, \n  aes(x = trump16, color = gerry, fill = gerry)\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#violin-plots",
    "href": "slides/04-exploring-data-I-slides.html#violin-plots",
    "title": "Exploring data I",
    "section": "Violin plots",
    "text": "Violin plots\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#multiple-geoms",
    "href": "slides/04-exploring-data-I-slides.html#multiple-geoms",
    "title": "Exploring data I",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_point() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#multiple-geoms-1",
    "href": "slides/04-exploring-data-I-slides.html#multiple-geoms-1",
    "title": "Exploring data I",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#remove-legend",
    "href": "slides/04-exploring-data-I-slides.html#remove-legend",
    "title": "Exploring data I",
    "section": "Remove legend",
    "text": "Remove legend\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  scale_color_colorblind() +\n  scale_fill_colorblind() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#multivariate-analysis-1",
    "href": "slides/04-exploring-data-I-slides.html#multivariate-analysis-1",
    "title": "Exploring data I",
    "section": "Multivariate analysis",
    "text": "Multivariate analysis\nAnalyzing the relationship between multiple variables:\n\n\nIn general, one variable is identified as the outcome of interest\nThe remaining variables are predictors or explanatory variables\n\nPlots for exploring multivariate relationships are the same as those for bivariate relationships, but conditional on one or more variables\n\nConditioning can be done via faceting or aesthetic mappings (e.g., scatterplot of y vs. x1, colored by x2, faceted by x3)\n\n\n\nSummary statistics for exploring multivariate relationships are the same as those for bivariate relationships, but conditional on one or more variables\n\nConditioning can be done via grouping (e.g., correlation between y and x1, grouped by levels of x2 and x3)"
  },
  {
    "objectID": "slides/04-exploring-data-I-slides.html#ae-04-gerrymander-explore-i",
    "href": "slides/04-exploring-data-I-slides.html#ae-04-gerrymander-explore-i",
    "title": "Exploring data I",
    "section": "ae-04-gerrymander-explore-I",
    "text": "ae-04-gerrymander-explore-I\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-04-gerrymander-explore-I.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/13-ethics.html#announcements",
    "href": "slides/13-ethics.html#announcements",
    "title": "Data science ethics",
    "section": "Announcements",
    "text": "Announcements\n\nPeer evaluation 1 due by 5:00 pm Friday (Oct 18) – look for an email from TEAMMATES\nMy office hours this week: 4:30 - 6:30 pm on Friday at Old Chem 213, back to normal next week\nLab on Monday: Work on project proposals!"
  },
  {
    "objectID": "slides/13-ethics.html#misrepresenting-data-science-results",
    "href": "slides/13-ethics.html#misrepresenting-data-science-results",
    "title": "Data science ethics",
    "section": "Misrepresenting data science results",
    "text": "Misrepresenting data science results\nSome common ways people do this, either intentionally or unintentionally, include:\n\n\nClaiming causality where it’s not in the scope of inference of the underlying study\nDistorting axes and scales to make the data tell a different story\nVisualizing spatial areas instead of human density for issues that depend on and affect humans\nOmitting uncertainty in reporting"
  },
  {
    "objectID": "slides/13-ethics.html#causality---time-coverage",
    "href": "slides/13-ethics.html#causality---time-coverage",
    "title": "Data science ethics",
    "section": "Causality - TIME coverage",
    "text": "Causality - TIME coverage\n\nHow plausible is the statement in the title of this article?\n\n\n\n\nAlice Park. Exercise Can Lower Risk of Some Cancers By 20%. Time Magazine. 16 May 2016."
  },
  {
    "objectID": "slides/13-ethics.html#causality---la-times-coverage",
    "href": "slides/13-ethics.html#causality---la-times-coverage",
    "title": "Data science ethics",
    "section": "Causality - LA Times coverage",
    "text": "Causality - LA Times coverage\n\nWhat does “research shows” mean?\n\n\n\n\nMelissa Healy. Exercising drives down risk for 13 cancers, research shows.\nLos Angeles Times. 16 May 2016."
  },
  {
    "objectID": "slides/13-ethics.html#causality---original-study",
    "href": "slides/13-ethics.html#causality---original-study",
    "title": "Data science ethics",
    "section": "Causality - Original study",
    "text": "Causality - Original study\nMoore, Steven C., et al. “Association of leisure-time physical activity with risk of 26 types of cancer in 1.44 million adults.” JAMA internal medicine 176.6 (2016): 816-825.\n\n\nVolunteers were asked about their physical activity level over the preceding year.\nHalf exercised less than about 150 minutes per week, half exercised more.\nCompared to the bottom 10% of exercisers, the top 10% had lower rates of esophageal, liver, lung, endometrial, colon, and breast cancer.\nResearchers found no association between exercising and 13 other cancers (e.g. pancreatic, ovarian, and brain).\n\n\nCarl Bergstrom and Jevin West. Calling Bullshit: The art of skepticism in a data-driven world.\nRandom House, 2020.\nSharon Begley. “Does exercise prevent cancer?”. StatNews. 16 May 2016."
  },
  {
    "objectID": "slides/13-ethics.html#axes-and-scales---tax-cuts",
    "href": "slides/13-ethics.html#axes-and-scales---tax-cuts",
    "title": "Data science ethics",
    "section": "Axes and scales - Tax cuts",
    "text": "Axes and scales - Tax cuts\n\nWhat is the difference between these two pictures? Which presents a better way to represent these data?\n\n\n\n\nChristopher Ingraham. “You’ve been reading charts wrong. Here’s how a pro does it.”. The Washington Post. 14 October 2019."
  },
  {
    "objectID": "slides/13-ethics.html#axes-and-scales---cost-of-gas",
    "href": "slides/13-ethics.html#axes-and-scales---cost-of-gas",
    "title": "Data science ethics",
    "section": "Axes and scales - Cost of gas",
    "text": "Axes and scales - Cost of gas\n\nWhat is wrong with this picture? How would you correct it?"
  },
  {
    "objectID": "slides/13-ethics.html#axes-and-scales---cost-of-gas-1",
    "href": "slides/13-ethics.html#axes-and-scales---cost-of-gas-1",
    "title": "Data science ethics",
    "section": "Axes and scales - Cost of gas",
    "text": "Axes and scales - Cost of gas"
  },
  {
    "objectID": "slides/13-ethics.html#axes-and-scales---covid-in-ga",
    "href": "slides/13-ethics.html#axes-and-scales---covid-in-ga",
    "title": "Data science ethics",
    "section": "Axes and scales - COVID in GA",
    "text": "Axes and scales - COVID in GA\n\nWhat is wrong with this picture? How would you correct it?\n\n\n\n\nGeorgia Department of Public Health. 11 May 2020."
  },
  {
    "objectID": "slides/13-ethics.html#axes-and-scales---covid-in-ga-1",
    "href": "slides/13-ethics.html#axes-and-scales---covid-in-ga-1",
    "title": "Data science ethics",
    "section": "Axes and scales - COVID in GA",
    "text": "Axes and scales - COVID in GA\n\n\n\nLucy D’Agostino McGowan. Graph detective. Live Free or Dichotomize. 17 May 2020."
  },
  {
    "objectID": "slides/13-ethics.html#axes-and-scales---pp-services",
    "href": "slides/13-ethics.html#axes-and-scales---pp-services",
    "title": "Data science ethics",
    "section": "Axes and scales - PP services",
    "text": "Axes and scales - PP services\n\n\n\nWhat is wrong with this picture? How would you correct it?\n\n\n\n\n\n\n\nTimothy B. Lee. Whatever you think of Planned Parenthood, this is a terrible and dishonest chart. Vox. 29 September 2019."
  },
  {
    "objectID": "slides/13-ethics.html#axes-and-scales---pp-services-1",
    "href": "slides/13-ethics.html#axes-and-scales---pp-services-1",
    "title": "Data science ethics",
    "section": "Axes and scales - PP services",
    "text": "Axes and scales - PP services"
  },
  {
    "objectID": "slides/13-ethics.html#maps-and-areas---voting-map",
    "href": "slides/13-ethics.html#maps-and-areas---voting-map",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting map",
    "text": "Maps and areas - Voting map\n\nDo you recognize this map? What does it show?\n\n\n\n\nLazaro Gamio. “Election maps are telling you big lies about small things”. The Washington Post. 1 Nov 2016."
  },
  {
    "objectID": "slides/13-ethics.html#maps-and-areas---two-alternate-tales",
    "href": "slides/13-ethics.html#maps-and-areas---two-alternate-tales",
    "title": "Data science ethics",
    "section": "Maps and areas - Two alternate tales",
    "text": "Maps and areas - Two alternate tales\n\n\n\n\n\n\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/13-ethics.html#maps-and-areas---voting-percentages",
    "href": "slides/13-ethics.html#maps-and-areas---voting-percentages",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting percentages",
    "text": "Maps and areas - Voting percentages\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/13-ethics.html#maps-and-areas---voting-percentages-1",
    "href": "slides/13-ethics.html#maps-and-areas---voting-percentages-1",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting percentages",
    "text": "Maps and areas - Voting percentages\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/13-ethics.html#uncertainty---catalan-independence",
    "href": "slides/13-ethics.html#uncertainty---catalan-independence",
    "title": "Data science ethics",
    "section": "Uncertainty - Catalan independence",
    "text": "Uncertainty - Catalan independence\nOn December 19, 2014, the front page of Spanish national newspaper El País read “Catalan public opinion swings toward ‘no’ for independence, says survey”.\n\n\n\n\n\n\n\n\n\n\nAlberto Cairo. The truthful art: Data, charts, and maps for communication. New Riders, 2016."
  },
  {
    "objectID": "slides/13-ethics.html#uncertainty---catalan-independence-1",
    "href": "slides/13-ethics.html#uncertainty---catalan-independence-1",
    "title": "Data science ethics",
    "section": "Uncertainty - Catalan independence",
    "text": "Uncertainty - Catalan independence\n\n\n\n\n\n\n\n\n\n\nAlberto Cairo. “Uncertainty and Graphicacy: How Should Statisticians Journalists and Designers Reveal Uncertainty in Graphics for Public Consumption?”, Power from Statistics: Data Information and Knowledge, 2017."
  },
  {
    "objectID": "slides/13-ethics.html#your-data",
    "href": "slides/13-ethics.html#your-data",
    "title": "Data science ethics",
    "section": "“Your” data",
    "text": "“Your” data\n\nEvery time we use apps, websites, and devices, our data is being collected and used or sold to others.\nMore importantly, decisions are made by law enforcement, financial institutions, and governments based on data that directly affect the lives of people."
  },
  {
    "objectID": "slides/13-ethics.html#privacy-of-your-data",
    "href": "slides/13-ethics.html#privacy-of-your-data",
    "title": "Data science ethics",
    "section": "Privacy of your data",
    "text": "Privacy of your data\n\nWhat pieces of data have you left on the internet today? Think through everything you’ve logged into, clicked on, checked in, either actively or automatically, that might be tracking you. Do you know where that data is stored? Who it can be accessed by? Whether it’s shared with others?"
  },
  {
    "objectID": "slides/13-ethics.html#sharing-your-data",
    "href": "slides/13-ethics.html#sharing-your-data",
    "title": "Data science ethics",
    "section": "Sharing your data",
    "text": "Sharing your data\n\nWhat are you OK with sharing?\n\n\n\n\n\nName\nAge\nEmail\nPhone Number\nList of every video you watch\nList of every video you comment on\n\n\n\n\n\nHow you type: speed, accuracy\nHow long you spend on different content\nList of all your private messages (date, time, person sent to)\nInfo about your photos (how it was taken, where it was taken (GPS), when it was taken)"
  },
  {
    "objectID": "slides/13-ethics.html#what-does-google-thinkknow-about-you",
    "href": "slides/13-ethics.html#what-does-google-thinkknow-about-you",
    "title": "Data science ethics",
    "section": "What does Google think/know about you?",
    "text": "What does Google think/know about you?\n\nHave you ever thought about why you’re seeing an ad on Google? Google it! Try to figure out if you have ad personalization on and how your ads are personalized."
  },
  {
    "objectID": "slides/13-ethics.html#your-browsing-history",
    "href": "slides/13-ethics.html#your-browsing-history",
    "title": "Data science ethics",
    "section": "Your browsing history",
    "text": "Your browsing history\n\nWhich of the following are you OK with your browsing history to be used towards?\n\n\n\nFor serving you targeted ads\nTo score you as a candidate for a job\nTo predict your race/ethnicity for voting purposes"
  },
  {
    "objectID": "slides/13-ethics.html#who-else-gets-to-use-your-data",
    "href": "slides/13-ethics.html#who-else-gets-to-use-your-data",
    "title": "Data science ethics",
    "section": "Who else gets to use your data?",
    "text": "Who else gets to use your data?\n\nSuppose you create a profile on a social media site and share your personal information on your profile. Who else gets to use that data?\n\n\n\nCompanies the social media company has a connection to?\nCompanies the social media company sells your data to?\nResearchers?"
  },
  {
    "objectID": "slides/13-ethics.html#aol-search-data-leak",
    "href": "slides/13-ethics.html#aol-search-data-leak",
    "title": "Data science ethics",
    "section": "AOL search data leak",
    "text": "AOL search data leak\n\n\n\nMichael Barbaro and Tom Zeller Jr. A Face Is Exposed for AOL Searcher No. 4417749.\nNew York Times. 9 August 2006."
  },
  {
    "objectID": "slides/13-ethics.html#ok-cupid-data-breach",
    "href": "slides/13-ethics.html#ok-cupid-data-breach",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nIn 2016, researchers published data of 70,000 OkCupid users—including usernames, political leanings, drug usage, and intimate sexual details\nResearchers didn’t release the real names and pictures of OKCupid users, but their identities could easily be uncovered from the details provided, e.g. usernames"
  },
  {
    "objectID": "slides/13-ethics.html#ok-cupid-data-breach-1",
    "href": "slides/13-ethics.html#ok-cupid-data-breach-1",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach"
  },
  {
    "objectID": "slides/13-ethics.html#ok-cupid-data-breach-2",
    "href": "slides/13-ethics.html#ok-cupid-data-breach-2",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nSome may object to the ethics of gathering and releasing this data. However, all the data found in the dataset are or were already publicly available, so releasing this dataset merely presents it in a more useful form.\nResearchers Emil Kirkegaard and Julius Daugbjerg Bjerrekær"
  },
  {
    "objectID": "slides/13-ethics.html#data-privacy",
    "href": "slides/13-ethics.html#data-privacy",
    "title": "Data science ethics",
    "section": "Data privacy",
    "text": "Data privacy\n\nIn analysis of data that individuals willingly shared publicly on a given platform (e.g. social media), how do you make sure you don’t violate reasonable expectations of privacy?"
  },
  {
    "objectID": "slides/13-ethics.html#garbage-in-garbage-out",
    "href": "slides/13-ethics.html#garbage-in-garbage-out",
    "title": "Data science ethics",
    "section": "Garbage in, garbage out",
    "text": "Garbage in, garbage out\n\nIn statistical modeling and inference we talk about “garbage in, garbage out” – if you don’t have good (random, representative) data, results of your analysis will not be reliable or generalizable.\nCorollary: Bias in, bias out."
  },
  {
    "objectID": "slides/13-ethics.html#google-translate",
    "href": "slides/13-ethics.html#google-translate",
    "title": "Data science ethics",
    "section": "Google Translate",
    "text": "Google Translate\n\nWhat might be the reason for Google’s gendered translation? How do ethics play into this situation?\n\n\n\n\nSource: Engadget - Google is working to remove gender bias in its translations"
  },
  {
    "objectID": "slides/13-ethics.html#machine-bias",
    "href": "slides/13-ethics.html#machine-bias",
    "title": "Data science ethics",
    "section": "Machine Bias",
    "text": "Machine Bias\n2016 ProPublica article on algorithm used for rating a defendant’s risk of future crime:\n\n\n\nIn forecasting who would re-offend, the algorithm made mistakes with black and white defendants at roughly the same rate but in very different ways.\n\nThe formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.\nWhite defendants were mislabeled as low risk more often than black defendants.\n\n\n\n\n\n\n\n\n\n\n\nSource: ProPublica"
  },
  {
    "objectID": "slides/13-ethics.html#risk-score-errors",
    "href": "slides/13-ethics.html#risk-score-errors",
    "title": "Data science ethics",
    "section": "Risk score errors",
    "text": "Risk score errors\n\n\n\nWhat is common among the defendants who were assigned a high/low risk score for reoffending?"
  },
  {
    "objectID": "slides/13-ethics.html#risk-scores",
    "href": "slides/13-ethics.html#risk-scores",
    "title": "Data science ethics",
    "section": "Risk scores",
    "text": "Risk scores\n\n\n\nHow can an algorithm that doesn’t use race as input data be racist?"
  },
  {
    "objectID": "slides/13-ethics.html#predicting-ethnicity",
    "href": "slides/13-ethics.html#predicting-ethnicity",
    "title": "Data science ethics",
    "section": "Predicting ethnicity",
    "text": "Predicting ethnicity\nImproving Ecological Inference by Predicting Individual Ethnicity from Voter Registration Record (Imran and Khan, 2016)\n\nIn both political behavior research and voting rights litigation, turnout and vote choice for different racial groups are often inferred using aggregate election results and racial composition. Over the past several decades, many statistical methods have been proposed to address this ecological inference problem. We propose an alternative method to reduce aggregation bias by predicting individual-level ethnicity from voter registration records. Building on the existing methodological literature, we use Bayes’s rule to combine the Census Bureau’s Surname List with various information from geocoded voter registration records. We evaluate the performance of the proposed methodology using approximately nine million voter registration records from Florida, where self-reported ethnicity is available. We find that it is possible to reduce the false positive rate among Black and Latino voters to 6% and 3%, respectively, while maintaining the true positive rate above 80%. Moreover, we use our predictions to estimate turnout by race and find that our estimates yields substantially less amounts of bias and root mean squared error than standard ecological inference estimates. We provide open-source software to implement the proposed methodology. The open-source software is available for implementing the proposed methodology."
  },
  {
    "objectID": "slides/13-ethics.html#wru-package",
    "href": "slides/13-ethics.html#wru-package",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\nThe said “source software” is the wru package: https://github.com/kosukeimai/wru.\n\nDo you have any ethical concerns about installing this package?"
  },
  {
    "objectID": "slides/13-ethics.html#wru-package-1",
    "href": "slides/13-ethics.html#wru-package-1",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\n\nWas the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nlibrary(wru)\npredict_race(voter.file = voters, surname.only = TRUE) |&gt;\n  select(surname, contains(\"pred\"))\n\n      surname    pred.whi    pred.bla     pred.his    pred.asi\n1      Khanna 0.045110474 0.003067623 0.0068522723 0.860411906\n2        Imai 0.052645440 0.001334812 0.0558160072 0.719376581\n3      Rivera 0.043285692 0.008204605 0.9136195794 0.024316883\n4     Fifield 0.895405704 0.001911388 0.0337464844 0.011079323\n5        Zhou 0.006572555 0.001298962 0.0005388581 0.982365594\n6    Ratkovic 0.861236727 0.008212824 0.0095395642 0.011334635\n7     Johnson 0.543815322 0.344128607 0.0272403940 0.007405765\n8       Lopez 0.038939877 0.004920643 0.9318797791 0.012154125\n10 Wantchekon 0.330697188 0.194700665 0.4042849478 0.021379541\n9       Morse 0.866360147 0.044429853 0.0246568086 0.010219712\n      pred.oth\n1  0.084557725\n2  0.170827160\n3  0.010573240\n4  0.057857101\n5  0.009224032\n6  0.109676251\n7  0.077409913\n8  0.012105576\n10 0.048937658\n9  0.054333479"
  },
  {
    "objectID": "slides/13-ethics.html#wru-package-2",
    "href": "slides/13-ethics.html#wru-package-2",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\n\nme &lt;- tibble(surname = \"Çetinkaya-Rundel\")\n\npredict_race(voter.file = me, surname.only = TRUE)\n\n           surname  pred.whi pred.bla pred.his pred.asi   pred.oth\n1 Çetinkaya-Rundel 0.9177967        0        0        0 0.08220329"
  },
  {
    "objectID": "slides/13-ethics.html#how-charts-lie",
    "href": "slides/13-ethics.html#how-charts-lie",
    "title": "Data science ethics",
    "section": "How Charts Lie",
    "text": "How Charts Lie\n\n\n\n\nHow Charts Lie\nGetting Smarter about Visual Information\nby Alberto Cairo"
  },
  {
    "objectID": "slides/13-ethics.html#calling-bullshit",
    "href": "slides/13-ethics.html#calling-bullshit",
    "title": "Data science ethics",
    "section": "Calling Bullshit",
    "text": "Calling Bullshit\n\n\n\n\nCalling Bullshit\nThe Art of Skepticism in a\nData-Driven World\nby Carl Bergstrom and Jevin West"
  },
  {
    "objectID": "slides/13-ethics.html#machine-bias-1",
    "href": "slides/13-ethics.html#machine-bias-1",
    "title": "Data science ethics",
    "section": "Machine Bias",
    "text": "Machine Bias\n\n\n\n\nMachine Bias\nby Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner"
  },
  {
    "objectID": "slides/13-ethics.html#ethics-and-data-science",
    "href": "slides/13-ethics.html#ethics-and-data-science",
    "title": "Data science ethics",
    "section": "Ethics and Data Science",
    "text": "Ethics and Data Science\n\n\n\n\nEthics and Data Science\nby Mike Loukides, Hilary Mason, DJ Patil\n(Free Kindle download)"
  },
  {
    "objectID": "slides/13-ethics.html#weapons-of-math-destruction",
    "href": "slides/13-ethics.html#weapons-of-math-destruction",
    "title": "Data science ethics",
    "section": "Weapons of Math Destruction",
    "text": "Weapons of Math Destruction\n\n\n\n\nWeapons of Math Destruction\nHow Big Data Increases Inequality and Threatens Democracy\nby Cathy O’Neil"
  },
  {
    "objectID": "slides/13-ethics.html#algorithms-of-oppression",
    "href": "slides/13-ethics.html#algorithms-of-oppression",
    "title": "Data science ethics",
    "section": "Algorithms of Oppression",
    "text": "Algorithms of Oppression\n\n\n\n\nAlgorithms of Oppression\nHow Search Engines Reinforce Racism\nby Safiya Umoja Noble"
  },
  {
    "objectID": "slides/13-ethics.html#and-more-recently",
    "href": "slides/13-ethics.html#and-more-recently",
    "title": "Data science ethics",
    "section": "And more recently…",
    "text": "And more recently…\nHow AI discriminates and what that means for your Google habit\nA conversation with UCLA internet studies scholar Safiya Noble\nby Julia Busiek"
  },
  {
    "objectID": "slides/13-ethics.html#parting-thoughts",
    "href": "slides/13-ethics.html#parting-thoughts",
    "title": "Data science ethics",
    "section": "Parting thoughts",
    "text": "Parting thoughts\n\nAt some point during your data science learning journey you will learn tools that can be used unethically\nYou might also be tempted to use your knowledge in a way that is ethically questionable either because of business goals or for the pursuit of further knowledge (or because your boss told you to do so)\n\n\nHow do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?"
  },
  {
    "objectID": "slides/13-ethics-slides.html#announcements",
    "href": "slides/13-ethics-slides.html#announcements",
    "title": "Data science ethics",
    "section": "Announcements",
    "text": "Announcements\n\nPeer evaluation 1 due by 5:00 pm Friday (Oct 18) – look for an email from TEAMMATES\nMy office hours this week: 4:30 - 6:30 pm on Friday at Old Chem 213, back to normal next week\nLab on Monday: Work on project proposals!"
  },
  {
    "objectID": "slides/13-ethics-slides.html#misrepresenting-data-science-results",
    "href": "slides/13-ethics-slides.html#misrepresenting-data-science-results",
    "title": "Data science ethics",
    "section": "Misrepresenting data science results",
    "text": "Misrepresenting data science results\nSome common ways people do this, either intentionally or unintentionally, include:\n\n\nClaiming causality where it’s not in the scope of inference of the underlying study\nDistorting axes and scales to make the data tell a different story\nVisualizing spatial areas instead of human density for issues that depend on and affect humans\nOmitting uncertainty in reporting"
  },
  {
    "objectID": "slides/13-ethics-slides.html#causality---time-coverage",
    "href": "slides/13-ethics-slides.html#causality---time-coverage",
    "title": "Data science ethics",
    "section": "Causality - TIME coverage",
    "text": "Causality - TIME coverage\n\nHow plausible is the statement in the title of this article?\n\n\n\n\nAlice Park. Exercise Can Lower Risk of Some Cancers By 20%. Time Magazine. 16 May 2016."
  },
  {
    "objectID": "slides/13-ethics-slides.html#causality---la-times-coverage",
    "href": "slides/13-ethics-slides.html#causality---la-times-coverage",
    "title": "Data science ethics",
    "section": "Causality - LA Times coverage",
    "text": "Causality - LA Times coverage\n\nWhat does “research shows” mean?\n\n\n\n\nMelissa Healy. Exercising drives down risk for 13 cancers, research shows.\nLos Angeles Times. 16 May 2016."
  },
  {
    "objectID": "slides/13-ethics-slides.html#causality---original-study",
    "href": "slides/13-ethics-slides.html#causality---original-study",
    "title": "Data science ethics",
    "section": "Causality - Original study",
    "text": "Causality - Original study\nMoore, Steven C., et al. “Association of leisure-time physical activity with risk of 26 types of cancer in 1.44 million adults.” JAMA internal medicine 176.6 (2016): 816-825.\n\n\nVolunteers were asked about their physical activity level over the preceding year.\nHalf exercised less than about 150 minutes per week, half exercised more.\nCompared to the bottom 10% of exercisers, the top 10% had lower rates of esophageal, liver, lung, endometrial, colon, and breast cancer.\nResearchers found no association between exercising and 13 other cancers (e.g. pancreatic, ovarian, and brain).\n\nCarl Bergstrom and Jevin West. Calling Bullshit: The art of skepticism in a data-driven world.\nRandom House, 2020.\nSharon Begley. “Does exercise prevent cancer?”. StatNews. 16 May 2016."
  },
  {
    "objectID": "slides/13-ethics-slides.html#axes-and-scales---tax-cuts",
    "href": "slides/13-ethics-slides.html#axes-and-scales---tax-cuts",
    "title": "Data science ethics",
    "section": "Axes and scales - Tax cuts",
    "text": "Axes and scales - Tax cuts\n\nWhat is the difference between these two pictures? Which presents a better way to represent these data?\n\n\n\n\nChristopher Ingraham. “You’ve been reading charts wrong. Here’s how a pro does it.”. The Washington Post. 14 October 2019."
  },
  {
    "objectID": "slides/13-ethics-slides.html#axes-and-scales---cost-of-gas",
    "href": "slides/13-ethics-slides.html#axes-and-scales---cost-of-gas",
    "title": "Data science ethics",
    "section": "Axes and scales - Cost of gas",
    "text": "Axes and scales - Cost of gas\n\nWhat is wrong with this picture? How would you correct it?"
  },
  {
    "objectID": "slides/13-ethics-slides.html#axes-and-scales---cost-of-gas-1",
    "href": "slides/13-ethics-slides.html#axes-and-scales---cost-of-gas-1",
    "title": "Data science ethics",
    "section": "Axes and scales - Cost of gas",
    "text": "Axes and scales - Cost of gas"
  },
  {
    "objectID": "slides/13-ethics-slides.html#axes-and-scales---covid-in-ga",
    "href": "slides/13-ethics-slides.html#axes-and-scales---covid-in-ga",
    "title": "Data science ethics",
    "section": "Axes and scales - COVID in GA",
    "text": "Axes and scales - COVID in GA\n\nWhat is wrong with this picture? How would you correct it?\n\n\n\n\nGeorgia Department of Public Health. 11 May 2020."
  },
  {
    "objectID": "slides/13-ethics-slides.html#axes-and-scales---covid-in-ga-1",
    "href": "slides/13-ethics-slides.html#axes-and-scales---covid-in-ga-1",
    "title": "Data science ethics",
    "section": "Axes and scales - COVID in GA",
    "text": "Axes and scales - COVID in GA\n\n\n\nLucy D’Agostino McGowan. Graph detective. Live Free or Dichotomize. 17 May 2020."
  },
  {
    "objectID": "slides/13-ethics-slides.html#axes-and-scales---pp-services",
    "href": "slides/13-ethics-slides.html#axes-and-scales---pp-services",
    "title": "Data science ethics",
    "section": "Axes and scales - PP services",
    "text": "Axes and scales - PP services\n\n\n\nWhat is wrong with this picture? How would you correct it?\n\n\n\n\n\n\nTimothy B. Lee. Whatever you think of Planned Parenthood, this is a terrible and dishonest chart. Vox. 29 September 2019."
  },
  {
    "objectID": "slides/13-ethics-slides.html#axes-and-scales---pp-services-1",
    "href": "slides/13-ethics-slides.html#axes-and-scales---pp-services-1",
    "title": "Data science ethics",
    "section": "Axes and scales - PP services",
    "text": "Axes and scales - PP services"
  },
  {
    "objectID": "slides/13-ethics-slides.html#maps-and-areas---voting-map",
    "href": "slides/13-ethics-slides.html#maps-and-areas---voting-map",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting map",
    "text": "Maps and areas - Voting map\n\nDo you recognize this map? What does it show?\n\n\n\n\nLazaro Gamio. “Election maps are telling you big lies about small things”. The Washington Post. 1 Nov 2016."
  },
  {
    "objectID": "slides/13-ethics-slides.html#maps-and-areas---two-alternate-tales",
    "href": "slides/13-ethics-slides.html#maps-and-areas---two-alternate-tales",
    "title": "Data science ethics",
    "section": "Maps and areas - Two alternate tales",
    "text": "Maps and areas - Two alternate tales\n\n\n\n\n\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/13-ethics-slides.html#maps-and-areas---voting-percentages",
    "href": "slides/13-ethics-slides.html#maps-and-areas---voting-percentages",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting percentages",
    "text": "Maps and areas - Voting percentages\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/13-ethics-slides.html#maps-and-areas---voting-percentages-1",
    "href": "slides/13-ethics-slides.html#maps-and-areas---voting-percentages-1",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting percentages",
    "text": "Maps and areas - Voting percentages\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/13-ethics-slides.html#uncertainty---catalan-independence",
    "href": "slides/13-ethics-slides.html#uncertainty---catalan-independence",
    "title": "Data science ethics",
    "section": "Uncertainty - Catalan independence",
    "text": "Uncertainty - Catalan independence\nOn December 19, 2014, the front page of Spanish national newspaper El País read “Catalan public opinion swings toward ‘no’ for independence, says survey”.\n\n\n\n\n\n\n\n\n\n\nAlberto Cairo. The truthful art: Data, charts, and maps for communication. New Riders, 2016."
  },
  {
    "objectID": "slides/13-ethics-slides.html#uncertainty---catalan-independence-1",
    "href": "slides/13-ethics-slides.html#uncertainty---catalan-independence-1",
    "title": "Data science ethics",
    "section": "Uncertainty - Catalan independence",
    "text": "Uncertainty - Catalan independence\n\n\n\n\n\n\n\n\n\n\nAlberto Cairo. “Uncertainty and Graphicacy: How Should Statisticians Journalists and Designers Reveal Uncertainty in Graphics for Public Consumption?”, Power from Statistics: Data Information and Knowledge, 2017."
  },
  {
    "objectID": "slides/13-ethics-slides.html#your-data",
    "href": "slides/13-ethics-slides.html#your-data",
    "title": "Data science ethics",
    "section": "“Your” data",
    "text": "“Your” data\n\nEvery time we use apps, websites, and devices, our data is being collected and used or sold to others.\nMore importantly, decisions are made by law enforcement, financial institutions, and governments based on data that directly affect the lives of people."
  },
  {
    "objectID": "slides/13-ethics-slides.html#privacy-of-your-data",
    "href": "slides/13-ethics-slides.html#privacy-of-your-data",
    "title": "Data science ethics",
    "section": "Privacy of your data",
    "text": "Privacy of your data\n\nWhat pieces of data have you left on the internet today? Think through everything you’ve logged into, clicked on, checked in, either actively or automatically, that might be tracking you. Do you know where that data is stored? Who it can be accessed by? Whether it’s shared with others?"
  },
  {
    "objectID": "slides/13-ethics-slides.html#sharing-your-data",
    "href": "slides/13-ethics-slides.html#sharing-your-data",
    "title": "Data science ethics",
    "section": "Sharing your data",
    "text": "Sharing your data\n\nWhat are you OK with sharing?\n\n\n\n\n\nName\nAge\nEmail\nPhone Number\nList of every video you watch\nList of every video you comment on\n\n\n\n\n\nHow you type: speed, accuracy\nHow long you spend on different content\nList of all your private messages (date, time, person sent to)\nInfo about your photos (how it was taken, where it was taken (GPS), when it was taken)"
  },
  {
    "objectID": "slides/13-ethics-slides.html#what-does-google-thinkknow-about-you",
    "href": "slides/13-ethics-slides.html#what-does-google-thinkknow-about-you",
    "title": "Data science ethics",
    "section": "What does Google think/know about you?",
    "text": "What does Google think/know about you?\n\nHave you ever thought about why you’re seeing an ad on Google? Google it! Try to figure out if you have ad personalization on and how your ads are personalized."
  },
  {
    "objectID": "slides/13-ethics-slides.html#your-browsing-history",
    "href": "slides/13-ethics-slides.html#your-browsing-history",
    "title": "Data science ethics",
    "section": "Your browsing history",
    "text": "Your browsing history\n\nWhich of the following are you OK with your browsing history to be used towards?\n\n\n\nFor serving you targeted ads\nTo score you as a candidate for a job\nTo predict your race/ethnicity for voting purposes"
  },
  {
    "objectID": "slides/13-ethics-slides.html#who-else-gets-to-use-your-data",
    "href": "slides/13-ethics-slides.html#who-else-gets-to-use-your-data",
    "title": "Data science ethics",
    "section": "Who else gets to use your data?",
    "text": "Who else gets to use your data?\n\nSuppose you create a profile on a social media site and share your personal information on your profile. Who else gets to use that data?\n\n\n\nCompanies the social media company has a connection to?\nCompanies the social media company sells your data to?\nResearchers?"
  },
  {
    "objectID": "slides/13-ethics-slides.html#aol-search-data-leak",
    "href": "slides/13-ethics-slides.html#aol-search-data-leak",
    "title": "Data science ethics",
    "section": "AOL search data leak",
    "text": "AOL search data leak\n\n\n\nMichael Barbaro and Tom Zeller Jr. A Face Is Exposed for AOL Searcher No. 4417749.\nNew York Times. 9 August 2006."
  },
  {
    "objectID": "slides/13-ethics-slides.html#ok-cupid-data-breach",
    "href": "slides/13-ethics-slides.html#ok-cupid-data-breach",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nIn 2016, researchers published data of 70,000 OkCupid users—including usernames, political leanings, drug usage, and intimate sexual details\nResearchers didn’t release the real names and pictures of OKCupid users, but their identities could easily be uncovered from the details provided, e.g. usernames"
  },
  {
    "objectID": "slides/13-ethics-slides.html#ok-cupid-data-breach-1",
    "href": "slides/13-ethics-slides.html#ok-cupid-data-breach-1",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach"
  },
  {
    "objectID": "slides/13-ethics-slides.html#ok-cupid-data-breach-2",
    "href": "slides/13-ethics-slides.html#ok-cupid-data-breach-2",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nSome may object to the ethics of gathering and releasing this data. However, all the data found in the dataset are or were already publicly available, so releasing this dataset merely presents it in a more useful form.\nResearchers Emil Kirkegaard and Julius Daugbjerg Bjerrekær"
  },
  {
    "objectID": "slides/13-ethics-slides.html#data-privacy",
    "href": "slides/13-ethics-slides.html#data-privacy",
    "title": "Data science ethics",
    "section": "Data privacy",
    "text": "Data privacy\n\nIn analysis of data that individuals willingly shared publicly on a given platform (e.g. social media), how do you make sure you don’t violate reasonable expectations of privacy?"
  },
  {
    "objectID": "slides/13-ethics-slides.html#garbage-in-garbage-out",
    "href": "slides/13-ethics-slides.html#garbage-in-garbage-out",
    "title": "Data science ethics",
    "section": "Garbage in, garbage out",
    "text": "Garbage in, garbage out\n\nIn statistical modeling and inference we talk about “garbage in, garbage out” – if you don’t have good (random, representative) data, results of your analysis will not be reliable or generalizable.\nCorollary: Bias in, bias out."
  },
  {
    "objectID": "slides/13-ethics-slides.html#google-translate",
    "href": "slides/13-ethics-slides.html#google-translate",
    "title": "Data science ethics",
    "section": "Google Translate",
    "text": "Google Translate\n\nWhat might be the reason for Google’s gendered translation? How do ethics play into this situation?\n\n\n\n\nSource: Engadget - Google is working to remove gender bias in its translations"
  },
  {
    "objectID": "slides/13-ethics-slides.html#machine-bias",
    "href": "slides/13-ethics-slides.html#machine-bias",
    "title": "Data science ethics",
    "section": "Machine Bias",
    "text": "Machine Bias\n2016 ProPublica article on algorithm used for rating a defendant’s risk of future crime:\n\n\n\nIn forecasting who would re-offend, the algorithm made mistakes with black and white defendants at roughly the same rate but in very different ways.\n\nThe formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.\nWhite defendants were mislabeled as low risk more often than black defendants.\n\n\n\n\n\n\n\n\n\n\nSource: ProPublica"
  },
  {
    "objectID": "slides/13-ethics-slides.html#risk-score-errors",
    "href": "slides/13-ethics-slides.html#risk-score-errors",
    "title": "Data science ethics",
    "section": "Risk score errors",
    "text": "Risk score errors\n\n\n\nWhat is common among the defendants who were assigned a high/low risk score for reoffending?"
  },
  {
    "objectID": "slides/13-ethics-slides.html#risk-scores",
    "href": "slides/13-ethics-slides.html#risk-scores",
    "title": "Data science ethics",
    "section": "Risk scores",
    "text": "Risk scores\n\n\n\nHow can an algorithm that doesn’t use race as input data be racist?"
  },
  {
    "objectID": "slides/13-ethics-slides.html#predicting-ethnicity",
    "href": "slides/13-ethics-slides.html#predicting-ethnicity",
    "title": "Data science ethics",
    "section": "Predicting ethnicity",
    "text": "Predicting ethnicity\nImproving Ecological Inference by Predicting Individual Ethnicity from Voter Registration Record (Imran and Khan, 2016)\n\nIn both political behavior research and voting rights litigation, turnout and vote choice for different racial groups are often inferred using aggregate election results and racial composition. Over the past several decades, many statistical methods have been proposed to address this ecological inference problem. We propose an alternative method to reduce aggregation bias by predicting individual-level ethnicity from voter registration records. Building on the existing methodological literature, we use Bayes’s rule to combine the Census Bureau’s Surname List with various information from geocoded voter registration records. We evaluate the performance of the proposed methodology using approximately nine million voter registration records from Florida, where self-reported ethnicity is available. We find that it is possible to reduce the false positive rate among Black and Latino voters to 6% and 3%, respectively, while maintaining the true positive rate above 80%. Moreover, we use our predictions to estimate turnout by race and find that our estimates yields substantially less amounts of bias and root mean squared error than standard ecological inference estimates. We provide open-source software to implement the proposed methodology. The open-source software is available for implementing the proposed methodology."
  },
  {
    "objectID": "slides/13-ethics-slides.html#wru-package",
    "href": "slides/13-ethics-slides.html#wru-package",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\nThe said “source software” is the wru package: https://github.com/kosukeimai/wru.\n\nDo you have any ethical concerns about installing this package?"
  },
  {
    "objectID": "slides/13-ethics-slides.html#wru-package-1",
    "href": "slides/13-ethics-slides.html#wru-package-1",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\n\nWas the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nlibrary(wru)\npredict_race(voter.file = voters, surname.only = TRUE) |&gt;\n  select(surname, contains(\"pred\"))\n\n      surname    pred.whi    pred.bla     pred.his    pred.asi\n1      Khanna 0.045110474 0.003067623 0.0068522723 0.860411906\n2        Imai 0.052645440 0.001334812 0.0558160072 0.719376581\n3      Rivera 0.043285692 0.008204605 0.9136195794 0.024316883\n4     Fifield 0.895405704 0.001911388 0.0337464844 0.011079323\n5        Zhou 0.006572555 0.001298962 0.0005388581 0.982365594\n6    Ratkovic 0.861236727 0.008212824 0.0095395642 0.011334635\n7     Johnson 0.543815322 0.344128607 0.0272403940 0.007405765\n8       Lopez 0.038939877 0.004920643 0.9318797791 0.012154125\n10 Wantchekon 0.330697188 0.194700665 0.4042849478 0.021379541\n9       Morse 0.866360147 0.044429853 0.0246568086 0.010219712\n      pred.oth\n1  0.084557725\n2  0.170827160\n3  0.010573240\n4  0.057857101\n5  0.009224032\n6  0.109676251\n7  0.077409913\n8  0.012105576\n10 0.048937658\n9  0.054333479"
  },
  {
    "objectID": "slides/13-ethics-slides.html#wru-package-2",
    "href": "slides/13-ethics-slides.html#wru-package-2",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\n\nme &lt;- tibble(surname = \"Çetinkaya-Rundel\")\n\npredict_race(voter.file = me, surname.only = TRUE)\n\n           surname  pred.whi pred.bla pred.his pred.asi   pred.oth\n1 Çetinkaya-Rundel 0.9177967        0        0        0 0.08220329"
  },
  {
    "objectID": "slides/13-ethics-slides.html#how-charts-lie",
    "href": "slides/13-ethics-slides.html#how-charts-lie",
    "title": "Data science ethics",
    "section": "How Charts Lie",
    "text": "How Charts Lie\n\n\n\n\nHow Charts Lie\nGetting Smarter about Visual Information\nby Alberto Cairo"
  },
  {
    "objectID": "slides/13-ethics-slides.html#calling-bullshit",
    "href": "slides/13-ethics-slides.html#calling-bullshit",
    "title": "Data science ethics",
    "section": "Calling Bullshit",
    "text": "Calling Bullshit\n\n\n\n\nCalling Bullshit\nThe Art of Skepticism in a\nData-Driven World\nby Carl Bergstrom and Jevin West"
  },
  {
    "objectID": "slides/13-ethics-slides.html#machine-bias-1",
    "href": "slides/13-ethics-slides.html#machine-bias-1",
    "title": "Data science ethics",
    "section": "Machine Bias",
    "text": "Machine Bias\n\n\n\n\nMachine Bias\nby Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner"
  },
  {
    "objectID": "slides/13-ethics-slides.html#ethics-and-data-science",
    "href": "slides/13-ethics-slides.html#ethics-and-data-science",
    "title": "Data science ethics",
    "section": "Ethics and Data Science",
    "text": "Ethics and Data Science\n\n\n\n\nEthics and Data Science\nby Mike Loukides, Hilary Mason, DJ Patil\n(Free Kindle download)"
  },
  {
    "objectID": "slides/13-ethics-slides.html#weapons-of-math-destruction",
    "href": "slides/13-ethics-slides.html#weapons-of-math-destruction",
    "title": "Data science ethics",
    "section": "Weapons of Math Destruction",
    "text": "Weapons of Math Destruction\n\n\n\n\nWeapons of Math Destruction\nHow Big Data Increases Inequality and Threatens Democracy\nby Cathy O’Neil"
  },
  {
    "objectID": "slides/13-ethics-slides.html#algorithms-of-oppression",
    "href": "slides/13-ethics-slides.html#algorithms-of-oppression",
    "title": "Data science ethics",
    "section": "Algorithms of Oppression",
    "text": "Algorithms of Oppression\n\n\n\n\nAlgorithms of Oppression\nHow Search Engines Reinforce Racism\nby Safiya Umoja Noble"
  },
  {
    "objectID": "slides/13-ethics-slides.html#and-more-recently",
    "href": "slides/13-ethics-slides.html#and-more-recently",
    "title": "Data science ethics",
    "section": "And more recently…",
    "text": "And more recently…\nHow AI discriminates and what that means for your Google habit\nA conversation with UCLA internet studies scholar Safiya Noble\nby Julia Busiek"
  },
  {
    "objectID": "slides/13-ethics-slides.html#parting-thoughts",
    "href": "slides/13-ethics-slides.html#parting-thoughts",
    "title": "Data science ethics",
    "section": "Parting thoughts",
    "text": "Parting thoughts\n\nAt some point during your data science learning journey you will learn tools that can be used unethically\nYou might also be tempted to use your knowledge in a way that is ethically questionable either because of business goals or for the pursuit of further knowledge (or because your boss told you to do so)\n\n\nHow do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?"
  },
  {
    "objectID": "slides/19-logistic-regression.html",
    "href": "slides/19-logistic-regression.html",
    "title": "Logistic regression",
    "section": "",
    "text": "We have been studying regression:\n\nWhat combinations of data types have we seen?\nWhat did the picture look like?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#when-last-we-left-our-heros",
    "href": "slides/19-logistic-regression.html#when-last-we-left-our-heros",
    "title": "Logistic regression",
    "section": "",
    "text": "We have been studying regression:\n\nWhat combinations of data types have we seen?\nWhat did the picture look like?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#recap-simple-linear-regression",
    "href": "slides/19-logistic-regression.html#recap-simple-linear-regression",
    "title": "Logistic regression",
    "section": "Recap: simple linear regression",
    "text": "Recap: simple linear regression\nNumerical response and one numerical predictor:"
  },
  {
    "objectID": "slides/19-logistic-regression.html#recap-simple-linear-regression-1",
    "href": "slides/19-logistic-regression.html#recap-simple-linear-regression-1",
    "title": "Logistic regression",
    "section": "Recap: simple linear regression",
    "text": "Recap: simple linear regression\nNumerical response and one categorical predictor (two levels):"
  },
  {
    "objectID": "slides/19-logistic-regression.html#recap-multiple-linear-regression",
    "href": "slides/19-logistic-regression.html#recap-multiple-linear-regression",
    "title": "Logistic regression",
    "section": "Recap: multiple linear regression",
    "text": "Recap: multiple linear regression\nNumerical response; numerical and categorical predictors:"
  },
  {
    "objectID": "slides/19-logistic-regression.html#today-a-binary-response",
    "href": "slides/19-logistic-regression.html#today-a-binary-response",
    "title": "Logistic regression",
    "section": "Today: a binary response",
    "text": "Today: a binary response\n\\[\ny =\n\\begin{cases}\n1 & &&\\text{eg. Yes, Win, True, Heads, Success}\\\\\n0 & &&\\text{eg. No, Lose, False, Tails, Failure}.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#who-cares",
    "href": "slides/19-logistic-regression.html#who-cares",
    "title": "Logistic regression",
    "section": "Who cares?",
    "text": "Who cares?\nIf we can model the relationship between predictors (\\(x\\)) and a binary response (\\(y\\)), we can use the model to do a special kind of prediction called classification."
  },
  {
    "objectID": "slides/19-logistic-regression.html#example-is-the-e-mail-spam-or-not",
    "href": "slides/19-logistic-regression.html#example-is-the-e-mail-spam-or-not",
    "title": "Logistic regression",
    "section": "Example: is the e-mail spam or not?",
    "text": "Example: is the e-mail spam or not?\n\\[\n\\mathbf{x}: \\text{word and character counts in an e-mail.}\n\\]\n\n\n\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{it's spam}\\\\\n0 & \\text{it's legit}\n\\end{cases}\n\\]\nEthical concerns?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#example-is-it-cancer-or-not",
    "href": "slides/19-logistic-regression.html#example-is-it-cancer-or-not",
    "title": "Logistic regression",
    "section": "Example: is it cancer or not?",
    "text": "Example: is it cancer or not?\n\\[\n\\mathbf{x}: \\text{features in a medical image.}\n\\]\n\n\n\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{it's cancer}\\\\\n0 & \\text{it's healthy}\n\\end{cases}\n\\]\nEthical concerns?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#example-will-they-default",
    "href": "slides/19-logistic-regression.html#example-will-they-default",
    "title": "Logistic regression",
    "section": "Example: will they default?",
    "text": "Example: will they default?\n\\[\n\\mathbf{x}: \\text{financial and demographic info about a loan applicant.}\n\\]\n\n\n\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{applicant is at risk of defaulting on loan}\\\\\n0 & \\text{applicant is safe}\n\\end{cases}\n\\]\nEthical concerns?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#example-will-they-re-offend",
    "href": "slides/19-logistic-regression.html#example-will-they-re-offend",
    "title": "Logistic regression",
    "section": "Example: will they re-offend?",
    "text": "Example: will they re-offend?\n\\[\n\\mathbf{x}: \\text{info about a criminal suspect and their case.}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{suspect is at risk of re-offending pre-trial}\\\\\n0 & \\text{suspect is safe}\n\\end{cases}\n\\]\nEthical concerns?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#how-do-we-model-this-type-of-data",
    "href": "slides/19-logistic-regression.html#how-do-we-model-this-type-of-data",
    "title": "Logistic regression",
    "section": "How do we model this type of data?",
    "text": "How do we model this type of data?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#straight-line-of-best-fit-is-a-little-silly",
    "href": "slides/19-logistic-regression.html#straight-line-of-best-fit-is-a-little-silly",
    "title": "Logistic regression",
    "section": "Straight line of best fit is a little silly",
    "text": "Straight line of best fit is a little silly"
  },
  {
    "objectID": "slides/19-logistic-regression.html#instead-s-curve-of-best-fit",
    "href": "slides/19-logistic-regression.html#instead-s-curve-of-best-fit",
    "title": "Logistic regression",
    "section": "Instead: S-curve of best fit",
    "text": "Instead: S-curve of best fit\nInstead of modeling \\(y\\) directly, we model the probability that \\(y=1\\):\n\n\n\n\n\n\n\n\n\n“Given new email, what’s the probability that it’s spam?’’\n“Given new image, what’s the probability that it’s cancer?’’\n“Given new loan application, what’s the probability that they default?’’"
  },
  {
    "objectID": "slides/19-logistic-regression.html#why-dont-we-model-y-directly",
    "href": "slides/19-logistic-regression.html#why-dont-we-model-y-directly",
    "title": "Logistic regression",
    "section": "Why don’t we model y directly?",
    "text": "Why don’t we model y directly?\n\n\nRecall regression with a numerical response:\n\nOur models do not output guarantees for \\(y\\), they output predictions that describe behavior on average;\n\n\n\nSimilar when modeling a binary response:\n\nOur models cannot directly guarantee that \\(y\\) will be zero or one. The correct analog to “on average” for a 0/1 response is “what’s the probability?”"
  },
  {
    "objectID": "slides/19-logistic-regression.html#so-what-is-this-s-curve-anyway",
    "href": "slides/19-logistic-regression.html#so-what-is-this-s-curve-anyway",
    "title": "Logistic regression",
    "section": "So, what is this S-curve, anyway?",
    "text": "So, what is this S-curve, anyway?\nIt’s the logistic function:\n\\[\n\\text{Prob}(y = 1)\n=\n\\frac{e^{\\beta_0+\\beta_1x}}{1+e^{\\beta_0+\\beta_1x}}.\n\\]\nIf you set p = Prob(y = 1) and do some algebra, you get the simple linear model for the log-odds:\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x.\n\\]\nThis is called the logistic regression model."
  },
  {
    "objectID": "slides/19-logistic-regression.html#log-odds",
    "href": "slides/19-logistic-regression.html#log-odds",
    "title": "Logistic regression",
    "section": "Log-odds?",
    "text": "Log-odds?\n\np = Prob(y = 1) is a probability. A number between 0 and 1;\np / (1 - p) is the odds. A number between 0 and \\(\\infty\\);\n\n“The odds of this lecture going well are 10 to 1.”\n\nThe log odds log(p / (1 - p)) is a number between \\(-\\infty\\) and \\(\\infty\\), which is suitable for the linear model."
  },
  {
    "objectID": "slides/19-logistic-regression.html#logistic-regression",
    "href": "slides/19-logistic-regression.html#logistic-regression",
    "title": "Logistic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x.\n\\]\n\nThe logit function log(p / (1-p)) is an example of a link function that transforms the linear model to have an appropriate range;\nThis is an example of a generalized linear model;"
  },
  {
    "objectID": "slides/19-logistic-regression.html#estimation",
    "href": "slides/19-logistic-regression.html#estimation",
    "title": "Logistic regression",
    "section": "Estimation",
    "text": "Estimation\n\nWe estimate the parameters \\(\\beta_0,\\,\\beta_1\\) using maximum likelihood (don’t worry about it) to get the “best fitting” S-curve;\nThe fitted model is\n\n\\[\n\\log\\left(\\frac{\\widehat{p}}{1-\\widehat{p}}\\right)\n=\nb_0+b_1x.\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#logistic-regression---classification",
    "href": "slides/19-logistic-regression.html#logistic-regression---classification",
    "title": "Logistic regression",
    "section": "Logistic regression -> classification?",
    "text": "Logistic regression -&gt; classification?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#step-1-pick-a-threshold",
    "href": "slides/19-logistic-regression.html#step-1-pick-a-threshold",
    "title": "Logistic regression",
    "section": "Step 1: pick a threshold",
    "text": "Step 1: pick a threshold\nSelect a number \\(0 &lt; p^* &lt; 1\\):\n\n\n\n\n\n\n\n\n\nif \\(\\text{Prob}(y=1)\\leq p^*\\), then predict \\(\\widehat{y}=0\\);\nif \\(\\text{Prob}(y=1)&gt; p^*\\), then predict \\(\\widehat{y}=1\\)."
  },
  {
    "objectID": "slides/19-logistic-regression.html#step-2-find-the-decision-boundary",
    "href": "slides/19-logistic-regression.html#step-2-find-the-decision-boundary",
    "title": "Logistic regression",
    "section": "Step 2: find the “decision boundary”",
    "text": "Step 2: find the “decision boundary”\nSolve for the x-value that matches the threshold:\n\n\n\n\n\n\n\n\n\nif \\(\\text{Prob}(y=1)\\leq p^*\\), then predict \\(\\widehat{y}=0\\);\nif \\(\\text{Prob}(y=1)&gt; p^*\\), then predict \\(\\widehat{y}=1\\)."
  },
  {
    "objectID": "slides/19-logistic-regression.html#step-3-classify-a-new-arrival",
    "href": "slides/19-logistic-regression.html#step-3-classify-a-new-arrival",
    "title": "Logistic regression",
    "section": "Step 3: classify a new arrival",
    "text": "Step 3: classify a new arrival\nA new person shows up with \\(x_{\\text{new}}\\). Which side of the boundary are they on?\n\n\n\n\n\n\n\n\n\nif \\(x_{\\text{new}} \\leq x^\\star\\), then \\(\\text{Prob}(y=1)\\leq p^*\\), so predict \\(\\widehat{y}=0\\) for the new person;\nif \\(x_{\\text{new}} &gt; x^\\star\\), then \\(\\text{Prob}(y=1)&gt; p^*\\), so predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/19-logistic-regression.html#lets-change-the-threshold",
    "href": "slides/19-logistic-regression.html#lets-change-the-threshold",
    "title": "Logistic regression",
    "section": "Let’s change the threshold",
    "text": "Let’s change the threshold\nA new person shows up with \\(x_{\\text{new}}\\). Which side of the boundary are they on?\n\n\n\n\n\n\n\n\n\nif \\(x_{\\text{new}} \\leq x^\\star\\), then \\(\\text{Prob}(y=1)\\leq p^*\\), so predict \\(\\widehat{y}=0\\) for the new person;\nif \\(x_{\\text{new}} &gt; x^\\star\\), then \\(\\text{Prob}(y=1)&gt; p^*\\), so predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/19-logistic-regression.html#nothing-special-about-one-predictor",
    "href": "slides/19-logistic-regression.html#nothing-special-about-one-predictor",
    "title": "Logistic regression",
    "section": "Nothing special about one predictor…",
    "text": "Nothing special about one predictor…\nTwo numerical predictors and one binary response:"
  },
  {
    "objectID": "slides/19-logistic-regression.html#multiple-logistic-regression",
    "href": "slides/19-logistic-regression.html#multiple-logistic-regression",
    "title": "Logistic regression",
    "section": "“Multiple” logistic regression",
    "text": "“Multiple” logistic regression\nOn the probability scale:\n\\[\n\\text{Prob}(y = 1)\n=\n\\frac{e^{\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m}}{1+e^{\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m}}.\n\\]\nFor the log-odds, a multiple linear regression:\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m.\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#decision-boundary-again",
    "href": "slides/19-logistic-regression.html#decision-boundary-again",
    "title": "Logistic regression",
    "section": "Decision boundary, again",
    "text": "Decision boundary, again\nIt’s linear! Consider two numerical predictors:\n\n\n\n\n\n\n\n\n\nif new \\((x_1,\\,x_2)\\) below, \\(\\text{Prob}(y=1)\\leq p^*\\). Predict \\(\\widehat{y}=0\\) for the new person;\nif new \\((x_1,\\,x_2)\\) above, \\(\\text{Prob}(y=1)&gt; p^*\\). Predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#when-last-we-left-our-heros",
    "href": "slides/19-logistic-regression-slides.html#when-last-we-left-our-heros",
    "title": "Logistic regression",
    "section": "When last we left our heros…",
    "text": "When last we left our heros…\nWe have been studying regression:\n\nWhat combinations of data types have we seen?\nWhat did the picture look like?"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#recap-simple-linear-regression",
    "href": "slides/19-logistic-regression-slides.html#recap-simple-linear-regression",
    "title": "Logistic regression",
    "section": "Recap: simple linear regression",
    "text": "Recap: simple linear regression\nNumerical response and one numerical predictor:"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#recap-simple-linear-regression-1",
    "href": "slides/19-logistic-regression-slides.html#recap-simple-linear-regression-1",
    "title": "Logistic regression",
    "section": "Recap: simple linear regression",
    "text": "Recap: simple linear regression\nNumerical response and one categorical predictor (two levels):"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#recap-multiple-linear-regression",
    "href": "slides/19-logistic-regression-slides.html#recap-multiple-linear-regression",
    "title": "Logistic regression",
    "section": "Recap: multiple linear regression",
    "text": "Recap: multiple linear regression\nNumerical response; numerical and categorical predictors:"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#today-a-binary-response",
    "href": "slides/19-logistic-regression-slides.html#today-a-binary-response",
    "title": "Logistic regression",
    "section": "Today: a binary response",
    "text": "Today: a binary response\n\\[\ny =\n\\begin{cases}\n1 & &&\\text{eg. Yes, Win, True, Heads, Success}\\\\\n0 & &&\\text{eg. No, Lose, False, Tails, Failure}.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#who-cares",
    "href": "slides/19-logistic-regression-slides.html#who-cares",
    "title": "Logistic regression",
    "section": "Who cares?",
    "text": "Who cares?\nIf we can model the relationship between predictors (\\(x\\)) and a binary response (\\(y\\)), we can use the model to do a special kind of prediction called classification."
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#example-is-the-e-mail-spam-or-not",
    "href": "slides/19-logistic-regression-slides.html#example-is-the-e-mail-spam-or-not",
    "title": "Logistic regression",
    "section": "Example: is the e-mail spam or not?",
    "text": "Example: is the e-mail spam or not?\n\\[\n\\mathbf{x}: \\text{word and character counts in an e-mail.}\n\\]\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{it's spam}\\\\\n0 & \\text{it's legit}\n\\end{cases}\n\\]\nEthical concerns?"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#example-is-it-cancer-or-not",
    "href": "slides/19-logistic-regression-slides.html#example-is-it-cancer-or-not",
    "title": "Logistic regression",
    "section": "Example: is it cancer or not?",
    "text": "Example: is it cancer or not?\n\\[\n\\mathbf{x}: \\text{features in a medical image.}\n\\]\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{it's cancer}\\\\\n0 & \\text{it's healthy}\n\\end{cases}\n\\]\nEthical concerns?"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#example-will-they-default",
    "href": "slides/19-logistic-regression-slides.html#example-will-they-default",
    "title": "Logistic regression",
    "section": "Example: will they default?",
    "text": "Example: will they default?\n\\[\n\\mathbf{x}: \\text{financial and demographic info about a loan applicant.}\n\\]\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{applicant is at risk of defaulting on loan}\\\\\n0 & \\text{applicant is safe}\n\\end{cases}\n\\]\nEthical concerns?"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#example-will-they-re-offend",
    "href": "slides/19-logistic-regression-slides.html#example-will-they-re-offend",
    "title": "Logistic regression",
    "section": "Example: will they re-offend?",
    "text": "Example: will they re-offend?\n\\[\n\\mathbf{x}: \\text{info about a criminal suspect and their case.}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{suspect is at risk of re-offending pre-trial}\\\\\n0 & \\text{suspect is safe}\n\\end{cases}\n\\]\nEthical concerns?"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#how-do-we-model-this-type-of-data",
    "href": "slides/19-logistic-regression-slides.html#how-do-we-model-this-type-of-data",
    "title": "Logistic regression",
    "section": "How do we model this type of data?",
    "text": "How do we model this type of data?"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#straight-line-of-best-fit-is-a-little-silly",
    "href": "slides/19-logistic-regression-slides.html#straight-line-of-best-fit-is-a-little-silly",
    "title": "Logistic regression",
    "section": "Straight line of best fit is a little silly",
    "text": "Straight line of best fit is a little silly"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#instead-s-curve-of-best-fit",
    "href": "slides/19-logistic-regression-slides.html#instead-s-curve-of-best-fit",
    "title": "Logistic regression",
    "section": "Instead: S-curve of best fit",
    "text": "Instead: S-curve of best fit\nInstead of modeling \\(y\\) directly, we model the probability that \\(y=1\\):\n\n\n“Given new email, what’s the probability that it’s spam?’’\n“Given new image, what’s the probability that it’s cancer?’’\n“Given new loan application, what’s the probability that they default?’’"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#why-dont-we-model-y-directly",
    "href": "slides/19-logistic-regression-slides.html#why-dont-we-model-y-directly",
    "title": "Logistic regression",
    "section": "Why don’t we model y directly?",
    "text": "Why don’t we model y directly?\n\n\nRecall regression with a numerical response:\n\nOur models do not output guarantees for \\(y\\), they output predictions that describe behavior on average;\n\n\n\nSimilar when modeling a binary response:\n\nOur models cannot directly guarantee that \\(y\\) will be zero or one. The correct analog to “on average” for a 0/1 response is “what’s the probability?”"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#so-what-is-this-s-curve-anyway",
    "href": "slides/19-logistic-regression-slides.html#so-what-is-this-s-curve-anyway",
    "title": "Logistic regression",
    "section": "So, what is this S-curve, anyway?",
    "text": "So, what is this S-curve, anyway?\nIt’s the logistic function:\n\\[\n\\text{Prob}(y = 1)\n=\n\\frac{e^{\\beta_0+\\beta_1x}}{1+e^{\\beta_0+\\beta_1x}}.\n\\]\nIf you set p = Prob(y = 1) and do some algebra, you get the simple linear model for the log-odds:\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x.\n\\]\nThis is called the logistic regression model."
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#log-odds",
    "href": "slides/19-logistic-regression-slides.html#log-odds",
    "title": "Logistic regression",
    "section": "Log-odds?",
    "text": "Log-odds?\n\np = Prob(y = 1) is a probability. A number between 0 and 1;\np / (1 - p) is the odds. A number between 0 and \\(\\infty\\);\n\n“The odds of this lecture going well are 10 to 1.”\n\nThe log odds log(p / (1 - p)) is a number between \\(-\\infty\\) and \\(\\infty\\), which is suitable for the linear model."
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#logistic-regression",
    "href": "slides/19-logistic-regression-slides.html#logistic-regression",
    "title": "Logistic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x.\n\\]\n\nThe logit function log(p / (1-p)) is an example of a link function that transforms the linear model to have an appropriate range;\nThis is an example of a generalized linear model;"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#estimation",
    "href": "slides/19-logistic-regression-slides.html#estimation",
    "title": "Logistic regression",
    "section": "Estimation",
    "text": "Estimation\n\nWe estimate the parameters \\(\\beta_0,\\,\\beta_1\\) using maximum likelihood (don’t worry about it) to get the “best fitting” S-curve;\nThe fitted model is\n\n\\[\n\\log\\left(\\frac{\\widehat{p}}{1-\\widehat{p}}\\right)\n=\nb_0+b_1x.\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#logistic-regression---classification",
    "href": "slides/19-logistic-regression-slides.html#logistic-regression---classification",
    "title": "Logistic regression",
    "section": "Logistic regression -> classification?",
    "text": "Logistic regression -&gt; classification?"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#step-1-pick-a-threshold",
    "href": "slides/19-logistic-regression-slides.html#step-1-pick-a-threshold",
    "title": "Logistic regression",
    "section": "Step 1: pick a threshold",
    "text": "Step 1: pick a threshold\nSelect a number \\(0 &lt; p^* &lt; 1\\):\n\n\nif \\(\\text{Prob}(y=1)\\leq p^*\\), then predict \\(\\widehat{y}=0\\);\nif \\(\\text{Prob}(y=1)&gt; p^*\\), then predict \\(\\widehat{y}=1\\)."
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#step-2-find-the-decision-boundary",
    "href": "slides/19-logistic-regression-slides.html#step-2-find-the-decision-boundary",
    "title": "Logistic regression",
    "section": "Step 2: find the “decision boundary”",
    "text": "Step 2: find the “decision boundary”\nSolve for the x-value that matches the threshold:\n\n\nif \\(\\text{Prob}(y=1)\\leq p^*\\), then predict \\(\\widehat{y}=0\\);\nif \\(\\text{Prob}(y=1)&gt; p^*\\), then predict \\(\\widehat{y}=1\\)."
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#step-3-classify-a-new-arrival",
    "href": "slides/19-logistic-regression-slides.html#step-3-classify-a-new-arrival",
    "title": "Logistic regression",
    "section": "Step 3: classify a new arrival",
    "text": "Step 3: classify a new arrival\nA new person shows up with \\(x_{\\text{new}}\\). Which side of the boundary are they on?\n\n\nif \\(x_{\\text{new}} \\leq x^\\star\\), then \\(\\text{Prob}(y=1)\\leq p^*\\), so predict \\(\\widehat{y}=0\\) for the new person;\nif \\(x_{\\text{new}} &gt; x^\\star\\), then \\(\\text{Prob}(y=1)&gt; p^*\\), so predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#lets-change-the-threshold",
    "href": "slides/19-logistic-regression-slides.html#lets-change-the-threshold",
    "title": "Logistic regression",
    "section": "Let’s change the threshold",
    "text": "Let’s change the threshold\nA new person shows up with \\(x_{\\text{new}}\\). Which side of the boundary are they on?\n\n\nif \\(x_{\\text{new}} \\leq x^\\star\\), then \\(\\text{Prob}(y=1)\\leq p^*\\), so predict \\(\\widehat{y}=0\\) for the new person;\nif \\(x_{\\text{new}} &gt; x^\\star\\), then \\(\\text{Prob}(y=1)&gt; p^*\\), so predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#nothing-special-about-one-predictor",
    "href": "slides/19-logistic-regression-slides.html#nothing-special-about-one-predictor",
    "title": "Logistic regression",
    "section": "Nothing special about one predictor…",
    "text": "Nothing special about one predictor…\nTwo numerical predictors and one binary response:"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#multiple-logistic-regression",
    "href": "slides/19-logistic-regression-slides.html#multiple-logistic-regression",
    "title": "Logistic regression",
    "section": "“Multiple” logistic regression",
    "text": "“Multiple” logistic regression\nOn the probability scale:\n\\[\n\\text{Prob}(y = 1)\n=\n\\frac{e^{\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m}}{1+e^{\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m}}.\n\\]\nFor the log-odds, a multiple linear regression:\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m.\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression-slides.html#decision-boundary-again",
    "href": "slides/19-logistic-regression-slides.html#decision-boundary-again",
    "title": "Logistic regression",
    "section": "Decision boundary, again",
    "text": "Decision boundary, again\nIt’s linear! Consider two numerical predictors:\n\n\nif new \\((x_1,\\,x_2)\\) below, \\(\\text{Prob}(y=1)\\leq p^*\\). Predict \\(\\widehat{y}=0\\) for the new person;\nif new \\((x_1,\\,x_2)\\) above, \\(\\text{Prob}(y=1)&gt; p^*\\). Predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/14-language-of-models.html#while-you-wait",
    "href": "slides/14-language-of-models.html#while-you-wait",
    "title": "Language of models",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-12-modeling-fish.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/14-language-of-models.html#announcements",
    "href": "slides/14-language-of-models.html#announcements",
    "title": "Language of models",
    "section": "Announcements",
    "text": "Announcements\n\nProject proposals due next Monday"
  },
  {
    "objectID": "slides/14-language-of-models.html#course-pace",
    "href": "slides/14-language-of-models.html#course-pace",
    "title": "Language of models",
    "section": "Course pace",
    "text": "Course pace"
  },
  {
    "objectID": "slides/14-language-of-models.html#lecture-pace",
    "href": "slides/14-language-of-models.html#lecture-pace",
    "title": "Language of models",
    "section": "Lecture pace",
    "text": "Lecture pace"
  },
  {
    "objectID": "slides/14-language-of-models.html#engagement",
    "href": "slides/14-language-of-models.html#engagement",
    "title": "Language of models",
    "section": "Engagement",
    "text": "Engagement"
  },
  {
    "objectID": "slides/14-language-of-models.html#resources",
    "href": "slides/14-language-of-models.html#resources",
    "title": "Language of models",
    "section": "Resources",
    "text": "Resources"
  },
  {
    "objectID": "slides/14-language-of-models.html#learn-best",
    "href": "slides/14-language-of-models.html#learn-best",
    "title": "Language of models",
    "section": "Learn best",
    "text": "Learn best"
  },
  {
    "objectID": "slides/14-language-of-models.html#lecture",
    "href": "slides/14-language-of-models.html#lecture",
    "title": "Language of models",
    "section": "Lecture",
    "text": "Lecture"
  },
  {
    "objectID": "slides/14-language-of-models.html#difficulty",
    "href": "slides/14-language-of-models.html#difficulty",
    "title": "Language of models",
    "section": "Difficulty",
    "text": "Difficulty"
  },
  {
    "objectID": "slides/14-language-of-models.html#guess",
    "href": "slides/14-language-of-models.html#guess",
    "title": "Language of models",
    "section": "Guess",
    "text": "Guess\n\nCan you guess what this box plot represents?"
  },
  {
    "objectID": "slides/14-language-of-models.html#video-watching-patterns",
    "href": "slides/14-language-of-models.html#video-watching-patterns",
    "title": "Language of models",
    "section": "Video watching patterns",
    "text": "Video watching patterns"
  },
  {
    "objectID": "slides/14-language-of-models.html#goals",
    "href": "slides/14-language-of-models.html#goals",
    "title": "Language of models",
    "section": "Goals",
    "text": "Goals\n\nWhat is a model?\nWhy do we model?\nWhat is correlation?"
  },
  {
    "objectID": "slides/14-language-of-models.html#lets-drive-a-tesla",
    "href": "slides/14-language-of-models.html#lets-drive-a-tesla",
    "title": "Language of models",
    "section": "Let’s drive a Tesla!",
    "text": "Let’s drive a Tesla!"
  },
  {
    "objectID": "slides/14-language-of-models.html#semi-or-garage",
    "href": "slides/14-language-of-models.html#semi-or-garage",
    "title": "Language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\ni love how Tesla thinks the wall in my garage is a semi. 😅\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/14-language-of-models.html#semi-or-garage-1",
    "href": "slides/14-language-of-models.html#semi-or-garage-1",
    "title": "Language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\nNew owner here. Just parked in my garage. Tesla thinks I crashed onto a semi.\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/14-language-of-models.html#car-or-trash",
    "href": "slides/14-language-of-models.html#car-or-trash",
    "title": "Language of models",
    "section": "Car or trash?",
    "text": "Car or trash?\n\nTesla calls Mercedes trash\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/14-language-of-models.html#leisure-commute-physical-activity-and-bp",
    "href": "slides/14-language-of-models.html#leisure-commute-physical-activity-and-bp",
    "title": "Language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\n\nRelation Between Leisure Time, Commuting, and Occupational Physical Activity With Blood Pressure in 125,402 Adults: The Lifelines Cohort\nByambasukh, Oyuntugs, Harold Snieder, and Eva Corpeleijn. “Relation between leisure time, commuting, and occupational physical activity with blood pressure in 125 402 adults: the lifelines cohort.” Journal of the American Heart Association 9.4 (2020): e014313."
  },
  {
    "objectID": "slides/14-language-of-models.html#leisure-commute-physical-activity-and-bp-1",
    "href": "slides/14-language-of-models.html#leisure-commute-physical-activity-and-bp-1",
    "title": "Language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\nBackground: Whether all domains of daily‐life moderate‐to‐vigorous physical activity (MVPA) are associated with lower blood pressure (BP) and how this association depends on age and body mass index remains unclear.\nMethods and Results: In the population‐based Lifelines cohort (N=125,402), MVPA was assessed by the Short Questionnaire to Assess Health‐Enhancing Physical Activity, a validated questionnaire in different domains such as commuting, leisure‐time, and occupational PA. BP was assessed using the last 3 of 10 measurements after 10 minutes’ rest in the supine position. Hypertension was defined as systolic BP ≥140 mm Hg and/or diastolic BP ≥90 mm Hg and/or use of antihypertensives. In regression analysis, higher commuting and leisure‐time but not occupational MVPA related to lower BP and lower hypertension risk. Commuting‐and‐leisure‐time MVPA was associated with BP in a dose‐dependent manner. β Coefficients (95% CI) from linear regression analyses were −1.64 (−2.03 to −1.24), −2.29 (−2.68 to −1.90), and finally −2.90 (−3.29 to −2.50) mm Hg systolic BP for the low, middle, and highest tertile of MVPA compared with “No MVPA” as the reference group after adjusting for age, sex, education, smoking and alcohol use. Further adjustment for body mass index attenuated the associations by 30% to 50%, but more MVPA remained significantly associated with lower BP and lower risk of hypertension. This association was age dependent. β Coefficients (95% CI) for the highest tertiles of commuting‐and‐leisure‐time MVPA were −1.67 (−2.20 to −1.15), −3.39 (−3.94 to −2.82) and −4.64 (−6.15 to −3.14) mm Hg systolic BP in adults &lt;40, 40 to 60, and &gt;60 years, respectively.\nConclusions: Higher commuting and leisure‐time but not occupational MVPA were significantly associated with lower BP and lower hypertension risk at all ages, but these associations were stronger in older adults."
  },
  {
    "objectID": "slides/14-language-of-models.html#modeling-cars",
    "href": "slides/14-language-of-models.html#modeling-cars",
    "title": "Language of models",
    "section": "Modeling cars",
    "text": "Modeling cars\n\n\nWhat is the relationship between cars’ weights and their mileage?\nWhat is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/14-language-of-models.html#modelling-cars",
    "href": "slides/14-language-of-models.html#modelling-cars",
    "title": "Language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nDescribe: What is the relationship between cars’ weights and their mileage?"
  },
  {
    "objectID": "slides/14-language-of-models.html#modelling-cars-1",
    "href": "slides/14-language-of-models.html#modelling-cars-1",
    "title": "Language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nPredict: What is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/14-language-of-models.html#modelling",
    "href": "slides/14-language-of-models.html#modelling",
    "title": "Language of models",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but there are many many other types of models too!)"
  },
  {
    "objectID": "slides/14-language-of-models.html#modelling-vocabulary",
    "href": "slides/14-language-of-models.html#modelling-vocabulary",
    "title": "Language of models",
    "section": "Modelling vocabulary",
    "text": "Modelling vocabulary\n\nPredictor (explanatory variable)\nOutcome (response variable)\nRegression line\n\nSlope\nIntercept\n\n\nCorrelation"
  },
  {
    "objectID": "slides/14-language-of-models.html#predictor-explanatory-variable",
    "href": "slides/14-language-of-models.html#predictor-explanatory-variable",
    "title": "Language of models",
    "section": "Predictor (explanatory variable)",
    "text": "Predictor (explanatory variable)\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/14-language-of-models.html#outcome-response-variable",
    "href": "slides/14-language-of-models.html#outcome-response-variable",
    "title": "Language of models",
    "section": "Outcome (response variable)",
    "text": "Outcome (response variable)\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/14-language-of-models.html#regression-line",
    "href": "slides/14-language-of-models.html#regression-line",
    "title": "Language of models",
    "section": "Regression line",
    "text": "Regression line"
  },
  {
    "objectID": "slides/14-language-of-models.html#regression-line-slope",
    "href": "slides/14-language-of-models.html#regression-line-slope",
    "title": "Language of models",
    "section": "Regression line: slope",
    "text": "Regression line: slope"
  },
  {
    "objectID": "slides/14-language-of-models.html#regression-line-intercept",
    "href": "slides/14-language-of-models.html#regression-line-intercept",
    "title": "Language of models",
    "section": "Regression line: intercept",
    "text": "Regression line: intercept"
  },
  {
    "objectID": "slides/14-language-of-models.html#correlation",
    "href": "slides/14-language-of-models.html#correlation",
    "title": "Language of models",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "slides/14-language-of-models.html#correlation-1",
    "href": "slides/14-language-of-models.html#correlation-1",
    "title": "Language of models",
    "section": "Correlation",
    "text": "Correlation\n\nRanges between -1 and 1.\nSame sign as the slope."
  },
  {
    "objectID": "slides/14-language-of-models.html#visualizing-the-model",
    "href": "slides/14-language-of-models.html#visualizing-the-model",
    "title": "Language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model"
  },
  {
    "objectID": "slides/14-language-of-models.html#ae-12-modeling-fish",
    "href": "slides/14-language-of-models.html#ae-12-modeling-fish",
    "title": "Language of models",
    "section": "ae-12-modeling-fish",
    "text": "ae-12-modeling-fish\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-12-modeling-fish.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#while-you-wait",
    "href": "slides/14-language-of-models-slides.html#while-you-wait",
    "title": "Language of models",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-12-modeling-fish.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#announcements",
    "href": "slides/14-language-of-models-slides.html#announcements",
    "title": "Language of models",
    "section": "Announcements",
    "text": "Announcements\n\nProject proposals due next Monday"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#course-pace",
    "href": "slides/14-language-of-models-slides.html#course-pace",
    "title": "Language of models",
    "section": "Course pace",
    "text": "Course pace"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#lecture-pace",
    "href": "slides/14-language-of-models-slides.html#lecture-pace",
    "title": "Language of models",
    "section": "Lecture pace",
    "text": "Lecture pace"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#engagement",
    "href": "slides/14-language-of-models-slides.html#engagement",
    "title": "Language of models",
    "section": "Engagement",
    "text": "Engagement"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#resources",
    "href": "slides/14-language-of-models-slides.html#resources",
    "title": "Language of models",
    "section": "Resources",
    "text": "Resources"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#learn-best",
    "href": "slides/14-language-of-models-slides.html#learn-best",
    "title": "Language of models",
    "section": "Learn best",
    "text": "Learn best"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#lecture",
    "href": "slides/14-language-of-models-slides.html#lecture",
    "title": "Language of models",
    "section": "Lecture",
    "text": "Lecture"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#difficulty",
    "href": "slides/14-language-of-models-slides.html#difficulty",
    "title": "Language of models",
    "section": "Difficulty",
    "text": "Difficulty"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#guess",
    "href": "slides/14-language-of-models-slides.html#guess",
    "title": "Language of models",
    "section": "Guess",
    "text": "Guess\n\nCan you guess what this box plot represents?"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#video-watching-patterns",
    "href": "slides/14-language-of-models-slides.html#video-watching-patterns",
    "title": "Language of models",
    "section": "Video watching patterns",
    "text": "Video watching patterns"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#goals",
    "href": "slides/14-language-of-models-slides.html#goals",
    "title": "Language of models",
    "section": "Goals",
    "text": "Goals\n\nWhat is a model?\nWhy do we model?\nWhat is correlation?"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#lets-drive-a-tesla",
    "href": "slides/14-language-of-models-slides.html#lets-drive-a-tesla",
    "title": "Language of models",
    "section": "Let’s drive a Tesla!",
    "text": "Let’s drive a Tesla!"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#semi-or-garage",
    "href": "slides/14-language-of-models-slides.html#semi-or-garage",
    "title": "Language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\ni love how Tesla thinks the wall in my garage is a semi. 😅\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#semi-or-garage-1",
    "href": "slides/14-language-of-models-slides.html#semi-or-garage-1",
    "title": "Language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\nNew owner here. Just parked in my garage. Tesla thinks I crashed onto a semi.\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#car-or-trash",
    "href": "slides/14-language-of-models-slides.html#car-or-trash",
    "title": "Language of models",
    "section": "Car or trash?",
    "text": "Car or trash?\n\nTesla calls Mercedes trash\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#leisure-commute-physical-activity-and-bp",
    "href": "slides/14-language-of-models-slides.html#leisure-commute-physical-activity-and-bp",
    "title": "Language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\n\nRelation Between Leisure Time, Commuting, and Occupational Physical Activity With Blood Pressure in 125,402 Adults: The Lifelines Cohort\nByambasukh, Oyuntugs, Harold Snieder, and Eva Corpeleijn. “Relation between leisure time, commuting, and occupational physical activity with blood pressure in 125 402 adults: the lifelines cohort.” Journal of the American Heart Association 9.4 (2020): e014313."
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#leisure-commute-physical-activity-and-bp-1",
    "href": "slides/14-language-of-models-slides.html#leisure-commute-physical-activity-and-bp-1",
    "title": "Language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\nBackground: Whether all domains of daily‐life moderate‐to‐vigorous physical activity (MVPA) are associated with lower blood pressure (BP) and how this association depends on age and body mass index remains unclear.\nMethods and Results: In the population‐based Lifelines cohort (N=125,402), MVPA was assessed by the Short Questionnaire to Assess Health‐Enhancing Physical Activity, a validated questionnaire in different domains such as commuting, leisure‐time, and occupational PA. BP was assessed using the last 3 of 10 measurements after 10 minutes’ rest in the supine position. Hypertension was defined as systolic BP ≥140 mm Hg and/or diastolic BP ≥90 mm Hg and/or use of antihypertensives. In regression analysis, higher commuting and leisure‐time but not occupational MVPA related to lower BP and lower hypertension risk. Commuting‐and‐leisure‐time MVPA was associated with BP in a dose‐dependent manner. β Coefficients (95% CI) from linear regression analyses were −1.64 (−2.03 to −1.24), −2.29 (−2.68 to −1.90), and finally −2.90 (−3.29 to −2.50) mm Hg systolic BP for the low, middle, and highest tertile of MVPA compared with “No MVPA” as the reference group after adjusting for age, sex, education, smoking and alcohol use. Further adjustment for body mass index attenuated the associations by 30% to 50%, but more MVPA remained significantly associated with lower BP and lower risk of hypertension. This association was age dependent. β Coefficients (95% CI) for the highest tertiles of commuting‐and‐leisure‐time MVPA were −1.67 (−2.20 to −1.15), −3.39 (−3.94 to −2.82) and −4.64 (−6.15 to −3.14) mm Hg systolic BP in adults &lt;40, 40 to 60, and &gt;60 years, respectively.\nConclusions: Higher commuting and leisure‐time but not occupational MVPA were significantly associated with lower BP and lower hypertension risk at all ages, but these associations were stronger in older adults."
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#modeling-cars",
    "href": "slides/14-language-of-models-slides.html#modeling-cars",
    "title": "Language of models",
    "section": "Modeling cars",
    "text": "Modeling cars\n\n\nWhat is the relationship between cars’ weights and their mileage?\nWhat is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#modelling-cars",
    "href": "slides/14-language-of-models-slides.html#modelling-cars",
    "title": "Language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nDescribe: What is the relationship between cars’ weights and their mileage?"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#modelling-cars-1",
    "href": "slides/14-language-of-models-slides.html#modelling-cars-1",
    "title": "Language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nPredict: What is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#modelling",
    "href": "slides/14-language-of-models-slides.html#modelling",
    "title": "Language of models",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but there are many many other types of models too!)"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#modelling-vocabulary",
    "href": "slides/14-language-of-models-slides.html#modelling-vocabulary",
    "title": "Language of models",
    "section": "Modelling vocabulary",
    "text": "Modelling vocabulary\n\nPredictor (explanatory variable)\nOutcome (response variable)\nRegression line\n\nSlope\nIntercept\n\n\nCorrelation"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#predictor-explanatory-variable",
    "href": "slides/14-language-of-models-slides.html#predictor-explanatory-variable",
    "title": "Language of models",
    "section": "Predictor (explanatory variable)",
    "text": "Predictor (explanatory variable)\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#outcome-response-variable",
    "href": "slides/14-language-of-models-slides.html#outcome-response-variable",
    "title": "Language of models",
    "section": "Outcome (response variable)",
    "text": "Outcome (response variable)\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#regression-line",
    "href": "slides/14-language-of-models-slides.html#regression-line",
    "title": "Language of models",
    "section": "Regression line",
    "text": "Regression line"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#regression-line-slope",
    "href": "slides/14-language-of-models-slides.html#regression-line-slope",
    "title": "Language of models",
    "section": "Regression line: slope",
    "text": "Regression line: slope"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#regression-line-intercept",
    "href": "slides/14-language-of-models-slides.html#regression-line-intercept",
    "title": "Language of models",
    "section": "Regression line: intercept",
    "text": "Regression line: intercept"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#correlation",
    "href": "slides/14-language-of-models-slides.html#correlation",
    "title": "Language of models",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#correlation-1",
    "href": "slides/14-language-of-models-slides.html#correlation-1",
    "title": "Language of models",
    "section": "Correlation",
    "text": "Correlation\n\nRanges between -1 and 1.\nSame sign as the slope."
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#visualizing-the-model",
    "href": "slides/14-language-of-models-slides.html#visualizing-the-model",
    "title": "Language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model"
  },
  {
    "objectID": "slides/14-language-of-models-slides.html#ae-12-modeling-fish",
    "href": "slides/14-language-of-models-slides.html#ae-12-modeling-fish",
    "title": "Language of models",
    "section": "ae-12-modeling-fish",
    "text": "ae-12-modeling-fish\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-12-modeling-fish.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/00-welcome-199.html#meet-the-prof",
    "href": "slides/00-welcome-199.html#meet-the-prof",
    "title": "Welcome to STA 199",
    "section": "Meet the prof",
    "text": "Meet the prof\n\n\nDr. Mine Çetinkaya-Rundel\nProfessor of the Practice\nOld Chem 213"
  },
  {
    "objectID": "slides/00-welcome-199.html#meet-the-course-team",
    "href": "slides/00-welcome-199.html#meet-the-course-team",
    "title": "Welcome to STA 199",
    "section": "Meet the course team",
    "text": "Meet the course team\n\n\n\nMary Knox (Course coordinator)\nMarie Neubrander (Head TA)\nFederico Arboleda\nJaekyoung Kim\nLynn Kremers\nNetra Mittal\nGrace Rade\nJasmine Wang\nEmily Jensen\nJonathan Lin\nMengqi Liu\n\n\n\nSonya Eason\nDomenic Fenoglio\nSarah Wu\nAvery Hodges\nDavid King\nHyunjin Lee\nKareena Legare\nLiane Ma\nNoah Obuya\nAnmol Sapru\nJohn Zito"
  },
  {
    "objectID": "slides/00-welcome-199.html#meet-each-other",
    "href": "slides/00-welcome-199.html#meet-each-other",
    "title": "Welcome to STA 199",
    "section": "Meet each other!",
    "text": "Meet each other!\n\nPlease share with at least two classmates…\n\nYour name\nYour year\nWhere you’re from\nWhat you did this past summer\nWhat you hope to get out of this course"
  },
  {
    "objectID": "slides/00-welcome-199.html#meet-data-science",
    "href": "slides/00-welcome-199.html#meet-data-science",
    "title": "Welcome to STA 199",
    "section": "Meet data science",
    "text": "Meet data science\n\n\nData science is an exciting discipline that allows you to turn raw data into understanding, insight, and knowledge.\nWe’re going to learn to do this in a tidy way – more on that later!\nThis is a course on introduction to data science, with an emphasis on statistical thinking."
  },
  {
    "objectID": "slides/00-welcome-199.html#application-exercise",
    "href": "slides/00-welcome-199.html#application-exercise",
    "title": "Welcome to STA 199",
    "section": "Application exercise",
    "text": "Application exercise\n\nOr more like demo for today…\n sta199-f24.github.io/ae/ae-00-unvotes.html"
  },
  {
    "objectID": "slides/00-welcome-199.html#data-science-life-cycle-1",
    "href": "slides/00-welcome-199.html#data-science-life-cycle-1",
    "title": "Welcome to STA 199",
    "section": "Data science life cycle",
    "text": "Data science life cycle"
  },
  {
    "objectID": "slides/00-welcome-199.html#collect-birthdays",
    "href": "slides/00-welcome-199.html#collect-birthdays",
    "title": "Welcome to STA 199",
    "section": "Collect birthdays",
    "text": "Collect birthdays\n\n\n\n\n\n\n\n\n\n  \n    −\n    +\n \n 01:00"
  },
  {
    "objectID": "slides/00-welcome-199.html#import",
    "href": "slides/00-welcome-199.html#import",
    "title": "Welcome to STA 199",
    "section": "Import",
    "text": "Import"
  },
  {
    "objectID": "slides/00-welcome-199.html#import-birthdays",
    "href": "slides/00-welcome-199.html#import-birthdays",
    "title": "Welcome to STA 199",
    "section": "Import birthdays",
    "text": "Import birthdays"
  },
  {
    "objectID": "slides/00-welcome-199.html#tidy-transform",
    "href": "slides/00-welcome-199.html#tidy-transform",
    "title": "Welcome to STA 199",
    "section": "Tidy + transform",
    "text": "Tidy + transform"
  },
  {
    "objectID": "slides/00-welcome-199.html#tidy-transform-birthdays",
    "href": "slides/00-welcome-199.html#tidy-transform-birthdays",
    "title": "Welcome to STA 199",
    "section": "Tidy + transform birthdays",
    "text": "Tidy + transform birthdays"
  },
  {
    "objectID": "slides/00-welcome-199.html#visualize",
    "href": "slides/00-welcome-199.html#visualize",
    "title": "Welcome to STA 199",
    "section": "Visualize",
    "text": "Visualize"
  },
  {
    "objectID": "slides/00-welcome-199.html#visualize-birthdays",
    "href": "slides/00-welcome-199.html#visualize-birthdays",
    "title": "Welcome to STA 199",
    "section": "Visualize birthdays",
    "text": "Visualize birthdays"
  },
  {
    "objectID": "slides/00-welcome-199.html#model",
    "href": "slides/00-welcome-199.html#model",
    "title": "Welcome to STA 199",
    "section": "Model",
    "text": "Model"
  },
  {
    "objectID": "slides/00-welcome-199.html#understand",
    "href": "slides/00-welcome-199.html#understand",
    "title": "Welcome to STA 199",
    "section": "Understand",
    "text": "Understand"
  },
  {
    "objectID": "slides/00-welcome-199.html#communicate",
    "href": "slides/00-welcome-199.html#communicate",
    "title": "Welcome to STA 199",
    "section": "Communicate",
    "text": "Communicate"
  },
  {
    "objectID": "slides/00-welcome-199.html#understand-communicate",
    "href": "slides/00-welcome-199.html#understand-communicate",
    "title": "Welcome to STA 199",
    "section": "Understand + communicate",
    "text": "Understand + communicate"
  },
  {
    "objectID": "slides/00-welcome-199.html#program",
    "href": "slides/00-welcome-199.html#program",
    "title": "Welcome to STA 199",
    "section": "Program",
    "text": "Program"
  },
  {
    "objectID": "slides/00-welcome-199.html#homepage",
    "href": "slides/00-welcome-199.html#homepage",
    "title": "Welcome to STA 199",
    "section": "Homepage",
    "text": "Homepage\nhttps://sta199-f24.github.io\n\nAll course materials\nLinks to Canvas, GitHub, RStudio containers, etc."
  },
  {
    "objectID": "slides/00-welcome-199.html#course-toolkit",
    "href": "slides/00-welcome-199.html#course-toolkit",
    "title": "Welcome to STA 199",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta199-f24\n\nRStudio containers: cmgr.oit.duke.edu/containers\n\nCommunication: Ed Discussion\nAssignment submission and feedback: Gradescope"
  },
  {
    "objectID": "slides/00-welcome-199.html#activities",
    "href": "slides/00-welcome-199.html#activities",
    "title": "Welcome to STA 199",
    "section": "Activities",
    "text": "Activities\n\nIntroduce new content and prepare for lectures by watching the videos and completing the readings\nAttend and actively participate in lectures and labs, office hours, team meetings\nPractice applying statistical concepts and computing with application exercises during lecture, graded for attempting\nPut together what you’ve learned to analyze real-world data\n\nLab assignments (7 or 8 throughout semester)\nExams (midterm + final)\nTerm project completed in teams"
  },
  {
    "objectID": "slides/00-welcome-199.html#application-exercises",
    "href": "slides/00-welcome-199.html#application-exercises",
    "title": "Welcome to STA 199",
    "section": "Application exercises",
    "text": "Application exercises\n\nDaily-ish in lecture\n“Graded” for attempt, not accuracy\nPractice Weeks 1 + 2, graded thereafter\nAt least one commit by 2 pm of the day of lecture\nTurn in at least 70% for full credit"
  },
  {
    "objectID": "slides/00-welcome-199.html#labs",
    "href": "slides/00-welcome-199.html#labs",
    "title": "Welcome to STA 199",
    "section": "Labs",
    "text": "Labs\n\nStart in lab session\nComplete at home\nDue within a week\nDiscussion with classmates ok, copying not ok!\nLowest score dropped"
  },
  {
    "objectID": "slides/00-welcome-199.html#exams",
    "href": "slides/00-welcome-199.html#exams",
    "title": "Welcome to STA 199",
    "section": "Exams",
    "text": "Exams\n\nTwo exams, each 20%\n\nMidterm comprised of two parts:\n\nIn-class (Oct 8): 75 minute in-class exam. Closed book, one sheet of notes (“cheat sheet”) – 70% of the grade.\nTake-home (Oct 8 - Oct 11): Follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam – 30% of the grade.\n\n\nFinal in-class only (Dec 12, 9am - 12pm): Closed book, one sheet of notes (“cheat sheet”).\n“Cheat sheet”: No larger than 8 1/2 x 11, both sides, must be prepared by you.\n\n\n\n\n\n\n\nCaution\n\n\n\nExam dates cannot be changed and no make-up exams will be given. If you can’t take the exams on these dates, you should drop this class."
  },
  {
    "objectID": "slides/00-welcome-199.html#project",
    "href": "slides/00-welcome-199.html#project",
    "title": "Welcome to STA 199",
    "section": "Project",
    "text": "Project\n\nDataset of your choice, method of your choice\nTeamwork\nFive milestones, interim deadline throughout semester\nFinal milestone: Presentation (video) and write-up\nPresentations submitted as videos\nPeer review between teams for content, peer evaluation within teams for contribution\nSome lab sessions allocated to project progress\n\n\n\n\n\n\n\nCaution\n\n\n\nProject due date cannot be changed. You must complete the project to pass this class."
  },
  {
    "objectID": "slides/00-welcome-199.html#teams",
    "href": "slides/00-welcome-199.html#teams",
    "title": "Welcome to STA 199",
    "section": "Teams",
    "text": "Teams\n\nAssigned by me\nProject\nPeer evaluation during teamwork and after completion\nExpectations and roles\n\nEveryone is expected to contribute equal effort\n\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/00-welcome-199.html#grading",
    "href": "slides/00-welcome-199.html#grading",
    "title": "Welcome to STA 199",
    "section": "Grading",
    "text": "Grading\n\n\nCategory\nPercentage\n\n\n\nApplication Exercises\n5%\n\n\nLabs\n35%\n\n\nMidterm\n20%\n\n\nFinal\n20%\n\n\nProject\n20%\n\n\n\nNo specific points allocated to attendance, but the application exercise score is implicitly tied to attendance.\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/00-welcome-199.html#support",
    "href": "slides/00-welcome-199.html#support",
    "title": "Welcome to STA 199",
    "section": "Support",
    "text": "Support\n\nHelp from humans:\n\nAttend office hours\nAsk and answer questions on the discussion forum\n\n\nHelp from AI: Use the course chatbot (in Canvas!)\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/00-welcome-199.html#announcements",
    "href": "slides/00-welcome-199.html#announcements",
    "title": "Welcome to STA 199",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Canvas (Announcements tool) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day\nI’ll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/00-welcome-199.html#diversity-inclusion",
    "href": "slides/00-welcome-199.html#diversity-inclusion",
    "title": "Welcome to STA 199",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nFill out the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisors, and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/00-welcome-199.html#accessibility",
    "href": "slides/00-welcome-199.html#accessibility",
    "title": "Welcome to STA 199",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/00-welcome-199.html#late-work-waivers-lecture-recordings-regrades",
    "href": "slides/00-welcome-199.html#late-work-waivers-lecture-recordings-regrades",
    "title": "Welcome to STA 199",
    "section": "Late work, waivers, lecture recordings, regrades…",
    "text": "Late work, waivers, lecture recordings, regrades…\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/00-welcome-199.html#use-of-ai-tools",
    "href": "slides/00-welcome-199.html#use-of-ai-tools",
    "title": "Welcome to STA 199",
    "section": "Use of AI tools",
    "text": "Use of AI tools\n\n\n AI tools for code:\n\nSure, but be careful/critical! Working code != correct/good code.\nMust explicitly cite, with at a minimum AI tool you’re using (e.g., ChatGPT) and your prompt.\n\n\n AI tools for narrative: Absolutely not!\n AI tools for learning: Sure, but be careful/critical!"
  },
  {
    "objectID": "slides/00-welcome-199.html#academic-integrity",
    "href": "slides/00-welcome-199.html#academic-integrity",
    "title": "Welcome to STA 199",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/00-welcome-199.html#this-weeks-tasks",
    "href": "slides/00-welcome-199.html#this-weeks-tasks",
    "title": "Welcome to STA 199",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nComplete Lab 0\n\nComputational setup\nGetting to know you survey\n\n\nRead the syllabus\nComplete readings and videos for next class"
  },
  {
    "objectID": "slides/00-welcome-199.html#midori-says",
    "href": "slides/00-welcome-199.html#midori-says",
    "title": "Welcome to STA 199",
    "section": "Midori says…",
    "text": "Midori says…"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#meet-the-prof",
    "href": "slides/00-welcome-199-slides.html#meet-the-prof",
    "title": "Welcome to STA 199",
    "section": "Meet the prof",
    "text": "Meet the prof\n\n\nDr. Mine Çetinkaya-Rundel\nProfessor of the Practice\nOld Chem 213"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#meet-the-course-team",
    "href": "slides/00-welcome-199-slides.html#meet-the-course-team",
    "title": "Welcome to STA 199",
    "section": "Meet the course team",
    "text": "Meet the course team\n\n\n\nMary Knox (Course coordinator)\nMarie Neubrander (Head TA)\nFederico Arboleda\nJaekyoung Kim\nLynn Kremers\nNetra Mittal\nGrace Rade\nJasmine Wang\nEmily Jensen\nJonathan Lin\nMengqi Liu\n\n\n\nSonya Eason\nDomenic Fenoglio\nSarah Wu\nAvery Hodges\nDavid King\nHyunjin Lee\nKareena Legare\nLiane Ma\nNoah Obuya\nAnmol Sapru\nJohn Zito"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#meet-each-other",
    "href": "slides/00-welcome-199-slides.html#meet-each-other",
    "title": "Welcome to STA 199",
    "section": "Meet each other!",
    "text": "Meet each other!\n\nPlease share with at least two classmates…\n\nYour name\nYour year\nWhere you’re from\nWhat you did this past summer\nWhat you hope to get out of this course\n\n\n\n  \n    −\n    +\n \n 04:00"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#meet-data-science",
    "href": "slides/00-welcome-199-slides.html#meet-data-science",
    "title": "Welcome to STA 199",
    "section": "Meet data science",
    "text": "Meet data science\n\n\nData science is an exciting discipline that allows you to turn raw data into understanding, insight, and knowledge.\nWe’re going to learn to do this in a tidy way – more on that later!\nThis is a course on introduction to data science, with an emphasis on statistical thinking."
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#application-exercise",
    "href": "slides/00-welcome-199-slides.html#application-exercise",
    "title": "Welcome to STA 199",
    "section": "Application exercise",
    "text": "Application exercise\n\nOr more like demo for today…\n sta199-f24.github.io/ae/ae-00-unvotes.html"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#data-science-life-cycle-1",
    "href": "slides/00-welcome-199-slides.html#data-science-life-cycle-1",
    "title": "Welcome to STA 199",
    "section": "Data science life cycle",
    "text": "Data science life cycle"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#collect-birthdays",
    "href": "slides/00-welcome-199-slides.html#collect-birthdays",
    "title": "Welcome to STA 199",
    "section": "Collect birthdays",
    "text": "Collect birthdays\n\n\n\n\n\n\n\n\n  \n    −\n    +\n \n 01:00"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#import",
    "href": "slides/00-welcome-199-slides.html#import",
    "title": "Welcome to STA 199",
    "section": "Import",
    "text": "Import"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#import-birthdays",
    "href": "slides/00-welcome-199-slides.html#import-birthdays",
    "title": "Welcome to STA 199",
    "section": "Import birthdays",
    "text": "Import birthdays"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#tidy-transform",
    "href": "slides/00-welcome-199-slides.html#tidy-transform",
    "title": "Welcome to STA 199",
    "section": "Tidy + transform",
    "text": "Tidy + transform"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#tidy-transform-birthdays",
    "href": "slides/00-welcome-199-slides.html#tidy-transform-birthdays",
    "title": "Welcome to STA 199",
    "section": "Tidy + transform birthdays",
    "text": "Tidy + transform birthdays"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#visualize",
    "href": "slides/00-welcome-199-slides.html#visualize",
    "title": "Welcome to STA 199",
    "section": "Visualize",
    "text": "Visualize"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#visualize-birthdays",
    "href": "slides/00-welcome-199-slides.html#visualize-birthdays",
    "title": "Welcome to STA 199",
    "section": "Visualize birthdays",
    "text": "Visualize birthdays"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#model",
    "href": "slides/00-welcome-199-slides.html#model",
    "title": "Welcome to STA 199",
    "section": "Model",
    "text": "Model"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#understand",
    "href": "slides/00-welcome-199-slides.html#understand",
    "title": "Welcome to STA 199",
    "section": "Understand",
    "text": "Understand"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#communicate",
    "href": "slides/00-welcome-199-slides.html#communicate",
    "title": "Welcome to STA 199",
    "section": "Communicate",
    "text": "Communicate"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#understand-communicate",
    "href": "slides/00-welcome-199-slides.html#understand-communicate",
    "title": "Welcome to STA 199",
    "section": "Understand + communicate",
    "text": "Understand + communicate"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#program",
    "href": "slides/00-welcome-199-slides.html#program",
    "title": "Welcome to STA 199",
    "section": "Program",
    "text": "Program"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#homepage",
    "href": "slides/00-welcome-199-slides.html#homepage",
    "title": "Welcome to STA 199",
    "section": "Homepage",
    "text": "Homepage\nhttps://sta199-f24.github.io\n\nAll course materials\nLinks to Canvas, GitHub, RStudio containers, etc."
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#course-toolkit",
    "href": "slides/00-welcome-199-slides.html#course-toolkit",
    "title": "Welcome to STA 199",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta199-f24\n\nRStudio containers: cmgr.oit.duke.edu/containers\n\nCommunication: Ed Discussion\nAssignment submission and feedback: Gradescope"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#activities",
    "href": "slides/00-welcome-199-slides.html#activities",
    "title": "Welcome to STA 199",
    "section": "Activities",
    "text": "Activities\n\nIntroduce new content and prepare for lectures by watching the videos and completing the readings\nAttend and actively participate in lectures and labs, office hours, team meetings\nPractice applying statistical concepts and computing with application exercises during lecture, graded for attempting\nPut together what you’ve learned to analyze real-world data\n\nLab assignments (7 or 8 throughout semester)\nExams (midterm + final)\nTerm project completed in teams"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#application-exercises",
    "href": "slides/00-welcome-199-slides.html#application-exercises",
    "title": "Welcome to STA 199",
    "section": "Application exercises",
    "text": "Application exercises\n\nDaily-ish in lecture\n“Graded” for attempt, not accuracy\nPractice Weeks 1 + 2, graded thereafter\nAt least one commit by 2 pm of the day of lecture\nTurn in at least 70% for full credit"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#labs",
    "href": "slides/00-welcome-199-slides.html#labs",
    "title": "Welcome to STA 199",
    "section": "Labs",
    "text": "Labs\n\nStart in lab session\nComplete at home\nDue within a week\nDiscussion with classmates ok, copying not ok!\nLowest score dropped"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#exams",
    "href": "slides/00-welcome-199-slides.html#exams",
    "title": "Welcome to STA 199",
    "section": "Exams",
    "text": "Exams\n\nTwo exams, each 20%\n\nMidterm comprised of two parts:\n\nIn-class (Oct 8): 75 minute in-class exam. Closed book, one sheet of notes (“cheat sheet”) – 70% of the grade.\nTake-home (Oct 8 - Oct 11): Follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam – 30% of the grade.\n\n\nFinal in-class only (Dec 12, 9am - 12pm): Closed book, one sheet of notes (“cheat sheet”).\n“Cheat sheet”: No larger than 8 1/2 x 11, both sides, must be prepared by you.\n\n\n\n\n\n\n\nCaution\n\n\nExam dates cannot be changed and no make-up exams will be given. If you can’t take the exams on these dates, you should drop this class."
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#project",
    "href": "slides/00-welcome-199-slides.html#project",
    "title": "Welcome to STA 199",
    "section": "Project",
    "text": "Project\n\nDataset of your choice, method of your choice\nTeamwork\nFive milestones, interim deadline throughout semester\nFinal milestone: Presentation (video) and write-up\nPresentations submitted as videos\nPeer review between teams for content, peer evaluation within teams for contribution\nSome lab sessions allocated to project progress\n\n\n\n\n\n\n\nCaution\n\n\nProject due date cannot be changed. You must complete the project to pass this class."
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#teams",
    "href": "slides/00-welcome-199-slides.html#teams",
    "title": "Welcome to STA 199",
    "section": "Teams",
    "text": "Teams\n\nAssigned by me\nProject\nPeer evaluation during teamwork and after completion\nExpectations and roles\n\nEveryone is expected to contribute equal effort\n\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#grading",
    "href": "slides/00-welcome-199-slides.html#grading",
    "title": "Welcome to STA 199",
    "section": "Grading",
    "text": "Grading\n\n\nCategory\nPercentage\n\n\n\nApplication Exercises\n5%\n\n\nLabs\n35%\n\n\nMidterm\n20%\n\n\nFinal\n20%\n\n\nProject\n20%\n\n\n\nNo specific points allocated to attendance, but the application exercise score is implicitly tied to attendance.\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#support",
    "href": "slides/00-welcome-199-slides.html#support",
    "title": "Welcome to STA 199",
    "section": "Support",
    "text": "Support\n\nHelp from humans:\n\nAttend office hours\nAsk and answer questions on the discussion forum\n\n\nHelp from AI: Use the course chatbot (in Canvas!)\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#announcements",
    "href": "slides/00-welcome-199-slides.html#announcements",
    "title": "Welcome to STA 199",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Canvas (Announcements tool) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day\nI’ll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#diversity-inclusion",
    "href": "slides/00-welcome-199-slides.html#diversity-inclusion",
    "title": "Welcome to STA 199",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nFill out the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisors, and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#accessibility",
    "href": "slides/00-welcome-199-slides.html#accessibility",
    "title": "Welcome to STA 199",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#late-work-waivers-lecture-recordings-regrades",
    "href": "slides/00-welcome-199-slides.html#late-work-waivers-lecture-recordings-regrades",
    "title": "Welcome to STA 199",
    "section": "Late work, waivers, lecture recordings, regrades…",
    "text": "Late work, waivers, lecture recordings, regrades…\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#use-of-ai-tools",
    "href": "slides/00-welcome-199-slides.html#use-of-ai-tools",
    "title": "Welcome to STA 199",
    "section": "Use of AI tools",
    "text": "Use of AI tools\n\n\n AI tools for code:\n\nSure, but be careful/critical! Working code != correct/good code.\nMust explicitly cite, with at a minimum AI tool you’re using (e.g., ChatGPT) and your prompt.\n\n\n AI tools for narrative: Absolutely not!\n AI tools for learning: Sure, but be careful/critical!"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#academic-integrity",
    "href": "slides/00-welcome-199-slides.html#academic-integrity",
    "title": "Welcome to STA 199",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#this-weeks-tasks",
    "href": "slides/00-welcome-199-slides.html#this-weeks-tasks",
    "title": "Welcome to STA 199",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nComplete Lab 0\n\nComputational setup\nGetting to know you survey\n\n\nRead the syllabus\nComplete readings and videos for next class"
  },
  {
    "objectID": "slides/00-welcome-199-slides.html#midori-says",
    "href": "slides/00-welcome-199-slides.html#midori-says",
    "title": "Welcome to STA 199",
    "section": "Midori says…",
    "text": "Midori says…"
  }
]